{
 "cells": [
  {
   "cell_type": "raw",
   "id": "c12c9f65-e52a-4c92-949c-ecb19365f8c0",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"(강의) Dataset\"\n",
    "author: \"신록예찬\"\n",
    "date: \"11/09/2024\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b12d1c-335e-4d49-b792-f179437e81a1",
   "metadata": {},
   "source": [
    "# 2. Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e291f0fe-5bf6-4a4e-863b-7cf3d0025a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall mp2024pkg -y\n",
    "# !pip install git+https://github.com/guebin/mp2024pkg.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "556f84cd-be8b-4d30-98f6-9626fb0da5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets \n",
    "import transformers\n",
    "import torch\n",
    "from mp2024pkg import signature, show\n",
    "from rich import print as rprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eec0b68-38c1-42ae-ad55-35ad7e92298f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\", num_labels=2\n",
    ")\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0cfffb-c22d-4194-acb9-d20ff178ee8e",
   "metadata": {},
   "source": [
    "# 3. Dataset 형식이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "792f5dca-a04b-4fee-81b7-eefe0f3b0e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = datasets.load_dataset('emotion')\n",
    "d = emotion['train'].select(range(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b100a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">emotion<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'train'</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.select</span><span style=\"font-weight: bold\">(</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">range</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">))</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "emotion\u001b[1m[\u001b[0m\u001b[32m'train'\u001b[0m\u001b[1m]\u001b[0m\u001b[1;35m.select\u001b[0m\u001b[1m(\u001b[0m\u001b[1;35mrange\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List Overview:\n",
      "Total items: 4\n",
      "\n",
      "1. list[0]\n",
      "   - Type: dict\n",
      "   - Length: 2\n",
      "   - Values: {'text': 'i didnt feel humiliated', 'label': 0}\n",
      "\n",
      "2. list[1]\n",
      "   - Type: dict\n",
      "   - Length: 2\n",
      "   - Values: {'text': 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake', 'label': 0}\n",
      "\n",
      "3. list[2]\n",
      "   - Type: dict\n",
      "   - Length: 2\n",
      "   - Values: {'text': 'im grabbing a minute to post i feel greedy wrong', 'label': 3}\n",
      "\n",
      "4. list[3]\n",
      "   - Type: dict\n",
      "   - Length: 2\n",
      "   - Values: {'text': 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property', 'label': 2}\n"
     ]
    }
   ],
   "source": [
    "rprint(\"emotion['train'].select(range(4))\")\n",
    "show(d) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dcc5e6-ca3d-4099-8053-588f60af81da",
   "metadata": {},
   "source": [
    "`-` 이때 데이터셋은 아래와 같이 length-$n$ list 구조로 이해하는게 편리하다. \n",
    "\n",
    "- dataset = [example, example, ..., example]\n",
    "- example = {'text': xxx, 'label' = yyy} \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdc641c-45f7-4d5b-84b5-c4e374a75115",
   "metadata": {},
   "source": [
    "`-` 그런데 dataset은 특이하게도 아래의 문법이 동작했었다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9beca12c-7a8e-416e-9cab-eb45759c27ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i didnt feel humiliated',\n",
       " 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
       " 'im grabbing a minute to post i feel greedy wrong',\n",
       " 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f8ddebe-ab69-4e8c-8c7b-bb257b23cee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 3, 2]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5752c25-6014-4131-a462-85cc93277f73",
   "metadata": {},
   "source": [
    "`-` 이러한 결과를 보면 dataset은 마치 dictionary처럼 느껴진다. 실제로 경우에 따라서 dataset을 dictionary처럼 생각해도된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "489de2b1-3565-44ae-ae2d-f580f57b958c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">d.to_dict</span><span style=\"font-weight: bold\">()</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35md.to_dict\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary Overview:\n",
      "Total keys: 2\n",
      "Keys: ['text', 'label']\n",
      "\n",
      "1. dict['text']\n",
      "   - Type: list\n",
      "   - Length: 4\n",
      "   - Values: ['i didnt feel humiliated', 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake', 'im grabbing a minute to post i feel greedy wrong', 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property']\n",
      "2. dict['label']\n",
      "   - Type: list\n",
      "   - Length: 4\n",
      "   - Values: [0, 0, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "rprint(\"d.to_dict()\")\n",
    "show(d.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "390fbe7c-4582-4489-89e5-0f89a036b15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">d.to_dict</span><span style=\"font-weight: bold\">()[</span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35md.to_dict\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\u001b[1m[\u001b[0m\u001b[32m'text'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List Overview:\n",
      "Total items: 4\n",
      "\n",
      "1. list[0]\n",
      "   - Type: str\n",
      "   - Length: 23\n",
      "   - Values: i didnt feel humiliated\n",
      "\n",
      "2. list[1]\n",
      "   - Type: str\n",
      "   - Length: 108\n",
      "   - Values: i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake\n",
      "\n",
      "3. list[2]\n",
      "   - Type: str\n",
      "   - Length: 48\n",
      "   - Values: im grabbing a minute to post i feel greedy wrong\n",
      "\n",
      "4. list[3]\n",
      "   - Type: str\n",
      "   - Length: 92\n",
      "   - Values: i am ever feeling nostalgic about the fireplace i will know that it is still on the property\n"
     ]
    }
   ],
   "source": [
    "rprint(\"d.to_dict()['text']\")\n",
    "show(d.to_dict()['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d68d7f-c11e-4f05-8d78-85eeaf389068",
   "metadata": {},
   "source": [
    "`-` 이때 데이터셋은 아래와 같이 dictionary 구조로 이해하는게 편리하다. \n",
    "\n",
    "- datasets = examples = {'text':[xxx,xxxx,xxxxx, ...], 'label':[yyy,yyyy,yyyyy, ....]} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09b2376-6a26-4d9a-bdf3-c3f63a76e892",
   "metadata": {},
   "source": [
    "`-` 딕셔너리를 데이터프레임과 비슷하게 생각할수도 있었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48172a90-dd2d-4465-af84-b5e096427837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [1, 2, 3, 4], 'b': [2, 3, 4, 5]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct = {'a':[1,2,3,4], 'b':[2,3,4,5]}\n",
    "dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "236620f3-e736-47c1-b12f-340186254aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b\n",
       "0  1  2\n",
       "1  2  3\n",
       "2  3  4\n",
       "3  4  5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36040f02-f788-47d3-9630-7a36fb930f17",
   "metadata": {},
   "source": [
    "`-` 이 개념을 이용하면 `d` 역시 데이터프레임과 비슷하게 이해할수도 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0ac5a5f-7ad4-49e6-9b98-f0ec7bd80faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0                            i didnt feel humiliated      0\n",
       "1  i can go from feeling so hopeless to so damned...      0\n",
       "2   im grabbing a minute to post i feel greedy wrong      3\n",
       "3  i am ever feeling nostalgic about the fireplac...      2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(d.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55a8584e-1c7a-45c0-bba9-9c2296896c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0                            i didnt feel humiliated      0\n",
       "1  i can go from feeling so hopeless to so damned...      0\n",
       "2   im grabbing a minute to post i feel greedy wrong      3\n",
       "3  i am ever feeling nostalgic about the fireplac...      2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a36348b-976f-47f3-9c77-a3c97fabb835",
   "metadata": {},
   "source": [
    "# 4. 쉬운함수들 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e2a330-d6dc-4e52-9527-724d8f53b8a1",
   "metadata": {},
   "source": [
    "## A. `.select()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3815c9d1",
   "metadata": {},
   "source": [
    "`# 예시1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cad35d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 8\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(8))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d4c0c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List Overview:\n",
      "Total items: 2\n",
      "\n",
      "1. list[0]\n",
      "   - Type: dict\n",
      "   - Length: 2\n",
      "   - Values: {'text': 'i didnt feel humiliated', 'label': 0}\n",
      "\n",
      "2. list[1]\n",
      "   - Type: dict\n",
      "   - Length: 2\n",
      "   - Values: {'text': 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake', 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "show(d.select(range(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adaa7e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List Overview:\n",
      "Total items: 2\n",
      "\n",
      "1. list[0]\n",
      "   - Type: dict\n",
      "   - Length: 2\n",
      "   - Values: {'text': 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake', 'label': 0}\n",
      "\n",
      "2. list[1]\n",
      "   - Type: dict\n",
      "   - Length: 2\n",
      "   - Values: {'text': 'im grabbing a minute to post i feel greedy wrong', 'label': 3}\n"
     ]
    }
   ],
   "source": [
    "show(d.select(range(1,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238ef673",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a7e1e6-ca02-4e5c-84aa-d5185e781bbb",
   "metadata": {},
   "source": [
    "## B. `.shuffle()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40de8f4e",
   "metadata": {},
   "source": [
    "`# 예시1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d6051a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48f79ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List Overview:\n",
      "Total items: 4\n",
      "\n",
      "1. list[0]\n",
      "   - Type: dict\n",
      "   - Length: 2\n",
      "   - Values: {'text': 'im grabbing a minute to post i feel greedy wrong', 'label': 3}\n",
      "\n",
      "2. list[1]\n",
      "   - Type: dict\n",
      "   - Length: 2\n",
      "   - Values: {'text': 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property', 'label': 2}\n",
      "\n",
      "3. list[2]\n",
      "   - Type: dict\n",
      "   - Length: 2\n",
      "   - Values: {'text': 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake', 'label': 0}\n",
      "\n",
      "4. list[3]\n",
      "   - Type: dict\n",
      "   - Length: 2\n",
      "   - Values: {'text': 'i didnt feel humiliated', 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "show(d.shuffle())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c5e9a0",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829f53b5-bc1b-4019-a17e-5fa43dee33b6",
   "metadata": {},
   "source": [
    "## C. `.select_columns()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4531c0a",
   "metadata": {},
   "source": [
    "`# 예시1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b331c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6efa6088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.select_columns(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1019e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.select_columns(['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3611e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.select_columns(['text','label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc30c66",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b028a33-bc91-45ca-b01d-6059cc9b73f6",
   "metadata": {},
   "source": [
    "## D. `.set_format()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7403ff98",
   "metadata": {},
   "source": [
    "`# 예시1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "391ef3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f2cbf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.set_format(type='pandas',columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a58eb1fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i didnt feel humiliated',\n",
       " 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
       " 'im grabbing a minute to post i feel greedy wrong',\n",
       " 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5e5d0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    3\n",
       "3    2\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23afdd54",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef47199b",
   "metadata": {},
   "source": [
    "`# 예시2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6d52ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91ff445d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.set_format(type='pandas',columns=['label','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89243dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                              i didnt feel humiliated\n",
       "1    i can go from feeling so hopeless to so damned...\n",
       "2     im grabbing a minute to post i feel greedy wrong\n",
       "3    i am ever feeling nostalgic about the fireplac...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "359cba97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    3\n",
       "3    2\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96b93a8",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cf96d0",
   "metadata": {},
   "source": [
    "`# 예시3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72642405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a20a68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.set_format(type='pt',columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4be706a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i didnt feel humiliated',\n",
       " 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
       " 'im grabbing a minute to post i feel greedy wrong',\n",
       " 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "99fc3634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 3, 2])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7b4f89",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bbf02e",
   "metadata": {},
   "source": [
    "## E. `.reset_format()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d768db",
   "metadata": {},
   "source": [
    "`# 예시1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "399e819b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ae0a498",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.set_format(type='torch',columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d56bcf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i didnt feel humiliated',\n",
       " 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
       " 'im grabbing a minute to post i feel greedy wrong',\n",
       " 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60027ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 3, 2])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e51d55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.reset_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "759c095e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 3, 2]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba450bf7",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f57ffd-c469-4d81-b5e4-e61dca92ff4b",
   "metadata": {},
   "source": [
    "# 5. `.map()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd1221d-2ee9-4823-a874-1ac60fcda4eb",
   "metadata": {},
   "source": [
    "## A. `d.map()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b56b90-8ac6-4742-9e89-4149ac8dfaef",
   "metadata": {},
   "source": [
    "`# 예제1` -- `.map()`에 대한 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d731355-0bc1-475d-b74b-4e7b580f07e0",
   "metadata": {},
   "source": [
    "아래와 같은 Dataset이 있다고 하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a678d8b8-8288-45aa-8a3b-5381d6fa5382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f97800ad-3aef-45e3-96df-d8b553547950",
   "metadata": {},
   "source": [
    "`d.map()`을 이용하여 아래와 같이 변환하라. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2533a239",
   "metadata": {},
   "source": [
    "|데이터|변환전|변환후|\n",
    "|:-|:-|:-|\n",
    "|d[0]|text: str<br/>label: int|text: str<br/>label: int<br/>input_ids: [int,...,int]<br/>attention_mask: [int,...,int]|\n",
    "|d[:1]|text: [str]<br/>label: [int]|text: [str]<br/>label: [int]<br/>input_ids: [[int,...,int]]<br/>attention_mask: [[int,...,int]]|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4710cda3-856f-405c-bc8c-078053c8af12",
   "metadata": {},
   "source": [
    "`(풀이1)` -- `d.map()`을 사용하지 않은 풀이.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452cc6f2-25c7-44e0-8e25-c70e7a13a801",
   "metadata": {},
   "source": [
    "*`d`는 아래와 같은 구조로 이해할 수 있음*\n",
    "\n",
    "- d = [example_1, example_2, example_3, example_4]\n",
    "- example_i = {'text': xxx, 'label' = yyy}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6687e865-f7ac-4524-af49-2dc4a6b3d85e",
   "metadata": {},
   "source": [
    "*리스트화*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8e78611a-4045-4987-b724-7dca2ccf8f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'i didnt feel humiliated', 'label': 0},\n",
       " {'text': 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
       "  'label': 0},\n",
       " {'text': 'im grabbing a minute to post i feel greedy wrong', 'label': 3},\n",
       " {'text': 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property',\n",
       "  'label': 2}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = list(d)\n",
    "lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2645b20d-e865-490e-aba3-a2df1df81ed8",
   "metadata": {},
   "source": [
    "*리스트의 첫 요소에 변환적용*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a2e6cb37-19be-49ce-b3e2-ba98e0902b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i didnt feel humiliated', 'label': 0}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = lst[0]\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "56563884-19fb-48f0-a26c-f2f80e506c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = tokenizer(l['text'])\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f77b24b-f2fd-4258-b84e-83d65e20f7fa",
   "metadata": {},
   "source": [
    "*`l`와 `tokenizer(l['text'])`을 합침*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4f6e3cf0-e602-4f9c-93e3-5657cf762fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [2, 3, 4]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예비학습\n",
    "{'a':[1,2,3], 'b':[4,5,6]} | {'c':[2,3,4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "62846200-d488-435a-9a9e-cd4bd8c54895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary Overview:\n",
      "Total keys: 4\n",
      "Keys: ['text', 'label', 'input_ids', 'attention_mask']\n",
      "\n",
      "1. dict['text']\n",
      "   - Type: str\n",
      "   - Length: 23\n",
      "   - Values: i didnt feel humiliated\n",
      "2. dict['label']\n",
      "   - Type: int\n",
      "   - Values: 0\n",
      "3. dict['input_ids']\n",
      "   - Type: list\n",
      "   - Length: 7\n",
      "   - Values: [101, 1045, 2134, 2102, 2514, 26608, 102]\n",
      "4. dict['attention_mask']\n",
      "   - Type: list\n",
      "   - Length: 7\n",
      "   - Values: [1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "show(l | r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d209ee2-66cf-489c-980e-bc55ea4df156",
   "metadata": {},
   "source": [
    "*반복*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "89eab9c2-cd5b-44a1-a1b8-80bb78209fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_transform(example):\n",
    "    # example = l = {'text': xxx, 'label':yyy} \n",
    "    result = tokenizer(example['text'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b0e5298b-ca71-45f3-845e-eb018ac45619",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst2 = [l | m_transform(l) for l in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "939b3910-43aa-4303-8464-9d0eeda8f90b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = datasets.Dataset.from_list(lst2)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d195536c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i didnt feel humiliated',\n",
       " 'label': 0,\n",
       " 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3c078601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated'],\n",
       " 'label': [0],\n",
       " 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]],\n",
       " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8881e21b-57f8-44ea-8dd4-2501cfb08bc5",
   "metadata": {},
   "source": [
    "`(풀이2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "35381b69-f2e3-451b-bed0-43884425fe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_transform(example):\n",
    "    # example = l = {'text': xxx, 'label':yyy} \n",
    "    rsult = tokenizer(example['text'])\n",
    "    return rsult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "70ecf868-ecd6-467f-a004-f3828f1969f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = d.map(m_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "05d6dfa5-d8d5-48e3-96dc-58c15c435a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i didnt feel humiliated',\n",
       " 'label': 0,\n",
       " 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "302b1c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated'],\n",
       " 'label': [0],\n",
       " 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]],\n",
       " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da06fc64-ba74-4d86-a54e-8896837452ac",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f94f44",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "\n",
    "**`.map()`의 특징**\n",
    "\n",
    "- 특징1: `.map()`은 입력으로 `example = {'text':xxx, 'label':yyy}` 꼴을 가정한다. \n",
    "- 특징2: `.map()`은 변환전 dict와 변환후 dict를 합친다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d881c77e",
   "metadata": {},
   "source": [
    "## B. `dd.map()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a420cf1d",
   "metadata": {},
   "source": [
    "`# 예제1` -- `dd`에도 `.map`을 적용할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3f5d4e",
   "metadata": {},
   "source": [
    "아래와 같은 DatasetDict가 있다고 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "69cec3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = datasets.DatasetDict({\n",
    "    'train':emotion['train'].select(range(4)),\n",
    "    'test':emotion['test'].select(range(4)),\n",
    "})\n",
    "dd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcd3305",
   "metadata": {},
   "source": [
    "`dd.map()`을 이용하여 아래와 같이 변환하라. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e40a1fe",
   "metadata": {},
   "source": [
    "|tr/test|데이터|변환전|변환후|\n",
    "|:-|:-|:-|:-|\n",
    "|train|d[0]|text: str<br/>label: int|text: str<br/>label: int<br/>input_ids: [int,...,int]<br/>attention_mask: [int,...,int]|\n",
    "|train|d[:1]|text: [str]<br/>label: [int]|text: [str]<br/>label: [int]<br/>input_ids: [[int,...,int]]<br/>attention_mask: [[int,...,int]]|\n",
    "|test|d[0]|text: str<br/>label: int|text: str<br/>label: int<br/>input_ids: [int,...,int]<br/>attention_mask: [int,...,int]|\n",
    "|test|d[:1]|text: [str]<br/>label: [int]|text: [str]<br/>label: [int]<br/>input_ids: [[int,...,int]]<br/>attention_mask: [[int,...,int]]|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352d445b",
   "metadata": {},
   "source": [
    "`(풀이)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "298bf6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_transform(example):\n",
    "    # example = {'text': xxx, 'label': yyy} \n",
    "    result = tokenizer(example['text'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "179d4342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.map(m_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e887768f",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c85d53",
   "metadata": {},
   "source": [
    "## C. `d.map(batch=True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897a2341",
   "metadata": {},
   "source": [
    "`# 예제1` -- `d.map(batch=True)`의 이해 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e318dd",
   "metadata": {},
   "source": [
    "아래와 같은 Dataset이 있다고 하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ebfb4fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 8\n",
       "})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(8))\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0e693b",
   "metadata": {},
   "source": [
    "`d.map(batch=True)`을 이용하여 아래와 같이 변환하라. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1b6825",
   "metadata": {},
   "source": [
    "|데이터|변환전|변환후|특이사항|\n",
    "|:-|:-|:-|:-|\n",
    "|d[0]|text: str<br/>label: int|text: str<br/>label: int<br/>input_ids: [int,...,int]<br/>attention_mask: [int,...,int]|변환시 2개의 observation씩 묶어서 패딩|\n",
    "|d[:1]|text: [str]<br/>label: [int]|text: [str]<br/>label: [int]<br/>input_ids: [[int,...,int]]<br/>attention_mask: [[int,...,int]]|변환시 2개의 observation씩 묶어서 패딩|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a063133",
   "metadata": {},
   "source": [
    "`(풀이1)` -- 실패"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d30fcd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_transform(example):\n",
    "    # example = {'text': xxx, 'label': yyy}\n",
    "    result = tokenizer(example['text'],padding=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ab164f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 1205.26 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 8\n",
       "})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = d.map(m_transform)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bbda54ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d2<span style=\"font-weight: bold\">[</span>:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">][</span><span style=\"color: #008000; text-decoration-color: #008000\">'input_ids'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d2\u001b[1m[\u001b[0m:\u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m[\u001b[0m\u001b[32m'input_ids'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List Overview:\n",
      "Total items: 4\n",
      "\n",
      "1. list[0]\n",
      "   - Type: list\n",
      "   - Length: 7\n",
      "   - Values: [101, 1045, 2134, 2102, 2514, 26608, 102]\n",
      "\n",
      "2. list[1]\n",
      "   - Type: list\n",
      "   - Length: 23\n",
      "   - Values: [101, 1045, 2064, 2175, 2013, 3110, 2061, 20625, 2000, 2061, 9636, 17772, 2074, 2013, 2108, 2105, 2619, 2040, 14977, 1998, 2003, 8300, 102]\n",
      "\n",
      "3. list[2]\n",
      "   - Type: list\n",
      "   - Length: 12\n",
      "   - Values: [101, 10047, 9775, 1037, 3371, 2000, 2695, 1045, 2514, 20505, 3308, 102]\n",
      "\n",
      "4. list[3]\n",
      "   - Type: list\n",
      "   - Length: 22\n",
      "   - Values: [101, 1045, 2572, 2412, 3110, 16839, 9080, 12863, 2055, 1996, 13788, 1045, 2097, 2113, 2008, 2009, 2003, 2145, 2006, 1996, 3200, 102]\n"
     ]
    }
   ],
   "source": [
    "rprint(\"d2[:4]['input_ids']\")\n",
    "show(d2[:4]['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf186e7",
   "metadata": {},
   "source": [
    "`(풀이2)` -- 성공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a98f4f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def m_transform(example):\n",
    "#     # example = {'text': xxx, 'label': yyy}\n",
    "#     result = tokenizer(example['text'], padding=True)\n",
    "#     return result\n",
    "\n",
    "def m_transform_batch(example_batch):\n",
    "    #example_batch = {'text': [xxx,xxxx], 'label': [yyy,yyyy]}\n",
    "    result = tokenizer(example_batch['text'], padding=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9638a335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 1426.51 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 8\n",
       "})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = d.map(m_transform_batch,batch_size=2,batched=True)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "54d5e34c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d2<span style=\"font-weight: bold\">[</span>:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">][</span><span style=\"color: #008000; text-decoration-color: #008000\">'input_ids'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d2\u001b[1m[\u001b[0m:\u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m[\u001b[0m\u001b[32m'input_ids'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List Overview:\n",
      "Total items: 4\n",
      "\n",
      "1. list[0]\n",
      "   - Type: list\n",
      "   - Length: 23\n",
      "   - Values: [101, 1045, 2134, 2102, 2514, 26608, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "2. list[1]\n",
      "   - Type: list\n",
      "   - Length: 23\n",
      "   - Values: [101, 1045, 2064, 2175, 2013, 3110, 2061, 20625, 2000, 2061, 9636, 17772, 2074, 2013, 2108, 2105, 2619, 2040, 14977, 1998, 2003, 8300, 102]\n",
      "\n",
      "3. list[2]\n",
      "   - Type: list\n",
      "   - Length: 22\n",
      "   - Values: [101, 10047, 9775, 1037, 3371, 2000, 2695, 1045, 2514, 20505, 3308, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "4. list[3]\n",
      "   - Type: list\n",
      "   - Length: 22\n",
      "   - Values: [101, 1045, 2572, 2412, 3110, 16839, 9080, 12863, 2055, 1996, 13788, 1045, 2097, 2113, 2008, 2009, 2003, 2145, 2006, 1996, 3200, 102]\n"
     ]
    }
   ],
   "source": [
    "rprint(\"d2[:4]['input_ids']\")\n",
    "show(d2[:4]['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163fd06b",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73508d92",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "\n",
    "**`.map(batch=True)`의 특징**\n",
    "\n",
    "- 특징1: `.map(batch=True)`은 입력으로 `example_batch = {'text':[xxx,xxxx,...], 'label':[yyy,yyyy,...]}` 꼴을 가정한다. \n",
    "- 특징2: `example_batch`는 `batch_size` 만큼 데이터가 있다고 생각한다. `\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2d76b7-c94e-4dd4-880c-6c7a112506d7",
   "metadata": {},
   "source": [
    "## D. `d.map()` + 칼럼선택"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba220f7-cecc-494f-9db2-bb7c4e822d81",
   "metadata": {},
   "source": [
    "`# 예제1` -- attention_maks 제외"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2432c987",
   "metadata": {},
   "source": [
    "아래와 같은 Dataset이 있다고 하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b72cf501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d29077c",
   "metadata": {},
   "source": [
    "`d.map()`을 이용하여 아래와 같이 변환하라. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2809d15",
   "metadata": {},
   "source": [
    "|데이터|변환전|변환후|\n",
    "|:-|:-|:-|\n",
    "|d[0]|text: str<br/>label: int|text: str<br/>label: int<br/>input_ids: [int,...,int]<br/>|\n",
    "|d[:1]|text: [str]<br/>label: [int]|text: [str]<br/>label: [int]<br/>input_ids: [[int,...,int]]<br/>|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756adda7-5753-45c8-b196-0ff3c49a8b7c",
   "metadata": {},
   "source": [
    "`(풀이1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4d74d5db-c5a9-4fe8-93e7-5c84a1e0b9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_transform(example):\n",
    "    # example = {'text': xxx, 'label': yyy} \n",
    "    result = tokenizer(example['text'])\n",
    "    del result['attention_mask'] \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "31e947a4-8807-4fdb-a9e9-cfec78c43a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 761.53 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = d.map(m_transform)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7fd3863d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i didnt feel humiliated',\n",
       " 'label': 0,\n",
       " 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102]}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "74dc58f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated'],\n",
       " 'label': [0],\n",
       " 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]]}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5a089e-161a-4ac9-b555-fe26f37585e3",
   "metadata": {},
   "source": [
    "`(풀이2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5bb09314-7ed3-401c-ac6a-6dca3f8fd6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_transform(example):\n",
    "    # example = {'text': xxx, 'label': yyy} \n",
    "    result = tokenizer(example['text'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8e226699-3ce9-41a0-b25c-135220be000b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = d.map(m_transform)\n",
    "d2 = d2.select_columns(['text','label','input_ids'])\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8e568343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i didnt feel humiliated',\n",
       " 'label': 0,\n",
       " 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102]}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c1df592d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated'],\n",
       " 'label': [0],\n",
       " 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]]}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a61636-59b6-467a-b949-26438845fdf5",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011613d3-004b-4fd3-b537-a634748a76df",
   "metadata": {},
   "source": [
    "`# 예제2` -- text 제외"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5336545b",
   "metadata": {},
   "source": [
    "아래와 같은 Dataset이 있다고 하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "24ddbe5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886e2c37",
   "metadata": {},
   "source": [
    "`d.map()`을 이용하여 아래와 같이 변환하라. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feee6857",
   "metadata": {},
   "source": [
    "|데이터|변환전|변환후|\n",
    "|:-|:-|:-|\n",
    "|d[0]|text: str<br/>label: int|label: int<br/>input_ids: [int,...,int]<br/>attention_mask: [int,...,int]|\n",
    "|d[:1]|text: [str]<br/>label: [int]|label: [int]<br/>input_ids: [[int,...,int]]<br/>attention_mask: [[int,...,int]]|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7cefac-c5ce-4f5e-95ac-d571defaef1a",
   "metadata": {},
   "source": [
    "`(풀이1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b55f3ef3-dfbb-481e-937d-99a5f8e7b179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_transform(example):\n",
    "    # example = {'text': xxx, 'label': yyy} \n",
    "    result = tokenizer(example['text'])\n",
    "    del example['text'] \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0141a97c-9706-48df-a89e-3f5006874eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = d.map(m_transform)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "68506d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b6c96a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': [0],\n",
       " 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]],\n",
       " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded258cf-6589-4162-bb9e-c195f24f6a8d",
   "metadata": {},
   "source": [
    "`(풀이2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "18c8e782-95ad-4650-9d44-4703ea9e3cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_transform(example):\n",
    "    # example = {'text': xxx, 'label': yyy} \n",
    "    result = tokenizer(example['text'],padding=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3a7c5065-40b3-4648-b34f-183875856a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = d.map(m_transform)\n",
    "d2.select_columns(['text','label','input_ids'])\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c73903d8-4b03-4492-9c8b-58c3c660fee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i didnt feel humiliated',\n",
       " 'label': 0,\n",
       " 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "642e6ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated'],\n",
       " 'label': [0],\n",
       " 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]],\n",
       " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d9e8cb-d903-46df-bbd6-1117548c2f37",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abf5685",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "\n",
    "**`.map()`에서 컬럼을 제외하려면?**\n",
    "\n",
    "- `del`을 이용한 풀이: 제외하고자 하는 column이 `example`에 있을 경우, `result`에 있을 경우 미묘하게 다름. \n",
    "- `select`를 이용한 풀이: 제외하고자 하는 column이 `example`에 있든지 `result`에 있든지 상관없음. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0783a2-d11f-49b7-8214-184f63303539",
   "metadata": {},
   "source": [
    "## E. `d.map()` + 타입변환 ($\\star$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43a2efd-8830-4a79-9445-58a4f30183cb",
   "metadata": {},
   "source": [
    "`# 예제1` -- `.map()`을 이용한 타입변환은 불가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f44257",
   "metadata": {},
   "source": [
    "아래와 같은 Dataset이 있다고 하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "03c8a9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f52112",
   "metadata": {},
   "source": [
    "`d.map()`을 이용하여 아래와 같이 변환하라. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b789ffc7",
   "metadata": {},
   "source": [
    "|데이터|변환전|변환후|\n",
    "|:-|:-|:-|\n",
    "|d[0]|text: str<br/>label: int|label: int<br/>input_ids: tensor([int,...,int])<br/>attention_mask: tensor([int,...,int])|\n",
    "|d[:1]|text: [str]<br/>label: [int]|label:[int]<br/>input_ids: tensor([[int,...,int]])<br/>attention_mask: tensor([[int,...,int]])|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bb0d7a-0a06-4bbe-9f1b-9c791be951a8",
   "metadata": {},
   "source": [
    "`(풀이1)` -- 실패"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dee19f19-e47a-406a-9287-51462a80220d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_transform(example):\n",
    "    # example = {'text': xxx, 'label': yyy} \n",
    "    result = tokenizer(example['text'])\n",
    "    del example['text']\n",
    "    result['input_ids'] = torch.tensor(result['input_ids'])\n",
    "    result['attention_mask'] = torch.tensor(result['attention_mask'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "be0d15b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = d.map(m_transform)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "63600704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "556dd91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': [0],\n",
       " 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]],\n",
       " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6595b447",
   "metadata": {},
   "source": [
    "`(풀이2)` -- 실패 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "27d09a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_transform(example):\n",
    "    # example = {'text': xxx, 'label': yyy} \n",
    "    result = tokenizer(example['text'], return_tensors='pt')\n",
    "    del example['text']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2d4e74e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = d.map(m_transform)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a9d2ff23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]],\n",
       " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "60e1a75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': [0],\n",
       " 'input_ids': [[[101, 1045, 2134, 2102, 2514, 26608, 102]]],\n",
       " 'attention_mask': [[[1, 1, 1, 1, 1, 1, 1]]]}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787970be",
   "metadata": {},
   "source": [
    "> 더 이상해짐.. 차원까지 이상함.. 차원이 문제가 아니고 형태가 아예 안바뀜.. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b480f05-e183-4857-b039-20b719b14c35",
   "metadata": {},
   "source": [
    "`(풀이3)` -- 성공??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7cbc8ce6-d96a-4ac4-9932-f93679f52830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_transform(example):\n",
    "    # example = {'text': xxx, 'label': yyy} \n",
    "    result = tokenizer(example['text'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "18c6311e-6347-4cc8-b872-083c4de876e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = d.map(m_transform)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c3e61982-68b0-41d8-9883-cf985aebf51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2.set_format(type='pt',columns=['input_ids','attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7de6297d-1f31-4483-a152-14573d868f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  1045,  2134,  2102,  2514, 26608,   102]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0e3f8378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1045,  2134,  2102,  2514, 26608,   102]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3f68c843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [tensor([  101,  1045,  2134,  2102,  2514, 26608,   102]),\n",
       "  tensor([  101,  1045,  2064,  2175,  2013,  3110,  2061, 20625,  2000,  2061,\n",
       "           9636, 17772,  2074,  2013,  2108,  2105,  2619,  2040, 14977,  1998,\n",
       "           2003,  8300,   102])],\n",
       " 'attention_mask': [tensor([1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])]}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[:2] # 희한하게 나오네.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb1e6ae",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234fc386-c94f-4f32-b90c-9a008b03605f",
   "metadata": {},
   "source": [
    "# 6. `.with_transform()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2856682-7db2-47d7-81f8-4a5b3d3ca759",
   "metadata": {},
   "source": [
    "## A. `d.with_transform()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4a0eca",
   "metadata": {},
   "source": [
    "`# 예제1` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0056da13",
   "metadata": {},
   "source": [
    "아래와 같은 Dataset이 있다고 하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c0818d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8544b4",
   "metadata": {},
   "source": [
    "`d.with_transform()`을 이용하여 아래와 같이 변환하라. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3648d223",
   "metadata": {},
   "source": [
    "|데이터|변환전|변환후|\n",
    "|:-|:-|:-|\n",
    "|d[0]|text: str<br/>label: int|text: str<br/>label: int<br/>input_ids: [int,...,int]<br/>attention_mask: [int,...,int]|\n",
    "|d[:1]|text: [str]<br/>label: [int]|text: [str]<br/>label: [int]<br/>input_ids: [[int,...,int]]<br/>attention_mask: [[int,...,int]]|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4726ea37",
   "metadata": {},
   "source": [
    "`(풀이)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "45c3b08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_transform(examples):\n",
    "    result = tokenizer(examples['text'])\n",
    "    result = result | examples\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "af7f249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = d.with_transform(w_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4baa112e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1],\n",
       " 'text': 'i didnt feel humiliated',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d676c144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]], 'text': ['i didnt feel humiliated'], 'label': [0]}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4b8d62",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f3f7dc",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "\n",
    "**`.with_transform()`와 `.map()`의 차이점**\n",
    "\n",
    "1. `.map()`은 입력으로 example꼴을, `.with_transform()`은 입력으로 examples를 기대한다. \n",
    "2. `.map()`은 변환전과 변환후 데이터가 자동으로 합쳐진다. `.with_transform()`은 변환후 데이터만 살아남는다. \n",
    "3. `.map()`은 변환이 실제로 이루어진다. `.with_transform()`은 변환이 실제로 이루어지지 않다가 `d[0]`,`d[:1]` 등이 실행하는 순간 이루어진다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5815a3d-b45a-4c98-9a7a-c1d2e8520972",
   "metadata": {},
   "source": [
    "`# 예제2`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d88d80f",
   "metadata": {},
   "source": [
    "아래와 같은 Dataset이 있다고 하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9f0a7057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f645bc",
   "metadata": {},
   "source": [
    "`d.with_transform()`을 이용하여 아래와 같이 변환하라. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41fa8fa",
   "metadata": {},
   "source": [
    "|데이터|변환전|변환후|\n",
    "|:-|:-|:-|\n",
    "|d[0]|text: str<br/>label: int|text: str<br/>label: int<br/>input_ids: [int,...,int]<br/>|\n",
    "|d[:1]|text: [str]<br/>label: [int]|text: [str]<br/>label: [int]<br/>input_ids: [[int,...,int]]<br/>|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d2bd17",
   "metadata": {},
   "source": [
    "`(풀이)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7cd7a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_transform(examples):\n",
    "    # examples = {'text': [xxx,xxxx,xxxxx], 'label': [yyy,yyyy,yyyyy]} \n",
    "    result = tokenizer(examples['text'])\n",
    "    result = examples | result \n",
    "    del result['attention_mask']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c42361e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = d.with_transform(w_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "961723bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i didnt feel humiliated',\n",
       " 'label': 0,\n",
       " 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102]}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2c773b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated'], 'label': [0], 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]]}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f5fbb7",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95410278",
   "metadata": {},
   "source": [
    "`# 예제3`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174b622f",
   "metadata": {},
   "source": [
    "아래와 같은 Dataset이 있다고 하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ea954eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a952e236",
   "metadata": {},
   "source": [
    "`d.with_transform()`을 이용하여 아래와 같이 변환하라. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19de8489",
   "metadata": {},
   "source": [
    "|데이터|변환전|변환후|\n",
    "|:-|:-|:-|\n",
    "|d[0]|text: str<br/>label: int|label: int<br/>input_ids: [int,...,int]<br/>attention_mask: [int,...,int]|\n",
    "|d[:1]|text: [str]<br/>label: [int]|label: [int]<br/>input_ids: [[int,...,int]]<br/>attention_mask: [[int,...,int]]|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cc6b36",
   "metadata": {},
   "source": [
    "`(풀이)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f7f2c5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_transform(examples):\n",
    "    # examples = {'text': [xxx,xxxx,xxxxx], 'label': [yyy,yyyy,yyyyy]} \n",
    "    result = tokenizer(examples['text'])\n",
    "    result['label'] = examples['label']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9a3a7428",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = d.with_transform(w_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5425f28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1],\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9e6775ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]], 'label': [0]}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461ea4e6",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477a4c4c",
   "metadata": {},
   "source": [
    "`# 예제4`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9407fb8c",
   "metadata": {},
   "source": [
    "아래와 같은 Dataset이 있다고 하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c6e06ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de9ade9",
   "metadata": {},
   "source": [
    "`d.with_transform()`을 이용하여 아래와 같이 변환하라. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa4befd",
   "metadata": {},
   "source": [
    "|데이터|변환전|변환후|\n",
    "|:-|:-|:-|\n",
    "|d[0]|text: str<br/>label: int|label: tensor(int)<br/>input_ids: tensor([int,...,int])<br/>attention_mask: tensor([int,...,int])|\n",
    "|d[:1]|text: [str]<br/>label: [int]|label: tensor([int])<br/>input_ids: tensor([[int,...,int]])<br/>attention_mask: tensor([[int,...,int]])|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8ddd86",
   "metadata": {},
   "source": [
    "`(풀이)` -- 실패"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "21e3fb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_transform(examples):\n",
    "    # examples = {'text': [xxx,xxxx,xxxxx], 'label': [yyy,yyyy,yyyyy]} \n",
    "    result = tokenizer(examples['text'])\n",
    "    result['label'] = torch.tensor(examples['label'])\n",
    "    result['input_ids'] = torch.tensor(result['input_ids'])\n",
    "    result['attention_mask'] = torch.tensor(result['attention_mask'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fcd9452e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = d.with_transform(w_transform)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "69c64726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  1045,  2134,  2102,  2514, 26608,   102]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1]),\n",
       " 'label': tensor(0)}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "464c5021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1045,  2134,  2102,  2514, 26608,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]]), 'label': tensor([0])}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "32e3a43f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 7 at dim 1 (got 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[123], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43md2\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/arrow_dataset.py:2861\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2860\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2861\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/arrow_dataset.py:2846\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2844\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m   2845\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices)\n\u001b[0;32m-> 2846\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[1;32m   2848\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2849\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/formatting/formatting.py:633\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    631\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39mformatter\u001b[38;5;241m.\u001b[39mfeatures)\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/formatting/formatting.py:401\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/formatting/formatting.py:516\u001b[0m, in \u001b[0;36mCustomFormatter.format_batch\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    514\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_batch(pa_table)\n\u001b[1;32m    515\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_features_decoder\u001b[38;5;241m.\u001b[39mdecode_batch(batch)\n\u001b[0;32m--> 516\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[119], line 5\u001b[0m, in \u001b[0;36mw_transform\u001b[0;34m(examples)\u001b[0m\n\u001b[1;32m      3\u001b[0m result \u001b[38;5;241m=\u001b[39m tokenizer(examples[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(examples[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 7 at dim 1 (got 23)"
     ]
    }
   ],
   "source": [
    "d2[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9336005",
   "metadata": {},
   "source": [
    "*에러나는이유*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0511ff91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i didnt feel humiliated',\n",
       " 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[:2]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4d21cfcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102], [101, 1045, 2064, 2175, 2013, 3110, 2061, 20625, 2000, 2061, 9636, 17772, 2074, 2013, 2108, 2105, 2619, 2040, 14977, 1998, 2003, 8300, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = tokenizer(d[:2]['text'])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a31d1a65",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 7 at dim 1 (got 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[126], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 7 at dim 1 (got 23)"
     ]
    }
   ],
   "source": [
    "torch.tensor(result['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e5ba33",
   "metadata": {},
   "source": [
    "- 패딩........."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cec281",
   "metadata": {},
   "source": [
    "`(풀이2)` -- 성공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "830f7b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_transform(examples):\n",
    "    # examples = {'text': [xxx,xxxx,xxxxx], 'label': [yyy,yyyy,yyyyy]} \n",
    "    result = tokenizer(examples['text'],padding=True)\n",
    "    result['label'] = torch.tensor(examples['label'])\n",
    "    result['input_ids'] = torch.tensor(result['input_ids'])\n",
    "    result['attention_mask'] = torch.tensor(result['attention_mask'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e9650694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = d.with_transform(w_transform)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cd8ac5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  1045,  2134,  2102,  2514, 26608,   102]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1]),\n",
       " 'label': tensor(0)}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e92e0568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1045,  2134,  2102,  2514, 26608,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]]), 'label': tensor([0])}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "474db222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1045,  2134,  2102,  2514, 26608,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [  101,  1045,  2064,  2175,  2013,  3110,  2061, 20625,  2000,  2061,\n",
       "          9636, 17772,  2074,  2013,  2108,  2105,  2619,  2040, 14977,  1998,\n",
       "          2003,  8300,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'label': tensor([0, 0])}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23a20fb",
   "metadata": {},
   "source": [
    "`(풀이3)` -- 이것도 성공.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b1aa6b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_transform(examples):\n",
    "    # examples = {'text': [xxx,xxxx,xxxxx], 'label': [yyy,yyyy,yyyyy]} \n",
    "    result = tokenizer(examples['text'],padding=True,return_tensors=\"pt\")\n",
    "    result['label'] = torch.tensor(examples['label'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6fd8f33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = d.with_transform(w_transform)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d87d90b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  1045,  2134,  2102,  2514, 26608,   102]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1]),\n",
       " 'label': tensor(0)}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "958317b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1045,  2134,  2102,  2514, 26608,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]]), 'label': tensor([0])}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5074058a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1045,  2134,  2102,  2514, 26608,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [  101,  1045,  2064,  2175,  2013,  3110,  2061, 20625,  2000,  2061,\n",
       "          9636, 17772,  2074,  2013,  2108,  2105,  2619,  2040, 14977,  1998,\n",
       "          2003,  8300,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'label': tensor([0, 0])}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0887c3a6",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4fed29",
   "metadata": {},
   "source": [
    "## B. `dd.with_transform()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba23b0b",
   "metadata": {},
   "source": [
    "`# 예제1`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78083c2e",
   "metadata": {},
   "source": [
    "아래와 같은 DatasetDict가 있다고 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0112def8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = datasets.DatasetDict({\n",
    "    'train':emotion['train'].select(range(4)),\n",
    "    'test':emotion['test'].select(range(4)),\n",
    "})\n",
    "dd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c8febc",
   "metadata": {},
   "source": [
    "`dd.map()`을 이용하여 아래와 같이 변환하라. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a144b9",
   "metadata": {},
   "source": [
    "|tr/test|데이터|변환전|변환후|\n",
    "|:-|:-|:-|:-|\n",
    "|train|d[0]|text: str<br/>label: int|text: str<br/>label: int<br/>input_ids: [int,...,int]<br/>attention_mask: [int,...,int]|\n",
    "|train|d[:1]|text: [str]<br/>label: [int]|text: [str]<br/>label: [int]<br/>input_ids: [[int,...,int]]<br/>attention_mask: [[int,...,int]]|\n",
    "|test|d[0]|text: str<br/>label: int|text: str<br/>label: int<br/>input_ids: [int,...,int]<br/>attention_mask: [int,...,int]|\n",
    "|test|d[:1]|text: [str]<br/>label: [int]|text: [str]<br/>label: [int]<br/>input_ids: [[int,...,int]]<br/>attention_mask: [[int,...,int]]|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d050d508",
   "metadata": {},
   "source": [
    "`(풀이)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0a9f57d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_transform(examples):\n",
    "    result = tokenizer(examples['text'])\n",
    "    result = examples | result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "74196890",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd2 = dd.with_transform(w_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "83d81081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i didnt feel humiliated',\n",
       " 'label': 0,\n",
       " 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd2['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "75cc441a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated'], 'label': [0], 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd2['train'][:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9192fe1b",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832c028c",
   "metadata": {},
   "source": [
    "## C. `d.reset_format()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2c8ea7",
   "metadata": {},
   "source": [
    "`# 예시1` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "859043c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d9dd00ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_transform(examples):\n",
    "    result = tokenizer(examples['text'])\n",
    "    result = result | examples\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6192129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = d.with_transform(w_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8d3cb28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1],\n",
       " 'text': 'i didnt feel humiliated',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5931e2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]], 'text': ['i didnt feel humiliated'], 'label': [0]}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "fb6baf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2.reset_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6aec5fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i didnt feel humiliated', 'label': 0}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "90995275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated'], 'label': [0]}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a98e9f3",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fb3703",
   "metadata": {},
   "source": [
    "`# 예시1` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5d735152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7820115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_transform(examples):\n",
    "    result = tokenizer(examples['text'])\n",
    "    result = result | examples\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3041c7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = d.with_transform(w_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c6e87bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1],\n",
       " 'text': 'i didnt feel humiliated',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9b1fa62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]], 'text': ['i didnt feel humiliated'], 'label': [0]}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "467fa0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2.set_format(type=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "67876b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i didnt feel humiliated', 'label': tensor(0)}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3d3b06d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated'], 'label': tensor([0])}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9355d2fe",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d12df5",
   "metadata": {},
   "source": [
    "# 7. 미묘한 차이 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45075c9a",
   "metadata": {},
   "source": [
    "`# 예시1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "423d7459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "dfdb899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_transform(example):\n",
    "    # example = {'text': xxx, 'label': yyy} \n",
    "    result = tokenizer(example['text'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5bcb0212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_transform(examples):\n",
    "    # examples = {'text': [xxx,xxxx,xxxxx], 'label': [yyy,yyyy,yyyyy]} \n",
    "    result = tokenizer(examples['text'])\n",
    "    result = examples| result \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "88328b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated'],\n",
       " 'label': tensor([0]),\n",
       " 'input_ids': tensor([[  101,  1045,  2134,  2102,  2514, 26608,   102]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = d.map(m_transform)\n",
    "d2.set_format(type=\"pt\")\n",
    "d2[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6c733fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated'], 'label': [0], 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3 = d.with_transform(w_transform)\n",
    "d3[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "87214562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated'], 'label': tensor([0])}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3.set_format(type=\"pt\")\n",
    "d3[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17977964",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03de5049",
   "metadata": {},
   "source": [
    "`# 예시2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a2814c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = emotion['train'].select(range(4))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b967dde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_transform(example):\n",
    "    # example = {'text': xxx, 'label': yyy} \n",
    "    result = tokenizer(example['text'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ed6d6a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_transform(examples):\n",
    "    # examples = {'text': [xxx,xxxx,xxxxx], 'label': [yyy,yyyy,yyyyy]} \n",
    "    result = tokenizer(examples['text'],return_tensors=\"pt\")\n",
    "    result = result | examples\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f92cd9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = d.map(m_transform)\n",
    "d2.set_format(type=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a52476cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated'],\n",
       " 'label': tensor([0]),\n",
       " 'input_ids': tensor([[  101,  1045,  2134,  2102,  2514, 26608,   102]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "112f77e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated',\n",
       "  'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake'],\n",
       " 'label': tensor([0, 0]),\n",
       " 'input_ids': [tensor([  101,  1045,  2134,  2102,  2514, 26608,   102]),\n",
       "  tensor([  101,  1045,  2064,  2175,  2013,  3110,  2061, 20625,  2000,  2061,\n",
       "           9636, 17772,  2074,  2013,  2108,  2105,  2619,  2040, 14977,  1998,\n",
       "           2003,  8300,   102])],\n",
       " 'attention_mask': [tensor([1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])]}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "90afbd91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1045,  2134,  2102,  2514, 26608,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]]), 'text': ['i didnt feel humiliated'], 'label': [0]}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = d.with_transform(w_transform)\n",
    "d2[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "43ac5c01",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:776\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor(value):\n\u001b[0;32m--> 776\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;66;03m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[39;00m\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;66;03m# # at-least2d\u001b[39;00m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;66;03m# if tensor.ndim > 2:\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor.squeeze(0)\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# elif tensor.ndim < 2:\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor[None, :]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:738\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors.<locals>.as_tensor\u001b[0;34m(value, dtype)\u001b[0m\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39marray(value))\n\u001b[0;32m--> 738\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 7 at dim 1 (got 23)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[171], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43md2\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/arrow_dataset.py:2861\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2860\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2861\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/arrow_dataset.py:2846\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2844\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m   2845\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices)\n\u001b[0;32m-> 2846\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[1;32m   2848\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2849\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/formatting/formatting.py:633\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    631\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39mformatter\u001b[38;5;241m.\u001b[39mfeatures)\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/formatting/formatting.py:401\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/formatting/formatting.py:516\u001b[0m, in \u001b[0;36mCustomFormatter.format_batch\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    514\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_batch(pa_table)\n\u001b[1;32m    515\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_features_decoder\u001b[38;5;241m.\u001b[39mdecode_batch(batch)\n\u001b[0;32m--> 516\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[166], line 3\u001b[0m, in \u001b[0;36mw_transform\u001b[0;34m(examples)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mw_transform\u001b[39m(examples):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# examples = {'text': [xxx,xxxx,xxxxx], 'label': [yyy,yyyy,yyyyy]} \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     result \u001b[38;5;241m=\u001b[39m result \u001b[38;5;241m|\u001b[39m examples\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3021\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3019\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   3020\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 3021\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3023\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3109\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3104\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3105\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match batch length of `text_pair`:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3106\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3107\u001b[0m         )\n\u001b[1;32m   3108\u001b[0m     batch_text_or_text_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[0;32m-> 3109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3111\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3127\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3129\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[1;32m   3132\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m   3133\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3151\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3152\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3311\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3301\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   3302\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   3303\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   3304\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3308\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3309\u001b[0m )\n\u001b[0;32m-> 3311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3313\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3329\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3330\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3331\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/tokenization_utils_fast.py:577\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_ids \u001b[38;5;129;01min\u001b[39;00m sanitized_tokens[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eventual_warn_about_too_long_sequence(input_ids, max_length, verbose)\n\u001b[0;32m--> 577\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatchEncoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43msanitized_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msanitized_encodings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:240\u001b[0m, in \u001b[0;36mBatchEncoding.__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    236\u001b[0m     n_sequences \u001b[38;5;241m=\u001b[39m encoding[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_sequences\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_sequences \u001b[38;5;241m=\u001b[39m n_sequences\n\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:792\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverflowing_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    788\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    789\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor returning overflowing tokens of different lengths. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    790\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease see if a fast version of this tokenizer is available to have this feature available.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    791\u001b[0m             ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m--> 792\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    793\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor, you should probably activate truncation and/or padding with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    794\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpadding=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtruncation=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to have batched tensors with the same length. Perhaps your\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    795\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m features (`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` in this case) have excessive nesting (inputs type `list` where type `int` is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    796\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expected).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    797\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected)."
     ]
    }
   ],
   "source": [
    "d2[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338cfdd6",
   "metadata": {},
   "source": [
    "`#`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
