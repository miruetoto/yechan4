{"title":"(강의) 데이터콜렉터","markdown":{"yaml":{"title":"(강의) 데이터콜렉터","author":"신록예찬","date":"11/16/2024"},"headingText":"1.","containsRefs":false,"markdown":"\n\n\n# 2. Imports\n\n```Python\n#!pip uninstall mp2024pkg -y\n#!pip install git+https://github.com/guebin/mp2024pkg.git\n```\n\n# 3. `data_collator` 이해\n\n## A. 외우세요 $(\\star\\star\\star)$\n\n`-` `data_collator`를 잘 설계하는 방법: `trainer_input`과 `model`이 주어졌을때 `data_collator`는 아래의 코드가 동작하도록 설계하면 된다. \n\n```Python\ntrainer_input = ~~~\nmodel = ~~~~ \nbatch_maker = transformers.Trainer(\n    model = model,\n    data_collator = lambda x: x\n) # 이 과정에서 model이 cuda로 감 \n_batched_data = batch_maker.get_test_dataloader(trainer_input) # 이 과정에서 trainer_input이 cuda로 감\nbatched_data = list(_batched_data)\nsingle_batch = batched_data[0]\nmodel.to(\"cpu\") # 경우에 따라 생략해야할수도있음\nmodel(**data_collator(single_batch))\n````\n\n`-` 위의 코드가 오류없이 실행되었다면 아래의 코드를 사용할 수 있다.\n\n```Python\ntrainer = transformers.Trainer(\n    model = model,\n    data_collator = data_collator\n)\ntrainer.predict(trainer_input)\n```\n\n> 이걸 어떻게 알았냐고요? 코드뜯어봤습니다.. $\\to$ 숙제\n\n:::{.callout-important}\n코랩사용자의 경우 아래와 같이 wandb(Weights & Biases) 로그인을 요구하는 문제가 있습니다. \n```bash\nwandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\nwandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\nwandb: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\nwandb: You can find your API key in your browser here: https://wandb.ai/authorize\nwandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\n```\n이를 해결하기 위해서는 아래의 코드를 코랩처음에 실행하면 됩니다. \n\n```Python\nimport os\nos.environ[\"WANDB_MODE\"] = \"offline\"\n```\n:::\n\n:::{.callout-note}\n\n주의: `data`의 type이 꼭 `Dataset` 일 필요는 없다..\n:::\n\n## B. IMDB -- 복습\n\nref: <https://huggingface.co/docs/transformers/tasks/sequence_classification>\n\n*1. 데이터준비: `\"guebin/imdb-tiny\"` $\\to$ `trainer_input`*\n\n*2. 모델준비: `\"distilbert/distilbert-base-uncased\"` $\\to$`model`*\n\n*3. 데이터콜렉터: `DataCollatorWithPadding()` $\\to$ `data_collator`*\n\n---\n\n데이터콜렉터가 올바로 설정되었는지 체크하고, 적당한 `trainer`를 만들어 \n\n```Python\ntrainer.predict(trainer_input)\n```\n\n이 정상동작하는지 확인하라. \n\n`(풀이)`\n\n- 잘 돌아감..\n- 잘 설계된 data_collator라는 의미\n- 이걸 이용해서 진짜 trainer를 만들자.. \n\n`#`\n\n`-`  관찰1: 여기에서 `batched_data[-1]`은 하나의 배치를 의미, 그런데 모델의 입력으로 사용하기에는 형식이 맞지 않음\n\n`-` 관찰2: 여기에서 `data_collator(batched_data[-1])` 역시 하나의 배치를 의미. 이번에는 형식이 잘 맞음. \n\n:::{.callout-note}\n### `data_collator` -- 심화이해\n\n아래의 형식으로 정리된 배치화된 자료가 있다고 하자. (주의: `batched_data`는 항상 list비슷한 오브젝트이어야함)\n\n```Python\nbatched_data = [batch_1, batch_2, ...,batch_n]\n```\n\n`data_collator` 는 각각의 `single_batch`, 즉 `batch_1`, `batch_2` 등을 `model`이 처리가능한 형태로 \"형식\"을 맞춰주는 역할을 한다. 즉 아래가 실행되도록 만들어주는 역할을 한다. \n\n```Python\nmodel(**data_collator(batch_1))\n```\n:::\n\n:::{.callout-note}\n### `trainer`와 `model`의 자료처리과정 비교\n\n***#. `model`의 자료처리과정*** \n\n-코드: `model.forward(model_input)`\n\n-처리과정: `model_input`에 정리된 입력을 단순히 `model.forward()` 함수가 처리. \n\n***#. `trainer`의 자료처리과정***\n\n-코드: `trainer.predict(trainer_input)`\n\n-처리과정: 크게 배치화 $\\to$ 데이터콜렉팅 $\\to$ 추론 의 과정을 거친다. \n\n1. `trainer_input`을 배치(batch)로 나눈다.\n2.\t각 배치(=`single_batch`)를 `data_collator`를 통해 형식을 맞춘다. \n3.\t형식이 조정된 데이터를 `model.forward`의 입력으로 전달한다. \n\n-슈도코드:\n```Python\n## 이 코드는.. \ntrainer.predict(trainer_input)\n\n## 대략 아래의 느낌으로 해석하면 된다.. (동일X. 결과정리, GPU처리 등 세부로직이 더 있음)\nbatched_data = some_function(trainer_input)\nfor single_batch in batched_data:\n    collated_data = data_collator(single_batch)\n    model(**collated_data)\n```\n\n:::\n\n:::{.callout-note}\n### `trainer.predict()` 의 분해\n\n`trainer.predict()`의 동작은 개념적으로 (1) 배치화 (2) 데이터콜렝팅 (3) 추론의 과정으로 분해할 수 있지만, 실제이러한 과정으로 코드를 정확하게 분리하는건 어렵다. (실제로도 별로 그럴 이유가 없다) 하지만 이해를 위해서 코드조각을 분리할 필요가 있는데 아래의 3개 코드조각은 이러한 분해를 최대한 비슷하게 수동구현한 것이다. \n\n`1`. 배치화: `trainer_input` $\\to$ `batched_data`\n\n```Python\nbatch_maker = transformers.Trainer(\n    model = model,\n    data_collator = lambda x: x\n)\n_batched_data = batch_maker.get_test_dataloader(trainer_input)\nbatched_data = list(_batched_data)\n```\n\n`2`. 데이터콜렉팅: `single_batch` $\\to$ `collated_data`\n\n```Python\n#for single_batch in batched_data:\n    collated_data = data_collator(single_batch)\n```\n\n`3`. 추론: `collated_data` $\\to$ `model_out`\n\n```Python\n#for single_batch in batched_data:\n    #collated_data = data_collator(single_batch)\n    model_out = model(**collated_data)\n```\n\n:::\n\n## C. FOOD101 -- 복습 \n\nref: <https://huggingface.co/docs/transformers/tasks/image_classification>\n\n*1. 데이터준비: `\"guebin/food101-tiny\"` $\\to$ `trainer_input`*\n\n*2. 모델준비: `\"google/vit-base-patch16-224-in21k\"` $\\to$`model`*\n\n*3. 데이터콜렉터: `DefaultDataCollator()` $\\to$ `data_collator`*\n\n---\n\n데이터콜렉터가 올바로 설정되었는지 체크하고, 적당한 `trainer`를 만들어 \n\n```Python\ntrainer.predict(trainer_input)\n```\n\n이 정상동작하는지 확인하라. \n\n`(풀이1)` -- 실패\n\n`-` 왜 실패했지?? (예전에는 분명히 되었던 것 같은뎅..)\n\n:::{.callout-note}\n**<에러메시지의 해석>**\n\n`-` 아래가 동작하지 않음. \n\n```Python\nbatched_data = list(_batched_data)\n```\n\n`-` 그 이유는 아래가 동작하지 않기 때문임. \n\n```Python \nnext(dataloader_iter)\n```\n\n`-` ...(생략)...\n\n`-` 최종적으로는 아래가 동작하지 않기 때문에 생긴 문제였음. (그런데 이건 `.with_transform()`에 있는 코드인데?)\n\n```Python\nexamples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n```\n\n`-` 결국 \n\n```Python\n[_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n```\n\n를 실행하는 시점에서 `examples[\"image\"]`가 없었다는 의미.\n:::\n\n> 눈치: `with_transform`이 지금 실행되는거였어?\n\n`-` 왜 이런일이 생기지? \n\n`-` 배치화를 하는 코드 \n\n```Python\n_batched_data = batch_maker.get_test_dataloader(trainer_input)\n```\n\n에서 아래의 column_names: \n\n- `pixel_values`\n- `head_mask`\n- `labels`\n- `output_attentions`\n- `output_hidden_states`\n- `interpolate_pos_encoding`\n- `return_dict`\n\n를 제외하고는 모두 트레이너(`batch_maker = trainer`)가 강제로 제거하는 로직이 있음.^[왜 이런 로직이 있을까? 이런 로직이 없다면 model의 args를 강제로 외우고 있어야 하니까..]\n\n`-` `image`라는 column_name은 위에 해당되지 않으므로 제거됨. \n\n`-` 그리고 `image` 칼럼이 제거된 이후에 `with_transform` 이 나중에 실행되면서 (지연실행) 문제가 발생. \n\n> 이걸 어떻게 알았냐고요? 코드뜯어봤습니다.. $\\to$ 숙제\n\n:::{.callout-note}\n### 중간정리\n\n`trainer.predict()` 은 (1) 배치화 (2) 데이터콜렉팅 (3) 추론의 과정을 거친다. 그리고 배치화와 데이터콜렉팅 사이에 \"싱글배치\"를 만드는 과정이 있다. \n\n- 세부사항1: 그런데 \"**배치화**\"단계에서 `model.forward()`의 입력으로 사용되지 않는 columns는 지워지는 내부로직이 존재한다. \n- 세부사항2: `trainer_input`에 걸려있는 `.with_transform()`은 \"**배치화**\"이후 싱글배치가 만들어지는 과정에서 실행된다. \n\n\n따라서 `.with_transform()` 에서 특정컬럼의 변화시키는 동작이 약속된 경우, 그 컬럼이 **배치화**의 단계에서 자동제거되어 코드가 돌아가지 않을 수 있는 위험성이 존재한다. \n\n\n:::\n\n`(풀이2)` -- `image`를 `return_dict` 로 위장.. // 완전 테크니컬한 풀이\n\n`-` 현재상황: `food['train']`에 `.with_transform(transforms)`을 걸어두고(?) `trainer_input`을 만든상황 \n\n`-` 문제: `trainer.predict()` 내부동작에서 `.with_transform(transform)` 이 실현될때 \n\n이 내용이 실행되어야하는데, `image`는 model의 입력으로 유하하지 않은 키라서 트레이너가 이미 제거한 상태임.\n\n`-` 전략: 제거가 안되게 막아보자..\n\n- 성공..\n\n`(풀이3)` -- trainer_input 에 예약된 `with_transform`을 지연실행하지 않고 즉시 실행\n\n`(풀이4)` -- 트레이너가 가진 \"사용하지 않는 column을 제거하는 기능\"을 `False` 시킴..\n\n`#`\n\n`(풀이5)` -- 트레이너가 가진 \"사용하지 않는 column을 제거하는 기능\"을 `False` 시킬꺼면, `batch_maker`를 고려할 필요도 없이 아래와 같이 바로 `single_batch`를 얻을 수 있음. \n\n*풀이4: 실제로 trainer가 싱글배치를 얻는 과정과 유사하게 얻는 방법*\n\n> 형식관찰: `single_batch`는 `[Dict, Dict, Dict, .... Dict]` 꼴임을 주목하라.\n\n*풀이5: 형식관찰에 힌트를 얻어 무식하게 얻은 싱글배치*\n\n*아무튼 풀이5 스타일로 싱글배치를 얻었다면? 이후의 코드는 동일*\n\n*참고1: 아래의 방식으로는 싱글배치를 얻을 수 없음*\n\n이유:\n\n*참고2: 아래의 방식으로도 싱글배치를 얻을 수 없음 -- 이유? 지연실행때문에..*\n\n## D. FOOD101 -- DefaultDataCollator 구현\n\n*1. 데이터준비: `\"guebin/food101-tiny\"` $\\to$ `trainer_input`*\n\n*2. 모델준비: `\"google/vit-base-patch16-224-in21k\"` $\\to$`model`*\n\n*3. 데이터콜렉터: `collate_fn` 직접설계*\n\n`DefaultDataCollator()` 와 동일한 역할을 하는 `collate_fn`을 설계하라. 이를 이용하여 적당한 `trainer`를 만들어 \n\n```Python\ntrainer.predict(trainer_input)\n```\n\n이 정상동작하는지 확인하라. \n\n`(풀이)`\n\n- 이대로 `model(**sigle_batch)`를 실행하면 에러가 나겠죠? \n\n---\n\n## E. IMDB -- DataCollatorWithPadding 구현\n\nref: <https://huggingface.co/docs/transformers/tasks/sequence_classification>\n\n*1. 데이터준비: `\"guebin/imdb-tiny\"` $\\to$ `trainer_input`*\n\n*2. 모델준비: `\"distilbert/distilbert-base-uncased\"` $\\to$`model`*\n\n*3. 데이터콜렉터: `collate_fn` 직접설계* \n\n---\n\n`DefaultDataCollator()` 와 동일한 역할을 하는 `collate_fn`을 설계하라. 이를 이용하여 적당한 `trainer`를 만들어 \n\n```Python\ntrainer.predict(trainer_input)\n```\n\n이 정상동작하는지 확인하라. \n\n`(풀이)`\n\n# 4. 연습 -- `sms_spam`\n\n## A. 방법1: 고정패딩, `collate_fn`\n\n- 이때 `input_ids`, `attention_mask`는 매트릭스 O\n\n- 이때 `input_ids`, `attention_mask`는 매트릭스 X\n\n- 이때 `input_ids`, `attention_mask`는 매트릭스 O\n\n## B. 방법2: 고정패딩, DefaultDataCollator\n\n`-` 방법1과 거의 동일 \n\n## C. 방법3: 동적패딩, `DataCollatorWithPadding`\n\n## D. 방법4: 동적패딩, 전처리X $(\\star)$\n","srcMarkdownNoYaml":"\n\n# 1. \n\n# 2. Imports\n\n```Python\n#!pip uninstall mp2024pkg -y\n#!pip install git+https://github.com/guebin/mp2024pkg.git\n```\n\n# 3. `data_collator` 이해\n\n## A. 외우세요 $(\\star\\star\\star)$\n\n`-` `data_collator`를 잘 설계하는 방법: `trainer_input`과 `model`이 주어졌을때 `data_collator`는 아래의 코드가 동작하도록 설계하면 된다. \n\n```Python\ntrainer_input = ~~~\nmodel = ~~~~ \nbatch_maker = transformers.Trainer(\n    model = model,\n    data_collator = lambda x: x\n) # 이 과정에서 model이 cuda로 감 \n_batched_data = batch_maker.get_test_dataloader(trainer_input) # 이 과정에서 trainer_input이 cuda로 감\nbatched_data = list(_batched_data)\nsingle_batch = batched_data[0]\nmodel.to(\"cpu\") # 경우에 따라 생략해야할수도있음\nmodel(**data_collator(single_batch))\n````\n\n`-` 위의 코드가 오류없이 실행되었다면 아래의 코드를 사용할 수 있다.\n\n```Python\ntrainer = transformers.Trainer(\n    model = model,\n    data_collator = data_collator\n)\ntrainer.predict(trainer_input)\n```\n\n> 이걸 어떻게 알았냐고요? 코드뜯어봤습니다.. $\\to$ 숙제\n\n:::{.callout-important}\n코랩사용자의 경우 아래와 같이 wandb(Weights & Biases) 로그인을 요구하는 문제가 있습니다. \n```bash\nwandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\nwandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\nwandb: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\nwandb: You can find your API key in your browser here: https://wandb.ai/authorize\nwandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\n```\n이를 해결하기 위해서는 아래의 코드를 코랩처음에 실행하면 됩니다. \n\n```Python\nimport os\nos.environ[\"WANDB_MODE\"] = \"offline\"\n```\n:::\n\n:::{.callout-note}\n\n주의: `data`의 type이 꼭 `Dataset` 일 필요는 없다..\n:::\n\n## B. IMDB -- 복습\n\nref: <https://huggingface.co/docs/transformers/tasks/sequence_classification>\n\n*1. 데이터준비: `\"guebin/imdb-tiny\"` $\\to$ `trainer_input`*\n\n*2. 모델준비: `\"distilbert/distilbert-base-uncased\"` $\\to$`model`*\n\n*3. 데이터콜렉터: `DataCollatorWithPadding()` $\\to$ `data_collator`*\n\n---\n\n데이터콜렉터가 올바로 설정되었는지 체크하고, 적당한 `trainer`를 만들어 \n\n```Python\ntrainer.predict(trainer_input)\n```\n\n이 정상동작하는지 확인하라. \n\n`(풀이)`\n\n- 잘 돌아감..\n- 잘 설계된 data_collator라는 의미\n- 이걸 이용해서 진짜 trainer를 만들자.. \n\n`#`\n\n`-`  관찰1: 여기에서 `batched_data[-1]`은 하나의 배치를 의미, 그런데 모델의 입력으로 사용하기에는 형식이 맞지 않음\n\n`-` 관찰2: 여기에서 `data_collator(batched_data[-1])` 역시 하나의 배치를 의미. 이번에는 형식이 잘 맞음. \n\n:::{.callout-note}\n### `data_collator` -- 심화이해\n\n아래의 형식으로 정리된 배치화된 자료가 있다고 하자. (주의: `batched_data`는 항상 list비슷한 오브젝트이어야함)\n\n```Python\nbatched_data = [batch_1, batch_2, ...,batch_n]\n```\n\n`data_collator` 는 각각의 `single_batch`, 즉 `batch_1`, `batch_2` 등을 `model`이 처리가능한 형태로 \"형식\"을 맞춰주는 역할을 한다. 즉 아래가 실행되도록 만들어주는 역할을 한다. \n\n```Python\nmodel(**data_collator(batch_1))\n```\n:::\n\n:::{.callout-note}\n### `trainer`와 `model`의 자료처리과정 비교\n\n***#. `model`의 자료처리과정*** \n\n-코드: `model.forward(model_input)`\n\n-처리과정: `model_input`에 정리된 입력을 단순히 `model.forward()` 함수가 처리. \n\n***#. `trainer`의 자료처리과정***\n\n-코드: `trainer.predict(trainer_input)`\n\n-처리과정: 크게 배치화 $\\to$ 데이터콜렉팅 $\\to$ 추론 의 과정을 거친다. \n\n1. `trainer_input`을 배치(batch)로 나눈다.\n2.\t각 배치(=`single_batch`)를 `data_collator`를 통해 형식을 맞춘다. \n3.\t형식이 조정된 데이터를 `model.forward`의 입력으로 전달한다. \n\n-슈도코드:\n```Python\n## 이 코드는.. \ntrainer.predict(trainer_input)\n\n## 대략 아래의 느낌으로 해석하면 된다.. (동일X. 결과정리, GPU처리 등 세부로직이 더 있음)\nbatched_data = some_function(trainer_input)\nfor single_batch in batched_data:\n    collated_data = data_collator(single_batch)\n    model(**collated_data)\n```\n\n:::\n\n:::{.callout-note}\n### `trainer.predict()` 의 분해\n\n`trainer.predict()`의 동작은 개념적으로 (1) 배치화 (2) 데이터콜렝팅 (3) 추론의 과정으로 분해할 수 있지만, 실제이러한 과정으로 코드를 정확하게 분리하는건 어렵다. (실제로도 별로 그럴 이유가 없다) 하지만 이해를 위해서 코드조각을 분리할 필요가 있는데 아래의 3개 코드조각은 이러한 분해를 최대한 비슷하게 수동구현한 것이다. \n\n`1`. 배치화: `trainer_input` $\\to$ `batched_data`\n\n```Python\nbatch_maker = transformers.Trainer(\n    model = model,\n    data_collator = lambda x: x\n)\n_batched_data = batch_maker.get_test_dataloader(trainer_input)\nbatched_data = list(_batched_data)\n```\n\n`2`. 데이터콜렉팅: `single_batch` $\\to$ `collated_data`\n\n```Python\n#for single_batch in batched_data:\n    collated_data = data_collator(single_batch)\n```\n\n`3`. 추론: `collated_data` $\\to$ `model_out`\n\n```Python\n#for single_batch in batched_data:\n    #collated_data = data_collator(single_batch)\n    model_out = model(**collated_data)\n```\n\n:::\n\n## C. FOOD101 -- 복습 \n\nref: <https://huggingface.co/docs/transformers/tasks/image_classification>\n\n*1. 데이터준비: `\"guebin/food101-tiny\"` $\\to$ `trainer_input`*\n\n*2. 모델준비: `\"google/vit-base-patch16-224-in21k\"` $\\to$`model`*\n\n*3. 데이터콜렉터: `DefaultDataCollator()` $\\to$ `data_collator`*\n\n---\n\n데이터콜렉터가 올바로 설정되었는지 체크하고, 적당한 `trainer`를 만들어 \n\n```Python\ntrainer.predict(trainer_input)\n```\n\n이 정상동작하는지 확인하라. \n\n`(풀이1)` -- 실패\n\n`-` 왜 실패했지?? (예전에는 분명히 되었던 것 같은뎅..)\n\n:::{.callout-note}\n**<에러메시지의 해석>**\n\n`-` 아래가 동작하지 않음. \n\n```Python\nbatched_data = list(_batched_data)\n```\n\n`-` 그 이유는 아래가 동작하지 않기 때문임. \n\n```Python \nnext(dataloader_iter)\n```\n\n`-` ...(생략)...\n\n`-` 최종적으로는 아래가 동작하지 않기 때문에 생긴 문제였음. (그런데 이건 `.with_transform()`에 있는 코드인데?)\n\n```Python\nexamples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n```\n\n`-` 결국 \n\n```Python\n[_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n```\n\n를 실행하는 시점에서 `examples[\"image\"]`가 없었다는 의미.\n:::\n\n> 눈치: `with_transform`이 지금 실행되는거였어?\n\n`-` 왜 이런일이 생기지? \n\n`-` 배치화를 하는 코드 \n\n```Python\n_batched_data = batch_maker.get_test_dataloader(trainer_input)\n```\n\n에서 아래의 column_names: \n\n- `pixel_values`\n- `head_mask`\n- `labels`\n- `output_attentions`\n- `output_hidden_states`\n- `interpolate_pos_encoding`\n- `return_dict`\n\n를 제외하고는 모두 트레이너(`batch_maker = trainer`)가 강제로 제거하는 로직이 있음.^[왜 이런 로직이 있을까? 이런 로직이 없다면 model의 args를 강제로 외우고 있어야 하니까..]\n\n`-` `image`라는 column_name은 위에 해당되지 않으므로 제거됨. \n\n`-` 그리고 `image` 칼럼이 제거된 이후에 `with_transform` 이 나중에 실행되면서 (지연실행) 문제가 발생. \n\n> 이걸 어떻게 알았냐고요? 코드뜯어봤습니다.. $\\to$ 숙제\n\n:::{.callout-note}\n### 중간정리\n\n`trainer.predict()` 은 (1) 배치화 (2) 데이터콜렉팅 (3) 추론의 과정을 거친다. 그리고 배치화와 데이터콜렉팅 사이에 \"싱글배치\"를 만드는 과정이 있다. \n\n- 세부사항1: 그런데 \"**배치화**\"단계에서 `model.forward()`의 입력으로 사용되지 않는 columns는 지워지는 내부로직이 존재한다. \n- 세부사항2: `trainer_input`에 걸려있는 `.with_transform()`은 \"**배치화**\"이후 싱글배치가 만들어지는 과정에서 실행된다. \n\n\n따라서 `.with_transform()` 에서 특정컬럼의 변화시키는 동작이 약속된 경우, 그 컬럼이 **배치화**의 단계에서 자동제거되어 코드가 돌아가지 않을 수 있는 위험성이 존재한다. \n\n\n:::\n\n`(풀이2)` -- `image`를 `return_dict` 로 위장.. // 완전 테크니컬한 풀이\n\n`-` 현재상황: `food['train']`에 `.with_transform(transforms)`을 걸어두고(?) `trainer_input`을 만든상황 \n\n`-` 문제: `trainer.predict()` 내부동작에서 `.with_transform(transform)` 이 실현될때 \n\n이 내용이 실행되어야하는데, `image`는 model의 입력으로 유하하지 않은 키라서 트레이너가 이미 제거한 상태임.\n\n`-` 전략: 제거가 안되게 막아보자..\n\n- 성공..\n\n`(풀이3)` -- trainer_input 에 예약된 `with_transform`을 지연실행하지 않고 즉시 실행\n\n`(풀이4)` -- 트레이너가 가진 \"사용하지 않는 column을 제거하는 기능\"을 `False` 시킴..\n\n`#`\n\n`(풀이5)` -- 트레이너가 가진 \"사용하지 않는 column을 제거하는 기능\"을 `False` 시킬꺼면, `batch_maker`를 고려할 필요도 없이 아래와 같이 바로 `single_batch`를 얻을 수 있음. \n\n*풀이4: 실제로 trainer가 싱글배치를 얻는 과정과 유사하게 얻는 방법*\n\n> 형식관찰: `single_batch`는 `[Dict, Dict, Dict, .... Dict]` 꼴임을 주목하라.\n\n*풀이5: 형식관찰에 힌트를 얻어 무식하게 얻은 싱글배치*\n\n*아무튼 풀이5 스타일로 싱글배치를 얻었다면? 이후의 코드는 동일*\n\n*참고1: 아래의 방식으로는 싱글배치를 얻을 수 없음*\n\n이유:\n\n*참고2: 아래의 방식으로도 싱글배치를 얻을 수 없음 -- 이유? 지연실행때문에..*\n\n## D. FOOD101 -- DefaultDataCollator 구현\n\n*1. 데이터준비: `\"guebin/food101-tiny\"` $\\to$ `trainer_input`*\n\n*2. 모델준비: `\"google/vit-base-patch16-224-in21k\"` $\\to$`model`*\n\n*3. 데이터콜렉터: `collate_fn` 직접설계*\n\n`DefaultDataCollator()` 와 동일한 역할을 하는 `collate_fn`을 설계하라. 이를 이용하여 적당한 `trainer`를 만들어 \n\n```Python\ntrainer.predict(trainer_input)\n```\n\n이 정상동작하는지 확인하라. \n\n`(풀이)`\n\n- 이대로 `model(**sigle_batch)`를 실행하면 에러가 나겠죠? \n\n---\n\n## E. IMDB -- DataCollatorWithPadding 구현\n\nref: <https://huggingface.co/docs/transformers/tasks/sequence_classification>\n\n*1. 데이터준비: `\"guebin/imdb-tiny\"` $\\to$ `trainer_input`*\n\n*2. 모델준비: `\"distilbert/distilbert-base-uncased\"` $\\to$`model`*\n\n*3. 데이터콜렉터: `collate_fn` 직접설계* \n\n---\n\n`DefaultDataCollator()` 와 동일한 역할을 하는 `collate_fn`을 설계하라. 이를 이용하여 적당한 `trainer`를 만들어 \n\n```Python\ntrainer.predict(trainer_input)\n```\n\n이 정상동작하는지 확인하라. \n\n`(풀이)`\n\n# 4. 연습 -- `sms_spam`\n\n## A. 방법1: 고정패딩, `collate_fn`\n\n- 이때 `input_ids`, `attention_mask`는 매트릭스 O\n\n- 이때 `input_ids`, `attention_mask`는 매트릭스 X\n\n- 이때 `input_ids`, `attention_mask`는 매트릭스 O\n\n## B. 방법2: 고정패딩, DefaultDataCollator\n\n`-` 방법1과 거의 동일 \n\n## C. 방법3: 동적패딩, `DataCollatorWithPadding`\n\n## D. 방법4: 동적패딩, 전처리X $(\\star)$\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"reference-location":"margin","toc":true,"output-file":"2024-11-16-(강의) 데이터콜렉터.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.520","theme":"cosmo","title-block-banner":false,"comments":{"utterances":{"repo":"miruetoto/yechan3"}},"bibliography":["../ref.bib"],"cap-location":"bottom","citation-location":"margin","code-copy":true,"title":"(강의) 데이터콜렉터","author":"신록예찬","date":"11/16/2024"},"extensions":{"book":{"multiFile":true}}},"ipynb":{"identifier":{"display-name":"Jupyter","target-format":"ipynb","base-format":"ipynb"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"png","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"ipynb","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"default-image-extension":"png","to":"ipynb","reference-location":"margin","output-file":"2024-11-16-(강의) 데이터콜렉터.ipynb"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"title-block-banner":false,"comments":{"utterances":{"repo":"miruetoto/yechan3"}},"bibliography":["../ref.bib"],"cap-location":"bottom","citation-location":"margin","title":"(강의) 데이터콜렉터","author":"신록예찬","date":"11/16/2024"}}},"projectFormats":["html"]}