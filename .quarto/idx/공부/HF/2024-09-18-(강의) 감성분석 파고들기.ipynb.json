{"title":"(강의) 감성분석 파고들기","markdown":{"yaml":{"title":"(강의) 감성분석 파고들기","author":"신록예찬","date":"09/18/2024"},"headingText":"1. Imports","containsRefs":false,"markdown":"\n\n\n# 2. 이전코드\n\n`-` Step1~4를 위한 준비\n\n`-` Step 1~4\n\n# 3. DataSet\n\n`-` 가장 중요한 원초적 질문: 데이터 셋을 바꿔치기 하려면? \n\n`-` 내가 원하는 데이터를 아래와 같은 형태로 정리가능해야함. \n\n`-` `datasets.arrow_dataset.Dataset` 의 인스턴스 만들기 \n\n아래와 같은 함수가 있음 \n\n이 함수를 쓰는 방법?\n\n### $\\star$ `datasets.Dataset.from_dict` 사용법\n\n`datasets.Dataset.from_dict`는 Python의 딕셔너리(`dict`)를 `Dataset` 객체로 변환하는 함수입니다. 주로 딕셔너리 형태의 데이터를 빠르게 데이터셋으로 변환할 때 사용됩니다.\n\n**간단한 사용법**\n\n```python\nfrom datasets import Dataset\n\n# 딕셔너리를 Dataset으로 변환\ndata_dict = {\n    'text': [\"Hello world\", \"How are you?\", \"Fine, thanks!\"],\n    'label': [0, 1, 1]\n}\n\n# Dataset 생성\ndataset = Dataset.from_dict(data_dict)\n\n# 출력\nprint(dataset)\n```\n\n**주요 매개변수:**\n- `mapping`: 필수, 문자열을 키로 하고 리스트 또는 배열을 값으로 하는 딕셔너리.\n- `features`: 선택, 데이터셋의 각 필드 타입을 정의.\n- `info`: 선택, 데이터셋에 대한 추가 정보(설명, 인용 등).\n- `split`: 선택, 데이터셋의 나누기('train', 'test' 등).\n\n**반환값:**\n- `Dataset`: PyArrow 기반의 데이터셋 객체.\n\n`-` `datasets.dataset_dict.DatasetDict`의 인스턴스 만들기 \n\n`-` 일단 아래와 같은 형태로 분석할 데이터를 정리할 수만 있다면, 나머지는 코드를 복붙해서 일단 돌릴 수 있음. \n\n```Python\ntrain_dict = {\n    'text': [\n        \"I prefer making decisions based on logic and objective facts.\",\n        \"I always consider how others might feel when making a decision.\",\n        \"Data and analysis drive most of my decisions.\",\n        \"I rely on my empathy and personal values to guide my choices.\"\n    ],\n    'label': [0, 1, 0, 1]  # 0은 T(사고형), 1은 F(감정형)\n}\n\ntest_dict = {\n    'text': [\n        \"I find it important to weigh all the pros and cons logically.\",\n        \"When making decisions, I prioritize harmony and people's emotions.\"\n    ],\n    'label': [0, 1]  # 0은 T(사고형), 1은 F(감정형)\n}\n\n```\n\n# 4. 토크나이저\n\n`-` 기본적인 사용방법\n\n::: {.callout-note}\n\n### $\\star$ `토크나이저` 사용법 (ref: ChatGPT)\n\n**주요 파라미터**:\n\n1. **text**: \n   - `Union[str, List[str], List[List[str]]]`\n   - 주어진 텍스트를 토큰화합니다. 이 텍스트는 문자열일 수도 있고, 문자열의 리스트 또는 리스트 안의 리스트일 수도 있습니다.\n\n2. **text_pair**: \n   - `Union[str, List[str], List[List[str]], NoneType]`\n   - 두 개의 텍스트를 함께 모델에 입력할 때 사용됩니다. 예를 들어, 질문-답변 쌍 같은 경우 이 두 번째 텍스트를 넣습니다.\n\n3. **text_target**: \n   - `Union[str, List[str], List[List[str]]]`\n   - 토큰화를 할 때 목표(target) 텍스트에 해당하는 부분입니다. 주로 시퀀스 생성 모델에서 활용됩니다.\n\n4. **text_pair_target**: \n   - `Union[str, List[str], List[List[str]], NoneType]`\n   - 위의 `text_pair`와 유사하게 목표(target) 텍스트의 두 번째 텍스트를 나타냅니다.\n\n5. **add_special_tokens**: \n   - `bool`\n   - 문장의 시작, 끝, 구분자 같은 특별한 토큰을 추가할지 여부를 결정합니다. 기본값은 `True`입니다.\n\n6. **padding**: \n   - `Union[bool, str, transformers.utils.generic.PaddingStrategy]`\n   - 문장 길이가 다를 때 패딩을 넣어 문장의 길이를 동일하게 맞춥니다. 패딩 전략에는 `True`, `False`, `'longest'`, `'max_length'` 등이 있습니다.\n\n7. **truncation**: \n   - `Union[bool, str, transformers.tokenization_utils_base.TruncationStrategy]`\n   - 문장이 너무 길 경우 지정된 최대 길이에 맞춰 잘라내는 옵션입니다. 전략에는 `True`, `False`, `'longest_first'`, `'only_first'`, `'only_second'` 등이 있습니다.\n\n8. **max_length**: \n   - `Optional[int]`\n   - 문장의 최대 길이를 설정합니다. `None`일 경우 기본 설정을 따릅니다.\n\n9. **stride**: \n   - `int`\n   - 텍스트를 자를 때 중첩을 만들기 위한 옵션입니다. 즉, 자른 부분과 다음 부분 사이의 겹치는 범위를 설정합니다.\n\n10. **is_split_into_words**: \n    - `bool`\n    - 텍스트가 이미 단어 단위로 분리되어 있는지 여부를 나타냅니다. 기본적으로는 `False`로, 텍스트가 단어 단위로 분리되지 않았다고 가정합니다.\n\n11. **return_tensors**: \n    - `Union[str, transformers.utils.generic.TensorType, NoneType]`\n    - 출력 형식으로 텐서를 반환할지 여부를 설정합니다. `'pt'`(PyTorch), `'tf'`(TensorFlow), `'np'`(NumPy) 등을 지정할 수 있습니다.\n\n12. **return_token_type_ids**: \n    - `Optional[bool]`\n    - 토큰 타입 ID를 반환할지 여부를 설정합니다. 주로 두 개의 문장을 함께 처리할 때 문장을 구분하기 위해 사용됩니다.\n\n13. **return_attention_mask**: \n    - `Optional[bool]`\n    - `attention_mask`를 반환할지 여부를 설정합니다. 패딩된 토큰이 모델의 어텐션에 영향을 주지 않도록 마스크를 설정합니다.\n\n14. **return_overflowing_tokens**: \n    - `bool`\n    - 텍스트가 최대 길이를 초과하는 경우, 잘린 토큰을 반환할지 여부를 결정합니다.\n\n15. **return_special_tokens_mask**: \n    - `bool`\n    - 특별한 토큰에 대한 마스크를 반환할지 여부를 설정합니다.\n\n16. **return_offsets_mapping**: \n    - `bool`\n    - 텍스트의 각 토큰이 원본 텍스트에서 어느 위치에 있는지 나타내는 오프셋 맵핑을 반환할지 여부를 설정합니다.\n\n17. **return_length**: \n    - `bool`\n    - 토큰화된 문장의 길이를 반환할지 여부를 설정합니다.\n\n18. **verbose**: \n    - `bool`\n    - 디버깅 메시지를 출력할지 여부를 설정합니다. 기본값은 `True`로 설정되어 있습니다.\n\n**사용 예시**:\n\n```python\nfrom transformers import AutoTokenizer\n\n# 토크나이저 불러오기\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n\n# 텍스트 토큰화\nencoding = tokenizer(\n    text=\"Hello, how are you?\",\n    padding=True,\n    truncation=True,\n    max_length=10,\n    return_tensors='pt'\n)\n\nprint(encoding)\n```\n\n이 코드에서는 \"Hello, how are you?\"라는 텍스트를 `bert-base-uncased` 토크나이저로 토큰화하고, 패딩과 트렁케이션을 적용하며, PyTorch 텐서 형식으로 반환하도록 설정했습니다.\n\n이러한 파라미터는 주로 자연어 처리(NLP) 모델을 훈련하거나 추론할 때 데이터 전처리 과정에서 많이 사용됩니다.\n:::\n\n`-` 기본사용1: 단어별로 다른숫자를 맵핑 + 처음과 끝은 항상 `101`, `102`\n\n`-` 기본사용2: 텍스트 혹은 텍스트의 리스트, 리스트의 리스트를 전달가능 \n\n`-` `truncation=True` 의 역할 \n\n`-` maxlen, padding, attention_mask\n\n# 5. 인공지능 ($\\star$)\n\n## A. 1단계\n\n> 인공지능에 대한 이해\n\n`-` 인공지능 불러오기 \n\n`-` 인공지능의 정체? 엄청나게 많은 숫자들이 포함된 어떠한 물체 (엄청나게 많은 파라메터들이 포함된 네트워크)\n\n`-` 인공지능? \"입력정보 -> 정리된숫자 -> 계산 -> 계산된숫자 -> 출력정보\" 의 과정에서 \"계산\"을 담당\n\n- 인공지능이 가지고 있는 숫자들은 계산에 사용되는 숫자들임.. \n\n`-` 입력정보에 영화에 대한 부정적 평가를 넣는다면?\n\n`-` 입력정보에 영화에 대한 긍정적 평가를 넣는다면?\n\n`-` 아무숫자나 뱉어내는듯 $\\to$ 멍청한 인공지능.. (옹호: 당연하지 학습전이니까)\n\n`-` 인공지능에 대한 이해1: 인공지능은 \"정리된숫자\"를 입력으로 하고 일련의 계산을 거쳐 \"계산된숫자\"를 출력해주는 함수라 생각할 수 있음.\n\n`-` 인공지능에 대한 이해2: 인공지능은 (1) 많은숫자들과 (2) 고유의 계산방식을 가지고 있음. \n\n- 인공지능이 내부에 자체적으로 저장하고 있는 숫자를 **파라메터**라고 부름. \n- 인공지능은 나름의 법칙에 따라 \"데이터\"와 \"파라메터\"를 계산함. 즉 인공지능은 자체적으로 데이터와 파라메터를 어떻게 계산할지 알고있는데, 이러한 고유의 계산방식을 **아키텍처**라고 말함. \n\n\n`-` 인공지능에 대한 이해3: 두 인공지능이 서로 다른 고유의 계산방식을 가지고 있다면 두 인공지능은 \"다른 모델\"임. \n\n`-` 인공지능에 대한 이해3': 동일한 생성방식으로 만들어진 인공지능들은 모두 같은 모델임. 예를들면 아래의 인공지능1,2는 같은 모델임 \n\n```Python\n인공지능1 = transformers.AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert/distilbert-base-uncased\", \n    num_labels=2\n)\n인공지능2 = transformers.AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert/distilbert-base-uncased\", \n    num_labels=2\n)\n```\n\n`-` 인공지능에 대한 이해4: 두 인공지능이 같은 모델이라고 해도, 항상 같은 결과를 주는건 아님. 파라메터에 따라 다른결과를 줄 수 도 있음. (예를들면 위의 인공지능1,2는 같은 모델이지만 다른 파라메터를 가지므로 다른 결과를 줌) \n\n## B. 2단계\n\n> 미니배치를 이해하자.\n\n`-` 예비학습 \n\n`-` 예비개념1: 인공지능은 사실 영화평을 하나씩 하나씩 처리하지 않는다. 덩어리로 처리한다. \n\n`-` 예비개념2: 그렇다고 해서 인공지능이 25000개를 모두 덩어리로 처리하는건 아니다 $\\to$ 16개씩, 혹은 32개씩 묶어서 작은덩어리로 만든 후 처리한다. \n\n- 16,32 와 같은 숫자를 `batch_size` 라고 한다.\n- 16개, 32개로 모인 작은덩어리를 미니배치라고 한다. \n\n`-` 16개의 입력정보를 한번에 처리 \n\n`-` 기억할 것: `정리된숫자들_토큰화된자료` 는 모두 길이가 512임. (그렇게 되도록 패딩함)\n\n`-` 실제 단어수\n\n`-` 패딩된단어수 \n\n`-` 이러한 변환이 이루어지는 이유? 인공지능은 항상 `(n,m)` 차원으로 정리된 정리된숫자들을 입력으로 받아야함. \n\n- 왜? 사실 인공지능은 행렬계산을 하도록 설계되어있음.\n- 그래서 할수없이 패딩처리를 해야하는 것임. (실제로는 행렬로 만들수 없지만 억지로 만들기 위해서..)\n\n## C. 3단계 \n\n> 동적패딩을 이해하자.\n\n`-` 만약에 `batch_size=4` 로 설정하여 처리한다면? \n\n`-` `정리된숫자들_토큰화된자료`의 차원은 어떠할까? (4,512)로 예상되지 않을까?\n\n- 끝차원이 512가 아니라 363이다.. 왜?? \n\n`-` 덩어리의 상태에 따라서 유동적으로 패딩 $\\to$ 그래도 잘 돌아감\n\n`-` 싹다 512로 통일한것대비 큰 차이없음.. \n\n## D. 4단계\n\n> 손실(=loss)의 개념을 이해하자. \n\n`-` `정리된숫자들_토큰화된자료`에서 `labels` 를 추가 전달하면 `인공지능(**정리된숫자들_토큰화된자료)`의 결과로 `loss`가 추가계산됨 \n\n`-` 정리를 해보자.\n\n`-` loss는 작을수록 좋은 것임. 문제를 많이 틀릴수록 loss가 큼, 문제를 조금 틀릴수록 loss가 작음  \n\n**텍스트0~텍스트3**\n\n**텍스트12498~텍스트12501**\n\n`-` 똑같이 틀려도 오답에 대한 확신이 강할수록 loss가 크다. \n\n**텍스트0~텍스트1**\n\n**텍스트1~텍스트2**\n\n`-` 손실 = 인공지능의 \"멍청한정도\" 혹은 \"똑똑한정도\"을 숫자화한것\n\n::: {.callout-note}\n\n### $\\star\\star\\star$ 학습이 가능한 이유 (대충 아이디어만) \n\n`1`. 랜덤으로 1개의 인공지능을 생성한다. (아래의 코드로 가능)\n\n```Python\n인공지능 = 인공지능생성기()\n```\n\n`2`. 인공지능의 파라메터중 하나를 찍는다. 예를들면 아래와 같은 상황이 있다고 하자. \n\n```Python\n인공지능.classifier.weight\n```\n```\nParameter containing:\ntensor([[-0.0234,  0.0279,  0.0242,  ...,  0.0091, -0.0063, -0.0133],\n        [ 0.0087,  0.0007, -0.0099,  ...,  0.0183, -0.0007,  0.0295]],\n       requires_grad=True)\n```\n\n하나의 숫자 `-0.0234` 를 선택한다.\n\n`3`. `-0.0234`의 값을 조금 변화시켜본다. 예를들면, `-0.0235`, `-0.0233` 와 같은 식으로 변화시켜본뒤 loss를 관찰한다. \n\n`4`. 원래값과 변화시킨값들중 loss를 가장 작게 만드는 값으로 `-0.0234`를 update한다. \n\n`5`. 다른 모든 파라메터에 대하여 1~4를 반복한다. (과정을 반복할수록 loss가 작아지겠죠, 즉 인공지능은 똑똑해지겠죠)\n:::\n\n\n`-` 인공지능의 학습은 마법같은 신비한 현상이 아니고 극한의 노가다를 통해 얻어지는 산물일 뿐이다. \n\n# 6. 데이터전처리2\n\n# 7. 데이터콜렉터 \n\n`-` 데이터콜렉터 사용방법 \n\n`-` 데이터콜렉터의 기능: batch_size 에 따라서 패딩시켜줌\n\n# 8. 평가하기\n\n`-` `accuracy.compute`의 기능\n\n`-` 함수내용 \n\n> `평가하기` 함수는 `eval_dataset`에 적용됨 \n\n# 9. 트레이너 세부지침\n\n::: {.callout-note} \n\n### 옵션 설명:\n\n1. **`output_dir=\"my_awesome_model\"`**:\n   - 학습된 모델과 관련 파일(예: 체크포인트, 로그 등)이 저장될 디렉토리 경로를 지정합니다.\n\n2. **`learning_rate=2e-5`**:\n   - 학습률(learning rate)을 설정합니다. 모델이 가중치를 업데이트할 때 사용하는 스텝 크기로, 작은 값일수록 학습 속도가 느려지지만 안정성이 높습니다.\n\n3. **`per_device_train_batch_size=16`**:\n   - **훈련** 시, 각 GPU 또는 CPU 디바이스에서 사용할 배치 크기를 설정합니다. 이 경우 각 디바이스에서 16개의 샘플을 한 번에 처리합니다.\n\n4. **`per_device_eval_batch_size=16`**:\n   - **평가** 시, 각 GPU 또는 CPU 디바이스에서 사용할 배치 크기를 설정합니다. 평가 시에는 훈련과 같은 배치 크기를 사용하는 것이 일반적입니다.\n\n5. **`num_train_epochs=2`**:\n   - 전체 훈련 데이터셋을 몇 번 반복(에포크)할지 설정합니다. 여기서는 데이터셋 전체를 2번 학습하게 됩니다.\n\n6. **`weight_decay=0.01`**:\n   - 가중치 감쇠(weight decay)를 적용하여 모델의 가중치가 지나치게 커지지 않도록 제어합니다. 0.01의 값은 가중치가 조금씩 감소하게 하여 모델의 일반화 성능을 높이는 데 도움을 줄 수 있습니다.\n\n7. **`eval_strategy=\"epoch\"`**:\n   - 평가 전략을 설정합니다. 여기서는 `epoch`으로 설정되어, 매 에포크가 끝날 때마다 평가가 진행됩니다.\n   - 다른 값으로는 `steps` (일정한 스텝마다 평가) 등이 있습니다.\n\n8. **`save_strategy=\"epoch\"`**:\n   - 모델을 언제 저장할지 설정합니다. `epoch`으로 설정되면, 매 에포크가 끝날 때마다 체크포인트를 저장합니다.\n   - 다른 값으로는 `steps` (일정한 스텝마다 저장) 등이 있습니다.\n\n9. **`load_best_model_at_end=True`**:\n   - 학습이 끝난 후, 가장 성능이 좋았던 체크포인트를 불러옵니다. 평가 지표에 따라 가장 성능이 좋았던 모델을 자동으로 불러와 최종 모델로 사용하게 됩니다.\n\n10. **`push_to_hub=False`**:\n    - 모델 학습이 끝난 후 Hugging Face Hub에 모델을 업로드할지 여부를 설정합니다. `False`로 설정하면 업로드하지 않습니다.\n    - `True`로 설정하면 모델과 관련된 파일들이 Hugging Face Hub에 업로드되어 다른 사람들과 공유할 수 있습니다.\n\n:::\n\n`-` lr = 학습률 = 답이 틀렸을 경우 혼내는 정도\n\n- 정확한 느낌은 경사하강법을 이해해야함. \n\n# 10. 트레이너\n\n`-` 트레이너를 이용한 학습\n\n`-` 인공지능이 똑똑해졌을까? \n\n`-` 입력정보에 영화에 대한 부정적 평가를 넣는다면?\n\n`-` 입력정보에 영화에 대한 긍정적 평가를 넣는다면?\n\n`-` 우리가 가져야할 생각: 신기하다 X // 노가다 많이 했구나.. O\n\n# 11. 파이프라인\n\n`-` 강인공지능? \n\n> ref: <https://zdnet.co.kr/view/?no=20160622145838>\n","srcMarkdownNoYaml":"\n\n# 1. Imports\n\n# 2. 이전코드\n\n`-` Step1~4를 위한 준비\n\n`-` Step 1~4\n\n# 3. DataSet\n\n`-` 가장 중요한 원초적 질문: 데이터 셋을 바꿔치기 하려면? \n\n`-` 내가 원하는 데이터를 아래와 같은 형태로 정리가능해야함. \n\n`-` `datasets.arrow_dataset.Dataset` 의 인스턴스 만들기 \n\n아래와 같은 함수가 있음 \n\n이 함수를 쓰는 방법?\n\n### $\\star$ `datasets.Dataset.from_dict` 사용법\n\n`datasets.Dataset.from_dict`는 Python의 딕셔너리(`dict`)를 `Dataset` 객체로 변환하는 함수입니다. 주로 딕셔너리 형태의 데이터를 빠르게 데이터셋으로 변환할 때 사용됩니다.\n\n**간단한 사용법**\n\n```python\nfrom datasets import Dataset\n\n# 딕셔너리를 Dataset으로 변환\ndata_dict = {\n    'text': [\"Hello world\", \"How are you?\", \"Fine, thanks!\"],\n    'label': [0, 1, 1]\n}\n\n# Dataset 생성\ndataset = Dataset.from_dict(data_dict)\n\n# 출력\nprint(dataset)\n```\n\n**주요 매개변수:**\n- `mapping`: 필수, 문자열을 키로 하고 리스트 또는 배열을 값으로 하는 딕셔너리.\n- `features`: 선택, 데이터셋의 각 필드 타입을 정의.\n- `info`: 선택, 데이터셋에 대한 추가 정보(설명, 인용 등).\n- `split`: 선택, 데이터셋의 나누기('train', 'test' 등).\n\n**반환값:**\n- `Dataset`: PyArrow 기반의 데이터셋 객체.\n\n`-` `datasets.dataset_dict.DatasetDict`의 인스턴스 만들기 \n\n`-` 일단 아래와 같은 형태로 분석할 데이터를 정리할 수만 있다면, 나머지는 코드를 복붙해서 일단 돌릴 수 있음. \n\n```Python\ntrain_dict = {\n    'text': [\n        \"I prefer making decisions based on logic and objective facts.\",\n        \"I always consider how others might feel when making a decision.\",\n        \"Data and analysis drive most of my decisions.\",\n        \"I rely on my empathy and personal values to guide my choices.\"\n    ],\n    'label': [0, 1, 0, 1]  # 0은 T(사고형), 1은 F(감정형)\n}\n\ntest_dict = {\n    'text': [\n        \"I find it important to weigh all the pros and cons logically.\",\n        \"When making decisions, I prioritize harmony and people's emotions.\"\n    ],\n    'label': [0, 1]  # 0은 T(사고형), 1은 F(감정형)\n}\n\n```\n\n# 4. 토크나이저\n\n`-` 기본적인 사용방법\n\n::: {.callout-note}\n\n### $\\star$ `토크나이저` 사용법 (ref: ChatGPT)\n\n**주요 파라미터**:\n\n1. **text**: \n   - `Union[str, List[str], List[List[str]]]`\n   - 주어진 텍스트를 토큰화합니다. 이 텍스트는 문자열일 수도 있고, 문자열의 리스트 또는 리스트 안의 리스트일 수도 있습니다.\n\n2. **text_pair**: \n   - `Union[str, List[str], List[List[str]], NoneType]`\n   - 두 개의 텍스트를 함께 모델에 입력할 때 사용됩니다. 예를 들어, 질문-답변 쌍 같은 경우 이 두 번째 텍스트를 넣습니다.\n\n3. **text_target**: \n   - `Union[str, List[str], List[List[str]]]`\n   - 토큰화를 할 때 목표(target) 텍스트에 해당하는 부분입니다. 주로 시퀀스 생성 모델에서 활용됩니다.\n\n4. **text_pair_target**: \n   - `Union[str, List[str], List[List[str]], NoneType]`\n   - 위의 `text_pair`와 유사하게 목표(target) 텍스트의 두 번째 텍스트를 나타냅니다.\n\n5. **add_special_tokens**: \n   - `bool`\n   - 문장의 시작, 끝, 구분자 같은 특별한 토큰을 추가할지 여부를 결정합니다. 기본값은 `True`입니다.\n\n6. **padding**: \n   - `Union[bool, str, transformers.utils.generic.PaddingStrategy]`\n   - 문장 길이가 다를 때 패딩을 넣어 문장의 길이를 동일하게 맞춥니다. 패딩 전략에는 `True`, `False`, `'longest'`, `'max_length'` 등이 있습니다.\n\n7. **truncation**: \n   - `Union[bool, str, transformers.tokenization_utils_base.TruncationStrategy]`\n   - 문장이 너무 길 경우 지정된 최대 길이에 맞춰 잘라내는 옵션입니다. 전략에는 `True`, `False`, `'longest_first'`, `'only_first'`, `'only_second'` 등이 있습니다.\n\n8. **max_length**: \n   - `Optional[int]`\n   - 문장의 최대 길이를 설정합니다. `None`일 경우 기본 설정을 따릅니다.\n\n9. **stride**: \n   - `int`\n   - 텍스트를 자를 때 중첩을 만들기 위한 옵션입니다. 즉, 자른 부분과 다음 부분 사이의 겹치는 범위를 설정합니다.\n\n10. **is_split_into_words**: \n    - `bool`\n    - 텍스트가 이미 단어 단위로 분리되어 있는지 여부를 나타냅니다. 기본적으로는 `False`로, 텍스트가 단어 단위로 분리되지 않았다고 가정합니다.\n\n11. **return_tensors**: \n    - `Union[str, transformers.utils.generic.TensorType, NoneType]`\n    - 출력 형식으로 텐서를 반환할지 여부를 설정합니다. `'pt'`(PyTorch), `'tf'`(TensorFlow), `'np'`(NumPy) 등을 지정할 수 있습니다.\n\n12. **return_token_type_ids**: \n    - `Optional[bool]`\n    - 토큰 타입 ID를 반환할지 여부를 설정합니다. 주로 두 개의 문장을 함께 처리할 때 문장을 구분하기 위해 사용됩니다.\n\n13. **return_attention_mask**: \n    - `Optional[bool]`\n    - `attention_mask`를 반환할지 여부를 설정합니다. 패딩된 토큰이 모델의 어텐션에 영향을 주지 않도록 마스크를 설정합니다.\n\n14. **return_overflowing_tokens**: \n    - `bool`\n    - 텍스트가 최대 길이를 초과하는 경우, 잘린 토큰을 반환할지 여부를 결정합니다.\n\n15. **return_special_tokens_mask**: \n    - `bool`\n    - 특별한 토큰에 대한 마스크를 반환할지 여부를 설정합니다.\n\n16. **return_offsets_mapping**: \n    - `bool`\n    - 텍스트의 각 토큰이 원본 텍스트에서 어느 위치에 있는지 나타내는 오프셋 맵핑을 반환할지 여부를 설정합니다.\n\n17. **return_length**: \n    - `bool`\n    - 토큰화된 문장의 길이를 반환할지 여부를 설정합니다.\n\n18. **verbose**: \n    - `bool`\n    - 디버깅 메시지를 출력할지 여부를 설정합니다. 기본값은 `True`로 설정되어 있습니다.\n\n**사용 예시**:\n\n```python\nfrom transformers import AutoTokenizer\n\n# 토크나이저 불러오기\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n\n# 텍스트 토큰화\nencoding = tokenizer(\n    text=\"Hello, how are you?\",\n    padding=True,\n    truncation=True,\n    max_length=10,\n    return_tensors='pt'\n)\n\nprint(encoding)\n```\n\n이 코드에서는 \"Hello, how are you?\"라는 텍스트를 `bert-base-uncased` 토크나이저로 토큰화하고, 패딩과 트렁케이션을 적용하며, PyTorch 텐서 형식으로 반환하도록 설정했습니다.\n\n이러한 파라미터는 주로 자연어 처리(NLP) 모델을 훈련하거나 추론할 때 데이터 전처리 과정에서 많이 사용됩니다.\n:::\n\n`-` 기본사용1: 단어별로 다른숫자를 맵핑 + 처음과 끝은 항상 `101`, `102`\n\n`-` 기본사용2: 텍스트 혹은 텍스트의 리스트, 리스트의 리스트를 전달가능 \n\n`-` `truncation=True` 의 역할 \n\n`-` maxlen, padding, attention_mask\n\n# 5. 인공지능 ($\\star$)\n\n## A. 1단계\n\n> 인공지능에 대한 이해\n\n`-` 인공지능 불러오기 \n\n`-` 인공지능의 정체? 엄청나게 많은 숫자들이 포함된 어떠한 물체 (엄청나게 많은 파라메터들이 포함된 네트워크)\n\n`-` 인공지능? \"입력정보 -> 정리된숫자 -> 계산 -> 계산된숫자 -> 출력정보\" 의 과정에서 \"계산\"을 담당\n\n- 인공지능이 가지고 있는 숫자들은 계산에 사용되는 숫자들임.. \n\n`-` 입력정보에 영화에 대한 부정적 평가를 넣는다면?\n\n`-` 입력정보에 영화에 대한 긍정적 평가를 넣는다면?\n\n`-` 아무숫자나 뱉어내는듯 $\\to$ 멍청한 인공지능.. (옹호: 당연하지 학습전이니까)\n\n`-` 인공지능에 대한 이해1: 인공지능은 \"정리된숫자\"를 입력으로 하고 일련의 계산을 거쳐 \"계산된숫자\"를 출력해주는 함수라 생각할 수 있음.\n\n`-` 인공지능에 대한 이해2: 인공지능은 (1) 많은숫자들과 (2) 고유의 계산방식을 가지고 있음. \n\n- 인공지능이 내부에 자체적으로 저장하고 있는 숫자를 **파라메터**라고 부름. \n- 인공지능은 나름의 법칙에 따라 \"데이터\"와 \"파라메터\"를 계산함. 즉 인공지능은 자체적으로 데이터와 파라메터를 어떻게 계산할지 알고있는데, 이러한 고유의 계산방식을 **아키텍처**라고 말함. \n\n\n`-` 인공지능에 대한 이해3: 두 인공지능이 서로 다른 고유의 계산방식을 가지고 있다면 두 인공지능은 \"다른 모델\"임. \n\n`-` 인공지능에 대한 이해3': 동일한 생성방식으로 만들어진 인공지능들은 모두 같은 모델임. 예를들면 아래의 인공지능1,2는 같은 모델임 \n\n```Python\n인공지능1 = transformers.AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert/distilbert-base-uncased\", \n    num_labels=2\n)\n인공지능2 = transformers.AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert/distilbert-base-uncased\", \n    num_labels=2\n)\n```\n\n`-` 인공지능에 대한 이해4: 두 인공지능이 같은 모델이라고 해도, 항상 같은 결과를 주는건 아님. 파라메터에 따라 다른결과를 줄 수 도 있음. (예를들면 위의 인공지능1,2는 같은 모델이지만 다른 파라메터를 가지므로 다른 결과를 줌) \n\n## B. 2단계\n\n> 미니배치를 이해하자.\n\n`-` 예비학습 \n\n`-` 예비개념1: 인공지능은 사실 영화평을 하나씩 하나씩 처리하지 않는다. 덩어리로 처리한다. \n\n`-` 예비개념2: 그렇다고 해서 인공지능이 25000개를 모두 덩어리로 처리하는건 아니다 $\\to$ 16개씩, 혹은 32개씩 묶어서 작은덩어리로 만든 후 처리한다. \n\n- 16,32 와 같은 숫자를 `batch_size` 라고 한다.\n- 16개, 32개로 모인 작은덩어리를 미니배치라고 한다. \n\n`-` 16개의 입력정보를 한번에 처리 \n\n`-` 기억할 것: `정리된숫자들_토큰화된자료` 는 모두 길이가 512임. (그렇게 되도록 패딩함)\n\n`-` 실제 단어수\n\n`-` 패딩된단어수 \n\n`-` 이러한 변환이 이루어지는 이유? 인공지능은 항상 `(n,m)` 차원으로 정리된 정리된숫자들을 입력으로 받아야함. \n\n- 왜? 사실 인공지능은 행렬계산을 하도록 설계되어있음.\n- 그래서 할수없이 패딩처리를 해야하는 것임. (실제로는 행렬로 만들수 없지만 억지로 만들기 위해서..)\n\n## C. 3단계 \n\n> 동적패딩을 이해하자.\n\n`-` 만약에 `batch_size=4` 로 설정하여 처리한다면? \n\n`-` `정리된숫자들_토큰화된자료`의 차원은 어떠할까? (4,512)로 예상되지 않을까?\n\n- 끝차원이 512가 아니라 363이다.. 왜?? \n\n`-` 덩어리의 상태에 따라서 유동적으로 패딩 $\\to$ 그래도 잘 돌아감\n\n`-` 싹다 512로 통일한것대비 큰 차이없음.. \n\n## D. 4단계\n\n> 손실(=loss)의 개념을 이해하자. \n\n`-` `정리된숫자들_토큰화된자료`에서 `labels` 를 추가 전달하면 `인공지능(**정리된숫자들_토큰화된자료)`의 결과로 `loss`가 추가계산됨 \n\n`-` 정리를 해보자.\n\n`-` loss는 작을수록 좋은 것임. 문제를 많이 틀릴수록 loss가 큼, 문제를 조금 틀릴수록 loss가 작음  \n\n**텍스트0~텍스트3**\n\n**텍스트12498~텍스트12501**\n\n`-` 똑같이 틀려도 오답에 대한 확신이 강할수록 loss가 크다. \n\n**텍스트0~텍스트1**\n\n**텍스트1~텍스트2**\n\n`-` 손실 = 인공지능의 \"멍청한정도\" 혹은 \"똑똑한정도\"을 숫자화한것\n\n::: {.callout-note}\n\n### $\\star\\star\\star$ 학습이 가능한 이유 (대충 아이디어만) \n\n`1`. 랜덤으로 1개의 인공지능을 생성한다. (아래의 코드로 가능)\n\n```Python\n인공지능 = 인공지능생성기()\n```\n\n`2`. 인공지능의 파라메터중 하나를 찍는다. 예를들면 아래와 같은 상황이 있다고 하자. \n\n```Python\n인공지능.classifier.weight\n```\n```\nParameter containing:\ntensor([[-0.0234,  0.0279,  0.0242,  ...,  0.0091, -0.0063, -0.0133],\n        [ 0.0087,  0.0007, -0.0099,  ...,  0.0183, -0.0007,  0.0295]],\n       requires_grad=True)\n```\n\n하나의 숫자 `-0.0234` 를 선택한다.\n\n`3`. `-0.0234`의 값을 조금 변화시켜본다. 예를들면, `-0.0235`, `-0.0233` 와 같은 식으로 변화시켜본뒤 loss를 관찰한다. \n\n`4`. 원래값과 변화시킨값들중 loss를 가장 작게 만드는 값으로 `-0.0234`를 update한다. \n\n`5`. 다른 모든 파라메터에 대하여 1~4를 반복한다. (과정을 반복할수록 loss가 작아지겠죠, 즉 인공지능은 똑똑해지겠죠)\n:::\n\n\n`-` 인공지능의 학습은 마법같은 신비한 현상이 아니고 극한의 노가다를 통해 얻어지는 산물일 뿐이다. \n\n# 6. 데이터전처리2\n\n# 7. 데이터콜렉터 \n\n`-` 데이터콜렉터 사용방법 \n\n`-` 데이터콜렉터의 기능: batch_size 에 따라서 패딩시켜줌\n\n# 8. 평가하기\n\n`-` `accuracy.compute`의 기능\n\n`-` 함수내용 \n\n> `평가하기` 함수는 `eval_dataset`에 적용됨 \n\n# 9. 트레이너 세부지침\n\n::: {.callout-note} \n\n### 옵션 설명:\n\n1. **`output_dir=\"my_awesome_model\"`**:\n   - 학습된 모델과 관련 파일(예: 체크포인트, 로그 등)이 저장될 디렉토리 경로를 지정합니다.\n\n2. **`learning_rate=2e-5`**:\n   - 학습률(learning rate)을 설정합니다. 모델이 가중치를 업데이트할 때 사용하는 스텝 크기로, 작은 값일수록 학습 속도가 느려지지만 안정성이 높습니다.\n\n3. **`per_device_train_batch_size=16`**:\n   - **훈련** 시, 각 GPU 또는 CPU 디바이스에서 사용할 배치 크기를 설정합니다. 이 경우 각 디바이스에서 16개의 샘플을 한 번에 처리합니다.\n\n4. **`per_device_eval_batch_size=16`**:\n   - **평가** 시, 각 GPU 또는 CPU 디바이스에서 사용할 배치 크기를 설정합니다. 평가 시에는 훈련과 같은 배치 크기를 사용하는 것이 일반적입니다.\n\n5. **`num_train_epochs=2`**:\n   - 전체 훈련 데이터셋을 몇 번 반복(에포크)할지 설정합니다. 여기서는 데이터셋 전체를 2번 학습하게 됩니다.\n\n6. **`weight_decay=0.01`**:\n   - 가중치 감쇠(weight decay)를 적용하여 모델의 가중치가 지나치게 커지지 않도록 제어합니다. 0.01의 값은 가중치가 조금씩 감소하게 하여 모델의 일반화 성능을 높이는 데 도움을 줄 수 있습니다.\n\n7. **`eval_strategy=\"epoch\"`**:\n   - 평가 전략을 설정합니다. 여기서는 `epoch`으로 설정되어, 매 에포크가 끝날 때마다 평가가 진행됩니다.\n   - 다른 값으로는 `steps` (일정한 스텝마다 평가) 등이 있습니다.\n\n8. **`save_strategy=\"epoch\"`**:\n   - 모델을 언제 저장할지 설정합니다. `epoch`으로 설정되면, 매 에포크가 끝날 때마다 체크포인트를 저장합니다.\n   - 다른 값으로는 `steps` (일정한 스텝마다 저장) 등이 있습니다.\n\n9. **`load_best_model_at_end=True`**:\n   - 학습이 끝난 후, 가장 성능이 좋았던 체크포인트를 불러옵니다. 평가 지표에 따라 가장 성능이 좋았던 모델을 자동으로 불러와 최종 모델로 사용하게 됩니다.\n\n10. **`push_to_hub=False`**:\n    - 모델 학습이 끝난 후 Hugging Face Hub에 모델을 업로드할지 여부를 설정합니다. `False`로 설정하면 업로드하지 않습니다.\n    - `True`로 설정하면 모델과 관련된 파일들이 Hugging Face Hub에 업로드되어 다른 사람들과 공유할 수 있습니다.\n\n:::\n\n`-` lr = 학습률 = 답이 틀렸을 경우 혼내는 정도\n\n- 정확한 느낌은 경사하강법을 이해해야함. \n\n# 10. 트레이너\n\n`-` 트레이너를 이용한 학습\n\n`-` 인공지능이 똑똑해졌을까? \n\n`-` 입력정보에 영화에 대한 부정적 평가를 넣는다면?\n\n`-` 입력정보에 영화에 대한 긍정적 평가를 넣는다면?\n\n`-` 우리가 가져야할 생각: 신기하다 X // 노가다 많이 했구나.. O\n\n# 11. 파이프라인\n\n`-` 강인공지능? \n\n> ref: <https://zdnet.co.kr/view/?no=20160622145838>\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"reference-location":"margin","toc":true,"output-file":"2024-09-18-(강의) 감성분석 파고들기.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.520","theme":"cosmo","title-block-banner":false,"comments":{"utterances":{"repo":"miruetoto/yechan3"}},"bibliography":["../ref.bib"],"cap-location":"bottom","citation-location":"margin","code-copy":true,"title":"(강의) 감성분석 파고들기","author":"신록예찬","date":"09/18/2024"},"extensions":{"book":{"multiFile":true}}},"ipynb":{"identifier":{"display-name":"Jupyter","target-format":"ipynb","base-format":"ipynb"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"png","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"ipynb","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"default-image-extension":"png","to":"ipynb","reference-location":"margin","output-file":"2024-09-18-(강의) 감성분석 파고들기.ipynb"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"title-block-banner":false,"comments":{"utterances":{"repo":"miruetoto/yechan3"}},"bibliography":["../ref.bib"],"cap-location":"bottom","citation-location":"margin","title":"(강의) 감성분석 파고들기","author":"신록예찬","date":"09/18/2024"}}},"projectFormats":["html"]}