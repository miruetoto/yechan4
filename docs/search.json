[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "신록예찬's Blog",
    "section": "",
    "text": "About this blog\nThis blog was created for my personal research, study and lecture preparation. Therefore, the contents of the blog can be thought of as my practice notes. As a result, sometimes the content of a post may be left unstructured or unfinished. The blog is named after my favorite essay ‘신록예찬’, which is also a nickname I use informally. You can check the written article in the sidebar on the left. It is a great honor for me if these posts can help others to learn and research.\n\nSome links that help me\n\nfirst batchsecond batchthird batchlectures notes\n\n\n\npaperswithcode: https://paperswithcode.com/\n플루토: https://cotangent.dev/how-to-publish-pluto-jl-notebooks-online-interactively/\n연구비: http://scieng.net/now/1047\n\n\n\n\nmatplotlib: https://matplotlib.org/stable/gallery/index.html\njupyterlab: https://jupyterlab.readthedocs.io/en/stable/index.html\npandas: https://pandas.pydata.org/docs/user_guide/index.html#user-guide\njulia: https://docs.julialang.org/en/v1/\nkeras: https://keras.io/examples/\njulia plots: https://docs.juliaplots.org/stable/\npytorch lightning: https://www.pytorchlightning.ai/\nplotly: https://plotly.com/graphing-libraries/\nquarto: https://quarto.org/\nAutoGluon: https://auto.gluon.ai/stable/index.html\n\n\n\n\nlatex: https://editor.codecogs.com/\ntable: https://www.tablesgenerator.com/\npytorch lightning (codes in book): https://github.com/PacktPublishing/Deep-Learning-with-PyTorch-Lightning\nPyG: https://github.com/rusty1s/pytorch_geometric\nrayshader: https://www.rayshader.com/reference/plot_gg.html\nSouth Korea (map): https://github.com/southkorea\nregexp: https://zvon.org/comp/m/regexp.html\nrpy2: https://rpy2.github.io/doc/v3.1.x/html/index.html\npywave: https://pywavelets.readthedocs.io/en/latest/ref/wavelets.html\nPyGSP: https://pygsp.readthedocs.io/en/stable/#\nlatex (neural networks): https://tikz.net/neural_networks/\nplotly overview: https://plotly.com/python/plotly-express/\nfastai (official): https://docs.fast.ai/\nfastai (lecture): https://course.fast.ai/#\nfastai (github codes): https://github.com/fastai/fastai/tree/master/dev_nbs/course\nGML (codes in book): https://github.com/PacktPublishing/Graph-Machine-Learning\nGMLKOR (codes in book): https://github.com/AcornPublishing/graph-ml\nmathNET https://gtribello.github.io/mathNET/index.html\n\n\n\n\nhttp://personal.psu.edu/drh20/asymp/fall2006/lectures/\nhttps://web.ma.utexas.edu/users/gordanz/lecture_notes_page.html\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\n \n\n\n(공부&서연) 지수분포 가설검정\n\n\n \n\n\n\n\n \n\n\n(공부&지윤) Imputer와 Scaler의 적용\n\n\n \n\n\n\n\n \n\n\n(공부) 리뷰 – EbayesThresh: R Programs for Empirical Bayes\n\n\n \n\n\n\n\n \n\n\n(공부) 추정\n\n\n \n\n\n\n\n \n\n\n(공부) 코드 – ggraph\n\n\n \n\n\n\n\n \n\n\n(공부) 퓨리에변환\n\n\n \n\n\n\n\n \n\n\n(연구&교수님) EBT – 첫 논문 재현 // 11월28일 다시~!\n\n\n \n\n\n\n\n \n\n\n \n\n\n \n\n\n\n\nNov 16, 2024\n\n\n(강의) 데이터콜렉터\n\n\n신록예찬 \n\n\n\n\nNov 9, 2024\n\n\n(강의) Dataset\n\n\n신록예찬 \n\n\n\n\nNov 8, 2024\n\n\n(강의) Model\n\n\n신록예찬 \n\n\n\n\nNov 7, 2024\n\n\n(강의) 선인장이미지분류 – ROC\n\n\n최규빈 \n\n\n\n\nNov 3, 2024\n\n\n(강의) with의 사용\n\n\n최규빈 \n\n\n\n\nNov 2, 2024\n\n\n(강의) numpy와 torch의 차이\n\n\n최규빈 \n\n\n\n\nNov 1, 2024\n\n\n(강의) 모듈설치 및 변경\n\n\n최규빈 \n\n\n\n\nOct 31, 2024\n\n\n(강의) pipeline의 이해\n\n\n신록예찬 \n\n\n\n\nOct 31, 2024\n\n\n(강의) torch.tensor 이해\n\n\n신록예찬 \n\n\n\n\nOct 31, 2024\n\n\n(강의) 이미지캡셔닝2\n\n\n신록예찬 \n\n\n\n\nOct 30, 2024\n\n\n(강의) 이미지분류 SIIM-ISIC\n\n\n신록예찬 \n\n\n\n\nOct 30, 2024\n\n\n(강의) 평가지표의 이해\n\n\n신록예찬 \n\n\n\n\nOct 29, 2024\n\n\n(강의) 이상탐지살펴봄\n\n\n신록예찬 \n\n\n\n\nOct 10, 2024\n\n\n(강의) 음성인식\n\n\n신록예찬 \n\n\n\n\nOct 10, 2024\n\n\n(강의) 이미지캡셔닝\n\n\n신록예찬 \n\n\n\n\nOct 1, 2024\n\n\n(강의) 비디오분류\n\n\n신록예찬 \n\n\n\n\nOct 1, 2024\n\n\n(강의) 음성분류\n\n\n신록예찬 \n\n\n\n\nSep 29, 2024\n\n\n(강의) 이미지분류\n\n\n신록예찬 \n\n\n\n\nSep 18, 2024\n\n\n(강의) 감성분석 파고들기\n\n\n신록예찬 \n\n\n\n\nSep 8, 2024\n\n\n(강의) 감성분류\n\n\n신록예찬 \n\n\n\n\nAug 29, 2024\n\n\n(공부) image_classification\n\n\n신록예찬 \n\n\n\n\nAug 29, 2024\n\n\n(공부) image_classification 2\n\n\n신록예찬 \n\n\n\n\nAug 28, 2024\n\n\n(강의) IMDB 자료 살펴보기, 지도학습의 개념\n\n\n신록예찬 \n\n\n\n\nAug 23, 2024\n\n\n(공부) xgboost 재현\n\n\n신록예찬 \n\n\n\n\nAug 14, 2024\n\n\n(연구&서연) Ebayesthresh Layer\n\n\n최규빈 \n\n\n\n\nAug 14, 2024\n\n\n(연구&서연) GODE – CLT\n\n\n최규빈 \n\n\n\n\nAug 14, 2024\n\n\n(연구&서연) GODE – Ex2 Distance Histogram 시각화\n\n\n최규빈 \n\n\n\n\nAug 14, 2024\n\n\n(연구&서연) GODE – Ex2 Distance의분포/Kappa에따른AUC 시각화\n\n\n최규빈 \n\n\n\n\nAug 14, 2024\n\n\n(연구&서연) GODE – Ex2 Kappa에 따른 성능 시각화\n\n\n최규빈 \n\n\n\n\nAug 14, 2024\n\n\n(연구&서연) GODE – Ex2 Kappa에 따른 성능 시각화\n\n\n최규빈 \n\n\n\n\nAug 12, 2024\n\n\n(공부) CGSP – Chap 12.2: Weakly Stationary Graph Processes\n\n\n신록예찬 \n\n\n\n\nAug 12, 2024\n\n\n(공부) 시계열과 GSP\n\n\n신록예찬 \n\n\n\n\nAug 12, 2024\n\n\n(연구&서연) GODE – 환경설정\n\n\n최규빈 \n\n\n\n\nAug 6, 2024\n\n\n(연구&교수님) 다중척도논문 – EMD 2\n\n\n최규빈 \n\n\n\n\nAug 1, 2024\n\n\n(연구&교수님) EBT – 첫 논문 재현\n\n\n최규빈 \n\n\n\n\nAug 1, 2024\n\n\n(연구&교수님) EBT – 첫 논문 재현 // 2024년 8월\n\n\n최규빈 \n\n\n\n\nJul 30, 2024\n\n\n(연구&교수님) EBT – ECG 자료 시각화\n\n\n최규빈 \n\n\n\n\nJul 27, 2024\n\n\n(연구&교수님) 다중척도논문 – TPT-FirstFig\n\n\n최규빈 \n\n\n\n\nJul 24, 2024\n\n\n(연구&교수님) 다중척도논문 – TPT, 미국지수분석\n\n\n최규빈 \n\n\n\n\nJul 24, 2024\n\n\n(연구&교수님) 다중척도논문 – TPT, 미국지수분석 (2)\n\n\n최규빈 \n\n\n\n\nJul 23, 2024\n\n\n(연구&교수님) 다중척도논문 – Beat\n\n\n최규빈 \n\n\n\n\nJul 23, 2024\n\n\n(연구&교수님) 다중척도논문 – FFT\n\n\n최규빈 \n\n\n\n\nJul 22, 2024\n\n\n(연구&교수님) 다중척도논문 – TPT, TPMA 설명\n\n\n최규빈 \n\n\n\n\nJul 22, 2024\n\n\n(연구&교수님) 다중척도논문 – librosa\n\n\n최규빈 \n\n\n\n\nJul 17, 2024\n\n\n(연구) graft – tutorial 2\n\n\n신록예찬 \n\n\n\n\nJul 10, 2024\n\n\n(연구&교수님) 다중척도논문 – DWT\n\n\n최규빈 \n\n\n\n\nJul 10, 2024\n\n\n(연구&교수님) 다중척도논문 – EMD\n\n\n최규빈 \n\n\n\n\nJul 10, 2024\n\n\n(연구&교수님) 다중척도논문 – STFT\n\n\n최규빈 \n\n\n\n\nJul 10, 2024\n\n\n(연구&교수님) 다중척도논문 – SiZer\n\n\n최규빈 \n\n\n\n\nJul 10, 2024\n\n\n(연구&교수님) 다중척도논문 – 그림들\n\n\n최규빈 \n\n\n\n\nJul 1, 2024\n\n\n(메모) 학과서버 공지\n\n\n신록예찬 \n\n\n\n\nJun 9, 2024\n\n\n(연구&교수님) 다중척도논문 – 환경설정\n\n\n최규빈 \n\n\n\n\nMay 2, 2024\n\n\n(연구&보람) AutoGluon\n\n\n김보람 \n\n\n\n\nMay 2, 2024\n\n\n(연구&보람) GCN (시뮬레이션)\n\n\n김보람 \n\n\n\n\nApr 24, 2024\n\n\n(연구&보람) 데이터정리\n\n\n김보람 \n\n\n\n\nApr 8, 2024\n\n\n(메모) grahpviz\n\n\n신록예찬 \n\n\n\n\nApr 3, 2024\n\n\n(연구&보람) 결과시각화 – Experiment 1\n\n\n김보람 \n\n\n\n\nApr 3, 2024\n\n\nExperiment 1(꺾은선)\n\n\n김보람 \n\n\n\n\nJan 31, 2024\n\n\n(공부) 코드 – AUC sklearn\n\n\n신록예찬 \n\n\n\n\nJan 26, 2024\n\n\n(공부) 조건부확률, 조건부기대값\n\n\n신록예찬 \n\n\n\n\nJan 25, 2024\n\n\n(연구&보람) 신용카드거래 사기탐지 – pyod 사용\n\n\n신록예찬,김보람 \n\n\n\n\nJan 24, 2024\n\n\n(연구&서연) IT-STGCN – ToyExam\n\n\nSEOYEON CHOI\n\n\n\n\nJan 19, 2024\n\n\n(연구) gglitely – 서브플랏\n\n\n신록예찬 \n\n\n\n\nJan 19, 2024\n\n\n(연구) gglitely – 연계\n\n\n신록예찬 \n\n\n\n\nJan 19, 2024\n\n\n(연구) gglitely – 튜토리얼\n\n\n신록예찬 \n\n\n\n\nJan 18, 2024\n\n\n(연구&보람) 신용카드거래 사기탐지 – pygod 셋팅\n\n\n신록예찬,김보람 \n\n\n\n\nJan 18, 2024\n\n\n(자료) 신용카드 사기거래\n\n\n신록예찬 \n\n\n\n\nJan 16, 2024\n\n\n(메모) R package 만들기\n\n\n신록예찬 \n\n\n\n\nJan 16, 2024\n\n\n(연구&교수님) EBT – 미구현코드\n\n\n최규빈 \n\n\n\n\nJan 15, 2024\n\n\n(연구) gglite – 내부기능\n\n\n신록예찬 \n\n\n\n\nJan 15, 2024\n\n\n(연구) gglite – 튜토리얼\n\n\n신록예찬 \n\n\n\n\nJan 8, 2024\n\n\n(연구&서연) IT-STGCN – 실험결과시각화\n\n\nSEOYEON CHOI\n\n\n\n\nDec 27, 2023\n\n\n(연구&재인) MBTI(정리) – 논문그림정리\n\n\n신록예찬 \n\n\n\n\nDec 22, 2023\n\n\n(연구&재인) MBTI(정리) – 실험결과 시각화\n\n\n신록예찬 \n\n\n\n\nDec 21, 2023\n\n\n(연구&재인) MBTI(정리) – TabularPredictor 실험\n\n\n신록예찬 \n\n\n\n\nDec 20, 2023\n\n\n(연구&재인) MBTI(정리) – 실험셋업 시각화\n\n\n신록예찬 \n\n\n\n\nDec 19, 2023\n\n\n(연구&재인) MBTI(정리) – 실험셋업\n\n\n신록예찬 \n\n\n\n\nDec 13, 2023\n\n\n(연구&재인) MBTI – 추가자료분석 (429)\n\n\n신록예찬 \n\n\n\n\nDec 13, 2023\n\n\n(연구&재인) MBTI – 추가자료분석 (all)\n\n\n신록예찬 \n\n\n\n\nNov 9, 2023\n\n\n(연구) graft – tutorial\n\n\n신록예찬 \n\n\n\n\nNov 9, 2023\n\n\n(자료) 데이터생성 – 성별,몸무게 –&gt; 키\n\n\n신록예찬 \n\n\n\n\nOct 26, 2023\n\n\n(공부) Julia – Vector\n\n\n신록예찬 \n\n\n\n\nOct 25, 2023\n\n\n(공부) Julia – 문자와 문자열\n\n\n신록예찬 \n\n\n\n\nOct 21, 2023\n\n\n(공부&지윤) Imputer와 Scaler의 적용\n\n\n신록예찬 \n\n\n\n\nOct 12, 2023\n\n\n(연구&재인) MBTI – MBTI\n\n\n신록예찬 \n\n\n\n\nOct 11, 2023\n\n\n(연구&재인) MBTI – 감성분석\n\n\n신록예찬 \n\n\n\n\nSep 24, 2023\n\n\n(공부) 코드 – ggraph\n\n\n신록예찬 \n\n\n\n\nSep 14, 2023\n\n\n(연구&서연) IT-STGCN – 논문리비전\n\n\n최서연 \n\n\n\n\nAug 25, 2023\n\n\n(연구&보람) 신용카드거래 사기탐지 – 데이터(8, df02)커널죽음\n\n\n김보람 \n\n\n\n\nAug 18, 2023\n\n\n(연구&교수님) EPT-DISSIM – PRCP_KOR2 데이터정리\n\n\n신록예찬 \n\n\n\n\nAug 14, 2023\n\n\n(연구&지윤) 태양광자료분석 – GConvLSTM +++++++ 이거!!! ++++++++++++\n\n\nJiyunLim \n\n\n\n\nAug 8, 2023\n\n\n(연구&교수님) EPT-DISSIM – 진행사항\n\n\n신록예찬 \n\n\n\n\nAug 7, 2023\n\n\n(연구&교수님) EPT-DISSIM – PRCP_KOR 데이터정리\n\n\n신록예찬 \n\n\n\n\nJul 30, 2023\n\n\n(연구&보람) CTGAN – 신용카드\n\n\n신록예찬 \n\n\n\n\nJul 20, 2023\n\n\n(연구&지윤) 태양광자료분석 – EPT + RGCN (시뮬레이션)\n\n\n신록예찬 \n\n\n\n\nJul 19, 2023\n\n\n(공부) PyG – lesson6: GCN\n\n\n신록예찬 \n\n\n\n\nJul 19, 2023\n\n\n(연구&보람) 신용카드거래 사기탐지 – 관련연구 리뷰\n\n\n신록예찬 \n\n\n\n\nJul 19, 2023\n\n\n(연구&보람) 신용카드거래 사기탐지 – 그래프자료로 데이터정리\n\n\n신록예찬 \n\n\n\n\nJul 17, 2023\n\n\n(연구&지윤) 태양광자료분석 – EPT + RGCN\n\n\n신록예찬 \n\n\n\n\nJul 14, 2023\n\n\n(공부) PyG – lesson5: Learning Methods on Graphs\n\n\n신록예찬 \n\n\n\n\nJul 12, 2023\n\n\n(공부) PyG – lesson3: 미니배치\n\n\n신록예찬 \n\n\n\n\nJul 12, 2023\n\n\n(공부) PyG – lesson4: Data Transform???\n\n\n신록예찬 \n\n\n\n\nJul 12, 2023\n\n\n(연구&교수님) old_hst\n\n\n신록예찬 \n\n\n\n\nJul 12, 2023\n\n\n(연구&교수님) 그래프신호만들고시각화하기\n\n\n신록예찬 \n\n\n\n\nJul 12, 2023\n\n\n(연구&교수님) 링형태의자료만들기\n\n\n신록예찬 \n\n\n\n\nJul 7, 2023\n\n\n(공부) PyG – lesson2: 벤치마크 데이터셋 (train/test분리)\n\n\n신록예찬 \n\n\n\n\nJul 4, 2023\n\n\n(공부) 토폴로지\n\n\n신록예찬 \n\n\n\n\nJul 2, 2023\n\n\n(공부) PyG – lesson1: 자료형\n\n\n신록예찬 \n\n\n\n\nJul 1, 2023\n\n\n(연구&보람) CTGAN – Start\n\n\n신록예찬 \n\n\n\n\nJul 1, 2023\n\n\n(연구&보람) CTGAN – TOY\n\n\n신록예찬 \n\n\n\n\nJun 23, 2023\n\n\n(공부&지윤) 커널리그레션\n\n\n신록예찬 \n\n\n\n\nJun 23, 2023\n\n\n(공부&지윤) 퓨리에변환(detailed)\n\n\n신록예찬 \n\n\n\n\nJun 23, 2023\n\n\n(공부&지윤) 퓨리에변환4jy\n\n\n신록예찬 \n\n\n\n\nJun 14, 2023\n\n\n(공부&지윤) 추정\n\n\n신록예찬 \n\n\n\n\nMay 19, 2023\n\n\n(연구&보람) 신용카드거래 사기탐지 – Try2\n\n\n신록예찬 \n\n\n\n\nMay 19, 2023\n\n\n(연구&보람) 신용카드거래 사기탐지 – Try2변형\n\n\n신록예찬 \n\n\n\n\nMay 12, 2023\n\n\n(연구&보람) 신용카드거래 사기탐지 – Try1\n\n\n신록예찬 \n\n\n\n\nMay 12, 2023\n\n\n(연구&보람) 신용카드거래 사기탐지 – Try1변형\n\n\n신록예찬 \n\n\n\n\nMay 6, 2023\n\n\n(연구&보람) 신용카드거래 사기탐지 – Start\n\n\n신록예찬 \n\n\n\n\nApr 27, 2023\n\n\n(연구&서연) IT-STGCN – Toy Example Figure(Intro)\n\n\n최서연 \n\n\n\n\nApr 4, 2023\n\n\n(연구&지윤) 태양광자료분석\n\n\n신록예찬 \n\n\n\n\nApr 3, 2023\n\n\n(연구&지윤) 태양광자료분석 – 일사량자료정리\n\n\n임지윤, 신록예찬\n\n\n\n\nMar 18, 2023\n\n\n(연구&서연) IT-STGCN – SimualtionPlanner-Tutorial\n\n\nSEOYEON CHOI\n\n\n\n\nMar 17, 2023\n\n\n(연구&서연) IT-STGCN – ITSTGCN-Tutorial\n\n\nSEOYEON CHOI\n\n\n\n\nMar 1, 2023\n\n\n(공부&서연) 지수분포 가설검정\n\n\n신록예찬 \n\n\n\n\nJan 20, 2023\n\n\n(공부) 추정\n\n\n신록예찬 \n\n\n\n\nJan 15, 2023\n\n\n(공부) CGSP – Chap 12.4: Node Subsampling for PSD Estimation\n\n\n신록예찬 \n\n\n\n\nJan 12, 2023\n\n\n(공부&서연) 지수분포 평균검정\n\n\n신록예찬 \n\n\n\n\nDec 30, 2022\n\n\n(연구&서연) IT-STGCN – Toy Example\n\n\n신록예찬 \n\n\n\n\nDec 29, 2022\n\n\n(연구&서연) IT-STGCN – Tables\n\n\n신록예찬 \n\n\n\n\nDec 29, 2022\n\n\n(연구&서연) IT-STGCN – Tutorial\n\n\n신록예찬, 최서연\n\n\n\n\nDec 27, 2022\n\n\n(공부) CGSP – Chap 12.2 ~ 3: Power Spectral Density and its Estimators\n\n\n신록예찬 \n\n\n\n\nDec 24, 2022\n\n\n(공부) CGSP – Chap 8.3: Discrete Fourier Transform\n\n\n신록예찬 \n\n\n\n\nDec 23, 2022\n\n\n(공부) 리뷰 – EbayesThresh: R Programs for Empirical Bayes Thresholding\n\n\n신록예찬 \n\n\n\n\nSep 21, 2022\n\n\n(공부) 파이토치 라이트닝 선형회귀\n\n\n최규빈 \n\n\n\n\nDec 10, 2021\n\n\n(연구&교수님) HST example 3\n\n\n신록예찬 \n\n\n\n\nOct 29, 2021\n\n\n(연구&교수님) HST example 3, 파이썬으로 변경\n\n\n신록예찬 \n\n\n\n\nSep 18, 2021\n\n\n(연구&교수님) hst plots\n\n\n신록예찬 \n\n\n\n\nAug 15, 2021\n\n\n(연구&교수님) HST example 3\n\n\n신록예찬 \n\n\n\n\nAug 9, 2021\n\n\n(연구&교수님) HST example 1, Appendix 추가 (1)\n\n\n신록예찬 \n\n\n\n\nAug 9, 2021\n\n\n(연구&교수님) HST example 1, Appendix 추가 (2)\n\n\n신록예찬 \n\n\n\n\nAug 9, 2021\n\n\n(연구&교수님) HST example 2 (1)\n\n\n신록예찬 \n\n\n\n\nAug 9, 2021\n\n\n(연구&교수님) HST example 2 (2)\n\n\n신록예찬 \n\n\n\n\nAug 9, 2021\n\n\n(연구&교수님) HST example 2 (3)\n\n\n신록예찬 \n\n\n\n\nAug 9, 2021\n\n\n(연구&교수님) HST example 2 (4)\n\n\n신록예찬 \n\n\n\n\nAug 9, 2021\n\n\n(연구&교수님) HST example 2 (5)\n\n\n신록예찬 \n\n\n\n\nAug 9, 2021\n\n\n(연구&교수님) HST example 2 (6)\n\n\n신록예찬 \n\n\n\n\nAug 9, 2021\n\n\n(연구&교수님) HST example 2 (7)\n\n\n신록예찬 \n\n\n\n\nAug 9, 2021\n\n\n(연구&교수님) HST example 2 이거로하자\n\n\n신록예찬 \n\n\n\n\nAug 5, 2021\n\n\n(연구&교수님) HST example 1, Appendix 추가\n\n\n신록예찬 \n\n\n\n\nAug 5, 2021\n\n\n(연구&교수님) HST example 2, Appendix 추가\n\n\n신록예찬 \n\n\n\n\nAug 5, 2021\n\n\n(연구&교수님) HST 이론개발\n\n\n신록예찬 \n\n\n\n\nAug 3, 2021\n\n\n(연구&교수님) HST example 2 (1)\n\n\n신록예찬 \n\n\n\n\nAug 3, 2021\n\n\n(연구&교수님) HST example 2 (2)\n\n\n신록예찬 \n\n\n\n\nAug 3, 2021\n\n\n(연구&교수님) HST example 2 (3)\n\n\n신록예찬 \n\n\n\n\nAug 3, 2021\n\n\n(연구&교수님) HST example 2 (4), 결과좋다\n\n\n신록예찬 \n\n\n\n\nAug 3, 2021\n\n\n(연구&교수님) HST example 2 (5)\n\n\n신록예찬 \n\n\n\n\nAug 3, 2021\n\n\n(연구&교수님) HST example 2 (6)\n\n\n신록예찬 \n\n\n\n\nAug 3, 2021\n\n\n(연구&교수님) HST example 2 (7)\n\n\n신록예찬 \n\n\n\n\nAug 3, 2021\n\n\n(연구&교수님) HST example 2 (8)\n\n\n신록예찬 \n\n\n\n\nAug 2, 2021\n\n\n(연구&교수님) HST example 1 (1)\n\n\n신록예찬 \n\n\n\n\nAug 2, 2021\n\n\n(연구&교수님) HST example 1 (2)\n\n\n신록예찬 \n\n\n\n\nAug 2, 2021\n\n\n(연구&교수님) HST example 1 (3)\n\n\n신록예찬 \n\n\n\n\nAug 2, 2021\n\n\n(연구&교수님) HST example 1 (4)\n\n\n신록예찬 \n\n\n\n\nAug 2, 2021\n\n\n(연구&교수님) HST example 1 (5), 이것도 좋아\n\n\n신록예찬 \n\n\n\n\nAug 2, 2021\n\n\n(연구&교수님) HST example 1 (6)\n\n\n신록예찬 \n\n\n\n\nAug 2, 2021\n\n\n(연구&교수님) HST example 1 (7)\n\n\n신록예찬 \n\n\n\n\nAug 2, 2021\n\n\n(연구&교수님) HST example 1 (8), 결과좋음\n\n\n신록예찬 \n\n\n\n\nJul 27, 2021\n\n\n(연구&교수님) HST example 2\n\n\n신록예찬 \n\n\n\n\nJul 22, 2021\n\n\n(연구&교수님) HST example 1\n\n\n신록예찬 \n\n\n\n\nJul 14, 2021\n\n\n(연구&교수님) HST old exam (Python)\n\n\n신록예찬 \n\n\n\n\nJul 14, 2021\n\n\n(연구&교수님) HST old exam (R)\n\n\n신록예찬 \n\n\n\n\nApr 26, 2019\n\n\n(공부) 퓨리에변환\n\n\n신록예찬 \n\n\n\n\nJan 10, 2000\n\n\n(메모) DGX station 설정\n\n\n신록예찬 \n\n\n\n\nJan 9, 2000\n\n\n(메모) docker\n\n\n신록예찬 \n\n\n\n\nJan 8, 2000\n\n\n(메모) 주피터랩, 설정 및 몇가지 팁\n\n\n신록예찬 \n\n\n\n\nJan 7, 2000\n\n\n(메모) 줄리아 설치 및 실행\n\n\n신록예찬 \n\n\n\n\nJan 6, 2000\n\n\n(메모) 깃 익히기\n\n\n신록예찬 \n\n\n\n\nJan 5, 2000\n\n\n(메모) vi 익히기\n\n\n신록예찬 \n\n\n\n\nJan 4, 2000\n\n\n(메모) tmux\n\n\n신록예찬 \n\n\n\n\nJan 4, 2000\n\n\n(메모) 우분투 익히기\n\n\n신록예찬 \n\n\n\n\nJan 2, 2000\n\n\n(메모) 우분투 포맷 및 개발용 서버 셋팅2\n\n\n신록예찬 \n\n\n\n\nJan 1, 2000\n\n\n(메모) 우분투 포맷 및 개발용 서버 셋팅 (old)\n\n\n신록예찬 \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "공부/PyG/ls3.html",
    "href": "공부/PyG/ls3.html",
    "title": "(공부) PyG – lesson3: 미니배치",
    "section": "",
    "text": "Download notebook\n!wget https://raw.githubusercontent.com/miruetoto/yechan3/main/posts/2_Studies/PyG/ls3.ipynb\n\n\n미니배치\n\nimport torch_geometric\n\n\ndataset = torch_geometric.datasets.TUDataset(\n    root='/tmp/ENZYMES', \n    name='ENZYMES'\n)\n\n\n(ChatGPT) ENZYMES는 그래프 분류를 위한 벤치마크 데이터셋 중 하나입니다. 이 데이터셋은 600개의 그래프로 구성되어 있으며, 6개의 클래스로 분류됩니다. 각 그래프는 효소(enzyme) 분자의 구조를 나타내며, 그래프의 노드는 원자(atom)를 나타내고, 엣지(edge)는 원자 간의 연결을 나타냅니다. ENZYMES 데이터셋은 화학 및 생물 정보학 분야에서 그래프 분류 알고리즘의 성능을 평가하기 위해 사용될 수 있습니다. 그래프 분류 알고리즘은 주어진 그래프를 특정 클래스 레이블로 분류하는 작업을 수행하는데 사용됩니다. 예를 들어, ENZYMES 데이터셋의 그래프는 특정 효소 종류를 나타내며, 그래프 분류 알고리즘은 주어진 효소 그래프가 어떤 종류의 효소인지 예측할 수 있습니다. PyG를 사용하여 ENZYMES 데이터셋을 초기화하면 해당 데이터셋을 다운로드하고 필요한 전처리를 자동으로 수행할 수 있습니다. 그래프 데이터를 다루는 머신 러닝 모델을 구축하고 훈련시키기 위해 ENZYMES 데이터셋을 사용할 수 있습니다.\n\n\nlen(dataset) # 이 데이터셋에는 600개의 그래프가 있음\n\n600\n\n\n\ndataset.num_classes # 6개의 클래스\n\n6\n\n\n\ndataset.num_node_features # 각 노드에는 3개의 피처가 있음\n\n3\n\n\n- 600개의 그래프중 첫번째 그래프에 접근\n\ndataset[0]\n\nData(edge_index=[2, 168], x=[37, 3], y=[1])\n\n\n\nx=[37, 3]: \\(|{\\cal V}|=37\\), \\(f \\in \\mathbb{R}^3\\)\nedge_index=[2, 168]: \\(|{\\cal E}|=168\\)\n\n- 600개중에서 두번째 그래프에 접근\n\ndataset[1]\n\nData(edge_index=[2, 102], x=[23, 3], y=[1])\n\n\n\nx=[23, 3]: \\(|{\\cal V}|=23\\), \\(f \\in \\mathbb{R}^3\\)\nedge_index=[2, 102]: \\(|{\\cal E}|=102\\)\n\n- dataset \\(\\to\\) loader\n\nloader = torch_geometric.loader.DataLoader(dataset, batch_size=2, shuffle=False)\n\n\nfor i,batch in enumerate(loader):\n    if i&lt;5:\n        print(i,batch)\n\n0 DataBatch(edge_index=[2, 270], x=[60, 3], y=[2], batch=[60], ptr=[3])\n1 DataBatch(edge_index=[2, 182], x=[49, 3], y=[2], batch=[49], ptr=[3])\n2 DataBatch(edge_index=[2, 182], x=[47, 3], y=[2], batch=[47], ptr=[3])\n3 DataBatch(edge_index=[2, 384], x=[114, 3], y=[2], batch=[114], ptr=[3])\n4 DataBatch(edge_index=[2, 184], x=[55, 3], y=[2], batch=[55], ptr=[3])\n\n\n\n600개 그래프를 2개씩 묶어서 배치를 만듬\n\n\ndataset[0], dataset[1]\n\n(Data(edge_index=[2, 168], x=[37, 3], y=[1]),\n Data(edge_index=[2, 102], x=[23, 3], y=[1]))\n\n\n\n이게 합쳐져서 0 DataBatch(edge_index=[2, 270], x=[60, 3], y=[2], batch=[60], ptr=[3])\n\n\ndataset[2], dataset[3]\n\n(Data(edge_index=[2, 92], x=[25, 3], y=[1]),\n Data(edge_index=[2, 90], x=[24, 3], y=[1]))\n\n\n\n이게 합쳐져서 1 DataBatch(edge_index=[2, 182], x=[49, 3], y=[2], batch=[49], ptr=[3])"
  },
  {
    "objectID": "공부/PyG/ls6.html",
    "href": "공부/PyG/ls6.html",
    "title": "(공부) PyG – lesson6: GCN",
    "section": "",
    "text": "Kipf and Welling (2016): https://arxiv.org/abs/1609.02907\n\nimport torch\nimport torch_geometric"
  },
  {
    "objectID": "공부/PyG/ls6.html#예제",
    "href": "공부/PyG/ls6.html#예제",
    "title": "(공부) PyG – lesson6: GCN",
    "section": "예제",
    "text": "예제\n- data\n\nx = torch.tensor([[20],\n                  [21],\n                  [19],\n                  [1],\n                  [2],\n                  [1]], dtype=torch.float)\n\nedge_index = torch.tensor([[0, 1, 2, 0, 1, 2, 3, 4, 3, 5, 4, 5],\n                           [1, 0, 0, 2, 2, 1, 4, 3, 5, 3, 5, 4]], dtype=torch.long)\n\ny = torch.tensor([1,1,1,0,0,0], dtype=torch.int64)\ndata = torch_geometric.data.Data(x=x, edge_index=edge_index, y=y) \n#data.train_mask = torch.tensor([True,False,True,True,False,True])\n#data.test_mask = torch.tensor([False,True,False,False,True,False])\ndata\n\nData(x=[6, 1], edge_index=[2, 12], y=[6])\n\n\n- GCNConv\n\ngconv = torch_geometric.nn.GCNConv(1,4)\ngconv\n\nGCNConv(1, 4)\n\n\n\ngconv(data.x, data.edge_index)\n\ntensor([[ 11.6402, -15.0337, -13.0234, -15.7613],\n        [ 11.6402, -15.0337, -13.0234, -15.7613],\n        [ 11.6402, -15.0337, -13.0234, -15.7613],\n        [  0.7760,  -1.0022,  -0.8682,  -1.0508],\n        [  0.7760,  -1.0022,  -0.8682,  -1.0508],\n        [  0.7760,  -1.0022,  -0.8682,  -1.0508]], grad_fn=&lt;AddBackward0&gt;)\n\n\n\nlist(gconv.parameters())\n\n[Parameter containing:\n tensor([0., 0., 0., 0.], requires_grad=True),\n Parameter containing:\n tensor([[ 0.5820],\n         [-0.7517],\n         [-0.6512],\n         [-0.7881]], requires_grad=True)]\n\n\n\n_,W = list(gconv.parameters())\nW\n\nParameter containing:\ntensor([[ 0.5820],\n        [-0.7517],\n        [-0.6512],\n        [-0.7881]], requires_grad=True)\n\n\n\nA = torch.tensor([[0., 1., 1., 0., 0., 0.],\n                  [1., 0., 1., 0., 0., 0.],\n                  [1., 1., 0., 0., 0., 0.],\n                  [0., 0., 0., 0., 1., 1.],\n                  [0., 0., 0., 1., 0., 1.],\n                  [0., 0., 0., 1., 1., 0.]])\nAtilde = A+torch.eye(6)\nAtilde\n\ntensor([[1., 1., 1., 0., 0., 0.],\n        [1., 1., 1., 0., 0., 0.],\n        [1., 1., 1., 0., 0., 0.],\n        [0., 0., 0., 1., 1., 1.],\n        [0., 0., 0., 1., 1., 1.],\n        [0., 0., 0., 1., 1., 1.]])\n\n\n\nAtilde@data.x@W.T/3, gconv(data.x,data.edge_index)\n\n(tensor([[ 11.6402, -15.0337, -13.0234, -15.7613],\n         [ 11.6402, -15.0337, -13.0234, -15.7613],\n         [ 11.6402, -15.0337, -13.0234, -15.7613],\n         [  0.7760,  -1.0022,  -0.8682,  -1.0508],\n         [  0.7760,  -1.0022,  -0.8682,  -1.0508],\n         [  0.7760,  -1.0022,  -0.8682,  -1.0508]], grad_fn=&lt;DivBackward0&gt;),\n tensor([[ 11.6402, -15.0337, -13.0234, -15.7613],\n         [ 11.6402, -15.0337, -13.0234, -15.7613],\n         [ 11.6402, -15.0337, -13.0234, -15.7613],\n         [  0.7760,  -1.0022,  -0.8682,  -1.0508],\n         [  0.7760,  -1.0022,  -0.8682,  -1.0508],\n         [  0.7760,  -1.0022,  -0.8682,  -1.0508]], grad_fn=&lt;AddBackward0&gt;))\n\n\n- 즉 아래의 수식에서\n\\[H^{(l+1)} = \\sigma\\big(\\tilde{D}^{-1/2}\\tilde{A}\\tilde{D}^{-1/2}H^{(l)}W^{(l)}\\big).\\]\n\\(\\tilde{D}^{-1/2}\\tilde{A}\\tilde{D}^{-1/2}H^{(l)}W^{(l)}\\)를 계산하는 Layer가 torch_geometric.nn.GCNConv() 으로 구현되어있음."
  },
  {
    "objectID": "공부/PyG/ls2.html",
    "href": "공부/PyG/ls2.html",
    "title": "(공부) PyG – lesson2: 벤치마크 데이터셋 (train/test분리)",
    "section": "",
    "text": "import torch_geometric"
  },
  {
    "objectID": "공부/PyG/ls2.html#정보",
    "href": "공부/PyG/ls2.html#정보",
    "title": "(공부) PyG – lesson2: 벤치마크 데이터셋 (train/test분리)",
    "section": "정보",
    "text": "정보\n- 기본정보: ENZYMES dataset\n\n(ChatGPT) ENZYMES는 그래프 분류를 위한 벤치마크 데이터셋 중 하나입니다. 이 데이터셋은 600개의 그래프로 구성되어 있으며, 6개의 클래스로 분류됩니다. 각 그래프는 효소(enzyme) 분자의 구조를 나타내며, 그래프의 노드는 원자(atom)를 나타내고, 엣지(edge)는 원자 간의 연결을 나타냅니다. ENZYMES 데이터셋은 화학 및 생물 정보학 분야에서 그래프 분류 알고리즘의 성능을 평가하기 위해 사용될 수 있습니다. 그래프 분류 알고리즘은 주어진 그래프를 특정 클래스 레이블로 분류하는 작업을 수행하는데 사용됩니다. 예를 들어, ENZYMES 데이터셋의 그래프는 특정 효소 종류를 나타내며, 그래프 분류 알고리즘은 주어진 효소 그래프가 어떤 종류의 효소인지 예측할 수 있습니다. PyG를 사용하여 ENZYMES 데이터셋을 초기화하면 해당 데이터셋을 다운로드하고 필요한 전처리를 자동으로 수행할 수 있습니다. 그래프 데이터를 다루는 머신 러닝 모델을 구축하고 훈련시키기 위해 ENZYMES 데이터셋을 사용할 수 있습니다.\n\n\ndataset # 데이터셋 이름\n\nENZYMES(600)\n\n\n\nlen(dataset) # 이 데이터셋에는 600개의 그래프가 있음\n\n600\n\n\n\ndataset.num_classes # 6개의 클래스\n\n6\n\n\n\ndataset.num_node_features # 각 노드에는 3개의 피처가 있음\n\n3\n\n\n- 600개의 그래프중 첫번째 그래프에 접근\n\ndataset[0]\n\nData(edge_index=[2, 168], x=[37, 3], y=[1])\n\n\n\nx=[37, 3]: \\(|{\\cal V}|=37\\), \\(f \\in \\mathbb{R}^3\\)\nedge_index=[2, 168]: \\(|{\\cal E}|=168\\)"
  },
  {
    "objectID": "공부/PyG/ls2.html#traintest-분리",
    "href": "공부/PyG/ls2.html#traintest-분리",
    "title": "(공부) PyG – lesson2: 벤치마크 데이터셋 (train/test분리)",
    "section": "Train/Test 분리",
    "text": "Train/Test 분리\n- 600개의 그래프중 540를 train으로, 60개를 test로\n\ntrain_dataset = dataset[:540]\ntest_dataset = dataset[540:]"
  },
  {
    "objectID": "공부/PyG/ls2.html#정보-1",
    "href": "공부/PyG/ls2.html#정보-1",
    "title": "(공부) PyG – lesson2: 벤치마크 데이터셋 (train/test분리)",
    "section": "정보",
    "text": "정보\n\nChatGPT: Cora는 그래프 분류를 위한 벤치마크 데이터셋 중 하나로, PyG에서도 사용할 수 있습니다. 이 데이터셋은 기계 학습 및 정보 검색 분야에서 널리 사용되는 학술 논문들의 인용 네트워크를 나타냅니다. Cora 데이터셋은 컴퓨터 과학 분야의 논문을 대상으로 합니다. 각 논문은 그래프의 노드로 표현되며, 노드는 논문을 나타냅니다. 노드 간의 엣지는 논문들 사이의 인용 관계를 나타냅니다. 따라서 Cora 데이터셋은 논문의 텍스트 기반 정보와 인용 관계에 대한 그래프 구조를 제공합니다. Cora 데이터셋은 7개의 클래스로 분류되며, 각 논문은 특성 벡터(feature vector)로 표현됩니다. 이 특성 벡터에는 논문의 단어 등 다양한 정보가 포함될 수 있습니다. PyG를 사용하여 Cora 데이터셋을 초기화하면 해당 데이터셋을 다운로드하고 전처리를 자동으로 수행할 수 있습니다. 이를 통해 머신 러닝 모델을 훈련시켜 Cora 데이터셋의 논문을 분류하거나 다양한 작업을 수행할 수 있습니다.\n\n- 기본정보\n\nlen(dataset) # 하나의 그래프가 있음\n\n1\n\n\n\ndataset.num_classes # 7개의 클래스가 있음\n\n7\n\n\n\ndataset.num_node_features # 각 노드는 1433개의 특징이 있음. (논문에 포함된 단어등 다양한 특성이 담겨있을 수 있음) \n\n1433\n\n\n- 그래프에 접근\n\ndataset[0] # 기본정보\n\nData(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n\n\n\nx=[2708, 1433]: 2708개의 논문이 있고, 각 논문은 1433개의 특징벡터들로 이루어져 있음.\nedge_index=[2, 10556]: 논문간의 인용은 약 10556.\ny=[2708]:\n\n\ndataset[0].x.shape # 2708개의 논문이 있고 1433개의 특징벡터를 가짐\n\ntorch.Size([2708, 1433])\n\n\n\ndataset[0].y.unique() # 논문이 7개의 카테고리로 분류되는듯\n\ntensor([0, 1, 2, 3, 4, 5, 6])"
  },
  {
    "objectID": "공부/PyG/ls2.html#traintest-이미-분리되어-있음",
    "href": "공부/PyG/ls2.html#traintest-이미-분리되어-있음",
    "title": "(공부) PyG – lesson2: 벤치마크 데이터셋 (train/test분리)",
    "section": "Train/Test (이미 분리되어 있음)",
    "text": "Train/Test (이미 분리되어 있음)\n\ndataset[0].train_mask \n# dataset[0].train_mask 는 True, False로 이루어져 있는 길이가 2708(=노드수=논문수)인 벡터\n# 여기에서 True인 노드만 훈련함\n\ntensor([ True,  True,  True,  ..., False, False, False])\n\n\n\ndataset[0].train_mask.sum() # 140개의 노드만 훈련함? \n\ntensor(140)\n\n\n\ndataset[0].val_mask.sum() # val은 500개의 노드?\n\ntensor(500)\n\n\n\ndataset[0].test_mask.sum() # test set은 1000?\n\ntensor(1000)"
  },
  {
    "objectID": "공부/2023-02-14-(공부&서연) 지수분포 평균검정.html",
    "href": "공부/2023-02-14-(공부&서연) 지수분포 평균검정.html",
    "title": "(공부&서연) 지수분포 평균검정",
    "section": "",
    "text": "using Distributions, Plots\n\n다음의 분포를 따르는\n\n\\(f(x; \\theta) = \\theta \\exp (-x\\theta )I(x&gt;0)\\)\n\n모집단으로부터 랜덤표본 \\(X_1,\\dots,X_n\\)을 이용하여 \\(\\theta\\)에 대한 신뢰구간을 구하고, 다음 가설\n\n\\(H_0: \\theta = \\theta_0\\) vs \\(H_1:\\theta \\neq \\theta_0\\)\n\n을 검정하고자 한다. 다음에 답하라.\n(a) \\(\\theta\\)에 대한 적절한 추축변량을 구하고, 해당 추축변량의 분포를 명시하라.\n(풀이)\n추축변량은 \\(2n\\bar{X}\\theta\\) 이며 분포는 자유도가 \\(2n\\)인 카이제곱분포를 따름. 왜냐하면\n\n\\(X_1 \\sim \\text{Exp}\\) with mean \\(1/\\theta\\)\n\\(2X_1\\theta \\sim \\text{Exp}\\) with mean \\(2\\)\n\\(2n\\bar{X}\\theta \\sim \\chi^2(2n)\\) (왜? 평균이2인 지수분포를 \\(n\\)번 더하면 자유도가 \\(2n\\)인 카이제곱분포가 되므로. –&gt; 참고)\n\n이기 떄문에.\n(시뮬레이션)\n\nn = 10\nθ = 2\npivotal_variable = [mean(rand(Exponential(1/2),n))*2*n*θ for i in 1:140000]\n# pivotal_variable = 추축변량\n\n140000-element Vector{Float64}:\n 19.866862184254465\n 17.492982610528998\n 13.463211578260314\n 19.472994478042697\n 13.424495255444352\n 21.744281289967418\n 22.929701779207697\n 13.561641745647645\n 25.277641996704048\n 16.566359730027052\n 19.550767074240074\n  9.914621718787568\n 11.857966801675106\n  ⋮\n 38.05226144210052\n 17.120691971399836\n 21.66831336505733\n 26.476356317147957\n 21.930886178263727\n 18.33570158249295\n 22.39822061516168\n 27.42899896779973\n 14.770009603430982\n 13.776401174299512\n 21.511825086436673\n 21.867878699644073\n\n\n\nhistogram(pivotal_variable)\nhistogram!(rand(Chisq(2*n),140000))\n\n\n\n\n\n\n\n\n\n추축변량은 자유도 \\(2n\\)인 카이제곱분포를 따름\n\n(b) \\(\\theta\\)에 대한 95% 신뢰구간을 구하라.\n(풀이)\n\\(P\\left(\\chi^2_{0.025}(2n) \\leq 2n\\bar{X}\\theta \\leq \\chi^2_{0.975}(2n) \\right) =0.95\\)\nThus the CI of \\(\\theta\\): \\(\\left(\\frac{\\chi^2_{0.025}(2n)}{2n\\bar{X}},\\frac{\\chi^2_{0.975}(2n)}{2n\\bar{X}} \\right)\\)\n(시뮬레이션)\n\nl = quantile(Chisq(2*n),0.025) ./ (pivotal_variable./θ)\nu = quantile(Chisq(2*n),0.975) ./ (pivotal_variable./θ)\n[l[i]&lt;θ&lt;u[i] for i in 1:140000] |&gt; mean\n\n0.95035\n\n\n(c) \\(P(X&gt;1)\\)에 대한 95% 신뢰구간\n(풀이)\n\\(P(X&gt;1) = \\int_{1}^{\\infty}\\theta \\exp(-x\\theta)dx =\\left[e^{-x\\theta} \\right]_1^{\\infty}=e^{-\\theta}\\)\nThus the CI of \\(P(X&gt;1)\\): \\(\\left(\\exp\\big(-\\frac{\\chi^2_{0.975}(2n)}{2n\\bar{X}}\\big),\\exp\\big(-\\frac{\\chi^2_{0.025}(2n)}{2n\\bar{X}}\\big) \\right)\\)\n(시뮬레이션)\n검토1: \\(P(X&gt;1)=E[I(X&gt;1)]=e^{-\\theta}\\) 임을 검토\n\nexp(-θ)\n\n0.1353352832366127\n\n\n\nmean(rand(Exponential(1/2),1000000) .&gt; 1)\n\n0.135678\n\n\n검토2: 신뢰구간\n\nu2 = exp.(-l)\nl2 = exp.(-u)\n[l2[i]&lt;exp(-θ)&lt;u2[i] for i in 1:140000] |&gt; mean\n\n0.95035\n\n\n(d)\n\\(\\Omega = \\{\\theta: \\theta&gt;0\\}\\), \\(\\Omega_0 =\\{2\\}\\)\n(e) \\(\\theta\\)의 가능도 함수를 기술하시오\n(풀이)\n\\(L(\\theta)=\\theta^n\\exp(-\\theta n\\bar{x})\\)\n(f) \\(\\theta\\)의 \\(\\Omega\\)에서의 최대가능도 추정량과 \\(\\Omega_0\\)에서의 최대가능도 추정량을 구하시오\n(풀이)\n\\(\\hat{\\theta}^{\\Omega}=1/\\bar{x}\\), \\(\\hat{\\theta}^{\\Omega_0}=\\theta_0\\)\n(g) 일반화 가능도 비1 \\(\\Lambda\\)를 구하시오.\n1 이게 뭐지..?(풀이)\n\\(\\frac{L\\big(\\hat{\\theta}^{\\Omega}\\big)}{L\\big(\\hat{\\theta}^{\\Omega_0}\\big)}=\\frac{1/\\bar{x}^n\\exp(-n)}{\\theta_0^n\\exp(-\\theta_0n\\bar{x})}\\)\n(h) 유의수준 \\(\\alpha\\)의 가능도비 검정법의 기각역을 \\(\\chi^2\\)의 분위수를 사용하여 표현하시오.\n(풀이)"
  },
  {
    "objectID": "공부/2023-10-26-(공부) Julia -- Vector.html",
    "href": "공부/2023-10-26-(공부) Julia -- Vector.html",
    "title": "(공부) Julia – Vector",
    "section": "",
    "text": "- Python의 리스트와 비슷하기도 하고, numpy array와 비슷하기도 함"
  },
  {
    "objectID": "공부/2023-10-26-(공부) Julia -- Vector.html#a.-더하기",
    "href": "공부/2023-10-26-(공부) Julia -- Vector.html#a.-더하기",
    "title": "(공부) Julia – Vector",
    "section": "A. 더하기",
    "text": "A. 더하기\n- 예시1 – 길이가 같은 벡터의 합\n\na = [1,2] \nb = [-1,-2]\na + b\n\n2-element Vector{Int64}:\n 0\n 0\n\n\n\n# 사실아래도 가능\na .+ b\n\n2-element Vector{Int64}:\n 0\n 0\n\n\n- 예시2 – 벡터+스칼라 (실패)\n\na = [1,2]\na + 1 # 브로드캐스팅 실패\n\nLoadError: MethodError: no method matching +(::Vector{Int64}, ::Int64)\nFor element-wise addition, use broadcasting with dot syntax: array .+ scalar\n\n\u001b[0mClosest candidates are:\n\u001b[0m  +(::Any, ::Any, \u001b[91m::Any\u001b[39m, \u001b[91m::Any...\u001b[39m)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4moperators.jl:578\u001b[24m\u001b[39m\n\u001b[0m  +(\u001b[91m::T\u001b[39m, ::T) where T&lt;:Union{Int128, Int16, Int32, Int64, Int8, UInt128, UInt16, UInt32, UInt64, UInt8}\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4mint.jl:87\u001b[24m\u001b[39m\n\u001b[0m  +(\u001b[91m::Base.TwicePrecision\u001b[39m, ::Number)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4mtwiceprecision.jl:290\u001b[24m\u001b[39m\n\u001b[0m  ...\n\n\n- 예시3 – 벡터+스칼라 (성공)\n\na = [1,2]\na .+ 1 \n\n2-element Vector{Int64}:\n 2\n 3"
  },
  {
    "objectID": "공부/2023-10-26-(공부) Julia -- Vector.html#b.-곱셉",
    "href": "공부/2023-10-26-(공부) Julia -- Vector.html#b.-곱셉",
    "title": "(공부) Julia – Vector",
    "section": "B. 곱셉",
    "text": "B. 곱셉\n- 예시1 – 벡터*스칼라 (성공)\n\na = [1,2]\na*2\n\n2-element Vector{Int64}:\n 2\n 4\n\n\n\n# 사실 아래도 가능\na .* 2\n\n2-element Vector{Int64}:\n 2\n 4\n\n\n\n# 사실 아래도 가능\n2a\n\n2-element Vector{Int64}:\n 2\n 4\n\n\n- 예시2 – 하다마르곱\n\na = [1,2]\nb = [2,3] \na .* b \n\n2-element Vector{Int64}:\n 2\n 6\n\n\n- 예시3 – 예시2를 응용\n\na = [1,'a']\nb = [3,'b']\na .* b\n\n2-element Vector{Any}:\n 3\n  \"ab\""
  },
  {
    "objectID": "공부/2023-10-26-(공부) Julia -- Vector.html#c.-제곱연산",
    "href": "공부/2023-10-26-(공부) Julia -- Vector.html#c.-제곱연산",
    "title": "(공부) Julia – Vector",
    "section": "C. 제곱연산",
    "text": "C. 제곱연산\n- 예시1\n\na = [1,2]\na .^ 2\n\n2-element Vector{Int64}:\n 1\n 4\n\n\n- 예시2\n\na = [\"a\", \"bb\"] \na .^ 2 \n\n2-element Vector{String}:\n \"aa\"\n \"bbbb\""
  },
  {
    "objectID": "공부/2023-10-26-(공부) Julia -- Vector.html#d.-내적",
    "href": "공부/2023-10-26-(공부) Julia -- Vector.html#d.-내적",
    "title": "(공부) Julia – Vector",
    "section": "D. 내적",
    "text": "D. 내적\n- 예시\n\nusing LinearAlgebra\n\n\n[1,2,3] ⋅ [1,2,3]\n\n14\n\n\n\ndot([1,2,3],[1,2,3])\n\n14\n\n\n\n[1,2,3]' * [1,2,3]\n\n14"
  },
  {
    "objectID": "공부/2023-10-26-(공부) Julia -- Vector.html#a.-append",
    "href": "공부/2023-10-26-(공부) Julia -- Vector.html#a.-append",
    "title": "(공부) Julia – Vector",
    "section": "A. append!",
    "text": "A. append!\n- 예시\n\na = [1,2,3]\nb = [4] \nappend!(a,b)\n\n4-element Vector{Int64}:\n 1\n 2\n 3\n 4\n\n\n\na,b\n\n([1, 2, 3, 4], [4])\n\n\n\nappend!는 numpy에서 concat 느낌"
  },
  {
    "objectID": "공부/2023-10-26-(공부) Julia -- Vector.html#b.-push",
    "href": "공부/2023-10-26-(공부) Julia -- Vector.html#b.-push",
    "title": "(공부) Julia – Vector",
    "section": "B. push!",
    "text": "B. push!\n- 예시\n\na = [1,2,3]\npush!(a,4)\n\n4-element Vector{Int64}:\n 1\n 2\n 3\n 4\n\n\n\npush!는 list에서 append 느낌"
  },
  {
    "objectID": "공부/2023-10-26-(공부) Julia -- Vector.html#a.-cat",
    "href": "공부/2023-10-26-(공부) Julia -- Vector.html#a.-cat",
    "title": "(공부) Julia – Vector",
    "section": "A. cat",
    "text": "A. cat\n\nnp.concat, np.stack 등이 합쳐진 형태\n\n- 예시1\n\na = [1,2,3]\nb = [4] \n\n1-element Vector{Int64}:\n 4\n\n\n\ncat(a,b,dims=1) # np.concat 과 비슷\n\n4-element Vector{Int64}:\n 1\n 2\n 3\n 4\n\n\n- 예시2\n\na = [1,2,3]\nb = -a\n\n3-element Vector{Int64}:\n -1\n -2\n -3\n\n\n\ncat(a,b,dims=2) \n\n3×2 Matrix{Int64}:\n 1  -1\n 2  -2\n 3  -3\n\n\n\ncat(a,b,dims=1)\n\n6-element Vector{Int64}:\n  1\n  2\n  3\n -1\n -2\n -3\n\n\n- 예시3\n\na = [1 2 3\n     3 4 5]\nb = -a\n\n2×3 Matrix{Int64}:\n -1  -2  -3\n -3  -4  -5\n\n\n\ncat(a,b,dims=1)\n\n4×3 Matrix{Int64}:\n  1   2   3\n  3   4   5\n -1  -2  -3\n -3  -4  -5\n\n\n\ncat(a,b,dims=2)\n\n2×6 Matrix{Int64}:\n 1  2  3  -1  -2  -3\n 3  4  5  -3  -4  -5\n\n\n\ncat(a,b,dims=3)\n\n2×3×2 Array{Int64, 3}:\n[:, :, 1] =\n 1  2  3\n 3  4  5\n\n[:, :, 2] =\n -1  -2  -3\n -3  -4  -5\n\n\n- 예시4 – 아래도 가능\n\na = [1,2,3]\nb = 2 \ncat(a,b,dims=1)\n\n4-element Vector{Int64}:\n 1\n 2\n 3\n 2\n\n\n- 예시5 – 아래도 가능\n\na = reshape(1:4, (2,2))\nb = [3,4]\na,b\n\n([1 3; 2 4], [3, 4])\n\n\n\ncat(a,b,dims=2)\n\n2×3 Matrix{Int64}:\n 1  3  3\n 2  4  4"
  },
  {
    "objectID": "공부/2023-10-26-(공부) Julia -- Vector.html#b.-를-이용한-결합",
    "href": "공부/2023-10-26-(공부) Julia -- Vector.html#b.-를-이용한-결합",
    "title": "(공부) Julia – Vector",
    "section": "B. []를 이용한 결합",
    "text": "B. []를 이용한 결합\n- 예시1\n\na = [1,2,3]\nb = -a\na,b\n\n([1, 2, 3], [-1, -2, -3])\n\n\n\n[a b]\n\n3×2 Matrix{Int64}:\n 1  -1\n 2  -2\n 3  -3\n\n\n\n[a\n b]\n\n6-element Vector{Int64}:\n  1\n  2\n  3\n -1\n -2\n -3\n\n\n- 예시2\n\na = [1,2,3] \nb = 4\n\n4\n\n\n\n[a \n b]\n\n4-element Vector{Int64}:\n 1\n 2\n 3\n 4\n\n\n- 예시3\n\na = [1 2; 3 4]\nb = [0,0] \n\n2-element Vector{Int64}:\n 0\n 0\n\n\n\n[a b]\n\n2×3 Matrix{Int64}:\n 1  2  0\n 3  4  0"
  },
  {
    "objectID": "공부/2023-05-13-(공부&지윤) 추정.html",
    "href": "공부/2023-05-13-(공부&지윤) 추정.html",
    "title": "(공부&지윤) 추정",
    "section": "",
    "text": "- 비편향추정량(UB)란 \\(\\theta\\)의 추정량 중\n\\[\\forall \\theta\\in \\Theta:~ E(\\hat{\\theta})=\\theta\\]\n를 만족하는 추정량 \\(\\hat{\\theta}\\)을 의미한다.\n- (예시) 아래와 같은 상황을 가정하자.\n\\[X_n \\overset{iid}{\\sim} N(\\theta,1)\\]\n여기에서\n\n\\(\\hat{\\theta}_1=0\\) 은 \\(\\theta=0\\) 일 경우에는 \\(E(\\hat{\\theta})=\\theta\\) 를 만족하지만 그 외의 경우에는 \\(E(\\hat{\\theta})\\neq\\theta\\) 이므로 UB가 아니다.\n\\(\\hat{\\theta}_2=X_1\\) 은 UB이다.\n\\(\\hat{\\theta}_3=\\frac{X_1+X_2}{2}\\) 역시 UB이다.\n\\(\\hat{\\theta}_4=X_1+X_2-X_3\\) 역시 UB이다.\n\\(\\hat{\\theta}_5=-99X_1+100X_2\\) 역시 UB이다.\n\\(\\hat{\\theta}_6=\\frac{X_1+0}{2}\\) 은 1과 동일한 이유로 UB가 아니다.\n\\(\\hat{\\theta}_7=\\bar{X}\\)는 UB이다.\n\\(\\hat{\\theta}_8=w_1X_1+\\dots+w_nX_n\\) ,where \\(\\sum_{i=1}^{n}w_i=1\\) 형태의 estimator는 모두 UB이다.\n\n- 최소분산비편향추정량(MVUE)란 \\(\\theta\\)에 대한 비편향추정량을 모아놓은 집합 \\(\\hat{\\Theta}_{UB}\\) 에서 최소분산을 가지는 추정량을 의미한다. MVUE를 구하는 방법은 아래와 같다.\n\n\\(\\theta\\)에 대한 모든 비편향추정량을 구한다. 즉 집합 \\(\\hat{\\Theta}_{UB}\\)를 구한다. 그리고 \\(\\forall \\hat{\\theta} \\in \\hat{\\Theta}_{UB}\\) 에 대하여 \\(V(\\hat{\\theta})\\) 를 구한 뒤 \\(V(\\hat{\\theta})\\)가 가장 작은 \\(\\hat{\\theta}\\)를 선택한다.\n\n예를들어 위의 예제에서 \\(V(\\hat{\\theta}_2)=1\\) 이고 \\(V(\\hat{\\theta}_3)=\\frac{1}{4}+\\frac{1}{4}=\\frac{1}{2}\\) 이므로 \\(\\hat{\\theta}_3\\) 이 더 좋은 추정량이라 볼 수 있다.\n- (의문) 왜 비편향추정량만 모아서 그중에서 최소분산을 구할까?\n\n\\(\\hat{\\theta}_1\\)와 같은 추정량은 \\(V(\\hat{\\theta}_1)=0\\) 이므로 그냥 최소분산을 만족한다. 따라서 이러한 추정량은 제외해야지 게임이 성립함.\n\n- 불만: 아래의 방법으로 구하는건 거의 불가능하지 않나?\n\n\\(\\theta\\)에 대한 모든 비편향추정량을 구한다. 즉 집합 \\(\\hat{\\Theta}_{UB}\\)를 구한다. 그리고 \\(\\forall \\hat{\\theta} \\in \\hat{\\Theta}_{UB}\\) 에 대하여 \\(V(\\hat{\\theta})\\) 를 구한 뒤 \\(V(\\hat{\\theta})\\)가 가장 작은 \\(\\hat{\\theta}\\)를 선택한다.\n\n- 이론: 크래머라오 하한값(편의상 \\(L^\\star\\)이라고 하자)이라고 있는데, 이는 \\({\\Theta}_{UB}\\)에 존재하는 모든 추정량에 대한 분산의 하한값을 제공한다.1 즉 아래가 성립한다.\n1 (사실 \\({\\Theta}_{UB}\\)가 아닌 집합에 대해서도 하한값을 제공함, 그런데 교재에서는 \\({\\Theta}_{UB}\\)에 대한 하한값만 다루는듯\n\\(L^\\star\\) is Cramer-Rao lower bound \\(\\Rightarrow\\) \\(\\forall \\hat{\\theta} \\in {\\Theta}_{UB}:~ V(\\hat{\\theta}) \\geq L^\\star\\)\n\n역은 성립하지 않음을 주의하자. 즉 아래를 만족하는 \\(L\\)이 존재할 수 있다.\n\n\\(V(\\hat{\\theta}) \\geq L &gt; L^\\star\\) for some \\(\\hat{\\theta} \\in \\Theta_{UB}\\)\n\n- 위의 이론을 이용하면 아래의 논리전개를 펼 수 있다.\n\n\\(L^\\star\\)를 구한다.\n왠지 MVUE가 될 것 같은 \\(\\hat{\\theta}\\)을 하나 찍고 그것의 분산 \\(V(\\hat{\\theta})\\)를 구한다.\n만약에 \\(V(\\hat{\\theta})=L^\\star\\)를 만족하면 그 \\(\\hat{\\theta}\\)이 MVUE라고 주장할 수 있다.\n\n- 위의 논리전개에 대한 불만 [p.212]\n\n\\(V(\\hat{\\theta})=L^\\star\\) 이길 기도해야함.\n\\(\\forall \\hat{\\theta} \\in {\\Theta}_{UB}:~ V(\\hat{\\theta}) \\geq L &gt; L^\\star\\) 와 같은 \\(L\\)이 존재하는 경우는 쓸 수 없음.\n\n- 또 다른 방법: 완비충분통계량을 이용함\n\n\n아래와 같은 상황을 가정하자.\n\\[ X_1,\\dots,X_n \\overset{iid}{\\sim} P_{\\theta}\\]\n- 충분통계량(SS)의 느낌: “이 값만 기억하면 \\(\\theta\\)를 추정하는데 무난할듯”\n- 예시1: \\(X_1 \\sim N(\\theta,1)\\)\n\n\\(X_1\\)은 \\(\\theta_1\\) 의 SS. (하나밖에 없으니 그거라도 기억해야지)\n즉 \\(\\hat{\\theta}=X_1\\)은 \\(\\theta\\)의 SS\n\n- 예시2: \\(X_1,X_2 \\sim N(\\theta,1)\\)\n\n당연히 \\(\\hat{\\boldsymbol \\theta}=(X_1,X_2)\\)는 \\(\\theta\\)의 SS (둘다 기억하면 당연히 \\(\\theta\\)를 추정함에 있어서 충분함)\n그렇지만 좀 더 생각해보면 굳이 값 두개를 기억하기보다 \\(\\frac{1}{2}(X_1+X_2)\\)의 값만 기억해도 왠지 충분할것 같음. 따라서 \\(\\hat{\\theta} = \\frac{1}{2}(X_1+X_2)\\) 역시 \\(\\theta\\)의 SS 일듯\n그런데 좀 더 생각해보니까 \\(X_1+X_2\\)의 값만 기억해도 \\(\\frac{1}{2}(X_1+X_2)\\)를 나중에 만들 수 있음 (1/2만 곱하면 되니까) 따라서 \\(X_1+X_2\\)만 기억해도 왠지 충분할 것 같음. 따라서 \\(\\hat{\\theta}=X_1+X_2\\) 역시 \\(\\theta\\)의 SS 일듯\n\n- 예시3: \\(X_1,\\dots,X_n \\sim N(\\theta,1)\\)\n\n당연히 \\(\\hat{\\boldsymbol \\theta}=(X_1,X_2,\\dots,X_n)\\)은 \\(\\theta\\)의 SS.\n하지만 \\(n\\)개의 숫자를 기억할 필요 없이 \\(\\sum_{i=1}^{n} X_i\\) 하나의 숫자만 기억해도 왠지 충분할듯. 그래서 \\(\\hat{\\theta} = \\sum_{i=1}^{n} X_i\\) 역시 \\(\\theta\\)의 SS 일듯\n\n- SS에 대한 직관1\n\n기억할 숫자가 적을수록 유리 -&gt; MSS의 개념\n충분통계량의 1:1은 충분통계량 (\\(\\frac{1}{2}(X_1+X_2)\\)을 기억하면 충분한 상황이라면, \\(X_1+X_2\\)를 기억해도 충분하니까..)\n\n- 예시4: \\(X_1,X_2 \\sim {\\cal B}er(\\theta)\\)\n\n당연히 \\(\\hat{\\boldsymbol \\theta}=(X_1,X_2)\\)은 \\(\\theta\\)의 SS.\n그리고 \\(\\hat{\\theta}=X_1+X_2\\) 역시 \\(\\theta\\) SS 일듯.\n두개보다 한개가 유리하니까 둘다 SS이면 \\((X_1,X_2)\\)보다 \\(X_1+X_2\\)가 더 좋은 SS.\n\\(X_1\\)은 SS가 아닐듯. \\(p\\)를 추정함에 있어서 \\(X_1\\)만 가지고서는 충분하지 않아보임\n\\(X_2\\)도 SS가 아닐듯.\n\n왠지 충분할 것 같은 느낌의 정의\n아래와 같은 상황을 가정하자.\n\\[X_1,X_2 \\sim {\\cal B}er(\\theta)\\]\n- 일반적으로\n\n\\(P((X_1,X_2)=(0,0))=P(X_1=0,X_2=0)=(1-\\theta)^2\\)\n\\(P((X_1,X_2)=(0,1))=P(X_1=0,X_2=1)=\\theta(1-\\theta)\\)\n\\(P((X_1,X_2)=(1,0))=P(X_1=1,X_2=0)=(1-\\theta)^2\\)\n\\(P((X_1,X_2)=(1,1))=P(X_1=1,X_2=1)=\\theta^2\\)\n\n와 같은 확률들은 \\(\\theta\\)가 unknown일 때 하나의 숫자로 정할 수 없다. 예를들어 \\(\\theta=0\\) 이라면 아래와 같을 것이고\n\n\\(P((X_1,X_2)=(0,0))=P(X_1=0,X_2=0)=1\\)\n\\(P((X_1,X_2)=(0,1))=P(X_1=0,X_2=1)=0\\)\n\\(P((X_1,X_2)=(1,0))=P(X_1=1,X_2=0)=0\\)\n\\(P((X_1,X_2)=(1,1))=P(X_1=1,X_2=1)=0\\)\n\n\\(\\theta=1/2\\) 이라면 아래와 같을 것이다.\n\n\\(P((X_1,X_2)=(0,0))=P(X_1=0,X_2=0)=1/4\\)\n\\(P((X_1,X_2)=(0,1))=P(X_1=0,X_2=1)=1/4\\)\n\\(P((X_1,X_2)=(1,0))=P(X_1=1,X_2=0)=1/4\\)\n\\(P((X_1,X_2)=(1,1))=P(X_1=1,X_2=1)=1/4\\)\n\n즉 \\(X_1,X_2\\)의 결합확률분포는 \\(\\theta\\)가 변함에 따라 같이 변화한다. 이를 이용해 우리는 \\(X_1,X_2\\)의 결합확률분포에서 관찰한 샘플들을 이용하여 \\(\\theta\\)의 값을 역으로 추론한다.\n- 만약에 어떠한 “특수한 정보를 알고 있을 경우” \\(X_1,X_2\\)의 결합확률분포를 완벽하게 기술할 수 있을 때를 가정해보자.\n- 경우1: \\(\\theta\\)를 알고 있을 경우. \\((X_1,X_2)\\)의 조인트를 완벽하게 기술할 수 있다. 예를들어 \\(\\theta=1/2\\)일 경우는 아래와 같다.\n\n\\(P(X_1=0,X_2=0 | \\theta=1/2)=1/4\\)\n\\(P(X_1=0,X_2=1 | \\theta=1/2)=1/4\\)\n\\(P(X_1=1,X_2=0 | \\theta=1/2)=1/4\\)\n\\(P(X_1=1,X_2=1 | \\theta=1/2)=1/4\\)\n\n- 경우2: \\(X_1,X_2\\)의 realization을 알고 있을 경우. \\((X_1,X_2)\\)의 조인트를 완벽하게 기술할 수 있다. 예를들어 \\(X_1=0,X_2=1\\)일 경우는 아래와 같다.\n\n\\(P(X_1=0,X_2=0 | X_1=0,X_2=0)=0\\)\n\\(P(X_1=0,X_2=1| X_1=0,X_2=1)=0\\)\n\\(P(X_1=1,X_2=0| X_1=1,X_2=0)=1\\)\n\\(P(X_1=1,X_2=1| X_1=1,X_2=1)=0\\)\n\n- 경우3: \\((X_1+X_2)(\\omega)\\)의 realization을 알고 있을 경우. 이때도 매우 특이하게 \\((X_1,X_2)\\) 의 조인트를 완벽하게 기술할 수 있다.\ncase1: \\(X_1+X_2=0\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1+X_2=0)=1\\)\n\\(P(X_1=0,X_2=1| X_1+X_2=0)=0\\)\n\\(P(X_1=1,X_2=0| X_1+X_2=0)=0\\)\n\\(P(X_1=1,X_2=1| X_1+X_2=0)=0\\)\n\ncase2: \\(X_1+X_2=1\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1+X_2=1)=0\\)\n\\(P(X_1=0,X_2=1| X_1+X_2=1)=1/2\\)\n\\(P(X_1=1,X_2=0| X_1+X_2=1)=1/2\\)\n\\(P(X_1=1,X_2=1| X_1+X_2=1)=0\\)\n\ncase3: \\(X_1+X_2=2\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1+X_2=2)=0\\)\n\\(P(X_1=0,X_2=1| X_1+X_2=2)=0\\)\n\\(P(X_1=1,X_2=0| X_1+X_2=2)=0\\)\n\\(P(X_1=1,X_2=1| X_1+X_2=2)=1\\)\n\n- 경우4: \\(X_1\\)의 realization만 알고 있을 경우. 이때는 \\((X_1,X_2)\\) 의 조인트를 완벽하게 기술할 수 없다.\ncase1: \\(X_1=0\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1=0)=1-\\theta\\)\n\\(P(X_1=0,X_2=1| X_1=0)=\\theta\\)\n\\(P(X_1=1,X_2=0| X_1=0)=0\\)\n\\(P(X_1=1,X_2=1| X_1=0)=0\\)\n\ncase2: \\(X_1=1\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1=1)=0\\)\n\\(P(X_1=0,X_2=1| X_1=1)=0\\)\n\\(P(X_1=1,X_2=0| X_1=1)=1-\\theta\\)\n\\(P(X_1=1,X_2=1| X_1=1)=\\theta\\)\n\n- 종합해보면 경우1,경우2,경우3은 경우4와 구분되는 어떠한 공통점을 가지고 있다 볼 수 있다. 특징은 결합확률분포가 \\(\\theta\\)에 대한 함수로 표현되지 않는다는 것이다. 하나씩 살펴보면\n\n경우1: 당연히 \\(\\theta\\)를 줬으니까 \\((X_1,X_2)\\)의 조인트는 \\(\\theta\\)에 의존하지 않음.\n경우2: \\(X_1,X_2\\)를 줬음. \\((X_1,X_2)\\)의 조인트는 \\(\\theta\\)에 의존하지 않음.\n경우3: \\(X_1+X_2\\)를 줬음. \\((X_1,X_2)\\)의 조인트는 \\(\\theta\\)에 의존하지 않음.\n\n이렇게보면 경우1과 경우2,3은 또 다시 구분된다. 경우1은 \\(\\theta\\)에 대한 완전한 정보를 준 상황이므로 당연히 조인트는 \\(\\theta\\)에 의존하지 않는다. 경우2-3은 \\(\\theta\\)를 주지 않았음에도 조인트가 \\(\\theta\\)에 의존하지 않는 매우 특별해보이는 상황이다. 따라서 이를 통해서 유추하면\n\n경우2에서는 \\((X_1,X_2)\\) 가 경우3에서는 \\(X_1+X_2\\)가 \\(\\theta\\)에 대한 완전한 정보를 대신하고 있는것 아닐까?\n\n라는 생각이 든다. 정리하면\n\n경우2: \\((X_1,X_2)\\)을 주는 것은 \\(\\theta\\)의 값을 그냥 알려주는 것과 대등한 효과\n경우3: \\(X_1+X_2\\)를 주는 것은 \\(\\theta\\)의 값을 그냥 알려주는 것과 대등한 효과\n\n라고 해석할 수 있는데 이를 수식화 하면 아래와 같다.\n- 대충정의: 어떠한 통계량 \\(S\\)의 값을 줬을때, \\((X_1,X_2\\dots,X_n)\\)의 조인트가 \\(\\theta\\)에 의존하지 않으면 그 통계량 \\(S\\)를 \\(\\theta\\)의 충분통계량이라고 한다.\n- 충분통계량 구하는 방법\n\n지수족일때 구하는 방식이 있음! &lt;– 외우세여\n분해정리를 쓰는 경우. &lt;– 거의 안쓰는거같은데..\n1-2로도 잘 모르겠으면 충분통계량일듯한 애를 잡아와서 정의에 넣고 노가다로 때려맞춤. (문제가 디스크릿할때만 쓸것)\n\n\n\n\n- 충분통계량에 대한 realization을 알려주면 \\(\\theta\\)의 값을 그냥 알려주는 효과임. 그래서 충분통계량은 좋은 것임\n- 그런데 충분통계량에도 급이 있음. 아래와 같은 상황을 가정하자.\n\\[X_1,X_2 \\sim {\\cal B}er(\\theta)\\]\n이 경우\n\n\\((X_1,X_2)\\)는 SS\n\\(X_1+X_2\\)는 SS\n\n이지만 1은 두개의 숫자를 기억해야하고 2는 하나의 숫자만 기억하면 되니까 2가 더 좋음\n- 예비개념: 상태1과 상태2가 있다고 하자. 상태1에서 상태2로 가는 변화는 쉽지만, 상태2에서 상태1로 가는 변화는 어렵다고 할때, 상태1이 더 좋은 상태이다.\n\n두가지 상태 “500원을 가지고 있음”, “1000원을 가지고 있음” 을 고려하자. 1000원을 500원을 만드는 것은 쉽지만 500원을 1000원으로 만들기는 어렵다. 따라서 1000원이 더 좋은 상태이다.\n\n- 충분통계량의 급을 어떻게 구분할까? 아래의 상황에서\n\n\\((X_1,X_2)\\)는 SS\n\\(X_1+X_2\\)는 SS\n\n1을 이용하면 2를 만들 수 있지만, 2를 이용해서 1을 만들 수는 없음. 즉 \\(1\\to 2\\) 인 변환(=함수)는 가능하지만 \\(2\\to 1\\)로 만드는 변환(=함수)는 가능하지 않음. 예비개념을 잘 이해했다면 2가 더 좋은 상태라고 볼 수 있다.\n- 이를 확장하자. 어떠한 충분 통계량 \\(S^\\star\\)가 있다고 가정하자. 다른 모든 충분통계량 \\(S_1,S_2,S_3 \\dots\\)에서 \\(S^\\star\\)로 만드는 변환은 존재하는데 (함수는 존재하는데) 그 반대는 \\(S^\\star\\)의 전단사인 충분통계량만 가능하다고 하자. 그렇다면 \\(S^\\star\\)는 가장 좋은 충분통계량이라고 하며, 가장 적은 숫자만 기억하면 되는 충분통계량이라 볼 수 있다. 이러한 충분통계량을 MSS 라고 하자.\n\n\n\n- 충분통계량 \\(S\\)을 알려주면 (기븐하면) \\(\\theta\\)에 대한 완벽한 정보를 알려주는 셈이다. 따라서 \\(\\theta\\)를 추정하는 어떠한 추정량 \\(\\hat{\\theta}\\)도 충분통계량의 정보 \\(S\\)가 있다면 \\(\\hat{\\theta}\\)를 업그레이드할 수 있다고 볼 수 있다. (뭐 수틀리면 정보야 안쓰면 그만이니까 나빠질것은 없다)\n- 충분통계량을 줬을때 \\(\\hat{\\theta}\\)의 업그레이드 방법은\n\\[\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)\\]\n와 같이 할 수 있는데 이는 충분통계량 \\(S\\)의 정보를 받아서 어떠한 방식으로 업데이트된 \\(\\hat{\\theta}\\) 이므로 \\(S\\)의 함수라 해석할 수 있다.\n- 이론 (라오블랙웰, Thm, 4.5): \\(\\hat{\\theta}\\)가 UB일때 충분통계량의 값을 알려주면 \\(\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)\\)와 같이 \\(\\hat{\\theta}\\)를 업그레이드 할 수 있다.\n\n\n\n- 충분통계량 \\(S\\)을 알려주면 (기븐하면) \\(\\theta\\)에 대한 완벽한 정보를 알려주는 셈이다. 따라서 \\(\\theta\\)를 추정하는 어떠한 추정량 \\(\\hat{\\theta}\\)도 충분통계량의 정보 \\(S\\)가 있다면 \\(\\hat{\\theta}\\)를 업그레이드할 수 있다고 볼 수 있다. (뭐 수틀리면 정보야 안쓰면 그만이니까 나빠질것은 없다)\n- 충분통계량을 줬을때 \\(\\hat{\\theta}\\)의 업그레이드 방법은\n\\[\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)\\]\n와 같이 할 수 있는데 이는 충분통계량 \\(S\\)의 정보를 받아서 어떠한 방식으로 업데이트된 \\(\\hat{\\theta}\\) 이므로 \\(S\\)의 함수라 해석할 수 있다.\n- 이론 (라오블랙웰, Thm, 4.5): \\(\\hat{\\theta}\\)가 UB일때 충분통계량의 값을 알려주면 \\(\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)\\)와 같이 \\(\\hat{\\theta}\\)를 업그레이드 할 수 있다."
  },
  {
    "objectID": "공부/2023-05-13-(공부&지윤) 추정.html#충분통계량",
    "href": "공부/2023-05-13-(공부&지윤) 추정.html#충분통계량",
    "title": "(공부&지윤) 추정",
    "section": "",
    "text": "아래와 같은 상황을 가정하자.\n\\[ X_1,\\dots,X_n \\overset{iid}{\\sim} P_{\\theta}\\]\n- 충분통계량(SS)의 느낌: “이 값만 기억하면 \\(\\theta\\)를 추정하는데 무난할듯”\n- 예시1: \\(X_1 \\sim N(\\theta,1)\\)\n\n\\(X_1\\)은 \\(\\theta_1\\) 의 SS. (하나밖에 없으니 그거라도 기억해야지)\n즉 \\(\\hat{\\theta}=X_1\\)은 \\(\\theta\\)의 SS\n\n- 예시2: \\(X_1,X_2 \\sim N(\\theta,1)\\)\n\n당연히 \\(\\hat{\\boldsymbol \\theta}=(X_1,X_2)\\)는 \\(\\theta\\)의 SS (둘다 기억하면 당연히 \\(\\theta\\)를 추정함에 있어서 충분함)\n그렇지만 좀 더 생각해보면 굳이 값 두개를 기억하기보다 \\(\\frac{1}{2}(X_1+X_2)\\)의 값만 기억해도 왠지 충분할것 같음. 따라서 \\(\\hat{\\theta} = \\frac{1}{2}(X_1+X_2)\\) 역시 \\(\\theta\\)의 SS 일듯\n그런데 좀 더 생각해보니까 \\(X_1+X_2\\)의 값만 기억해도 \\(\\frac{1}{2}(X_1+X_2)\\)를 나중에 만들 수 있음 (1/2만 곱하면 되니까) 따라서 \\(X_1+X_2\\)만 기억해도 왠지 충분할 것 같음. 따라서 \\(\\hat{\\theta}=X_1+X_2\\) 역시 \\(\\theta\\)의 SS 일듯\n\n- 예시3: \\(X_1,\\dots,X_n \\sim N(\\theta,1)\\)\n\n당연히 \\(\\hat{\\boldsymbol \\theta}=(X_1,X_2,\\dots,X_n)\\)은 \\(\\theta\\)의 SS.\n하지만 \\(n\\)개의 숫자를 기억할 필요 없이 \\(\\sum_{i=1}^{n} X_i\\) 하나의 숫자만 기억해도 왠지 충분할듯. 그래서 \\(\\hat{\\theta} = \\sum_{i=1}^{n} X_i\\) 역시 \\(\\theta\\)의 SS 일듯\n\n- SS에 대한 직관1\n\n기억할 숫자가 적을수록 유리 -&gt; MSS의 개념\n충분통계량의 1:1은 충분통계량 (\\(\\frac{1}{2}(X_1+X_2)\\)을 기억하면 충분한 상황이라면, \\(X_1+X_2\\)를 기억해도 충분하니까..)\n\n- 예시4: \\(X_1,X_2 \\sim {\\cal B}er(\\theta)\\)\n\n당연히 \\(\\hat{\\boldsymbol \\theta}=(X_1,X_2)\\)은 \\(\\theta\\)의 SS.\n그리고 \\(\\hat{\\theta}=X_1+X_2\\) 역시 \\(\\theta\\) SS 일듯.\n두개보다 한개가 유리하니까 둘다 SS이면 \\((X_1,X_2)\\)보다 \\(X_1+X_2\\)가 더 좋은 SS.\n\\(X_1\\)은 SS가 아닐듯. \\(p\\)를 추정함에 있어서 \\(X_1\\)만 가지고서는 충분하지 않아보임\n\\(X_2\\)도 SS가 아닐듯.\n\n왠지 충분할 것 같은 느낌의 정의\n아래와 같은 상황을 가정하자.\n\\[X_1,X_2 \\sim {\\cal B}er(\\theta)\\]\n- 일반적으로\n\n\\(P((X_1,X_2)=(0,0))=P(X_1=0,X_2=0)=(1-\\theta)^2\\)\n\\(P((X_1,X_2)=(0,1))=P(X_1=0,X_2=1)=\\theta(1-\\theta)\\)\n\\(P((X_1,X_2)=(1,0))=P(X_1=1,X_2=0)=(1-\\theta)^2\\)\n\\(P((X_1,X_2)=(1,1))=P(X_1=1,X_2=1)=\\theta^2\\)\n\n와 같은 확률들은 \\(\\theta\\)가 unknown일 때 하나의 숫자로 정할 수 없다. 예를들어 \\(\\theta=0\\) 이라면 아래와 같을 것이고\n\n\\(P((X_1,X_2)=(0,0))=P(X_1=0,X_2=0)=1\\)\n\\(P((X_1,X_2)=(0,1))=P(X_1=0,X_2=1)=0\\)\n\\(P((X_1,X_2)=(1,0))=P(X_1=1,X_2=0)=0\\)\n\\(P((X_1,X_2)=(1,1))=P(X_1=1,X_2=1)=0\\)\n\n\\(\\theta=1/2\\) 이라면 아래와 같을 것이다.\n\n\\(P((X_1,X_2)=(0,0))=P(X_1=0,X_2=0)=1/4\\)\n\\(P((X_1,X_2)=(0,1))=P(X_1=0,X_2=1)=1/4\\)\n\\(P((X_1,X_2)=(1,0))=P(X_1=1,X_2=0)=1/4\\)\n\\(P((X_1,X_2)=(1,1))=P(X_1=1,X_2=1)=1/4\\)\n\n즉 \\(X_1,X_2\\)의 결합확률분포는 \\(\\theta\\)가 변함에 따라 같이 변화한다. 이를 이용해 우리는 \\(X_1,X_2\\)의 결합확률분포에서 관찰한 샘플들을 이용하여 \\(\\theta\\)의 값을 역으로 추론한다.\n- 만약에 어떠한 “특수한 정보를 알고 있을 경우” \\(X_1,X_2\\)의 결합확률분포를 완벽하게 기술할 수 있을 때를 가정해보자.\n- 경우1: \\(\\theta\\)를 알고 있을 경우. \\((X_1,X_2)\\)의 조인트를 완벽하게 기술할 수 있다. 예를들어 \\(\\theta=1/2\\)일 경우는 아래와 같다.\n\n\\(P(X_1=0,X_2=0 | \\theta=1/2)=1/4\\)\n\\(P(X_1=0,X_2=1 | \\theta=1/2)=1/4\\)\n\\(P(X_1=1,X_2=0 | \\theta=1/2)=1/4\\)\n\\(P(X_1=1,X_2=1 | \\theta=1/2)=1/4\\)\n\n- 경우2: \\(X_1,X_2\\)의 realization을 알고 있을 경우. \\((X_1,X_2)\\)의 조인트를 완벽하게 기술할 수 있다. 예를들어 \\(X_1=0,X_2=1\\)일 경우는 아래와 같다.\n\n\\(P(X_1=0,X_2=0 | X_1=0,X_2=0)=0\\)\n\\(P(X_1=0,X_2=1| X_1=0,X_2=1)=0\\)\n\\(P(X_1=1,X_2=0| X_1=1,X_2=0)=1\\)\n\\(P(X_1=1,X_2=1| X_1=1,X_2=1)=0\\)\n\n- 경우3: \\((X_1+X_2)(\\omega)\\)의 realization을 알고 있을 경우. 이때도 매우 특이하게 \\((X_1,X_2)\\) 의 조인트를 완벽하게 기술할 수 있다.\ncase1: \\(X_1+X_2=0\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1+X_2=0)=1\\)\n\\(P(X_1=0,X_2=1| X_1+X_2=0)=0\\)\n\\(P(X_1=1,X_2=0| X_1+X_2=0)=0\\)\n\\(P(X_1=1,X_2=1| X_1+X_2=0)=0\\)\n\ncase2: \\(X_1+X_2=1\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1+X_2=1)=0\\)\n\\(P(X_1=0,X_2=1| X_1+X_2=1)=1/2\\)\n\\(P(X_1=1,X_2=0| X_1+X_2=1)=1/2\\)\n\\(P(X_1=1,X_2=1| X_1+X_2=1)=0\\)\n\ncase3: \\(X_1+X_2=2\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1+X_2=2)=0\\)\n\\(P(X_1=0,X_2=1| X_1+X_2=2)=0\\)\n\\(P(X_1=1,X_2=0| X_1+X_2=2)=0\\)\n\\(P(X_1=1,X_2=1| X_1+X_2=2)=1\\)\n\n- 경우4: \\(X_1\\)의 realization만 알고 있을 경우. 이때는 \\((X_1,X_2)\\) 의 조인트를 완벽하게 기술할 수 없다.\ncase1: \\(X_1=0\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1=0)=1-\\theta\\)\n\\(P(X_1=0,X_2=1| X_1=0)=\\theta\\)\n\\(P(X_1=1,X_2=0| X_1=0)=0\\)\n\\(P(X_1=1,X_2=1| X_1=0)=0\\)\n\ncase2: \\(X_1=1\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1=1)=0\\)\n\\(P(X_1=0,X_2=1| X_1=1)=0\\)\n\\(P(X_1=1,X_2=0| X_1=1)=1-\\theta\\)\n\\(P(X_1=1,X_2=1| X_1=1)=\\theta\\)\n\n- 종합해보면 경우1,경우2,경우3은 경우4와 구분되는 어떠한 공통점을 가지고 있다 볼 수 있다. 특징은 결합확률분포가 \\(\\theta\\)에 대한 함수로 표현되지 않는다는 것이다. 하나씩 살펴보면\n\n경우1: 당연히 \\(\\theta\\)를 줬으니까 \\((X_1,X_2)\\)의 조인트는 \\(\\theta\\)에 의존하지 않음.\n경우2: \\(X_1,X_2\\)를 줬음. \\((X_1,X_2)\\)의 조인트는 \\(\\theta\\)에 의존하지 않음.\n경우3: \\(X_1+X_2\\)를 줬음. \\((X_1,X_2)\\)의 조인트는 \\(\\theta\\)에 의존하지 않음.\n\n이렇게보면 경우1과 경우2,3은 또 다시 구분된다. 경우1은 \\(\\theta\\)에 대한 완전한 정보를 준 상황이므로 당연히 조인트는 \\(\\theta\\)에 의존하지 않는다. 경우2-3은 \\(\\theta\\)를 주지 않았음에도 조인트가 \\(\\theta\\)에 의존하지 않는 매우 특별해보이는 상황이다. 따라서 이를 통해서 유추하면\n\n경우2에서는 \\((X_1,X_2)\\) 가 경우3에서는 \\(X_1+X_2\\)가 \\(\\theta\\)에 대한 완전한 정보를 대신하고 있는것 아닐까?\n\n라는 생각이 든다. 정리하면\n\n경우2: \\((X_1,X_2)\\)을 주는 것은 \\(\\theta\\)의 값을 그냥 알려주는 것과 대등한 효과\n경우3: \\(X_1+X_2\\)를 주는 것은 \\(\\theta\\)의 값을 그냥 알려주는 것과 대등한 효과\n\n라고 해석할 수 있는데 이를 수식화 하면 아래와 같다.\n- 대충정의: 어떠한 통계량 \\(S\\)의 값을 줬을때, \\((X_1,X_2\\dots,X_n)\\)의 조인트가 \\(\\theta\\)에 의존하지 않으면 그 통계량 \\(S\\)를 \\(\\theta\\)의 충분통계량이라고 한다.\n- 충분통계량 구하는 방법\n\n지수족일때 구하는 방식이 있음! &lt;– 외우세여\n분해정리를 쓰는 경우. &lt;– 거의 안쓰는거같은데..\n1-2로도 잘 모르겠으면 충분통계량일듯한 애를 잡아와서 정의에 넣고 노가다로 때려맞춤. (문제가 디스크릿할때만 쓸것)"
  },
  {
    "objectID": "공부/2023-05-13-(공부&지윤) 추정.html#최소충분통계량",
    "href": "공부/2023-05-13-(공부&지윤) 추정.html#최소충분통계량",
    "title": "(공부&지윤) 추정",
    "section": "",
    "text": "- 충분통계량에 대한 realization을 알려주면 \\(\\theta\\)의 값을 그냥 알려주는 효과임. 그래서 충분통계량은 좋은 것임\n- 그런데 충분통계량에도 급이 있음. 아래와 같은 상황을 가정하자.\n\\[X_1,X_2 \\sim {\\cal B}er(\\theta)\\]\n이 경우\n\n\\((X_1,X_2)\\)는 SS\n\\(X_1+X_2\\)는 SS\n\n이지만 1은 두개의 숫자를 기억해야하고 2는 하나의 숫자만 기억하면 되니까 2가 더 좋음\n- 예비개념: 상태1과 상태2가 있다고 하자. 상태1에서 상태2로 가는 변화는 쉽지만, 상태2에서 상태1로 가는 변화는 어렵다고 할때, 상태1이 더 좋은 상태이다.\n\n두가지 상태 “500원을 가지고 있음”, “1000원을 가지고 있음” 을 고려하자. 1000원을 500원을 만드는 것은 쉽지만 500원을 1000원으로 만들기는 어렵다. 따라서 1000원이 더 좋은 상태이다.\n\n- 충분통계량의 급을 어떻게 구분할까? 아래의 상황에서\n\n\\((X_1,X_2)\\)는 SS\n\\(X_1+X_2\\)는 SS\n\n1을 이용하면 2를 만들 수 있지만, 2를 이용해서 1을 만들 수는 없음. 즉 \\(1\\to 2\\) 인 변환(=함수)는 가능하지만 \\(2\\to 1\\)로 만드는 변환(=함수)는 가능하지 않음. 예비개념을 잘 이해했다면 2가 더 좋은 상태라고 볼 수 있다.\n- 이를 확장하자. 어떠한 충분 통계량 \\(S^\\star\\)가 있다고 가정하자. 다른 모든 충분통계량 \\(S_1,S_2,S_3 \\dots\\)에서 \\(S^\\star\\)로 만드는 변환은 존재하는데 (함수는 존재하는데) 그 반대는 \\(S^\\star\\)의 전단사인 충분통계량만 가능하다고 하자. 그렇다면 \\(S^\\star\\)는 가장 좋은 충분통계량이라고 하며, 가장 적은 숫자만 기억하면 되는 충분통계량이라 볼 수 있다. 이러한 충분통계량을 MSS 라고 하자."
  },
  {
    "objectID": "공부/2023-05-13-(공부&지윤) 추정.html#라오블랙웰",
    "href": "공부/2023-05-13-(공부&지윤) 추정.html#라오블랙웰",
    "title": "(공부&지윤) 추정",
    "section": "",
    "text": "- 충분통계량 \\(S\\)을 알려주면 (기븐하면) \\(\\theta\\)에 대한 완벽한 정보를 알려주는 셈이다. 따라서 \\(\\theta\\)를 추정하는 어떠한 추정량 \\(\\hat{\\theta}\\)도 충분통계량의 정보 \\(S\\)가 있다면 \\(\\hat{\\theta}\\)를 업그레이드할 수 있다고 볼 수 있다. (뭐 수틀리면 정보야 안쓰면 그만이니까 나빠질것은 없다)\n- 충분통계량을 줬을때 \\(\\hat{\\theta}\\)의 업그레이드 방법은\n\\[\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)\\]\n와 같이 할 수 있는데 이는 충분통계량 \\(S\\)의 정보를 받아서 어떠한 방식으로 업데이트된 \\(\\hat{\\theta}\\) 이므로 \\(S\\)의 함수라 해석할 수 있다.\n- 이론 (라오블랙웰, Thm, 4.5): \\(\\hat{\\theta}\\)가 UB일때 충분통계량의 값을 알려주면 \\(\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)\\)와 같이 \\(\\hat{\\theta}\\)를 업그레이드 할 수 있다."
  },
  {
    "objectID": "공부/2023-05-13-(공부&지윤) 추정.html#레만쉐페정리",
    "href": "공부/2023-05-13-(공부&지윤) 추정.html#레만쉐페정리",
    "title": "(공부&지윤) 추정",
    "section": "",
    "text": "- 충분통계량 \\(S\\)을 알려주면 (기븐하면) \\(\\theta\\)에 대한 완벽한 정보를 알려주는 셈이다. 따라서 \\(\\theta\\)를 추정하는 어떠한 추정량 \\(\\hat{\\theta}\\)도 충분통계량의 정보 \\(S\\)가 있다면 \\(\\hat{\\theta}\\)를 업그레이드할 수 있다고 볼 수 있다. (뭐 수틀리면 정보야 안쓰면 그만이니까 나빠질것은 없다)\n- 충분통계량을 줬을때 \\(\\hat{\\theta}\\)의 업그레이드 방법은\n\\[\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)\\]\n와 같이 할 수 있는데 이는 충분통계량 \\(S\\)의 정보를 받아서 어떠한 방식으로 업데이트된 \\(\\hat{\\theta}\\) 이므로 \\(S\\)의 함수라 해석할 수 있다.\n- 이론 (라오블랙웰, Thm, 4.5): \\(\\hat{\\theta}\\)가 UB일때 충분통계량의 값을 알려주면 \\(\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)\\)와 같이 \\(\\hat{\\theta}\\)를 업그레이드 할 수 있다."
  },
  {
    "objectID": "공부/2023-01-20-(공부) 추정.html",
    "href": "공부/2023-01-20-(공부) 추정.html",
    "title": "(공부) 추정",
    "section": "",
    "text": "using Distributions, Plots"
  },
  {
    "objectID": "공부/2023-01-20-(공부) 추정.html#mle의-일치성에-대한-구체적인-논의",
    "href": "공부/2023-01-20-(공부) 추정.html#mle의-일치성에-대한-구체적인-논의",
    "title": "(공부) 추정",
    "section": "MLE의 일치성에 대한 구체적인 논의",
    "text": "MLE의 일치성에 대한 구체적인 논의\n\\(X_1,\\dots,X_{10} \\overset{i.i.d.}{\\sim} Ber(\\theta)\\) 이라고 하자.\n\nx = rand(Bernoulli(0.3),10)\nx\n\n10-element Vector{Bool}:\n 0\n 0\n 1\n 1\n 1\n 1\n 0\n 0\n 0\n 0\n\n\n여기에서 \\(\\theta\\)는 추정해야할 미지의 모수이지만 우리는 시뮬레이션의 편의상 \\(\\theta\\)의 참값을 \\(\\theta_0=\\frac{1}{3}\\)로 알고 있다고 하자. MLE를 논의함에 있어 핵심적인 역할을 하는 것은 \\(Y_1=\\log f(X_1;\\theta)\\)이다. 아래는 \\(Y_1\\)에 대한 몇가지 코멘트이다.\n(1) \\(Y_1\\)은 \\(X_1\\)와 \\(\\theta\\)의 함수이다.\n\n우선 \\(X_1\\)의 함수이므로 \\(Y_1\\)역시 확률변수이다. 따라서 \\(Y_1\\)에 대하여 평균등을 취할 수 있으며 LLN을 쓸 수 있다.\n\\(Y_1\\)은 \\(\\theta\\)에 대한 함수이므로 \\(\\theta\\)에 대하여 미분할 수 있다.\n\n(베르누이 예제)\n우리의 베르누이 예제에서 \\(Y_1\\)은 아래와 같이 계산된다.\n\\[Y_1 = \\log f(X_1;\\theta)= X_1 \\log \\theta + (1-X_1)\\log(1-\\theta)\\]\n보는 것 처럼 \\(Y_1\\)은 \\(X_1\\)와 \\(\\theta\\)의 함수임\n(2) \\(\\mathbb{E}_{\\theta_0}(Y_1)\\)은 \\(\\theta\\) 만의 함수이다. 적당한 조건4이 만족된다면 \\(\\mathbb{E}_{\\theta_0}(Y_1)\\)은 \\(\\theta_0\\) 에서 최대화 된다.\n4 identifiable & common support(베르누이 예제)\n\\(\\mathbb{E}_{\\theta_0}(Y_1) = \\mathbb{E}_{\\theta_0}(X_1)\\log\\theta + (1-\\mathbb{E}_{\\theta_0}(X_1))\\log(1-\\theta) = \\frac{1}{3} \\log\\theta + (1-\\frac{1}{3})\\log(1-\\theta)\\)\n\n일반적인 상황에서는 참모수를 모르지만 우리는 시뮬레이션을 \\(\\theta=1/3\\)에서 하였으므로 참모수 \\(\\theta_0=\\mathbb{E}_{\\theta_0}(X_1)=\\frac{1}{3}\\)을 알고 있다고 가정한다.\n\n\nplot(θ -&gt; (1/3)*log(θ) + (1-1/3)*log(1-θ)) \n\n\n\n\n\n\n\n\n보는것처럼 이 함수 \\(\\mathbb{E}_{\\theta_0}(Y_1)\\)은 \\(\\theta=\\theta_0=\\frac{1}{3}\\) 에서 최대값을 가진다.\n(3) \\(\\frac{\\partial}{\\partial \\theta}Y_1\\) 역시 \\(X_1\\)와 \\(\\theta\\)의 함수이다.\n\n따라서 \\(\\frac{\\partial}{\\partial \\theta}Y_1\\) 역시 확률변수이고 \\(\\frac{\\partial}{\\partial \\theta}Y_1\\)에 대하여 평균등을 취할 수 있으며 LLN을 쓸 수 있다.\n\n(베르누이 예제)\n\\(\\frac{\\partial}{\\partial\\theta}Y_1 = X_1\\frac{1}{\\theta} + (1-X_1)\\frac{-1}{1-\\theta}\\)\n(4) \\(\\mathbb{E}_{\\theta}[\\frac{\\partial}{\\partial \\theta}Y_1]=0\\) 이다.\n(베르누이 예제)\n\\(\\mathbb{E}_{\\theta}[\\frac{\\partial}{\\partial\\theta}Y_1] = \\theta\\frac{1}{\\theta} + (1-\\theta)\\frac{-1}{1-\\theta}=0\\)\n(5) \\(\\mathbb{V}_{\\theta}[\\frac{\\partial}{\\partial\\theta}Y_1]=\\mathbb{E}_{\\theta}[-\\frac{\\partial^2}{\\partial \\theta^2}Y_1]=I(\\theta)\\)\n(베르누이 예제)\n\\(\\mathbb{V}_{\\theta}\\big[\\frac{\\partial}{\\partial\\theta}Y_1\\big]=\\mathbb{E}_{\\theta}\\big[(\\frac{\\partial}{\\partial\\theta}Y_1)^2\\big]=\\mathbb{E}_{\\theta}\\big[-\\frac{\\partial^2}{\\partial\\theta^2}Y_1\\big]=\\frac{1}{\\theta(1-\\theta)}\\)\n\n두번째 등호는 \\(\\mathbb{E}_{\\theta}[\\frac{\\partial}{\\partial\\theta}Y_1]=0\\)을 이용하여 증명가능하다.\n언뜻 보면 \\(\\mathbb{V}_{\\theta}\\big[\\frac{\\partial}{\\partial\\theta}Y_1\\big]\\)를 계산하는 것이 \\(\\mathbb{E}_{\\theta}\\big[-\\frac{\\partial^2}{\\partial\\theta^2}Y_1\\big]\\)를 계산하는것보다 훨씬 쉬워보인다. 그런데 \\(X_1\\)와 \\(1-X_1\\)이 독립이 아니라서 \\(\\mathbb{V}(X+Y)=\\mathbb{V}(X)+\\mathbb{V}(V)+2\\text{Cov}(X,Y)\\)와 같이 공분산 term을 계산해야 하므로 계산이 까다롭다.\n\n\n베르누이에 대한 피셔정보량은 https://en.wikipedia.org/wiki/Fisher_information 에서 확인할 수 있음"
  },
  {
    "objectID": "공부/2024-01-30-(공부) 코드 -- AUC.html",
    "href": "공부/2024-01-30-(공부) 코드 -- AUC.html",
    "title": "(공부) 코드 – AUC sklearn",
    "section": "",
    "text": "import numpy as np\nfrom sklearn.metrics import roc_auc_score\n\n\ny = np.array([0,0,0,0,1])\nyhat = np.array([0,0,0,0,1])/10\n\n\ny,yhat\n\n(array([0, 0, 0, 0, 1]), array([0. , 0. , 0. , 0. , 0.1]))\n\n\n\nroc_auc_score(y,yhat)\n\n1.0"
  },
  {
    "objectID": "공부/2023-09-24-(공부) 코드 -- ggraph.out.html",
    "href": "공부/2023-09-24-(공부) 코드 -- ggraph.out.html",
    "title": "(공부) 코드 – ggraph",
    "section": "",
    "text": "신록예찬\n2023-09-24\n\nImports\n\nsource(\"ggplot3.R\")\nlibrary(ggraph)\nlibrary(tidygraph)\n\n\nfigsize()\n\n\nas_tbl_graph(highschool)\n\n# A tbl_graph: 70 nodes and 506 edges\n#\n# A directed multigraph with 1 component\n#\n# A tibble: 70 × 1\n  name \n  &lt;chr&gt;\n1 1    \n2 2    \n3 3    \n4 4    \n5 5    \n6 6    \n# ℹ 64 more rows\n#\n# A tibble: 506 × 3\n   from    to  year\n  &lt;int&gt; &lt;int&gt; &lt;dbl&gt;\n1     1    13  1957\n2     1    14  1957\n3     1    20  1957\n# ℹ 503 more rows\n\n\n\n\n\n# Create graph of highschool friendships\ngraph &lt;- as_tbl_graph(highschool) %&gt;% \n    mutate(Popularity = centrality_degree(mode = 'in'))\n\n# plot using ggraph\nggraph(graph, layout = 'kk') + \n    geom_edge_fan(aes(alpha = after_stat(index)), show.legend = FALSE) + \n    geom_node_point(aes(size = Popularity)) + \n    facet_edges(~year) + \n    theme_graph(foreground = 'steelblue', fg_text_colour = 'white')"
  },
  {
    "objectID": "공부/2023-10-21-(공부&지윤) Imputer와 Scaler의 적용.out.html",
    "href": "공부/2023-10-21-(공부&지윤) Imputer와 Scaler의 적용.out.html",
    "title": "(공부&지윤) Imputer와 Scaler의 적용",
    "section": "",
    "text": "신록예찬\n2023-10-21\n\nimport numpy as np \nimport pandas as pd\nimport sklearn.preprocessing\nimport sklearn.impute \n\n\nX = pd.DataFrame({'X':[7.424885,4.201394,np.nan,np.nan,5.190914,np.nan,6.433033]})\nX"
  },
  {
    "objectID": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.html",
    "href": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.html",
    "title": "(공부) 리뷰 – EbayesThresh: R Programs for Empirical Bayes Thresholding",
    "section": "",
    "text": "ref: https://www.jstatsoft.org/article/view/v012i08"
  },
  {
    "objectID": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.html#ebayesthresh로-무엇을-할-수-있는가",
    "href": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.html#ebayesthresh로-무엇을-할-수-있는가",
    "title": "(공부) 리뷰 – EbayesThresh: R Programs for Empirical Bayes Thresholding",
    "section": "Ebayesthresh로 무엇을 할 수 있는가?",
    "text": "Ebayesthresh로 무엇을 할 수 있는가?\n아래와 같은 상황을 가정하자.\n\\[X_i = \\mu_i +\\epsilon_i.\\]\n여기에서 아래를 가정한다.\n\n\\(\\epsilon_i \\overset{iid}{\\sim} N(0,1)\\)\neach \\(\\mu_i\\) is zero with probability \\((1−w)\\), while, with probability \\(w\\), \\(\\mu_i\\) is drawn from a symmetric heavy-tailed density \\(\\gamma\\).\n\n일반적으로 \\(w\\), 즉 \\(\\mu_i\\)가 0이 아닐 확률은 매우 작은값으로 설정된다. 따라서 위와 같은 구조로 \\(\\epsilon_i\\)와 \\(\\mu_i\\)를 생성하면 아래와 같이 된다.\n\n\\(\\epsilon_i\\): 절대값이 작은 신호들이 dense하게 있음.\n\\(\\mu_i\\): 절대값이 큰 신호들이 sparse하게 있음. (sparse한 이유는 \\(w\\)가 작으므로)\n\n따라서 \\(X_i\\)의 모양은 아래의 그림의 왼쪽과 같다.\n\n이 논문의 목표는 왼쪽의 그림 \\(X_i= \\mu_i +\\epsilon_i\\)로부터 오른쪽의 그림 \\(\\hat{\\mu}_i\\)을 구하는 것이다. 즉 작은 절대값의 노이즈 \\(\\epsilon_i\\)에서 큰 절대값의 신호 \\(\\mu_i\\)를 골라내는 일을 목표로 한다. 저자들은 이러한 작업을 “건초더미에서 바늘찾기”라는 말로 비유하였다. 이러한 “건초더미에서 바늘찾기”는 여러 분야에 응용될 수 있다. 구체적으로는 천문학, 이미지프로세싱, 데이터마이닝, 모형선택등에 사용될 수 있다고 한다. 언급한 분야에 대한 자세한 discussion은 Johnstone and Silverman (2004)에서 찾을 수 있다. 또한 “건초더미에서 바늘찾기”는 위에서 언급한 분야 이외에 퓨리에, 웨이블릿 혹은 다른 dictionaries에 의한 함수추정문제를 해결할 수 있다. 이는 퓨리에나 웨이블릿변환과 같은 multiscale trasnform이 원래 신호를 sparese한 구조로 바꾸기 때문이다. 즉 퓨리에변환 웨이블릿변환으로 underlying function을 추정할 수 있다는 의미이다. 우리는 이러한 접근법에 좀 더 초점을 맞추도록 하겠다."
  },
  {
    "objectID": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.html#간단한-사용법",
    "href": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.html#간단한-사용법",
    "title": "(공부) 리뷰 – EbayesThresh: R Programs for Empirical Bayes Thresholding",
    "section": "간단한 사용법",
    "text": "간단한 사용법\nR을 이용하여 Ebayesthresh를 사용하는 간단한 방법을 살펴보도록 하자. 논문에 표현된 그림1을 재현하여 보자.\n\nlibrary(EbayesThresh)\n\n\nset.seed(1)\nx &lt;- rnorm(1000) + sample(c( runif(25,-7,7), rep(0,975)))\nplot(x,type='l',lwd=0.2)\n\n\n\n\n\n\n\n\n위와 같은 자료 \\(X_i\\)를 관측하였다고 가정하자. 이 신호에는 “건초(\\(\\epsilon_i\\))”더미에 25개의 “바늘(\\(\\mu_i\\))”이 섞여있다. 여기에서 “바늘”만 골라내는 코드는 아래와 같이 작성할 수 있다.\n\nmuhat &lt;- ebayesthresh(x, sdev=1)\n\n결과를 시각화하면 아래와 같다.\n\nplot(x,type='l',lwd=0.2)\nlines(muhat,col=2,lwd=2)"
  },
  {
    "objectID": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.html#arguments",
    "href": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.html#arguments",
    "title": "(공부) 리뷰 – EbayesThresh: R Programs for Empirical Bayes Thresholding",
    "section": "arguments",
    "text": "arguments\n일반적으로 ebayesthresh 함수를 사용하는 방법은 아래와 같다.\n\nmuhat &lt;- ebayesthresh(\n    x,\n    prior = \"laplace\", \n    a = 0.5, \n    bayesfac = FALSE, \n    sdev = NA, \n    verbose = FALSE, \n    threshrule = \"median\"\n)\n\nprior, a: \\(\\mu_i\\)의 density. 보통 \\(\\frac{1}{2}a \\exp(-a|u|)\\)라고 가정한다. parameter \\(a\\)는 Section 2.1에서 자시해 나옴.\nbayesfac, threshrule: Section 2.2, 2.3에 자세히 나온다.\nsdev: \\(\\epsilon_i\\)의 sd를 의미한다. 이 값을 알고 있다면 설정하면 되지만 보통은 이 값을 모른다고 가정한다. \\(\\epsilon_i\\)의 sd를 모르는 경우는 observed data로 부터 추정하는데 보통 \\({\\tt median}(|X_i|)\\)로 추정한다.\n\\(\\epsilon_i\\)의 sd를 \\({\\tt median}(|X_i|)\\)로 추정하는 motivation을 이해하는 것이 중요하다. 이는 sparse assumption of \\(\\mu_i\\)에서 시작한다. 신호 \\(\\mu_i\\)가 합리적인 수준에서 sparse하다면 median absolute value of \\(X_i\\)는 \\(\\mu_i\\)의 값들과 상관이 없을 것이다. 하지만 당연히 신호가 sparse하지 않다면 이러한 방식으로 sdev를 추정하는 것은 매우 조심스럽게 수행되어야 할 것이다.\n\nn &lt;- 1000\nx &lt;- rnorm(n) + sample(c(runif(25,-7,7), rep(0,n-25)))\nprint(sd(x))\nprint(median(abs(x)))\n\n[1] 1.117016\n[1] 0.6787613\n\n\n\n실제로는 잘 추론하지 못하는 것 같다?"
  },
  {
    "objectID": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.html#원리",
    "href": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.html#원리",
    "title": "(공부) 리뷰 – EbayesThresh: R Programs for Empirical Bayes Thresholding",
    "section": "원리",
    "text": "원리\n어떻게 \\(\\hat{\\mu}_i\\)를 추정할 수 있을까? 가장 간단한 방법은 thresholding이다.\n많은 실제예제에서 \\(\\mu_i\\)는 어떤 의미에서 (in some sense) sparse하다고 여길 수 있다. EbayesThresh 패키지는 이처럼 \\(\\mu_i\\)가 sparse하다는 구조 (혹은 가정)을 이용하여 \\(\\mu_i\\)를 적절하게 추정한다.\nSparsity를 이용하는 자연스러운 방법은 threshoding이다: 여기에서 threshold의 값 \\(t\\)를 너무 크게 잡으면 신호를 잡음으로 잘못 판단할 것이고 \\(t\\)의 값이 너무 작다면 잡음을 신호로 잘못 판단할 수 있다. 따라서 \\(t\\)의 선택은 이 양쪽 기준사이의 tradeoff가 있는데 EbayesThresh는 이러한 tradeoff를 자동으로 조정하는 효과가 있다.\n\n\\(\\mu_i\\)는 \\(w\\)의 확률로 0 이며 \\((1-w)\\)의 확률로 0이 아니다. \\(\\mu_i\\)가 0이 아닐경우에는 symmetric heavy-tailed density \\(\\gamma\\)에서 추출된다고 가정한다. 여기에서 prior에 대한 key parameter인 \\(w\\)는 데이터로부터 자동으로 추정된다. (marginal maximum likelihood 를 이용한다) 그리고 추정된 \\(w\\)는 Bayesian model로 다시 대입된다.\n\\(w\\)가 추정되면 Bayesian model은 thresholding procedure를 수행할 수 있다. 왜냐하면 \\(w\\)를 추정하면 \\(t(w)\\)를 선택한다는 말과 같은말이기 때문이다.\n\nargument"
  },
  {
    "objectID": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.html#the-bayesian-model",
    "href": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.html#the-bayesian-model",
    "title": "(공부) 리뷰 – EbayesThresh: R Programs for Empirical Bayes Thresholding",
    "section": "The Bayesian model",
    "text": "The Bayesian model\n\\[X_i \\sim N(\\mu_i,1)\\]\n\\(f_{\\text{prior}}(\\mu)=(1-w)\\delta_0(\\mu)+w \\gamma_a(\\mu), \\quad \\gamma_a(\\mu)=\\frac{1}{2}a\\exp(-a|\\mu|)\\)\n여기에서 \\(\\gamma_a(\\mu)\\)는 하나의 예시일 뿐이다. Ebayesthresh에 디폴트로 설정된 prior=\"laplace\"를 셋팅하면 \\(\\gamma_a(\\mu)\\)가 사용된다. \\(\\gamma\\)의 선택은 tail이 polynomial rates로 줄어드는 어떠한 분포를 사용해도 무방하다. 저자들은 quasi-Cauchy분포를 제안하였는데 이는 Johnstone and Sliverman이 만든 theoretical assumption을 만족하는 분포중 가장 꼬리가 두꺼운 분포이다."
  },
  {
    "objectID": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.html#thresholding-rules",
    "href": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.html#thresholding-rules",
    "title": "(공부) 리뷰 – EbayesThresh: R Programs for Empirical Bayes Thresholding",
    "section": "Thresholding rules",
    "text": "Thresholding rules\n모수 \\(\\mu\\)는 사전분포(prior distribution)를 가진다고 가정하고 \\(X \\sim N(\\mu,1)\\)이라고 가정하자. 이 경우 \\(X=x\\)가 given되었을 경우 \\(\\mu\\)의 사후분포(posterior distribution)를 구할 수 있다. (자세한 내용은 Section 6을 참고해야함) 사후분포의 중앙값을 \\(\\hat{\\mu}(x;w)\\)라고 하자. (사후분포의 중앙값이 \\(w\\)에 영향받는 이유는 사전분포가 \\(w\\)에 depend하기 때문이다. 여기에서 \\(w\\)는 marginal MLE로 적절히 추론한다고 가정한다)\n\\(X_i\\)는 독립이라고 가정한다. 여기에서 \\(X_i\\)가 독립이 아니라면 약간의 정보손실이 있을 수 있다. 하지만 \\(X_i\\) 사이에 너무 많은 dependency가 존재하는 경우가 아니라면 Ebayesthresh는 어느정도 합리적인 결과를 제공한다.\n만약에 bayesfac=TRUE를 사용하면 \\(\\mu\\)의 사후분포의 중앙값 대신에 Bayes factor threshold 를 쓸 수도 있다."
  },
  {
    "objectID": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.html#choosing-the-threshold",
    "href": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.html#choosing-the-threshold",
    "title": "(공부) 리뷰 – EbayesThresh: R Programs for Empirical Bayes Thresholding",
    "section": "Choosing the threshold",
    "text": "Choosing the threshold\n\\(X_i\\)의 marginal density는\n\\((1-w)\\phi(x) +w(\\gamma \\star \\phi)(x)\\)\n\\(l(w) = \\sum_{i=1}^{n}\\log \\big\\{(1-w)\\phi(X_i)+wg(X_i) \\big\\}\\)\n와 같이 정의가능하다. 단, 여기에서 \\(g:= \\gamma\\star \\phi\\) 이다.\n이제 우리는 아래의 식을 풀면된다.\n\\[\\underset{w}{\\operatorname{argmax}} l(w)\\quad\\quad \\text{subject to}\\quad t(w) \\leq \\sqrt{2\\log n}\\]\n여기에서 \\(\\sqrt{2\\log n}\\)은 흔히 말하는 universal threshold 이다.\n만약에 \\(w\\)이외에 \\(a\\)도 추정해야 한다면 아래와 같이 추정할 수 있다.\n\\[\\underset{w}{\\operatorname{argmax}} l(w)\\quad\\quad \\text{subject to}\\quad t(w) \\leq \\sqrt{2\\log n}\\]"
  },
  {
    "objectID": "공부/2023-06-28-(공부&지윤) 커널리그레션.html",
    "href": "공부/2023-06-28-(공부&지윤) 커널리그레션.html",
    "title": "(공부&지윤) 커널리그레션",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\n\nx = np.linspace(0,1,5)\nx\n\narray([0.  , 0.25, 0.5 , 0.75, 1.  ])\n\n\n\ny = x*2 + np.random.randn(5)*0.3\ny\n\narray([0.01044984, 0.93755458, 0.43942577, 1.0639859 , 2.1133726 ])\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,2*x,'--')\n\n\n\n\n\n\n\n\n\\[y_i= \\sum_{i=1}^{5}\\theta_i\\exp\\left(-\\frac{|x-x_i|^2}{2h^2}\\right)\\]\n\nh= 0.15\nx0 = lambda xstar: np.exp(-(xstar-x[0])**2 / 2 / (h**2))\nx1 = lambda xstar: np.exp(-(xstar-x[1])**2 / 2 / (h**2))\nx2 = lambda xstar: np.exp(-(xstar-x[2])**2 / 2 / (h**2))\nx3 = lambda xstar: np.exp(-(xstar-x[3])**2 / 2 / (h**2))\nx4 = lambda xstar: np.exp(-(xstar-x[4])**2 / 2 / (h**2))\n\n\nθ0 = 0\nθ1 = 0.2\nθ2 = 0.5\nθ3 = 1.0\nθ4 = 1.5\n\n\nxstar = 0.6 \n\n\nθ0*x0(0.6)+θ1*x1(0.6)+θ2*x2(0.6)+θ3*x3(0.6)+θ4*x4(0.6)\n\n1.062893318071169\n\n\n\n_yhat = lambda xstar : θ0*x0(xstar)+\\\nθ1*x1(xstar)+\\\nθ2*x2(xstar)+\\\nθ3*x3(xstar)+\\\nθ4*x4(xstar)\n\n\n(_yhat(0)-y[0])**2\n\n0.0017104251892816106\n\n\n\nloss = (_yhat(0)-y[0])**2 + (_yhat(0.25)-y[1])**2+ \\\n(_yhat(0.5)-y[2])**2+(_yhat(0.75)-y[3])**2+\\\n(_yhat(1)-y[4])**2\n\n\\(loss(\\theta_0,\\theta_1,\\theta_2,\\theta_3,\\theta_4)\\) 를 최소화하는 \\({\\boldsymbol \\theta}\\)를 구한다.\n\n_x = np.linspace(0,1,1000)\nplt.plot(x,y,'o')\nplt.plot(x,2*x,'--')\nplt.plot(_x,_yhat(_x))"
  },
  {
    "objectID": "공부/2023-09-24-(공부) 코드 -- ggraph.html",
    "href": "공부/2023-09-24-(공부) 코드 -- ggraph.html",
    "title": "(공부) 코드 – ggraph",
    "section": "",
    "text": "Imports\n\nsource(\"ggplot3.R\")\nlibrary(ggraph)\nlibrary(tidygraph)\n\n\nfigsize()\n\n\nas_tbl_graph(highschool)\n\n\n# A tbl_graph: 70 nodes and 506 edges\n#\n# A directed multigraph with 1 component\n#\n# A tibble: 70 × 1\n  name \n  &lt;chr&gt;\n1 1    \n2 2    \n3 3    \n4 4    \n5 5    \n6 6    \n# ℹ 64 more rows\n#\n# A tibble: 506 × 3\n   from    to  year\n  &lt;int&gt; &lt;int&gt; &lt;dbl&gt;\n1     1    13  1957\n2     1    14  1957\n3     1    20  1957\n# ℹ 503 more rows\n\n\n\n\n\n\n# Create graph of highschool friendships\ngraph &lt;- as_tbl_graph(highschool) %&gt;% \n    mutate(Popularity = centrality_degree(mode = 'in'))\n\n# plot using ggraph\nggraph(graph, layout = 'kk') + \n    geom_edge_fan(aes(alpha = after_stat(index)), show.legend = FALSE) + \n    geom_node_point(aes(size = Popularity)) + \n    facet_edges(~year) + \n    theme_graph(foreground = 'steelblue', fg_text_colour = 'white')"
  },
  {
    "objectID": "공부/HF/2024-10-10-(강의) 이미지캡셔닝.html",
    "href": "공부/HF/2024-10-10-(강의) 이미지캡셔닝.html",
    "title": "(강의) 이미지캡셔닝",
    "section": "",
    "text": "# Transformers installation\n! pip install transformers datasets\n# To install from source instead of the last release, comment the command above and uncomment the following one.\n# ! pip install git+https://github.com/huggingface/transformers.git\n\nRequirement already satisfied: transformers in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (4.46.3)\nRequirement already satisfied: datasets in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (2.19.1)\nRequirement already satisfied: filelock in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub&lt;1.0,&gt;=0.23.2 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from transformers) (0.24.6)\nRequirement already satisfied: numpy&gt;=1.17 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging&gt;=20.0 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from transformers) (24.1)\nRequirement already satisfied: pyyaml&gt;=5.1 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from transformers) (2024.7.24)\nRequirement already satisfied: requests in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers&lt;0.21,&gt;=0.20 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: safetensors&gt;=0.4.1 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm&gt;=4.27 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow&gt;=12.0.0 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill&lt;0.3.9,&gt;=0.3.0 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from datasets) (2.0.2)\nRequirement already satisfied: multiprocess in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from datasets) (0.70.15)\nRequirement already satisfied: fsspec&lt;=2024.3.1,&gt;=2023.1.0 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from fsspec[http]&lt;=2024.3.1,&gt;=2023.1.0-&gt;datasets) (2024.3.1)\nRequirement already satisfied: aiohttp in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: aiosignal&gt;=1.1.2 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from aiohttp-&gt;datasets) (1.2.0)\nRequirement already satisfied: attrs&gt;=17.3.0 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from aiohttp-&gt;datasets) (23.1.0)\nRequirement already satisfied: frozenlist&gt;=1.1.1 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from aiohttp-&gt;datasets) (1.4.0)\nRequirement already satisfied: multidict&lt;7.0,&gt;=4.5 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from aiohttp-&gt;datasets) (6.0.4)\nRequirement already satisfied: yarl&lt;2.0,&gt;=1.0 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from aiohttp-&gt;datasets) (1.9.3)\nRequirement already satisfied: typing-extensions&gt;=3.7.4.3 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from huggingface-hub&lt;1.0,&gt;=0.23.2-&gt;transformers) (4.11.0)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from requests-&gt;transformers) (3.3.2)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from requests-&gt;transformers) (3.7)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from requests-&gt;transformers) (2.2.2)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from requests-&gt;transformers) (2024.8.30)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from pandas-&gt;datasets) (2.9.0.post0)\nRequirement already satisfied: pytz&gt;=2020.1 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from pandas-&gt;datasets) (2024.1)\nRequirement already satisfied: tzdata&gt;=2022.7 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from pandas-&gt;datasets) (2023.3)\nRequirement already satisfied: six&gt;=1.5 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas-&gt;datasets) (1.16.0)"
  },
  {
    "objectID": "공부/HF/2024-10-10-(강의) 이미지캡셔닝.html#load-the-pokémon-blip-captions-dataset",
    "href": "공부/HF/2024-10-10-(강의) 이미지캡셔닝.html#load-the-pokémon-blip-captions-dataset",
    "title": "(강의) 이미지캡셔닝",
    "section": "Load the Pokémon BLIP captions dataset",
    "text": "Load the Pokémon BLIP captions dataset\nUse the 🤗 Dataset library to load a dataset that consists of {image-caption} pairs. To create your own image captioning dataset in PyTorch, you can follow this notebook.\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"reach-vb/pokemon-blip-captions\")\nds\n\n/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n\nDatasetDict({\n    train: Dataset({\n        features: ['image', 'text'],\n        num_rows: 833\n    })\n})\n\n\n\nds = ds[\"train\"].train_test_split(test_size=0.1)\ntrain_ds = ds[\"train\"]\ntest_ds = ds[\"test\"]\n\nLet’s visualize a couple of samples from the training set.\n\nfrom textwrap import wrap\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\ndef plot_images(images, captions):\n    plt.figure(figsize=(20, 20))\n    for i in range(len(images)):\n        ax = plt.subplot(1, len(images), i + 1)\n        caption = captions[i]\n        caption = \"\\n\".join(wrap(caption, 12))\n        plt.title(caption)\n        plt.imshow(images[i])\n        plt.axis(\"off\")\n\n\nsample_images_to_visualize = [np.array(train_ds[i][\"image\"]) for i in range(5)]\nsample_captions = [train_ds[i][\"text\"] for i in range(5)]\nplot_images(sample_images_to_visualize, sample_captions)"
  },
  {
    "objectID": "공부/HF/2024-10-10-(강의) 이미지캡셔닝.html#preprocess-the-dataset",
    "href": "공부/HF/2024-10-10-(강의) 이미지캡셔닝.html#preprocess-the-dataset",
    "title": "(강의) 이미지캡셔닝",
    "section": "Preprocess the dataset",
    "text": "Preprocess the dataset\nSince the dataset has two modalities (image and text), the pre-processing pipeline will preprocess images and the captions.\nTo do so, load the processor class associated with the model you are about to fine-tune.\n\nfrom transformers import AutoProcessor\n\ncheckpoint = \"microsoft/git-base\"\nprocessor = AutoProcessor.from_pretrained(checkpoint)\n\nThe processor will internally pre-process the image (which includes resizing, and pixel scaling) and tokenize the caption.\n\ndef transforms(example_batch):\n    images = [x for x in example_batch[\"image\"]]\n    captions = [x for x in example_batch[\"text\"]]\n    inputs = processor(images=images, text=captions, padding=\"max_length\")\n    inputs.update({\"labels\": inputs[\"input_ids\"]})\n    return inputs\n\n\ntrain_ds.set_transform(transforms)\ntest_ds.set_transform(transforms)\n\nWith the dataset ready, you can now set up the model for fine-tuning."
  },
  {
    "objectID": "공부/HF/2024-10-10-(강의) 이미지캡셔닝.html#load-a-base-model",
    "href": "공부/HF/2024-10-10-(강의) 이미지캡셔닝.html#load-a-base-model",
    "title": "(강의) 이미지캡셔닝",
    "section": "Load a base model",
    "text": "Load a base model\nLoad the “microsoft/git-base” into a AutoModelForCausalLM object.\n\nfrom transformers import AutoModelForCausalLM\n\nmodel = AutoModelForCausalLM.from_pretrained(checkpoint)"
  },
  {
    "objectID": "공부/HF/2024-10-10-(강의) 이미지캡셔닝.html#evaluate",
    "href": "공부/HF/2024-10-10-(강의) 이미지캡셔닝.html#evaluate",
    "title": "(강의) 이미지캡셔닝",
    "section": "Evaluate",
    "text": "Evaluate\nImage captioning models are typically evaluated with the Rouge Score or Word Error Rate. For this guide, you will use the Word Error Rate (WER).\nWe use the 🤗 Evaluate library to do so. For potential limitations and other gotchas of the WER, refer to this guide.\n\nfrom evaluate import load\nimport torch\n\nwer = load(\"wer\")\n\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predicted = logits.argmax(-1)\n    decoded_labels = processor.batch_decode(labels, skip_special_tokens=True)\n    decoded_predictions = processor.batch_decode(predicted, skip_special_tokens=True)\n    wer_score = wer.compute(predictions=decoded_predictions, references=decoded_labels)\n    return {\"wer_score\": wer_score}"
  },
  {
    "objectID": "공부/HF/2024-10-10-(강의) 이미지캡셔닝.html#train",
    "href": "공부/HF/2024-10-10-(강의) 이미지캡셔닝.html#train",
    "title": "(강의) 이미지캡셔닝",
    "section": "Train!",
    "text": "Train!\nNow, you are ready to start fine-tuning the model. You will use the 🤗 Trainer for this.\nFirst, define the training arguments using TrainingArguments.\n\nfrom transformers import TrainingArguments, Trainer\n\nmodel_name = checkpoint.split(\"/\")[1]\n\ntraining_args = TrainingArguments(\n    output_dir=f\"{model_name}-pokemon\",\n    learning_rate=5e-5,\n    num_train_epochs=50,\n    fp16=True,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    gradient_accumulation_steps=2,\n    save_total_limit=3,\n    eval_strategy=\"steps\",\n    eval_steps=50,\n    save_strategy=\"steps\",\n    save_steps=50,\n    logging_steps=50,\n    remove_unused_columns=False,\n    push_to_hub=False,\n    label_names=[\"labels\"],\n    load_best_model_at_end=True,\n    report_to=\"none\"\n)\n\nTypeError: TrainingArguments.__init__() got an unexpected keyword argument 'fp8'\n\n\nThen pass them along with the datasets and the model to 🤗 Trainer.\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_ds,\n    eval_dataset=test_ds,\n    compute_metrics=compute_metrics,\n)\n\n/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n\n\nTo start training, simply call train() on the Trainer object.\n\ntrainer.train()\n\n\n    \n      \n      \n      [  821/37450 03:34 &lt; 2:40:03, 3.81 it/s, Epoch 1.09/50]\n    \n    \n\n\n\nStep\nTraining Loss\nValidation Loss\nWer Score\n\n\n\n\n50\n0.026300\n0.044181\n20.547879\n\n\n100\n0.027600\n0.042344\n20.498182\n\n\n150\n0.030300\n0.042287\n0.946667\n\n\n200\n0.029400\n0.042165\n20.414545\n\n\n250\n0.028100\n0.043227\n20.484848\n\n\n300\n0.031700\n0.043206\n20.488485\n\n\n350\n0.040200\n0.038477\n20.465455\n\n\n400\n0.047200\n0.038973\n20.496970\n\n\n450\n0.036400\n0.037987\n20.480000\n\n\n500\n0.037600\n0.039909\n20.478788\n\n\n550\n0.035200\n0.037943\n20.466667\n\n\n600\n0.036000\n0.036907\n20.464242\n\n\n650\n0.036200\n0.037871\n20.484848\n\n\n700\n0.036000\n0.038082\n20.460606\n\n\n750\n0.034300\n0.038345\n20.473939\n\n\n800\n0.029600\n0.039002\n20.484848\n\n\n\n\n\n\nKeyboardInterrupt: \n\n\nYou should see the training loss drop smoothly as training progresses.\nOnce training is completed, share your model to the Hub with the push_to_hub() method so everyone can use your model:\n\ntrainer.push_to_hub()"
  },
  {
    "objectID": "공부/HF/2024-10-10-(강의) 이미지캡셔닝.html#inference",
    "href": "공부/HF/2024-10-10-(강의) 이미지캡셔닝.html#inference",
    "title": "(강의) 이미지캡셔닝",
    "section": "Inference",
    "text": "Inference\nTake a sample image from test_ds to test the model.\n\nfrom PIL import Image\nimport requests\n\nurl = \"https://huggingface.co/datasets/sayakpaul/sample-datasets/resolve/main/pokemon.png\"\nimage = Image.open(requests.get(url, stream=True).raw)\nimage\n\n\n&lt;img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/test_image_image_cap.png\" alt=\"Test image\"/&gt;\n\nPrepare image for the model.\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ninputs = processor(images=image, return_tensors=\"pt\").to(device)\npixel_values = inputs.pixel_values\n\nCall generate and decode the predictions.\n\ngenerated_ids = model.generate(pixel_values=pixel_values, max_length=50)\ngenerated_caption = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\nprint(generated_caption)\n\na drawing of a pink and blue pokemon\nLooks like the fine-tuned model generated a pretty good caption!"
  },
  {
    "objectID": "공부/HF/2024-08-28-(강의) IMDB 자료 살펴보기, 지도학습의 개념.html",
    "href": "공부/HF/2024-08-28-(강의) IMDB 자료 살펴보기, 지도학습의 개념.html",
    "title": "(강의) IMDB 자료 살펴보기, 지도학습의 개념",
    "section": "",
    "text": "- 데이터 분석을 하고 싶음.\n\n할줄아는것이 별로 없음.\n이론적으로 처음부터 익히기엔 각이 안나옴. (엄두가 나지 않는다.)\n블로그등을 보면서 데이터 분석하는 코드를 독학하기로함.\n전략: (1) 블로그의 코드를 돌려본다. (2) 블로그의 코드를 이해한다. (이론을 이해하는게 아님. 코드를 이해하는 것임) (3) 블로그의 코드에서 데이터 부분만 내가 사용할 데이터로 바꿔친다. (4) 돌려서 결과를 제출한다.\n\n- 어려울 것이라 예상하는 점\n\n\n안돌아갈걸?\n\n\n이해가 안될걸?\n\n\n이게 진짜 어려움..\n\n\n돌아는 가는데 결과가 안좋을거에요.\n\n\n- 소망:\n\n(1)-(4) 의 과정이 매끄럽게 되었으면..\n이 과정이 빠르게 반복해서 여러코드를 최대한 빨리 정리할 수 있으면..\n그래서 비슷한 분석을 할때 참고할 거리가 많았으면..\n나중에는 원리를 알아 코드를 많이 참고하지 않고도 내가 어느정도 분석할 수 있으면..\n\n- 마음가짐: 컨셉을 잘 잡아야함.\n\n나는 어떠한 코드도 짤 수 있는 사람이다. X\n나는 어떠한 코드도 이해할 수 있는 사람이다. X\n나는 어떠한 코드도 베낄 수 있는 (활용할 수 있는) 사람이다. O\n\n\n느리지만 정확하게 해결하는것은 옳지 않음. 모든 분석은 시간싸움임. 느려지는 순간 이미 뒤쳐진다. (마라톤 하는게 아님. 100m달리기임.)\n\n- 전 컴공과 교수가 아니에요. (그럴만한 실력도 없어요) 그냥 먹고살기 위해서 눈치껏 코딩할 뿐입니다.\n\n그래서 강의노트도 무식하게 만들예정..\n이전에는 예쁘게 만든 편임.. (빅데이터혁신공유대학 프로그램.. 서해안권 어쩌고..)"
  },
  {
    "objectID": "공부/HF/2024-08-28-(강의) IMDB 자료 살펴보기, 지도학습의 개념.html#a.-imdb",
    "href": "공부/HF/2024-08-28-(강의) IMDB 자료 살펴보기, 지도학습의 개념.html#a.-imdb",
    "title": "(강의) IMDB 자료 살펴보기, 지도학습의 개념",
    "section": "A. imdb",
    "text": "A. imdb\n- 그럼 이제 imdb 는 뭐지??\n\n아마 데이터가 있겠죠?\n그런데 그걸 어떻게 보죠??\n되게 궁금한데 이거 홈페이지에도 데이터 살펴보는 방법 없어요\n\n- 뜯어보자..\n\nimdb\n\nDatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 25000\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 25000\n    })\n    unsupervised: Dataset({\n        features: ['text', 'label'],\n        num_rows: 50000\n    })\n})\n\n\n\n딕셔너리 아니야?\n\n- 딕셔너리는 아님\n\ntype(imdb)\n\ndatasets.dataset_dict.DatasetDict\n\n\n- 그런데 거의 딕셔너리처럼 쓰라는거 같음\n\nimdb.keys()\n\ndict_keys(['train', 'test', 'unsupervised'])\n\n\n\nimdb['train']\n\nDataset({\n    features: ['text', 'label'],\n    num_rows: 25000\n})\n\n\n\nimdb['test']\n\nDataset({\n    features: ['text', 'label'],\n    num_rows: 25000\n})\n\n\n\nimdb['unsupervised']\n\nDataset({\n    features: ['text', 'label'],\n    num_rows: 50000\n})\n\n\n- imdb는 딕셔너리 같은것이고 imdb['train'] 와 같은 명령어로 세부항목에 접근가능함. 즉 아래의 구조임.\n\nimdb['train'] \\(\\subset\\) imdb\nimdb['test'] \\(\\subset\\) imdb\nimdb['unsupervised'] \\(\\subset\\) imdb"
  },
  {
    "objectID": "공부/HF/2024-08-28-(강의) IMDB 자료 살펴보기, 지도학습의 개념.html#b.-imdbtrain",
    "href": "공부/HF/2024-08-28-(강의) IMDB 자료 살펴보기, 지도학습의 개념.html#b.-imdbtrain",
    "title": "(강의) IMDB 자료 살펴보기, 지도학습의 개념",
    "section": "B. imdb['train']",
    "text": "B. imdb['train']\n- 그럼 이제 imdb['train'] 가 뭔지 볼까?\n\nimdb['train']\n\nDataset({\n    features: ['text', 'label'],\n    num_rows: 25000\n})\n\n\n\n이것도 혹시 딕셔너리 비슷한것??\n\n\nimdb['train'].keys()\n\nAttributeError: 'Dataset' object has no attribute 'keys'\n\n\n\nimdb['train']['features']\n\nKeyError: \"Column features not in the dataset. Current columns in the dataset: ['text', 'label']\"\n\n\n\n딕셔너리 처럼 잘 안되네..\n\n- 쓸만한게 있을까? __getitem__ 이 있음.. –&gt; 이런거 리스트에도 있었는데\n\nset(dir(imdb['train'])) # get_item 가지고 있넹.. \n\n{'_TF_DATASET_REFS',\n '__class__',\n '__del__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__enter__',\n '__eq__',\n '__exit__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__getitem__',\n '__getitems__',\n '__getstate__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__iter__',\n '__le__',\n '__len__',\n '__lt__',\n '__module__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__setstate__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n '__weakref__',\n '_build_local_temp_path',\n '_check_index_is_initialized',\n '_data',\n '_estimate_nbytes',\n '_fingerprint',\n '_format_columns',\n '_format_kwargs',\n '_format_type',\n '_generate_tables_from_cache_file',\n '_generate_tables_from_shards',\n '_get_cache_file_path',\n '_get_output_signature',\n '_getitem',\n '_indexes',\n '_indices',\n '_info',\n '_map_single',\n '_new_dataset_with_indices',\n '_output_all_columns',\n '_push_parquet_shards_to_hub',\n '_save_to_disk_single',\n '_select_contiguous',\n '_select_with_indices_mapping',\n '_split',\n 'add_column',\n 'add_elasticsearch_index',\n 'add_faiss_index',\n 'add_faiss_index_from_external_arrays',\n 'add_item',\n 'align_labels_with_mapping',\n 'builder_name',\n 'cache_files',\n 'cast',\n 'cast_column',\n 'citation',\n 'class_encode_column',\n 'cleanup_cache_files',\n 'column_names',\n 'config_name',\n 'data',\n 'dataset_size',\n 'description',\n 'download_checksums',\n 'download_size',\n 'drop_index',\n 'export',\n 'features',\n 'filter',\n 'flatten',\n 'flatten_indices',\n 'format',\n 'formatted_as',\n 'from_buffer',\n 'from_csv',\n 'from_dict',\n 'from_file',\n 'from_generator',\n 'from_json',\n 'from_list',\n 'from_pandas',\n 'from_parquet',\n 'from_polars',\n 'from_spark',\n 'from_sql',\n 'from_text',\n 'get_index',\n 'get_nearest_examples',\n 'get_nearest_examples_batch',\n 'homepage',\n 'info',\n 'is_index_initialized',\n 'iter',\n 'license',\n 'list_indexes',\n 'load_elasticsearch_index',\n 'load_faiss_index',\n 'load_from_disk',\n 'map',\n 'num_columns',\n 'num_rows',\n 'prepare_for_task',\n 'push_to_hub',\n 'remove_columns',\n 'rename_column',\n 'rename_columns',\n 'reset_format',\n 'save_faiss_index',\n 'save_to_disk',\n 'search',\n 'search_batch',\n 'select',\n 'select_columns',\n 'set_format',\n 'set_transform',\n 'shape',\n 'shard',\n 'shuffle',\n 'size_in_bytes',\n 'skip',\n 'sort',\n 'split',\n 'supervised_keys',\n 'take',\n 'task_templates',\n 'to_csv',\n 'to_dict',\n 'to_iterable_dataset',\n 'to_json',\n 'to_list',\n 'to_pandas',\n 'to_parquet',\n 'to_polars',\n 'to_sql',\n 'to_tf_dataset',\n 'train_test_split',\n 'unique',\n 'version',\n 'with_format',\n 'with_transform'}\n\n\n- 리스트처럼 써볼까?\n\nimdb['train'][0]\n\n{'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.&lt;br /&gt;&lt;br /&gt;The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.&lt;br /&gt;&lt;br /&gt;What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.&lt;br /&gt;&lt;br /&gt;I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.',\n 'label': 0}\n\n\n\nimdb['train'][1]\n\n{'text': '\"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn\\'t matter what one\\'s political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn\\'t true. I\\'ve seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don\\'t exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we\\'re treated to the site of Vincent Gallo\\'s throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) \"double-standard\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won\\'t see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women\\'s bodies.',\n 'label': 0}\n\n\n\nimdb['train'][:2]\n\n{'text': ['I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.&lt;br /&gt;&lt;br /&gt;The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.&lt;br /&gt;&lt;br /&gt;What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.&lt;br /&gt;&lt;br /&gt;I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.',\n  '\"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn\\'t matter what one\\'s political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn\\'t true. I\\'ve seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don\\'t exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we\\'re treated to the site of Vincent Gallo\\'s throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) \"double-standard\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won\\'t see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women\\'s bodies.'],\n 'label': [0, 0]}\n\n\n\nimdb['train'][-1]\n\n{'text': 'The story centers around Barry McKenzie who must go to England if he wishes to claim his inheritance. Being about the grossest Aussie shearer ever to set foot outside this great Nation of ours there is something of a culture clash and much fun and games ensue. The songs of Barry McKenzie(Barry Crocker) are highlights.',\n 'label': 1}\n\n\n- text와 label의 의미는 뭐지??\n\ntype(imdb['train'][1])\n\ndict\n\n\n\nprint(imdb['train'][1]['text'])\n\n\"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn't matter what one's political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn't true. I've seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don't exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we're treated to the site of Vincent Gallo's throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) \"double-standard\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won't see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women's bodies.\n\n\n\n영어: “I Am Curious: Yellow” is a risible and pretentious steaming pile. It doesn’t matter what one’s political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn’t true. I’ve seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don’t exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we’re treated to the site of Vincent Gallo’s throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) “double-standard” in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won’t see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women’s bodies.\n\n\n한글: 영화 I Am Curious: Yellow는 우스꽝스럽고 허세 가득한 쓰레기일 뿐입니다. 정치적 견해가 무엇이든 상관없이, 이 영화는 어떤 수준에서도 진지하게 받아들일 수 없습니다. 남성의 전면 누드가 자동으로 NC-17 등급을 받는다는 주장에 대해서는, 그것은 사실이 아닙니다. 저는 남성 누드가 나오는 R등급 영화들을 본 적이 있습니다. 물론, 잠깐 등장하는 장면일 뿐이었지만, 그럼 여성의 외음부가 드러나는 R등급 영화는 어디 있나요? 그런 영화는 존재하지 않습니다. 같은 논리가 케이블 TV 쇼에도 적용됩니다. 남성의 성기가 흔들리는 장면은 나오지만, 클리토리스는 보이지 않습니다. 그리고 The Brown Bunny 같은 허세 가득한 독립 영화에서도, 빈센트 갈로의 성기가 등장하는 반면, 클로이 세비니의 여성 성기는 보이지 않습니다. 누드에 있어서 ’이중잣대’라고 우는 사람들은, 남성과 여성 간의 불가피한 해부학적 차이를 고려해야 합니다. 여배우가 누드로 등장할 때는 성기가 드러나지 않지만, 남성의 경우 그렇지 않다는 점입니다. 사실, 여성의 성기가 나오는 미국 영화는 포르노나 노골적인 에로 영화를 제외하면 거의 없습니다. 이 이중잣대는 문화적으로 여성의 신체 내부를 다루는 방식에 대한 문제일 뿐, 진정한 이중잣대라고 할 수는 없습니다.\n\n\n영화평인듯..\n겁나 뭐라함\n\n- 이 텍스트에 대한 라벨은 0\n\nimdb['train'][1]['label']\n\n0\n\n\n- imdb['train'][2] 도 살펴보자. \\(\\to\\) 부정적으로 평가하고 라벨이 0\n\nimdb['train'][2]\n\n{'text': \"If only to avoid making this type of film in the future. This film is interesting as an experiment but tells no cogent story.&lt;br /&gt;&lt;br /&gt;One might feel virtuous for sitting thru it because it touches on so many IMPORTANT issues but it does so without any discernable motive. The viewer comes away with no new perspectives (unless one comes up with one while one's mind wanders, as it will invariably do during this pointless film).&lt;br /&gt;&lt;br /&gt;One might better spend one's time staring out a window at a tree growing.&lt;br /&gt;&lt;br /&gt;\",\n 'label': 0}\n\n\n- imdb['train'][-2] 도 살펴보자. \\(\\to\\) 긍정적으로 평가하고 라벨이 1\n\nimdb['train'][-2]\n\n{'text': '\\'The Adventures Of Barry McKenzie\\' started life as a satirical comic strip in \\'Private Eye\\', written by Barry Humphries and based on an idea by Peter Cook. McKenzie ( \\'Bazza\\' to his friends ) is a lanky, loud, hat-wearing Australian whose two main interests in life are sex ( despite never having had any ) and Fosters lager. In 1972, he found his way to the big screen for the first of two outings. It must have been tempting for Humphries to cast himself as \\'Bazza\\', but he wisely left the job to Barry Crocker ( later to sing the theme to the television soap opera \\'Neighbours\\'! ). Humphries instead played multiple roles in true Peter Sellers fashion, most notably Bazza\\'s overbearing Aunt \\'Edna Everage\\' ( this was before she became a Dame ).&lt;br /&gt;&lt;br /&gt;You know this is not going to be \\'The Importance Of Being Ernest\\' when its censorship classification N.P.A. stands for \\'No Poofters Allowed\\'. Pom-hating Bazza is told by a Sydney solicitor that in order to inherit a share in his father\\'s will he must go to England to absorb British culture. With Aunt Edna in tow, he catches a Quantas flight to Hong Kong, and then on to London. An over-efficient customs officer makes Bazza pay import duties on everything he bought over there, including a suitcase full of \\'tubes of Fosters lager\\'. As he puts it: \"when it comes to fleecing you, the Poms have got the edge on the gyppos!\". A crafty taxi driver ( Bernard Spear ) maximises the fare by taking Bazza and Edna first to Stonehenge, then Scotland. The streets of London are filthy, and their hotel is a hovel run by a seedy landlord ( Spike Milligan ) who makes Bazza put pound notes in the electricity meter every twenty minutes. There is some good news for our hero though; he meets up with other Aussies in Earls Court, and Fosters is on sale in British pubs.&lt;br /&gt;&lt;br /&gt;What happens next is a series of comical escapades that take Bazza from starring in his own cigarette commercial, putting curry down his pants in the belief it is some form of aphrodisiac, a bizarre encounter with Dennis Price as an upper-class pervert who loves being spanked while wearing a schoolboy\\'s uniform, a Young Conservative dance in Rickmansworth to a charity rock concert where his song about \\'chundering\\' ( vomiting ) almost makes him an international star, and finally to the B.B.C. T.V. Centre where he pulls his pants down on a live talk-show hosted by the thinking man\\'s crumpet herself, Joan Bakewell. A fire breaks out, and Bazza\\'s friends come to the rescue - downing cans of Fosters, they urinate on the flames en masse.&lt;br /&gt;&lt;br /&gt;This is a far cry from Bruce Beresford\\'s later works - \\'Breaker Morant\\' and \\'Driving Miss Daisy\\'. On release, it was savaged by critics for being too \\'vulgar\\'. Well, yes, it is, but it is also great non-P.C. fun. \\'Bazza\\' is a disgusting creation, but his zest for life is unmistakable, you cannot help but like the guy. His various euphemisms for urinating ( \\'point Percy at the porcelain\\' ) and vomiting ( \\'the Technicolour yawn\\' ) have passed into the English language without a lot of people knowing where they came from. Other guest stars include Dick Bentley ( as a detective who chases Bazza everywhere ), Peter Cook, Julie Covington ( later to star in \\'Rock Follies\\' ), and even future arts presenter Russell Davies.&lt;br /&gt;&lt;br /&gt;A sequel - the wonderfully-named \\'Barry McKenzie Holds His Own - came out two years later. At its premiere, Humphries took the opportunity to blast the critics who had savaged the first film. Good for him.&lt;br /&gt;&lt;br /&gt;What must have been of greater concern to him, though, was the release of \\'Crocodile Dundee\\' in 1985. It also featured a lanky, hat-wearing Aussie struggling to come to terms with a foreign culture. And made tonnes more money.&lt;br /&gt;&lt;br /&gt;The song on the end credits ( performed by Snacka Fitzgibbon ) is magnificent. You have a love a lyric that includes the line: \"If you want to send your sister in a frenzy, introduce her to Barry McKenzie!\". Time to end this review. I have to go the dunny to shake hands with the unemployed...',\n 'label': 1}\n\n\n- 요약: imdb['train'] 에는 여러개의 영화평이 있고, 각각 긍정평가와 부정평가를 담고 있다.\n\n몇개의 영화평??\n\n\nlen(imdb['train']) # 어케 len을 쓸 생각을 했어?? 어지간하면 리스트 비슷한건 len이 있더라고요..\n\n25000\n\n\n\nimdb['train'][-1]\n\n{'text': 'The story centers around Barry McKenzie who must go to England if he wishes to claim his inheritance. Being about the grossest Aussie shearer ever to set foot outside this great Nation of ours there is something of a culture clash and much fun and games ensue. The songs of Barry McKenzie(Barry Crocker) are highlights.',\n 'label': 1}\n\n\n\nimdb['train'][24999]\n\n{'text': 'The story centers around Barry McKenzie who must go to England if he wishes to claim his inheritance. Being about the grossest Aussie shearer ever to set foot outside this great Nation of ours there is something of a culture clash and much fun and games ensue. The songs of Barry McKenzie(Barry Crocker) are highlights.',\n 'label': 1}"
  },
  {
    "objectID": "공부/HF/2024-08-28-(강의) IMDB 자료 살펴보기, 지도학습의 개념.html#c.-imdbtest",
    "href": "공부/HF/2024-08-28-(강의) IMDB 자료 살펴보기, 지도학습의 개념.html#c.-imdbtest",
    "title": "(강의) IMDB 자료 살펴보기, 지도학습의 개념",
    "section": "C. imdb['test']",
    "text": "C. imdb['test']\n- imdb[\"train\"] 과 비슷함\n\nimdb[\"test\"][0]\n\n{'text': 'I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV are usually underfunded, under-appreciated and misunderstood. I tried to like this, I really did, but it is to good TV sci-fi as Babylon 5 is to Star Trek (the original). Silly prosthetics, cheap cardboard sets, stilted dialogues, CG that doesn\\'t match the background, and painfully one-dimensional characters cannot be overcome with a \\'sci-fi\\' setting. (I\\'m sure there are those of you out there who think Babylon 5 is good sci-fi TV. It\\'s not. It\\'s clichéd and uninspiring.) While US viewers might like emotion and character development, sci-fi is a genre that does not take itself seriously (cf. Star Trek). It may treat important issues, yet not as a serious philosophy. It\\'s really difficult to care about the characters here as they are not simply foolish, just missing a spark of life. Their actions and reactions are wooden and predictable, often painful to watch. The makers of Earth KNOW it\\'s rubbish as they have to always say \"Gene Roddenberry\\'s Earth...\" otherwise people would not continue watching. Roddenberry\\'s ashes must be turning in their orbit as this dull, cheap, poorly edited (watching it without advert breaks really brings this home) trudging Trabant of a show lumbers into space. Spoiler. So, kill off a main character. And then bring him back as another actor. Jeeez! Dallas all over again.',\n 'label': 0}\n\n\n\nlen(imdb[\"test\"])\n\n25000"
  },
  {
    "objectID": "공부/HF/2024-08-28-(강의) IMDB 자료 살펴보기, 지도학습의 개념.html#d.-imdbunsupervised",
    "href": "공부/HF/2024-08-28-(강의) IMDB 자료 살펴보기, 지도학습의 개념.html#d.-imdbunsupervised",
    "title": "(강의) IMDB 자료 살펴보기, 지도학습의 개념",
    "section": "D. imdb['unsupervised']",
    "text": "D. imdb['unsupervised']\n- 대충 이러한 구조임\n\nimdb\n\nDatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 25000\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 25000\n    })\n    unsupervised: Dataset({\n        features: ['text', 'label'],\n        num_rows: 50000\n    })\n})\n\n\n- 느낌적으로 imdb['unsupervised'] 는.. 두개의 합집합이 아닐까? (아니야..)\n\nimdb['unsupervised'][0]\n\n{'text': 'This is just a precious little diamond. The play, the script are excellent. I cant compare this movie with anything else, maybe except the movie \"Leon\" wonderfully played by Jean Reno and Natalie Portman. But... What can I say about this one? This is the best movie Anne Parillaud has ever played in (See please \"Frankie Starlight\", she\\'s speaking English there) to see what I mean. The story of young punk girl Nikita, taken into the depraved world of the secret government forces has been exceptionally over used by Americans. Never mind the \"Point of no return\" and especially the \"La femme Nikita\" TV series. They cannot compare the original believe me! Trash these videos. Buy this one, do not rent it, BUY it. BTW beware of the subtitles of the LA company which \"translate\" the US release. What a disgrace! If you cant understand French, get a dubbed version. But you\\'ll regret later :)',\n 'label': -1}\n\n\n\nset([l['label'] for l in imdb['unsupervised']])\n\n{-1}\n\n\n\n일단 라벨은 -1 밖에 없넹..\n\n\nimdb['train'][0]\n\n{'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.&lt;br /&gt;&lt;br /&gt;The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.&lt;br /&gt;&lt;br /&gt;What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.&lt;br /&gt;&lt;br /&gt;I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.',\n 'label': 0}\n\n\n\ntext0 = imdb['unsupervised'][0]['text']\n\n\nsum([text0 in l['text'] for l in imdb['train']])\n\n0\n\n\n\nsum([text0 in l['text'] for l in imdb['test']])\n\n0"
  },
  {
    "objectID": "공부/HF/2024-08-28-(강의) IMDB 자료 살펴보기, 지도학습의 개념.html#f.-정리",
    "href": "공부/HF/2024-08-28-(강의) IMDB 자료 살펴보기, 지도학습의 개념.html#f.-정리",
    "title": "(강의) IMDB 자료 살펴보기, 지도학습의 개념",
    "section": "F. 정리",
    "text": "F. 정리\n- 요약:\n\nimdb는 각각 imdb['train'], imdb['test'], imdb['unsupervised'] 로 나누어져 있다.\nimdb['train'], imdb['test'] 에는 각각 (text,label) 과 같은 형식의 정보가 있다. 여기에서 label은 0 혹은 1의 값을 가지는데 0은 부정, 1은 긍정을 나타낸다.\nimdb['unsupervised'] 에도 각각 (text,label) 과 같은 형식의 정보가 있으나, 여기에서 label은 -1의 값만 있다. 이는 긍정 혹은 부정도 의미하지 않는듯 하다. 따라서 이것은 사실상 imdb['unsupervised'] 에는 text 정보만 있고 그 text가 긍정평가인지 부정평가인지는 분류가 되어있지 않은 상태라고 볼 수 있다.\n\n- 외우세요: “train”, “test”, “unsupervised” 란 단어는 중요한 단어니까 외우세여"
  },
  {
    "objectID": "공부/HF/2024-08-28-(강의) IMDB 자료 살펴보기, 지도학습의 개념.html#a.-기계학습딥러닝의-과업",
    "href": "공부/HF/2024-08-28-(강의) IMDB 자료 살펴보기, 지도학습의 개념.html#a.-기계학습딥러닝의-과업",
    "title": "(강의) IMDB 자료 살펴보기, 지도학습의 개념",
    "section": "A. 기계학습/딥러닝의 과업",
    "text": "A. 기계학습/딥러닝의 과업\n- 왜 이렇게 데이터가 나누어져 있나?\n\n개념: 머신러닝에는 지도학습과 비지도학습이 있음.\n데이터 세트에서 imdb['train'], imdb['test'] 은 지도학습 모델을 배우기 위한 예제데이터이고, imdb['unsupervised']는 비지도학습을 모델을 배우기 위한 예제데이터임.\n아무튼 지금 이 수업에서는 지도학습을 설명할 것이고 따라서 imdb['train'], imdb['test'] 만 쓰겠음"
  },
  {
    "objectID": "공부/HF/2024-08-28-(강의) IMDB 자료 살펴보기, 지도학습의 개념.html#b.-지도학습의-목표",
    "href": "공부/HF/2024-08-28-(강의) IMDB 자료 살펴보기, 지도학습의 개념.html#b.-지도학습의-목표",
    "title": "(강의) IMDB 자료 살펴보기, 지도학습의 개념",
    "section": "B. 지도학습의 목표",
    "text": "B. 지도학습의 목표\n- 지도학습이란? (이 예제 한정해서 설명)\n\n자료가 “(텍스트,라벨)” 의 형태로 정리되어 있을 때, “텍스트”를 입력으로 주면 “라벨”을 출력해주는 함수 f를 찾는 일\n코드로 예를들어 설명하면 적당히 f이라는 이름의 함수가 존재하여 아래와 같은 동작이 가능해야함.\n\nf(\"영화가 너무 재미없어요.\")\n&gt; \"부정평가입니다\"\n\nf(\"영화 괜찮은데요??\")\n&gt; \"긍정평가입니다\"\n\nf(\"배우들 연기 진짜 잘함. 영상미도 있음. 그런데 스토리가 망했네.\")\n&gt; \"부정평가입니다\"\n- 이러한 함수 f 을 우리가 잘 정의한다면 좋겠음. (가능한가?)\n- 대충 아래의 과정을 거친다고 생각하면 편리함\n\n정보(숫자,텍스트,이미지,…) \\(\\to\\) 숫자 \\(\\to\\) 계산 \\(\\to\\) 계산된숫자 \\(\\to\\) 정보\n\n- 예를들면 아래와 같은 방식이 가능\n\n긍정단어 = {'좋아', '재미있었음', '잘생김', '예뻐', '연기훌륭함'}\n부정단어 = {'지루해', '재미없었음', '비추천'}\n\n\ntext0 = '남주가 너무 잘생김 여주도 예뻐 영화가 중간에 조금 지루해 그래도 아무튼 재미있었음'\n\n\n긍정단어수 = sum([l in 긍정단어 for l in text0.split(' ')]) \n부정단어수 = sum([l in 부정단어 for l in text0.split(' ')]) \n긍정단어수/(긍정단어수+부정단어수) \n\n0.75\n\n\n\ndef f(text):\n    긍정단어수 = sum([l in 긍정단어 for l in text.split(' ')]) \n    부정단어수 = sum([l in 부정단어 for l in text.split(' ')]) \n    결과 = 긍정단어수/(긍정단어수+부정단어수) \n    if 결과&gt;0.5: \n        return 결과, \"긍정평가\"\n    else:\n        return 결과, \"부정평가\"\n\n\nf('남주가 너무 잘생김 여주도 예뻐 영화가 중간에 조금 지루해 그래도 아무튼 재미있었음')\n\n(0.75, '긍정평가')\n\n\n- 그렇지만 당연히 위의 모델은 약점이 많음.\n\nf('남주가 너무 잘생겼어 여주도 예쁨 영화가 중간에 조금 지루해 그래도 아무튼 괜찮았음')\n\n(0.0, '부정평가')\n\n\n\nf('캐스팅 좋아 여주인공이 특히 예쁨 배우들 연기훌륭함 그렇지만 스토리때문에 나는 개인적으로 비추천')\n\n(0.6666666666666666, '긍정평가')\n\n\n- 다행인점: 좋은 f를 만들기 위해서 고민할 필요 없음. (똑똑한사람들이 다 만들어 놓음)\n\n옜날방식: f를 한땀한땀 설계. 초고수가 밤새 코딩해서 진짜 잘 맞추는 f를 한번에 제시.\n최근방식: f를 대충 설계. 거의 멍청이 f임. 그런데 데이터를 줄수록 f가 점점 똑똑해짐. 나중에는 다 맞춤. \\(\\to\\) 인공지능?????"
  },
  {
    "objectID": "공부/HF/2024-08-28-(강의) IMDB 자료 살펴보기, 지도학습의 개념.html#c.-traintest-자료의-의미",
    "href": "공부/HF/2024-08-28-(강의) IMDB 자료 살펴보기, 지도학습의 개념.html#c.-traintest-자료의-의미",
    "title": "(강의) IMDB 자료 살펴보기, 지도학습의 개념",
    "section": "C. train/test 자료의 의미",
    "text": "C. train/test 자료의 의미\n- 초고수가 f를 직접 설계하는 경우와는 다르게 컴퓨터가 데이터를 보고 f를 알아서 수정할 경우 이상한 방식으로 수정할 수가 있음.\n\n어떻게 이런일이 가능할까?\n\n- 최규빈 교수의 착각\n\n상상: 나는 학생들에게 파이썬프로그래밍을 잘 강의하고 싶었다. 나는 학생들에게 다양한 문제를 풀어줬으며, 문제를 풀면서 학생들이 스스로 개념을 깨우치길 원했다. 나는 다양한 예시를 통하여 이해하는 것이 좋다고 생각했기 때문이다. 예시는 많을수록 좋다고 생각해서 한 학기동안 총 1000개의 문제를 풀어줬다. 기말고사는 풀어준 문제중에서 약 20문항을 샘플링하여 출제했다. 놀랍게도 학생들이 모두 만점을 받았으며 나는 아주 만족스러웠다. 한 학기 동안 고생한 보람이 있어보였다. 눈물이 흘렀다.\n질문: 저는 잘 평가한 걸까요? 학생들은 진짜 파이썬프로그래밍을 잘 이해했을까요? (학과 교수님들께 자랑해도 될까요??)\n이렇게 하고 싶지 않나요?: 1000개의 문제에서 샘플링하여 100% 출제하지 않고, 새로운 문항을 개발하여 학생들에게 준다면??\n요령있는 교수라면 이렇게 할거에요: 50000개의 문제세트가 있다고 가정. 수업시간에는 학생들에게 예시로 25000개정도의 문항만 풀이하며 설명. 기말고사에는 수업시간에 풀이하지 않은 25000의 문항을 출제함.\n만약에 학생들이 수업시간에 풀어준 25000개의 문제를 올바르게 이해했다면, 수업시간에 풀이하지 않은 문항 25000개 역시 잘 풀었을 것임.\n\n- 이 상황을 살짝 바꿔볼게요.\n\n상상: 나는 인공지능에게 “영화평가 텍스트를 주면 그것이 긍정평가인지 부정평가인지 판단하는 능력”을 잘 학습시키고 싶었다. 나는 인공지능에게 다양한 데이터를 제공했으며, 데이터를 보고 인공지능이 스스로 원리를 깨우치길 원했다. 데이터는 많을수록 좋다고 생각해서 약 50000개의 “(텍스트,라벨)” 쌍을 제공했다. 그리고 50000개의 “(텍스트,라벨)” 쌍에서 약 20문항을 샘플링하여 테스트했다. 놀랍게도 인공지능은 20문항을 모두 맞추었다. 나는 아주 만족스러웠다.\n질문: 저는 인공지능을 잘 학습시켰을까요?\n이렇게 하고 싶지 않나요?: 50000개의 데이터중, 25000개의 “(텍스트,라벨)”만 인공지능에게 제공하여 학습시킴. 그리고 나머지 25000개는 평가용으로 테스트해봄.\n만약에 인공지능이 진짜 영화평가 텍스트를 바탕으로 그것이 긍정평가인지 부정평가인지 판단하는 능력을 길렀다면? 내가 인공지능에 제공하지 않은 25000에 대하여서도 함수 f가 올바르게 동작해야함!\n\n- train data / test data\n\ntrain data 는 인공지능에게 학습용으로 미리 제공하는 데이터\ntest data 는 인공지능이 진짜 잘 학습했는지 평가하기 위해 학습시 제공하지 않는 자료"
  },
  {
    "objectID": "공부/HF/2024-08-28-(강의) IMDB 자료 살펴보기, 지도학습의 개념.html#d.-trainvaltest-자료의-의미",
    "href": "공부/HF/2024-08-28-(강의) IMDB 자료 살펴보기, 지도학습의 개념.html#d.-trainvaltest-자료의-의미",
    "title": "(강의) IMDB 자료 살펴보기, 지도학습의 개념",
    "section": "D. train/val/test 자료의 의미",
    "text": "D. train/val/test 자료의 의미\n- 학생입장에서 생각해본다면?\n\n소망: 내가 외우려고 한게 아니고 하도 공부하다보니까 문제가 외워졌음. 나도 그러기 싫음. 나도 내가 올바르게 공부했는지 체크하고 싶어.\n아이디어: 교수님이 풀어준 25000개중에서 15000개정도만 내가 풀이를 보면서 공부하고 나머지 10000개는 나 스스로 올바르게 공부했는지 체크하는 용도로 삼자.\n진행사항:\n\n1일차: 15000: 50점, 10000: 30점\n2일차: 15000: 90점, 10000: 85점\n3일차: 15000: 100점, 10000: 80점 &lt;– 이런 경험 없어요??\n\n판단: 이게 한 3일차 공부하다보니까 문제를 내가 너무 외운것같네? 오히려 2일차때의 느낌이 더 좋음. 그냥 2일차의 느낌으로 시험보러 가자.\n\n- 이럴경우 아래와 같이 상황이 정리된다.\n\n원래: 교수가 수업시간에 풀어준 25000문제 = 학생이 공부할 25000문제 = train // 교수가 기말시험으로 제출한 25000문제 = test\n바뀐상황: 학생공부할 15000문제 = train / 학생자체test 10000문제 = test // 교수가 기말시험으로 제출한 25000문제 = 찐 test\n\n- 이때 학생자체적으로 빼둔 test set을 validation set이라고 부른다 따라서 아래와 같이 정리가능하다.\n\ntrain = 15000문제 = 학생이 스스로 공부\nvalidation = 10000문제 = 학생이 공부할때 사용하지 않음. 자가진단용.\ntest = 25000문제 = 교수가 출제하는 시험\n\n- train/validation/test에 대한 용어는 엄밀하지 않게 사용되는 경우가 많아 그때그때 상황에 따라 맞게 알아서 해석해야 한다.\n\n억지상황1: 교수가 시험보지 않음. 그런데 내가 스스로 공부하면서 체크하고 싶어서 1000개의 문제를 구하고 매일 800개를 학습하고 200개를 이용하여 검증함. 이 경우는 200개의 문항을 validation이라고 부르기도 하고 test라고 부르기도함. (엄밀하게는 validation이 맞지만, 외부데이터가 없으므로 val/test의 경계가 흐릿해지는 상황)\n억지상황2: 나혼자 1000개의 문항을 800/200으로 나누어 매일 공부하고 있었음. 이때 나는 200개의 문항을 test라고 부르기도 하고 validation이라고 부르기도함. 그런데 교수가 보고 갑자기 나보고 외부 코딩대회에 나가라고 했음. 이 경우 200개의 문항은 validation이 되고 외부코딩대회에서 출제된 문항이 test가 되는 것임.\n\n- 느낌: 아래의 느낌을 기억하는게 중요함.\n\ntrain: 학습에 사용하는 자료.\nvalidation: 학습에 사용하지 않는 자료. 왜 안써? 더 좋은 훈련을 위한 목적.\ntest: 학습에 사용하지 않는 자료. 왜 안써? 올바르게 학습됨을 평가하기 위한 목적.\n\n\n헷갈리는 이유는 더 좋은 훈련을 위한 목적과 올바르게 학습됨을 폄가하기 위한 목적이 무 자르듯이 구분되지 않기 때문\n\n- 이상한 분류법\n\n데이터를 보통2개로 나누면 train/test 로 3개로 나누면 train/val/test 라고 표현한다고 생각하면 편리함.\n딱 맞는 정의는 아님. 의미상 구분해야함."
  },
  {
    "objectID": "공부/HF/2024-10-10-(강의) 음성인식.html",
    "href": "공부/HF/2024-10-10-(강의) 음성인식.html",
    "title": "(강의) 음성인식",
    "section": "",
    "text": "pip install transformers datasets evaluate jiwer\n\nRequirement already satisfied: transformers in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (4.45.1)\nRequirement already satisfied: datasets in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (2.19.1)\nRequirement already satisfied: evaluate in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (0.4.2)\nRequirement already satisfied: jiwer in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (3.0.4)\nRequirement already satisfied: filelock in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub&lt;1.0,&gt;=0.23.2 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from transformers) (0.24.6)\nRequirement already satisfied: numpy&gt;=1.17 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging&gt;=20.0 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from transformers) (24.1)\nRequirement already satisfied: pyyaml&gt;=5.1 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from transformers) (2024.7.24)\nRequirement already satisfied: requests in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers&lt;0.21,&gt;=0.20 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: safetensors&gt;=0.4.1 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm&gt;=4.27 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow&gt;=12.0.0 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill&lt;0.3.9,&gt;=0.3.0 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from datasets) (2.0.2)\nRequirement already satisfied: multiprocess in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from datasets) (0.70.15)\nRequirement already satisfied: fsspec&lt;=2024.3.1,&gt;=2023.1.0 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from fsspec[http]&lt;=2024.3.1,&gt;=2023.1.0-&gt;datasets) (2024.3.1)\nRequirement already satisfied: aiohttp in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: click&lt;9.0.0,&gt;=8.1.3 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from jiwer) (8.1.7)\nRequirement already satisfied: rapidfuzz&lt;4,&gt;=3 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from jiwer) (3.10.0)\nRequirement already satisfied: aiosignal&gt;=1.1.2 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from aiohttp-&gt;datasets) (1.2.0)\nRequirement already satisfied: attrs&gt;=17.3.0 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from aiohttp-&gt;datasets) (23.1.0)\nRequirement already satisfied: frozenlist&gt;=1.1.1 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from aiohttp-&gt;datasets) (1.4.0)\nRequirement already satisfied: multidict&lt;7.0,&gt;=4.5 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from aiohttp-&gt;datasets) (6.0.4)\nRequirement already satisfied: yarl&lt;2.0,&gt;=1.0 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from aiohttp-&gt;datasets) (1.9.3)\nRequirement already satisfied: typing-extensions&gt;=3.7.4.3 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from huggingface-hub&lt;1.0,&gt;=0.23.2-&gt;transformers) (4.11.0)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from requests-&gt;transformers) (3.3.2)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from requests-&gt;transformers) (3.7)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from requests-&gt;transformers) (2.2.2)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from requests-&gt;transformers) (2024.8.30)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from pandas-&gt;datasets) (2.9.0.post0)\nRequirement already satisfied: pytz&gt;=2020.1 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from pandas-&gt;datasets) (2024.1)\nRequirement already satisfied: tzdata&gt;=2022.7 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from pandas-&gt;datasets) (2023.3)\nRequirement already satisfied: six&gt;=1.5 in /home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas-&gt;datasets) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\nfrom datasets import load_dataset, Audio\n\nminds = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train[:100]\")\n\n/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/load.py:1486: FutureWarning: The repository for PolyAI/minds14 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/PolyAI/minds14\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n  warnings.warn(\n\n\n\nminds = minds.train_test_split(test_size=0.2)\n\n\nminds\n\nDatasetDict({\n    train: Dataset({\n        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n        num_rows: 80\n    })\n    test: Dataset({\n        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n        num_rows: 20\n    })\n})\n\n\n\nminds = minds.remove_columns([\"english_transcription\", \"intent_class\", \"lang_id\"])\n\n\nminds[\"train\"][0]\n\n{'path': '/home/cgb3/.cache/huggingface/datasets/downloads/extracted/75236ad3a9fd9bbe635f6aa63106ed2d33d9507d30786db63f62cb59a5716646/en-US~BALANCE/602b9c72bb1e6d0fbce91f87.wav',\n 'audio': {'path': '/home/cgb3/.cache/huggingface/datasets/downloads/extracted/75236ad3a9fd9bbe635f6aa63106ed2d33d9507d30786db63f62cb59a5716646/en-US~BALANCE/602b9c72bb1e6d0fbce91f87.wav',\n  'array': array([ 0.00024414, -0.00024414,  0.        , ...,  0.01037598,\n          0.0098877 ,  0.0098877 ]),\n  'sampling_rate': 8000},\n 'transcription': 'what is my account balance'}\n\n\n\nfrom transformers import AutoProcessor\n\nprocessor = AutoProcessor.from_pretrained(\"facebook/wav2vec2-base\")\n\n/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/configuration_utils.py:302: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n  warnings.warn(\n/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n\n\n\nminds = minds.cast_column(\"audio\", Audio(sampling_rate=16_000))\nminds[\"train\"][0]\n\n{'path': '/home/cgb3/.cache/huggingface/datasets/downloads/extracted/75236ad3a9fd9bbe635f6aa63106ed2d33d9507d30786db63f62cb59a5716646/en-US~BALANCE/602b9c72bb1e6d0fbce91f87.wav',\n 'audio': {'path': '/home/cgb3/.cache/huggingface/datasets/downloads/extracted/75236ad3a9fd9bbe635f6aa63106ed2d33d9507d30786db63f62cb59a5716646/en-US~BALANCE/602b9c72bb1e6d0fbce91f87.wav',\n  'array': array([ 2.35084444e-04,  3.73781659e-05, -2.34791543e-04, ...,\n          1.11566903e-02,  9.70520079e-03,  4.98228893e-03]),\n  'sampling_rate': 16000},\n 'transcription': 'what is my account balance'}\n\n\n\ndef uppercase(example):\n    return {\"transcription\": example[\"transcription\"].upper()}\n\n\nminds = minds.map(uppercase)\n\nMap: 100%|██████████| 80/80 [00:00&lt;00:00, 9887.85 examples/s]\nMap: 100%|██████████| 20/20 [00:00&lt;00:00, 5103.49 examples/s]\n\n\n\ndef prepare_dataset(batch):\n    audio = batch[\"audio\"]\n    batch = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"], text=batch[\"transcription\"])\n    batch[\"input_length\"] = len(batch[\"input_values\"][0])\n    return batch\n\n\nencoded_minds = minds.map(prepare_dataset, remove_columns=minds.column_names[\"train\"], num_proc=4)\n\nMap (num_proc=4): 100%|██████████| 80/80 [00:00&lt;00:00, 474.87 examples/s]\nMap (num_proc=4): 100%|██████████| 20/20 [00:00&lt;00:00, 177.41 examples/s]\n\n\n\nimport torch\n\nfrom dataclasses import dataclass, field\nfrom typing import Any, Dict, List, Optional, Union\n\n\n@dataclass\nclass DataCollatorCTCWithPadding:\n    processor: AutoProcessor\n    padding: Union[bool, str] = \"longest\"\n\n    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -&gt; Dict[str, torch.Tensor]:\n        # split inputs and labels since they have to be of different lengths and need\n        # different padding methods\n        input_features = [{\"input_values\": feature[\"input_values\"][0]} for feature in features]\n        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n\n        batch = self.processor.pad(input_features, padding=self.padding, return_tensors=\"pt\")\n\n        labels_batch = self.processor.pad(labels=label_features, padding=self.padding, return_tensors=\"pt\")\n\n        # replace padding with -100 to ignore loss correctly\n        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n\n        batch[\"labels\"] = labels\n\n        return batch\n\n\ndata_collator = DataCollatorCTCWithPadding(processor=processor, padding=\"longest\")\n\n\nimport evaluate\n\n#wer = evaluate.load(\"wer\")\n\n\nimport numpy as np\n\n\ndef compute_metrics(pred):\n    pred_logits = pred.predictions\n    pred_ids = np.argmax(pred_logits, axis=-1)\n\n    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n\n    pred_str = processor.batch_decode(pred_ids)\n    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n    wer = evaluate.load(\"wer\")\n    #wer = \n\n    return {\"wer\": wer.compute(predictions=pred_str, references=label_str)}\n\n\nfrom transformers import AutoModelForCTC, TrainingArguments, Trainer\n\nmodel = AutoModelForCTC.from_pretrained(\n    \"facebook/wav2vec2-base\",\n    ctc_loss_reduction=\"mean\",\n    pad_token_id=processor.tokenizer.pad_token_id,\n)\n\n/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/configuration_utils.py:302: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n  warnings.warn(\nSome weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['lm_head.bias', 'lm_head.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n\n\ntraining_args = TrainingArguments(\n    output_dir=\"my_awesome_asr_mind_model\",\n    per_device_train_batch_size=8,\n    gradient_accumulation_steps=2,\n    learning_rate=1e-5,\n    warmup_steps=500,\n    max_steps=200,\n    gradient_checkpointing=True,\n    fp16=True,\n    group_by_length=True,\n    eval_strategy=\"steps\",\n    per_device_eval_batch_size=8,\n    save_steps=100,\n    eval_steps=100,\n    logging_steps=25,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"wer\",\n    greater_is_better=False,\n    push_to_hub=False,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=encoded_minds[\"train\"],\n    eval_dataset=encoded_minds[\"test\"],\n    tokenizer=processor,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()\n\n/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\nmax_steps is given, it will override any value given in num_train_epochs\n/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n\n\n\n    \n      \n      \n      [200/200 02:39, Epoch 40/40]\n    \n    \n\n\n\nStep\nTraining Loss\nValidation Loss\nWer\n\n\n\n\n100\n33.995700\n29.663630\n1.000000\n\n\n200\n6.715300\n5.154046\n1.000000\n\n\n\n\n\n\nTrainOutput(global_step=200, training_loss=27.734552917480467, metrics={'train_runtime': 160.7855, 'train_samples_per_second': 19.902, 'train_steps_per_second': 1.244, 'total_flos': 3.839687518470912e+17, 'train_loss': 27.734552917480467, 'epoch': 40.0})\n\n\n\nfrom datasets import load_dataset, Audio\n\ndataset = load_dataset(\"PolyAI/minds14\", \"en-US\", split=\"train\")\ndataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\nsampling_rate = dataset.features[\"audio\"].sampling_rate\naudio_file = dataset[0][\"audio\"][\"path\"]\n\n/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/load.py:1486: FutureWarning: The repository for PolyAI/minds14 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/PolyAI/minds14\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n  warnings.warn(\n\n\n\nfrom transformers import pipeline\n\ntranscriber = pipeline(\"automatic-speech-recognition\", model=\"my_awesome_asr_mind_model/checkpoint-200\")\ntranscriber(audio_file)\n\nHardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n\n\n{'text': ''}"
  },
  {
    "objectID": "공부/HF/2024-09-18-(강의) 감성분석 파고들기.html",
    "href": "공부/HF/2024-09-18-(강의) 감성분석 파고들기.html",
    "title": "(강의) 감성분석 파고들기",
    "section": "",
    "text": "import datasets\nimport transformers\nimport evaluate\nimport numpy as np\nimport torch"
  },
  {
    "objectID": "공부/HF/2024-09-18-(강의) 감성분석 파고들기.html#a.-1단계",
    "href": "공부/HF/2024-09-18-(강의) 감성분석 파고들기.html#a.-1단계",
    "title": "(강의) 감성분석 파고들기",
    "section": "A. 1단계",
    "text": "A. 1단계\n\n인공지능에 대한 이해\n\n- 인공지능 불러오기\n\ntorch.random.manual_seed(43052)\n인공지능 = transformers.AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert/distilbert-base-uncased\", \n    num_labels=2\n)\n\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n\n- 인공지능의 정체? 엄청나게 많은 숫자들이 포함된 어떠한 물체 (엄청나게 많은 파라메터들이 포함된 네트워크)\n\n인공지능\n\nDistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)\n\n\n\n인공지능.classifier.weight\n\nParameter containing:\ntensor([[-0.0234,  0.0279,  0.0242,  ...,  0.0091, -0.0063, -0.0133],\n        [ 0.0087,  0.0007, -0.0099,  ...,  0.0183, -0.0007,  0.0295]],\n       requires_grad=True)\n\n\n\n인공지능.pre_classifier.weight\n\nParameter containing:\ntensor([[-0.0122,  0.0030,  0.0301,  ...,  0.0003,  0.0327, -0.0123],\n        [-0.0041,  0.0008,  0.0169,  ..., -0.0163, -0.0117, -0.0135],\n        [ 0.0020, -0.0215, -0.0021,  ...,  0.0016,  0.0102, -0.0483],\n        ...,\n        [-0.0026, -0.0327,  0.0099,  ...,  0.0341, -0.0184, -0.0109],\n        [ 0.0088, -0.0345, -0.0011,  ...,  0.0018,  0.0172, -0.0122],\n        [-0.0148,  0.0147, -0.0184,  ..., -0.0166,  0.0241,  0.0201]],\n       requires_grad=True)\n\n\n- 인공지능? “입력정보 -&gt; 정리된숫자 -&gt; 계산 -&gt; 계산된숫자 -&gt; 출력정보” 의 과정에서 “계산”을 담당\n\n인공지능이 가지고 있는 숫자들은 계산에 사용되는 숫자들임..\n\n- 입력정보에 영화에 대한 부정적 평가를 넣는다면?\n\n입력정보_원시텍스트 = \"This movie was a huge disappointment.\"\n정리된숫자_토큰화된자료 = 토크나이저(입력정보_원시텍스트,truncation=True,return_tensors='pt')\n정리된숫자_토큰화된자료\n\n{'input_ids': tensor([[  101,  2023,  3185,  2001,  1037,  4121, 10520,  1012,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n\n\n\n인공지능(**정리된숫자_토큰화된자료)\n\nSequenceClassifierOutput(loss=None, logits=tensor([[-0.1173,  0.0261]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)\n\n\n\n계산된숫자_로짓 = 인공지능(**정리된숫자_토큰화된자료).logits.detach().numpy()\n계산된숫자_로짓\n\narray([[-0.11731046,  0.02610319]], dtype=float32)\n\n\n\n출력정보_확률 = np.exp(계산된숫자_로짓) / np.exp(계산된숫자_로짓).sum()\n출력정보_확률 # 0일확률, 1일확률\n\narray([[0.46420792, 0.53579205]], dtype=float32)\n\n\n\n출력정보_확률.argmax() # 부정적 영화평가에 대한 인공지능의 예측\n\n1\n\n\n\n계산된숫자_로짓.argmax() # 부정적 영화평가에 대한 인공지능의 예측 &lt;-- 이렇게 구해도됩니다.. 왜??\n\n1\n\n\n- 입력정보에 영화에 대한 긍정적 평가를 넣는다면?\n\n입력정보_원시텍스트 = \"This was a masterpiece.\"\n정리된숫자_토큰화된자료 = 토크나이저(입력정보_원시텍스트,truncation=True,return_tensors='pt')\n정리된숫자_토큰화된자료\n\n{'input_ids': tensor([[  101,  2023,  2001,  1037, 17743,  1012,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}\n\n\n\n인공지능(**정리된숫자_토큰화된자료)\n\nSequenceClassifierOutput(loss=None, logits=tensor([[-0.1080,  0.0264]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)\n\n\n\n계산된숫자_로짓 = 인공지능(**정리된숫자_토큰화된자료).logits.detach().numpy()\n계산된숫자_로짓\n\narray([[-0.10802954,  0.02638793]], dtype=float32)\n\n\n\n출력정보_확률 = np.exp(계산된숫자_로짓) / np.exp(계산된숫자_로짓).sum()\n출력정보_확률 # 0일확률, 1일확률\n\narray([[0.46644613, 0.53355384]], dtype=float32)\n\n\n\n출력정보_확률.argmax()\n계산된숫자_로짓.argmax() # 부정적 영화평가에 대한 인공지능의 예측\n\n1\n\n\n- 아무숫자나 뱉어내는듯 \\(\\to\\) 멍청한 인공지능.. (옹호: 당연하지 학습전이니까)\n- 인공지능에 대한 이해1: 인공지능은 “정리된숫자”를 입력으로 하고 일련의 계산을 거쳐 “계산된숫자”를 출력해주는 함수라 생각할 수 있음.\n- 인공지능에 대한 이해2: 인공지능은 (1) 많은숫자들과 (2) 고유의 계산방식을 가지고 있음.\n\n인공지능이 내부에 자체적으로 저장하고 있는 숫자를 파라메터라고 부름.\n인공지능은 나름의 법칙에 따라 “데이터”와 “파라메터”를 계산함. 즉 인공지능은 자체적으로 데이터와 파라메터를 어떻게 계산할지 알고있는데, 이러한 고유의 계산방식을 아키텍처라고 말함.\n\n- 인공지능에 대한 이해3: 두 인공지능이 서로 다른 고유의 계산방식을 가지고 있다면 두 인공지능은 “다른 모델”임.\n- 인공지능에 대한 이해3’: 동일한 생성방식으로 만들어진 인공지능들은 모두 같은 모델임. 예를들면 아래의 인공지능1,2는 같은 모델임\n인공지능1 = transformers.AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert/distilbert-base-uncased\", \n    num_labels=2\n)\n인공지능2 = transformers.AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert/distilbert-base-uncased\", \n    num_labels=2\n)\n- 인공지능에 대한 이해4: 두 인공지능이 같은 모델이라고 해도, 항상 같은 결과를 주는건 아님. 파라메터에 따라 다른결과를 줄 수 도 있음. (예를들면 위의 인공지능1,2는 같은 모델이지만 다른 파라메터를 가지므로 다른 결과를 줌)"
  },
  {
    "objectID": "공부/HF/2024-09-18-(강의) 감성분석 파고들기.html#b.-2단계",
    "href": "공부/HF/2024-09-18-(강의) 감성분석 파고들기.html#b.-2단계",
    "title": "(강의) 감성분석 파고들기",
    "section": "B. 2단계",
    "text": "B. 2단계\n\n미니배치를 이해하자.\n\n- 예비학습\n\narr = np.array([[1,2],[2,3],[3,4]])\narr\n\narray([[1, 2],\n       [2, 3],\n       [3, 4]])\n\n\n\narr / arr.sum(axis=1).reshape(-1,1)\n\narray([[0.33333333, 0.66666667],\n       [0.4       , 0.6       ],\n       [0.42857143, 0.57142857]])\n\n\n- 예비개념1: 인공지능은 사실 영화평을 하나씩 하나씩 처리하지 않는다. 덩어리로 처리한다.\n- 예비개념2: 그렇다고 해서 인공지능이 25000개를 모두 덩어리로 처리하는건 아니다 \\(\\to\\) 16개씩, 혹은 32개씩 묶어서 작은덩어리로 만든 후 처리한다.\n\n16,32 와 같은 숫자를 batch_size 라고 한다.\n16개, 32개로 모인 작은덩어리를 미니배치라고 한다.\n\n- 16개의 입력정보를 한번에 처리\n\n입력정보들_원시텍스트 = 데이터['train'][:16]['text']\n정리된숫자들_토큰화된자료 = 토크나이저(입력정보들_원시텍스트,truncation=True,return_tensors='pt',padding=True)\n계산된숫자들_로짓 = 인공지능(**정리된숫자들_토큰화된자료).logits.data.numpy()\n출력정보들_확률 = np.exp(계산된숫자들_로짓) / np.exp(계산된숫자들_로짓).sum(axis=1).reshape(-1,1)\n출력정보들_확률\n\narray([[0.47823825, 0.5217617 ],\n       [0.47215328, 0.5278467 ],\n       [0.4804948 , 0.5195052 ],\n       [0.46609667, 0.5339033 ],\n       [0.48814487, 0.5118551 ],\n       [0.48004225, 0.5199578 ],\n       [0.49288097, 0.50711906],\n       [0.49470255, 0.5052974 ],\n       [0.4941453 , 0.50585467],\n       [0.49016201, 0.50983804],\n       [0.495789  , 0.504211  ],\n       [0.48260576, 0.51739424],\n       [0.49386355, 0.5061364 ],\n       [0.49013382, 0.5098662 ],\n       [0.48240176, 0.5175982 ],\n       [0.49301967, 0.5069803 ]], dtype=float32)\n\n\n\n#출력정보들_확률.argmax(axis=1) \n계산된숫자들_로짓.argmax(axis=1)\n\narray([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n\n\n- 기억할 것: 정리된숫자들_토큰화된자료 는 모두 길이가 512임. (그렇게 되도록 패딩함)\n\n정리된숫자들_토큰화된자료['input_ids'].shape, 정리된숫자들_토큰화된자료['attention_mask'].shape\n\n(torch.Size([16, 512]), torch.Size([16, 512]))\n\n\n- 실제 단어수\n\n정리된숫자들_토큰화된자료['attention_mask'].sum(axis=1)\n\ntensor([363, 304, 133, 185, 495, 154, 143, 388, 512, 297, 365, 171, 192, 173,\n        470, 263])\n\n\n- 패딩된단어수\n\n512 - 정리된숫자들_토큰화된자료['attention_mask'].sum(axis=1)\n\ntensor([149, 208, 379, 327,  17, 358, 369, 124,   0, 215, 147, 341, 320, 339,\n         42, 249])\n\n\n- 이러한 변환이 이루어지는 이유? 인공지능은 항상 (n,m) 차원으로 정리된 정리된숫자들을 입력으로 받아야함.\n\n왜? 사실 인공지능은 행렬계산을 하도록 설계되어있음.\n그래서 할수없이 패딩처리를 해야하는 것임. (실제로는 행렬로 만들수 없지만 억지로 만들기 위해서..)"
  },
  {
    "objectID": "공부/HF/2024-09-18-(강의) 감성분석 파고들기.html#c.-3단계",
    "href": "공부/HF/2024-09-18-(강의) 감성분석 파고들기.html#c.-3단계",
    "title": "(강의) 감성분석 파고들기",
    "section": "C. 3단계",
    "text": "C. 3단계\n\n동적패딩을 이해하자.\n\n- 만약에 batch_size=4 로 설정하여 처리한다면?\n\n입력정보들_원시텍스트 = 데이터['train'][:4]['text']\n정리된숫자들_토큰화된자료 = 토크나이저(입력정보들_원시텍스트,truncation=True,return_tensors='pt',padding=True)\n계산된숫자들_로짓 = 인공지능(**정리된숫자들_토큰화된자료).logits.data.numpy()\n출력정보들_확률 = np.exp(계산된숫자들_로짓) / np.exp(계산된숫자들_로짓).sum(axis=1).reshape(-1,1)\n출력정보들_확률\n\narray([[0.47823825, 0.5217618 ],\n       [0.47215328, 0.5278467 ],\n       [0.4804948 , 0.5195052 ],\n       [0.46609667, 0.5339033 ]], dtype=float32)\n\n\n\n계산된숫자들_로짓.argmax(axis=1)\n\narray([1, 1, 1, 1])\n\n\n- 정리된숫자들_토큰화된자료의 차원은 어떠할까? (4,512)로 예상되지 않을까?\n\n정리된숫자들_토큰화된자료['input_ids'].shape, 정리된숫자들_토큰화된자료['attention_mask'].shape\n\n(torch.Size([4, 363]), torch.Size([4, 363]))\n\n\n\n끝차원이 512가 아니라 363이다.. 왜??\n\n- 덩어리의 상태에 따라서 유동적으로 패딩 \\(\\to\\) 그래도 잘 돌아감\n\n입력정보들_원시데이터 = 데이터['train'][:4]['text']\n정리된숫자들_토큰화된자료 = 토크나이저(입력정보들_원시데이터,truncation=True,return_tensors='pt',padding=True)\nprint(정리된숫자들_토큰화된자료['input_ids'].shape)\nprint(인공지능(**정리된숫자들_토큰화된자료))\n\ntorch.Size([4, 363])\nSequenceClassifierOutput(loss=None, logits=tensor([[-0.0847,  0.0024],\n        [-0.0830,  0.0285],\n        [-0.0600,  0.0180],\n        [-0.0919,  0.0440]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)\n\n\n\n입력정보들_원시데이터 = 데이터['train'][4:8]['text']\n정리된숫자들_토큰화된자료 = 토크나이저(입력정보들_원시데이터,truncation=True,return_tensors='pt',padding=True)\nprint(정리된숫자들_토큰화된자료['input_ids'].shape)\nprint(인공지능(**정리된숫자들_토큰화된자료))\n\ntorch.Size([4, 495])\nSequenceClassifierOutput(loss=None, logits=tensor([[-0.0422,  0.0053],\n        [-0.0646,  0.0152],\n        [-0.0172,  0.0112],\n        [-0.0283, -0.0072]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)\n\n\n\n입력정보들_원시데이터 = 데이터['train'][8:12]['text']\n정리된숫자들_토큰화된자료 = 토크나이저(입력정보들_원시데이터,truncation=True,return_tensors='pt',padding=True)\nprint(정리된숫자들_토큰화된자료['input_ids'].shape)\nprint(인공지능(**정리된숫자들_토큰화된자료))\n\ntorch.Size([4, 512])\nSequenceClassifierOutput(loss=None, logits=tensor([[-0.0246, -0.0012],\n        [-0.0594, -0.0200],\n        [-0.0240, -0.0071],\n        [-0.0836, -0.0140]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)\n\n\n\n입력정보들_원시데이터 = 데이터['train'][12:16]['text']\n정리된숫자들_토큰화된자료 = 토크나이저(입력정보들_원시데이터,truncation=True,return_tensors='pt',padding=True)\nprint(정리된숫자들_토큰화된자료['input_ids'].shape)\nprint(인공지능(**정리된숫자들_토큰화된자료))\n\ntorch.Size([4, 470])\nSequenceClassifierOutput(loss=None, logits=tensor([[-0.0440, -0.0195],\n        [-0.0469, -0.0074],\n        [-0.0542,  0.0162],\n        [-0.0316, -0.0037]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)\n\n\n- 싹다 512로 통일한것대비 큰 차이없음..\n\n입력정보들_원시데이터 = 데이터['train'][:16]['text']\n정리된숫자들_토큰화된자료 = 토크나이저(입력정보들_원시데이터,truncation=True,return_tensors='pt',padding=True)\nprint(정리된숫자들_토큰화된자료['input_ids'].shape)\nprint(인공지능(**정리된숫자들_토큰화된자료))\n\ntorch.Size([16, 512])\nSequenceClassifierOutput(loss=None, logits=tensor([[-0.0847,  0.0024],\n        [-0.0830,  0.0285],\n        [-0.0600,  0.0180],\n        [-0.0919,  0.0440],\n        [-0.0422,  0.0053],\n        [-0.0646,  0.0152],\n        [-0.0172,  0.0112],\n        [-0.0283, -0.0072],\n        [-0.0246, -0.0012],\n        [-0.0594, -0.0200],\n        [-0.0240, -0.0071],\n        [-0.0836, -0.0140],\n        [-0.0440, -0.0195],\n        [-0.0469, -0.0074],\n        [-0.0542,  0.0162],\n        [-0.0316, -0.0037]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)"
  },
  {
    "objectID": "공부/HF/2024-09-18-(강의) 감성분석 파고들기.html#d.-4단계",
    "href": "공부/HF/2024-09-18-(강의) 감성분석 파고들기.html#d.-4단계",
    "title": "(강의) 감성분석 파고들기",
    "section": "D. 4단계",
    "text": "D. 4단계\n\n손실(=loss)의 개념을 이해하자.\n\n- 정리된숫자들_토큰화된자료에서 labels 를 추가 전달하면 인공지능(**정리된숫자들_토큰화된자료)의 결과로 loss가 추가계산됨\n\n입력정보들_원시데이터 = 데이터['train'][:4]['text']\n정리된숫자들_토큰화된자료 = 토크나이저(입력정보들_원시데이터,truncation=True,return_tensors='pt',padding=True)\n#데이터['train'][:4]['label']\n정리된숫자들_토큰화된자료['labels'] = torch.tensor([0,0,0,0]) # 정답입력\n인공지능(**정리된숫자들_토큰화된자료)\n\nSequenceClassifierOutput(loss=tensor(0.7461, grad_fn=&lt;NllLossBackward0&gt;), logits=tensor([[-0.0847,  0.0024],\n        [-0.0830,  0.0285],\n        [-0.0600,  0.0180],\n        [-0.0919,  0.0440]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)\n\n\n- 정리를 해보자.\n\n입력정보들_원시데이터 = 데이터['train'][:4]['text']\n정리된숫자들_토큰화된자료 = 토크나이저(입력정보들_원시데이터,truncation=True,return_tensors='pt',padding=True)\nprint(f'실제정답: {데이터['train'][:4]['label']}')\n정리된숫자들_토큰화된자료['labels'] = torch.tensor(데이터['train'][:4]['label']) # 정답입력\n계산된숫자들_로짓 = 인공지능(**정리된숫자들_토큰화된자료).logits.detach().numpy()\n출력정보들_확률 = np.exp(계산된숫자들_로짓) / np.exp(계산된숫자들_로짓).sum(axis=1).reshape(-1,1)\nprint(f'인공지능의예측: {출력정보들_확률.argmax(axis=1)}')\nprint(f'인공지능확신정도: {출력정보들_확률.max(axis=1)}')\nprint(f'손실: {인공지능(**정리된숫자들_토큰화된자료).loss.item():.4f}')\n\n실제정답: [0, 0, 0, 0]\n인공지능의예측: [1 1 1 1]\n인공지능확신정도: [0.5217618 0.5278467 0.5195052 0.5339033]\n손실: 0.7461\n\n\n- loss는 작을수록 좋은 것임. 문제를 많이 틀릴수록 loss가 큼, 문제를 조금 틀릴수록 loss가 작음\n텍스트0~텍스트3\n\n입력정보들_원시데이터 = 데이터['train'][:4]['text']\n정리된숫자들_토큰화된자료 = 토크나이저(입력정보들_원시데이터,truncation=True,return_tensors='pt',padding=True)\nprint(f'실제정답: {데이터['train'][:4]['label']}')\n정리된숫자들_토큰화된자료['labels'] = torch.tensor(데이터['train'][:4]['label']) # 정답입력\n계산된숫자들_로짓 = 인공지능(**정리된숫자들_토큰화된자료).logits.detach().numpy()\n출력정보들_확률 = np.exp(계산된숫자들_로짓) / np.exp(계산된숫자들_로짓).sum(axis=1).reshape(-1,1)\nprint(f'인공지능의예측: {출력정보들_확률.argmax(axis=1)}')\nprint(f'인공지능확신정도: {출력정보들_확률.max(axis=1)}')\nprint(f'손실: {인공지능(**정리된숫자들_토큰화된자료).loss.item():.4f}')\n\n실제정답: [0, 0, 0, 0]\n인공지능의예측: [1 1 1 1]\n인공지능확신정도: [0.5217618 0.5278467 0.5195052 0.5339033]\n손실: 0.7461\n\n\n텍스트12498~텍스트12501\n\n입력정보들_원시데이터 = 데이터['train'][12498:12502]['text']\n정리된숫자들_토큰화된자료 = 토크나이저(입력정보들_원시데이터,truncation=True,return_tensors='pt',padding=True)\nprint(f'실제정답: {데이터['train'][12498:12502]['label']}')\n정리된숫자들_토큰화된자료['labels'] = torch.tensor(데이터['train'][12498:12502]['label']) # 정답입력\n계산된숫자들_로짓 = 인공지능(**정리된숫자들_토큰화된자료).logits.detach().numpy()\n출력정보들_확률 = np.exp(계산된숫자들_로짓) / np.exp(계산된숫자들_로짓).sum(axis=1).reshape(-1,1)\nprint(f'인공지능의예측: {출력정보들_확률.argmax(axis=1)}')\nprint(f'인공지능확신정도: {출력정보들_확률.max(axis=1)}')\nprint(f'손실: {인공지능(**정리된숫자들_토큰화된자료).loss.item():.4f}')\n\n실제정답: [0, 0, 1, 1]\n인공지능의예측: [1 1 1 1]\n인공지능확신정도: [0.52731967 0.5243837  0.51578873 0.5351162 ]\n손실: 0.6950\n\n\n- 똑같이 틀려도 오답에 대한 확신이 강할수록 loss가 크다.\n텍스트0~텍스트1\n\n입력정보들_원시데이터 = 데이터['train'][:2]['text']\n정리된숫자들_토큰화된자료 = 토크나이저(입력정보들_원시데이터,truncation=True,return_tensors='pt',padding=True)\nprint(f'실제정답: {데이터['train'][:2]['label']}')\n정리된숫자들_토큰화된자료['labels'] = torch.tensor(데이터['train'][:2]['label']) # 정답입력\n계산된숫자들_로짓 = 인공지능(**정리된숫자들_토큰화된자료).logits.detach().numpy()\n출력정보들_확률 = np.exp(계산된숫자들_로짓) / np.exp(계산된숫자들_로짓).sum(axis=1).reshape(-1,1)\nprint(f'인공지능의예측: {출력정보들_확률.argmax(axis=1)}')\nprint(f'인공지능확신정도: {출력정보들_확률.max(axis=1)}')\nprint(f'손실: {인공지능(**정리된숫자들_토큰화된자료).loss.item():.4f}')\n\n실제정답: [0, 0]\n인공지능의예측: [1 1]\n인공지능확신정도: [0.5217617 0.5278467]\n손실: 0.7440\n\n\n텍스트1~텍스트2\n\n입력정보들_원시데이터 = 데이터['train'][1:3]['text']\n정리된숫자들_토큰화된자료 = 토크나이저(입력정보들_원시데이터,truncation=True,return_tensors='pt',padding=True)\nprint(f'실제정답: {데이터['train'][1:3]['label']}')\n정리된숫자들_토큰화된자료['labels'] = torch.tensor(데이터['train'][1:3]['label']) # 정답입력\n계산된숫자들_로짓 = 인공지능(**정리된숫자들_토큰화된자료).logits.detach().numpy()\n출력정보들_확률 = np.exp(계산된숫자들_로짓) / np.exp(계산된숫자들_로짓).sum(axis=1).reshape(-1,1)\nprint(f'인공지능의예측: {출력정보들_확률.argmax(axis=1)}')\nprint(f'인공지능확신정도: {출력정보들_확률.max(axis=1)}')\nprint(f'손실: {인공지능(**정리된숫자들_토큰화된자료).loss.item():.4f}')\n\n실제정답: [0, 0]\n인공지능의예측: [1 1]\n인공지능확신정도: [0.5278467 0.5195052]\n손실: 0.7417\n\n\n- 손실 = 인공지능의 “멍청한정도” 혹은 “똑똑한정도”을 숫자화한것\n\n\n\n\n\n\n\\(\\star\\star\\star\\) 학습이 가능한 이유 (대충 아이디어만)\n\n\n\n1. 랜덤으로 1개의 인공지능을 생성한다. (아래의 코드로 가능)\n인공지능 = 인공지능생성기()\n2. 인공지능의 파라메터중 하나를 찍는다. 예를들면 아래와 같은 상황이 있다고 하자.\n인공지능.classifier.weight\nParameter containing:\ntensor([[-0.0234,  0.0279,  0.0242,  ...,  0.0091, -0.0063, -0.0133],\n        [ 0.0087,  0.0007, -0.0099,  ...,  0.0183, -0.0007,  0.0295]],\n       requires_grad=True)\n하나의 숫자 -0.0234 를 선택한다.\n3. -0.0234의 값을 조금 변화시켜본다. 예를들면, -0.0235, -0.0233 와 같은 식으로 변화시켜본뒤 loss를 관찰한다.\n4. 원래값과 변화시킨값들중 loss를 가장 작게 만드는 값으로 -0.0234를 update한다.\n5. 다른 모든 파라메터에 대하여 1~4를 반복한다. (과정을 반복할수록 loss가 작아지겠죠, 즉 인공지능은 똑똑해지겠죠)\n\n\n- 인공지능의 학습은 마법같은 신비한 현상이 아니고 극한의 노가다를 통해 얻어지는 산물일 뿐이다."
  },
  {
    "objectID": "공부/HF/2024-11-07-(강의) 선인장 이미지분류.html#a.-ref",
    "href": "공부/HF/2024-11-07-(강의) 선인장 이미지분류.html#a.-ref",
    "title": "(강의) 선인장이미지분류 – ROC",
    "section": "A. ref",
    "text": "A. ref\nref: https://www.kaggle.com/c/aerial-cactus-identification"
  },
  {
    "objectID": "공부/HF/2024-11-07-(강의) 선인장 이미지분류.html#b.-데이터-살펴보기",
    "href": "공부/HF/2024-11-07-(강의) 선인장 이미지분류.html#b.-데이터-살펴보기",
    "title": "(강의) 선인장이미지분류 – ROC",
    "section": "B. 데이터 살펴보기",
    "text": "B. 데이터 살펴보기\n1. 압축풀기\n\nwith zipfile.ZipFile('aerial-cactus-identification.zip', 'r') as z:\n    z.extractall('./data')\n\n\nwith zipfile.ZipFile('./data/test.zip', 'r') as z_test:\n    z_test.extractall('./data')    \nwith zipfile.ZipFile('./data/train.zip', 'r') as z_train:\n    z_train.extractall('./data')\n\n\n# !cat ./data/train.csv | head -n 5\n\n\n마지막은 오류는 무시해도 상관없음..\n\n\n# !cat ./data/sample_submission.csv | head -n 5\n\n\n예측값이 아니고 확률을 제출하는듯"
  },
  {
    "objectID": "공부/HF/2024-11-07-(강의) 선인장 이미지분류.html#a.-accuracy-계산",
    "href": "공부/HF/2024-11-07-(강의) 선인장 이미지분류.html#a.-accuracy-계산",
    "title": "(강의) 선인장이미지분류 – ROC",
    "section": "A. accuracy 계산",
    "text": "A. accuracy 계산\n- accuracy의 계산: logits와 labels가 아래와 같이 주어졌다고 하자.\n\nlogits = np.array(\n    [[ 2.7346244, -3.1177292],\n     [ 2.7103324, -3.1362345],\n     [ 2.7464483, -3.0521457],\n     [ 2.7195318, -3.122628 ],\n     [ 2.7138977, -3.1041346],\n     [ 2.7398622, -3.1098123],\n     [ 0.0657177, -0.0930362],\n     [-2.7668718,  3.0918367]]\n)\nreferences = labels = np.array([0,0,0,0,0,0,1,1])\n\n\npredictions = logits.argmax(axis=1)\npredictions\n\narray([0, 0, 0, 0, 0, 0, 0, 1])\n\n\naccuracy는 아래와 같이 계산할 수 있다.\n\n(predictions == references).sum()/8\n\n0.875\n\n\n\n(predictions == references).mean()\n\n0.875\n\n\n이걸 아래와 같이 계산할 수도 있다.\n\nacc = evaluate.load(\"accuracy\")\nacc.compute(predictions=predictions, references=references)\n\n{'accuracy': 0.875}"
  },
  {
    "objectID": "공부/HF/2024-11-07-(강의) 선인장 이미지분류.html#b.-recall-계산",
    "href": "공부/HF/2024-11-07-(강의) 선인장 이미지분류.html#b.-recall-계산",
    "title": "(강의) 선인장이미지분류 – ROC",
    "section": "B. recall 계산",
    "text": "B. recall 계산\n- 경우에 따라서 1을 얼마나 더 잘맞추는지 알고 싶은 경우도 있다.\n\\[\\frac{\\text{실제 라벨이 1인 관측치 중 올바르게 예측된 관측치수}}{\\text{실제 라벨이 1인 관측치 수}}\\]\n\nlogits = np.array(\n    [[ 2.7346244, -3.1177292],\n     [ 2.7103324, -3.1362345],\n     [ 2.7464483, -3.0521457],\n     [ 2.7195318, -3.122628 ],\n     [ 2.7138977, -3.1041346],\n     [ 2.7398622, -3.1098123],\n     [ 0.0657177, -0.0930362],\n     [-2.7668718,  3.0918367]]\n)\nreferences = labels = np.array([0,0,0,0,0,0,1,1])\n\n\npredictions = logits.argmax(axis=1)\npredictions\n\narray([0, 0, 0, 0, 0, 0, 0, 1])\n\n\n\n(predictions[labels==1] == 1).mean()\n\n0.5\n\n\n이것을 아래와 같이 구할수도 있다.\n\nrec = evaluate.load(\"recall\")\nrec.compute(predictions=predictions, references=references)\n\n{'recall': 0.5}"
  },
  {
    "objectID": "공부/HF/2024-11-07-(강의) 선인장 이미지분류.html#c.-auc-계산",
    "href": "공부/HF/2024-11-07-(강의) 선인장 이미지분류.html#c.-auc-계산",
    "title": "(강의) 선인장이미지분류 – ROC",
    "section": "C. auc 계산",
    "text": "C. auc 계산\n- accuracy 이외의 평가지표들\n\nhttps://guebin.github.io/MP2023/posts/12wk-46.html // 시험에는 X\n\n- AUC: 클래스간의 불균형이 있을때 유의미한 평가지표\n\nlogits = np.array(\n    [[ 2.7346244, -3.1177292],\n     [ 2.7103324, -3.1362345],\n     [ 2.7464483, -3.0521457],\n     [ 2.7195318, -3.122628 ],\n     [ 2.7138977, -3.1041346],\n     [ 2.7398622, -3.1098123],\n     [ 0.0657177, -0.0930362],\n     [-2.7668718,  3.0918367]]\n)\nreferences = labels = np.array([0,0,0,0,0,0,1,1])\n\n\nprobabilities = torch.tensor(logits).softmax(dim=1).numpy()\nprediction_scores = probabilities[:,1]\nprediction_scores\n\narray([0.0028649 , 0.00288148, 0.00302265, 0.00289417, 0.00296464,\n       0.00287256, 0.46039467, 0.9971532 ])\n\n\n\n0.4 이상부터는 1로 판단한다면? \\(\\to\\) 다 맞춘거아니야?\n\n\nroc_auc = evaluate.load(\"roc_auc\")\nroc_auc.compute(references= references, prediction_scores= prediction_scores)\n\n{'roc_auc': 1.0}\n\n\n# 예제1 – 시각화\n\nlogits = np.array(\n    [[ 2.7346244, -3.1177292],\n     [ 2.7103324, -3.1362345],\n     [ 2.7464483, -3.0521457],\n     [ 2.7195318, -3.122628 ],\n     [ 2.7138977, -3.1041346],\n     [ 2.7398622, -3.1098123],\n     [ 0.0657177, -0.0930362],\n     [-2.7668718,  3.0918367]]\n)\nlabels = np.array([0,0,0,0,0,0,1,1])\nprobabilities = torch.tensor(logits).softmax(dim=1).numpy()\nplt.plot(probabilities[:,1],'--o')\nplt.plot(labels,'x')\nplt.axhline(y=0.5, color='red', linestyle='--')\nroc_auc = evaluate.load(\"roc_auc\")\nacc = evaluate.load(\"accuracy\")\nrec = evaluate.load(\"recall\")\nresults = {\n    'accuracy': acc.compute(predictions= logits.argmax(axis=1), references=labels)['accuracy'],\n    'recall': rec.compute(predictions= logits.argmax(axis=1), references=labels)['recall'],\n    'roc_auc': roc_auc.compute(references= labels, prediction_scores= probabilities[:,1])['roc_auc']\n}\nplt.title(f\"ACC={results['accuracy']}, REC={results['recall']}, ROC_AUC={results['roc_auc']}\")\n\nText(0.5, 1.0, 'ACC=0.875, REC=0.5, ROC_AUC=1.0')\n\n\n\n\n\n\n\n\n\n\nlogits = np.array(\n    [[ 2.7346244, -3.1177292],\n     [ 2.7103324, -3.1362345],\n     [ 2.7464483, -3.0521457],\n     [ 2.7195318, -3.122628 ],\n     [ 2.7138977, -3.1041346],\n     [ 0.0657177, -0.0930362],     \n     [ 2.7398622, -3.1098123],\n     [-2.7668718,  3.0918367]]\n)\nlabels = np.array([0,0,0,0,0,0,1,1])\nprobabilities = torch.tensor(logits).softmax(dim=1).numpy()\nplt.plot(probabilities[:,1],'--o')\nplt.plot(labels,'x')\nplt.axhline(y=0.5, color='red', linestyle='--')\nroc_auc = evaluate.load(\"roc_auc\")\nacc = evaluate.load(\"accuracy\")\nrec = evaluate.load(\"recall\")\nresults = {\n    'accuracy': acc.compute(predictions= logits.argmax(axis=1), references=labels)['accuracy'],\n    'recall': rec.compute(predictions= logits.argmax(axis=1), references=labels)['recall'],\n    'roc_auc': roc_auc.compute(references= labels, prediction_scores= probabilities[:,1])['roc_auc']\n}\nplt.title(f\"ACC={results['accuracy']}, REC={results['recall']}, ROC_AUC={results['roc_auc']}\")\n\nText(0.5, 1.0, 'ACC=0.875, REC=0.5, ROC_AUC=0.5833333333333333')"
  },
  {
    "objectID": "공부/HF/2024-11-07-(강의) 선인장 이미지분류.html#a.-예쁜-정석-코드",
    "href": "공부/HF/2024-11-07-(강의) 선인장 이미지분류.html#a.-예쁜-정석-코드",
    "title": "(강의) 선인장이미지분류 – ROC",
    "section": "A. 예쁜(?) 정석 코드",
    "text": "A. 예쁜(?) 정석 코드\nStep1: Data\n\nctx_train = datasets.Dataset.from_pandas(train_csv)\nctx_test = datasets.Dataset.from_pandas(test_csv).remove_columns(['has_cactus'])\n\n\nctx_train = ctx_train.map(lambda example: {'path': f'./data/train/{example['id']}'})\nctx_test = ctx_test.map(lambda example: {'path': f'./data/test/{example['id']}'})\n\nMap: 100%|██████████████████████| 17500/17500 [00:00&lt;00:00, 65880.11 examples/s]\nMap: 100%|████████████████████████| 4000/4000 [00:00&lt;00:00, 92217.97 examples/s]\n\n\n\nctx = datasets.DatasetDict({'train':ctx_train,'test':ctx_test})\nctx\n\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'has_cactus', 'path'],\n        num_rows: 17500\n    })\n    test: Dataset({\n        features: ['id', 'path'],\n        num_rows: 4000\n    })\n})\n\n\n\ncompose('./data/train/0004be2cfeaba1c0361d39e2b000257b.jpg')\n\ntensor([[[0.5333, 0.5333, 0.5333,  ..., 0.6157, 0.6157, 0.6157],\n         [0.5333, 0.5333, 0.5333,  ..., 0.6157, 0.6157, 0.6157],\n         [0.5333, 0.5333, 0.5333,  ..., 0.6157, 0.6157, 0.6157],\n         ...,\n         [0.7176, 0.7176, 0.7176,  ..., 0.5451, 0.5451, 0.5451],\n         [0.7176, 0.7176, 0.7176,  ..., 0.5451, 0.5451, 0.5451],\n         [0.7176, 0.7176, 0.7176,  ..., 0.5451, 0.5451, 0.5451]],\n\n        [[0.5412, 0.5412, 0.5412,  ..., 0.5255, 0.5255, 0.5255],\n         [0.5412, 0.5412, 0.5412,  ..., 0.5255, 0.5255, 0.5255],\n         [0.5412, 0.5412, 0.5412,  ..., 0.5255, 0.5255, 0.5255],\n         ...,\n         [0.6157, 0.6157, 0.6157,  ..., 0.4314, 0.4314, 0.4314],\n         [0.6157, 0.6157, 0.6157,  ..., 0.4314, 0.4314, 0.4314],\n         [0.6157, 0.6157, 0.6157,  ..., 0.4314, 0.4314, 0.4314]],\n\n        [[0.4902, 0.4902, 0.4902,  ..., 0.5490, 0.5490, 0.5490],\n         [0.4902, 0.4902, 0.4902,  ..., 0.5490, 0.5490, 0.5490],\n         [0.4902, 0.4902, 0.4902,  ..., 0.5490, 0.5490, 0.5490],\n         ...,\n         [0.6588, 0.6588, 0.6588,  ..., 0.5098, 0.5098, 0.5098],\n         [0.6588, 0.6588, 0.6588,  ..., 0.5098, 0.5098, 0.5098],\n         [0.6588, 0.6588, 0.6588,  ..., 0.5098, 0.5098, 0.5098]]])\n\n\n\ncompose = torchvision.transforms.Compose([\n    lambda path: PIL.Image.open(path),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Resize(224),\n])\ndef w_trans(examples):\n    dct = dict()\n    try: \n        dct['labels'] = torch.tensor(examples['has_cactus']).long()\n    except: \n        pass \n    dct['pixel_values'] = torch.stack(list(map(compose,examples['path']))).float() # 명확하게\n    return dct \n\n\nctx = ctx.with_transform(w_trans)\nctx\n\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'has_cactus', 'path'],\n        num_rows: 17500\n    })\n    test: Dataset({\n        features: ['id', 'path'],\n        num_rows: 4000\n    })\n})\n\n\n\nctx['train'][:2]\n\n{'labels': tensor([1, 1]),\n 'pixel_values': tensor([[[[0.5333, 0.5333, 0.5333,  ..., 0.6157, 0.6157, 0.6157],\n           [0.5333, 0.5333, 0.5333,  ..., 0.6157, 0.6157, 0.6157],\n           [0.5333, 0.5333, 0.5333,  ..., 0.6157, 0.6157, 0.6157],\n           ...,\n           [0.7176, 0.7176, 0.7176,  ..., 0.5451, 0.5451, 0.5451],\n           [0.7176, 0.7176, 0.7176,  ..., 0.5451, 0.5451, 0.5451],\n           [0.7176, 0.7176, 0.7176,  ..., 0.5451, 0.5451, 0.5451]],\n \n          [[0.5412, 0.5412, 0.5412,  ..., 0.5255, 0.5255, 0.5255],\n           [0.5412, 0.5412, 0.5412,  ..., 0.5255, 0.5255, 0.5255],\n           [0.5412, 0.5412, 0.5412,  ..., 0.5255, 0.5255, 0.5255],\n           ...,\n           [0.6157, 0.6157, 0.6157,  ..., 0.4314, 0.4314, 0.4314],\n           [0.6157, 0.6157, 0.6157,  ..., 0.4314, 0.4314, 0.4314],\n           [0.6157, 0.6157, 0.6157,  ..., 0.4314, 0.4314, 0.4314]],\n \n          [[0.4902, 0.4902, 0.4902,  ..., 0.5490, 0.5490, 0.5490],\n           [0.4902, 0.4902, 0.4902,  ..., 0.5490, 0.5490, 0.5490],\n           [0.4902, 0.4902, 0.4902,  ..., 0.5490, 0.5490, 0.5490],\n           ...,\n           [0.6588, 0.6588, 0.6588,  ..., 0.5098, 0.5098, 0.5098],\n           [0.6588, 0.6588, 0.6588,  ..., 0.5098, 0.5098, 0.5098],\n           [0.6588, 0.6588, 0.6588,  ..., 0.5098, 0.5098, 0.5098]]],\n \n \n         [[[0.4627, 0.4627, 0.4627,  ..., 0.4824, 0.4824, 0.4824],\n           [0.4627, 0.4627, 0.4627,  ..., 0.4824, 0.4824, 0.4824],\n           [0.4627, 0.4627, 0.4627,  ..., 0.4824, 0.4824, 0.4824],\n           ...,\n           [0.3647, 0.3647, 0.3647,  ..., 0.4941, 0.4941, 0.4941],\n           [0.3647, 0.3647, 0.3647,  ..., 0.4941, 0.4941, 0.4941],\n           [0.3647, 0.3647, 0.3647,  ..., 0.4941, 0.4941, 0.4941]],\n \n          [[0.4275, 0.4275, 0.4275,  ..., 0.3804, 0.3804, 0.3804],\n           [0.4275, 0.4275, 0.4275,  ..., 0.3804, 0.3804, 0.3804],\n           [0.4275, 0.4275, 0.4275,  ..., 0.3804, 0.3804, 0.3804],\n           ...,\n           [0.3059, 0.3059, 0.3059,  ..., 0.4314, 0.4314, 0.4314],\n           [0.3059, 0.3059, 0.3059,  ..., 0.4314, 0.4314, 0.4314],\n           [0.3059, 0.3059, 0.3059,  ..., 0.4314, 0.4314, 0.4314]],\n \n          [[0.4471, 0.4471, 0.4471,  ..., 0.4235, 0.4235, 0.4235],\n           [0.4471, 0.4471, 0.4471,  ..., 0.4235, 0.4235, 0.4235],\n           [0.4471, 0.4471, 0.4471,  ..., 0.4235, 0.4235, 0.4235],\n           ...,\n           [0.3255, 0.3255, 0.3255,  ..., 0.4745, 0.4745, 0.4745],\n           [0.3255, 0.3255, 0.3255,  ..., 0.4745, 0.4745, 0.4745],\n           [0.3255, 0.3255, 0.3255,  ..., 0.4745, 0.4745, 0.4745]]]])}\n\n\nStep2: Model\n\nmodel = transformers.AutoModelForImageClassification.from_pretrained(\n    \"google/vit-base-patch16-224-in21k\",\n    num_labels=2,\n)\n\nSome weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n\nStep3: Train\n\ndata_collator = transformers.DefaultDataCollator()\ndata_collator\n\nDefaultDataCollator(return_tensors='pt')\n\n\n\n# single_batch = [ctx['train'][0],ctx['train'][1]]\n# single_batch = [ctx['test'][0],ctx['test'][1]]\n# model(**data_collator(single_batch))\n\n\nctx\n\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'has_cactus', 'path'],\n        num_rows: 17500\n    })\n    test: Dataset({\n        features: ['id', 'path'],\n        num_rows: 4000\n    })\n})\n\n\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=1)\n    prediction_scores = torch.tensor(logits).softmax(dim=1).numpy()[:,1]\n    #---#\n    accuracy = evaluate.load(\"accuracy\")\n    recall = evaluate.load(\"recall\")\n    roc_auc = evaluate.load(\"roc_auc\")\n    dct1 = accuracy.compute(predictions=predictions, references=labels)\n    dct2 = recall.compute(predictions=predictions, references=labels)\n    dct3 = roc_auc.compute(prediction_scores=prediction_scores, references=labels)\n    return dct1|dct2|dct3\nargs = transformers.TrainingArguments(\n    output_dir=\"./model/ctx\",\n    remove_unused_columns=False,\n    #---#\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=5e-5,\n    per_device_train_batch_size=16,\n    gradient_accumulation_steps=4,\n    per_device_eval_batch_size=16,\n    num_train_epochs=1,\n    warmup_ratio=0.1,\n    logging_steps=10,\n    load_best_model_at_end=True,\n    #metric_for_best_model=\"accuracy\",\n    push_to_hub=False,\n    report_to=\"none\"\n)\ntrainer = transformers.Trainer(\n    model=model,\n    args=args,\n    data_collator=data_collator,\n    train_dataset=ctx['train'].select(range(1000)),\n    eval_dataset=ctx['train'].select(range(1000,1500)),\n    compute_metrics=compute_metrics,\n)\n\n\nctx\n\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'has_cactus', 'path'],\n        num_rows: 17500\n    })\n    test: Dataset({\n        features: ['id', 'path'],\n        num_rows: 4000\n    })\n})\n\n\n\ntrainer.train()\n\n\n    \n      \n      \n      [15/15 00:13, Epoch 0/1]\n    \n    \n\n\n\nEpoch\nTraining Loss\nValidation Loss\nAccuracy\nRecall\nRoc Auc\n\n\n\n\n0\n0.486200\n0.270196\n0.956000\n1.000000\n0.998761\n\n\n\n\n\n\nTrainOutput(global_step=15, training_loss=0.4222262461980184, metrics={'train_runtime': 14.1654, 'train_samples_per_second': 70.594, 'train_steps_per_second': 1.059, 'total_flos': 7.439231003000832e+16, 'train_loss': 0.4222262461980184, 'epoch': 0.9523809523809523})\n\n\nStep4: Prediction\n\nout = trainer.predict(ctx['test'])\nout \n\n\n\n\nPredictionOutput(predictions=array([[-0.87309086,  0.76549405],\n       [-0.9422926 ,  1.0070752 ],\n       [-0.02508726, -0.12881294],\n       ...,\n       [-1.0198429 ,  1.0380617 ],\n       [-1.0059347 ,  0.9955274 ],\n       [-0.8788617 ,  0.75964546]], dtype=float32), label_ids=None, metrics={'test_runtime': 10.9475, 'test_samples_per_second': 365.379, 'test_steps_per_second': 22.836})\n\n\n\nlogits = out.predictions\nprob = torch.tensor(logits).softmax(dim=1).numpy()[:,1]\nprob\n\narray([0.83734226, 0.8753777 , 0.4740918 , ..., 0.8867439 , 0.8809505 ,\n       0.83733165], dtype=float32)\n\n\n\ntest_csv['has_cactus'] = prob \ntest_csv\n\n\n\n\n\n\n\n\nid\nhas_cactus\n\n\n\n\n0\n000940378805c44108d287872b2f04ce.jpg\n0.837342\n\n\n1\n0017242f54ececa4512b4d7937d1e21e.jpg\n0.875378\n\n\n2\n001ee6d8564003107853118ab87df407.jpg\n0.474092\n\n\n3\n002e175c3c1e060769475f52182583d0.jpg\n0.429720\n\n\n4\n0036e44a7e8f7218e9bc7bf8137e4943.jpg\n0.862989\n\n\n...\n...\n...\n\n\n3995\nffaafd0c9f2f0e73172848463bc2e523.jpg\n0.866051\n\n\n3996\nffae37344310a1549162493237d25d3f.jpg\n0.902185\n\n\n3997\nffbd469c56873d064326204aac546e0d.jpg\n0.886744\n\n\n3998\nffcb76b7d47f29ece11c751e5f763f52.jpg\n0.880951\n\n\n3999\nfffed17d1a8e0433a934db518d7f532c.jpg\n0.837332\n\n\n\n\n4000 rows × 2 columns\n\n\n\nStep1 ~ Step4\n\ntrain_csv = pd.read_csv(\"./data/train.csv\")\ntest_csv = pd.read_csv(\"./data/sample_submission.csv\")\n#--#\n# Step1: Data\nctx_train = datasets.Dataset.from_pandas(train_csv)\nctx_test = datasets.Dataset.from_pandas(test_csv).remove_columns(['has_cactus'])\nctx_train = ctx_train.map(lambda example: {'path': f'./data/train/{example['id']}'})\nctx_test = ctx_test.map(lambda example: {'path': f'./data/test/{example['id']}'})\nctx = datasets.DatasetDict({'train':ctx_train,'test':ctx_test})\ncompose = torchvision.transforms.Compose([\n    lambda path: PIL.Image.open(path),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Resize(224),\n])\ndef w_trans(examples):\n    dct = dict()\n    try: \n        dct['labels'] = torch.tensor(examples['has_cactus']).long()\n    except: \n        pass \n    dct['pixel_values'] = torch.stack(list(map(compose,examples['path']))).float() # 명확하게\n    return dct \nctx = ctx.with_transform(w_trans)\n# Step2: Model \nmodel = transformers.AutoModelForImageClassification.from_pretrained(\n    \"google/vit-base-patch16-224-in21k\",\n    num_labels=2,\n)\n# Step3: Train \ndata_collator = transformers.DefaultDataCollator()\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=1)\n    prediction_scores = torch.tensor(logits).softmax(dim=1).numpy()[:,1]\n    #---#\n    accuracy = evaluate.load(\"accuracy\")\n    recall = evaluate.load(\"recall\")\n    roc_auc = evaluate.load(\"roc_auc\")\n    dct1 = accuracy.compute(predictions=predictions, references=labels)\n    dct2 = recall.compute(predictions=predictions, references=labels)\n    dct3 = roc_auc.compute(prediction_scores=prediction_scores, references=labels)\n    return dct1|dct2|dct3\ntrainer = transformers.Trainer(\n    model=model,\n    args=transformers.TrainingArguments(\n        output_dir=\"./model/ctx\",\n        remove_unused_columns=False,\n        #---#\n        eval_strategy=\"epoch\",\n        save_strategy=\"epoch\",\n        learning_rate=5e-5,\n        per_device_train_batch_size=16,\n        gradient_accumulation_steps=4,\n        per_device_eval_batch_size=16,\n        num_train_epochs=2,\n        warmup_ratio=0.1,\n        logging_steps=10,\n        load_best_model_at_end=True,\n        #metric_for_best_model=\"accuracy\",\n        push_to_hub=False,\n        report_to=\"none\"),\n    data_collator=data_collator,\n    train_dataset=ctx['train'].select(range(1000)),\n    eval_dataset=ctx['train'].select(range(1000,1500)),\n    compute_metrics=compute_metrics,\n)\ntrainer.train()\n# Step4: Prediction\nout = trainer.predict(ctx['test'])\ndef update(out,test_csv):\n    logits = out.predictions\n    prob = torch.tensor(logits).softmax(dim=1).numpy()[:,1]\n    test_csv['has_cactus'] = prob\n    return test_csv\ntest_csv = update(out,test_csv)\n\nMap: 100%|██████████████████████| 17500/17500 [00:00&lt;00:00, 63956.34 examples/s]\nMap: 100%|████████████████████████| 4000/4000 [00:00&lt;00:00, 91609.69 examples/s]\nSome weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n\n\n    \n      \n      \n      [30/30 00:27, Epoch 1/2]\n    \n    \n\n\n\nEpoch\nTraining Loss\nValidation Loss\nAccuracy\nRecall\nRoc Auc\n\n\n\n\n0\n0.500400\n0.204903\n0.970000\n0.997312\n0.999223\n\n\n1\n0.111500\n0.110077\n0.990000\n0.994624\n0.999748"
  },
  {
    "objectID": "공부/HF/2024-11-07-(강의) 선인장 이미지분류.html#b.-자유로운-코드",
    "href": "공부/HF/2024-11-07-(강의) 선인장 이미지분류.html#b.-자유로운-코드",
    "title": "(강의) 선인장이미지분류 – ROC",
    "section": "B. \b자유로운 코드",
    "text": "B. \b자유로운 코드\nStep1: Datasets\n\ntrain_csv = pd.read_csv(\"./data/train.csv\")\ntest_csv = pd.read_csv(\"./data/sample_submission.csv\")\nctx_train = datasets.Dataset.from_pandas(train_csv.assign(path = train_csv.id.map(lambda x: f'./data/train/{x}')))\nctx_test = datasets.Dataset.from_pandas(test_csv.assign(path = test_csv.id.map(lambda x: f'./data/test/{x}'))).remove_columns(['has_cactus'])\nctx = datasets.DatasetDict({'train':ctx_train, 'test':ctx_test})\nctx\n\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'has_cactus', 'path'],\n        num_rows: 17500\n    })\n    test: Dataset({\n        features: ['id', 'path'],\n        num_rows: 4000\n    })\n})\n\n\nStep2~3 과정의 간보기\n\n## 간보기코드\nsingle_batch = [ctx['train'][0],ctx['train'][1]]\nsingle_batch\ncompose = torchvision.transforms.Compose([\n    lambda path: PIL.Image.open(path),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Resize(224),\n])\ndef collate_fn(single_batch):\n    dct = dict()\n    dct['pixel_values'] = torch.stack(list(map(compose,[o['path'] for o in single_batch]))).float()\n    try: \n        dct['labels'] = torch.tensor([o.get('has_cactus') for o in single_batch]).long() # 이거안하면 에러남\n    except: \n        pass \n    return dct \nmodel = transformers.AutoModelForImageClassification.from_pretrained(\n    \"google/vit-base-patch16-224-in21k\",\n    num_labels=2,\n)\nmodel(**collate_fn(single_batch))\n\nSome weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n\nImageClassifierOutput(loss=tensor(0.6570, grad_fn=&lt;NllLossBackward0&gt;), logits=tensor([[ 0.0427,  0.2046],\n        [-0.0234, -0.0343]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)\n\n\nStep1~4\n\ntrain_csv = pd.read_csv(\"./data/train.csv\")\ntest_csv = pd.read_csv(\"./data/sample_submission.csv\")\n#--#\n# Step1: Data \nctx_train = datasets.Dataset.from_pandas(train_csv.assign(path = train_csv.id.map(lambda x: f'./data/train/{x}')))\nctx_test = datasets.Dataset.from_pandas(test_csv.assign(path = test_csv.id.map(lambda x: f'./data/test/{x}'))).remove_columns(['has_cactus'])\nctx = datasets.DatasetDict({'train':ctx_train, 'test':ctx_test})\ncompose = torchvision.transforms.Compose([\n    lambda path: PIL.Image.open(path),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Resize(224),\n])\n# Step2: Model\nmodel = transformers.AutoModelForImageClassification.from_pretrained(\n    \"google/vit-base-patch16-224-in21k\",\n    num_labels=2,\n)\n# Step3: Trainer -&gt; train \ndef collate_fn(single_batch):\n    dct = dict()\n    dct['pixel_values'] = torch.stack(list(map(compose,[o['path'] for o in single_batch]))).float()\n    try: \n        dct['labels'] = torch.tensor([o.get('has_cactus') for o in single_batch]).long() # 이거안하면 에러남\n    except: \n        pass \n    return dct \ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=1)\n    prediction_scores = torch.tensor(logits).softmax(dim=1).numpy()[:,1]\n    #---#\n    accuracy = evaluate.load(\"accuracy\")\n    recall = evaluate.load(\"recall\")\n    roc_auc = evaluate.load(\"roc_auc\")\n    dct1 = accuracy.compute(predictions=predictions, references=labels)\n    dct2 = recall.compute(predictions=predictions, references=labels)\n    dct3 = roc_auc.compute(prediction_scores=prediction_scores, references=labels)\n    return dct1|dct2|dct3\ntrainer = transformers.Trainer(\n    model=model,\n    args=transformers.TrainingArguments(\n        output_dir=\"./model/ctx\",\n        remove_unused_columns=False,\n        #---#\n        eval_strategy=\"epoch\",\n        save_strategy=\"epoch\",\n        learning_rate=5e-5,\n        per_device_train_batch_size=16,\n        gradient_accumulation_steps=4,\n        per_device_eval_batch_size=16,\n        num_train_epochs=1,\n        warmup_ratio=0.1,\n        logging_steps=10,\n        load_best_model_at_end=True,\n        #metric_for_best_model=\"accuracy\",\n        push_to_hub=False,\n        report_to=\"none\"),\n    data_collator=collate_fn,\n    train_dataset=ctx['train'].select(range(1000)),\n    eval_dataset=ctx['train'].select(range(1000,1500)),\n    compute_metrics=compute_metrics,\n)\ntrainer.train()\n# Step4: Prediction\nout = trainer.predict(ctx['test'])\ndef update(out,test_csv):\n    logits = out.predictions\n    prob = torch.tensor(logits).softmax(dim=1).numpy()[:,1]\n    test_csv['has_cactus'] = prob\n    return test_csv\ntest_csv = update(out,test_csv)\n\nSome weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n\n\n    \n      \n      \n      [15/15 00:14, Epoch 0/1]\n    \n    \n\n\n\nEpoch\nTraining Loss\nValidation Loss\nAccuracy\nRecall\nRoc Auc\n\n\n\n\n0\n0.499300\n0.276025\n0.918000\n1.000000\n0.999286"
  },
  {
    "objectID": "공부/HF/2024-11-01-(강의) 모듈설치 및 변경.html#a.-패키지위치",
    "href": "공부/HF/2024-11-01-(강의) 모듈설치 및 변경.html#a.-패키지위치",
    "title": "(강의) 모듈설치 및 변경",
    "section": "A. 패키지위치",
    "text": "A. 패키지위치\n- numpy가 설치된 위치를 알아보자.\n\nnp?\n\nType:        module\nString form: &lt;module 'numpy' from '/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/numpy/__init__.py'&gt;\nFile:        ~/anaconda3/envs/hf/lib/python3.12/site-packages/numpy/__init__.py\nDocstring:  \nNumPy\n=====\n\nProvides\n  1. An array object of arbitrary homogeneous items\n  2. Fast mathematical operations over arrays\n  3. Linear Algebra, Fourier Transforms, Random Number Generation\n\nHow to use the documentation\n----------------------------\nDocumentation is available in two forms: docstrings provided\nwith the code, and a loose standing reference guide, available from\n`the NumPy homepage &lt;https://numpy.org&gt;`_.\n\nWe recommend exploring the docstrings using\n`IPython &lt;https://ipython.org&gt;`_, an advanced Python shell with\nTAB-completion and introspection capabilities.  See below for further\ninstructions.\n\nThe docstring examples assume that `numpy` has been imported as ``np``::\n\n  &gt;&gt;&gt; import numpy as np\n\nCode snippets are indicated by three greater-than signs::\n\n  &gt;&gt;&gt; x = 42\n  &gt;&gt;&gt; x = x + 1\n\nUse the built-in ``help`` function to view a function's docstring::\n\n  &gt;&gt;&gt; help(np.sort)\n  ... # doctest: +SKIP\n\nFor some objects, ``np.info(obj)`` may provide additional help.  This is\nparticularly true if you see the line \"Help on ufunc object:\" at the top\nof the help() page.  Ufuncs are implemented in C, not Python, for speed.\nThe native Python help() does not know how to view their help, but our\nnp.info() function does.\n\nTo search for documents containing a keyword, do::\n\n  &gt;&gt;&gt; np.lookfor('keyword')\n  ... # doctest: +SKIP\n\nGeneral-purpose documents like a glossary and help on the basic concepts\nof numpy are available under the ``doc`` sub-module::\n\n  &gt;&gt;&gt; from numpy import doc\n  &gt;&gt;&gt; help(doc)\n  ... # doctest: +SKIP\n\nAvailable subpackages\n---------------------\nlib\n    Basic functions used by several sub-packages.\nrandom\n    Core Random Tools\nlinalg\n    Core Linear Algebra Tools\nfft\n    Core FFT routines\npolynomial\n    Polynomial tools\ntesting\n    NumPy testing tools\ndistutils\n    Enhancements to distutils with support for\n    Fortran compilers support and more  (for Python &lt;= 3.11).\n\nUtilities\n---------\ntest\n    Run numpy unittests\nshow_config\n    Show numpy build configuration\nmatlib\n    Make everything matrices.\n__version__\n    NumPy version string\n\nViewing documentation using IPython\n-----------------------------------\n\nStart IPython and import `numpy` usually under the alias ``np``: `import\nnumpy as np`.  Then, directly past or use the ``%cpaste`` magic to paste\nexamples into the shell.  To see which functions are available in `numpy`,\ntype ``np.&lt;TAB&gt;`` (where ``&lt;TAB&gt;`` refers to the TAB key), or use\n``np.*cos*?&lt;ENTER&gt;`` (where ``&lt;ENTER&gt;`` refers to the ENTER key) to narrow\ndown the list.  To view the docstring for a function, use\n``np.cos?&lt;ENTER&gt;`` (to view the docstring) and ``np.cos??&lt;ENTER&gt;`` (to view\nthe source code).\n\nCopies vs. in-place operation\n-----------------------------\nMost of the functions in `numpy` return a copy of the array argument\n(e.g., `np.sort`).  In-place versions of these functions are often\navailable as array methods, i.e. ``x = np.array([1,2,3]); x.sort()``.\nExceptions to this rule are documented.\n\n\n- numpy폴더는 있고 mp2024pkg 폴더는 없음..\n- 그래서 numpy는 임포트되는데 mp2024pkg는 임포트되지 않음\n\nimport mp2024pkg"
  },
  {
    "objectID": "공부/HF/2024-11-01-(강의) 모듈설치 및 변경.html#b.-패키지설치",
    "href": "공부/HF/2024-11-01-(강의) 모듈설치 및 변경.html#b.-패키지설치",
    "title": "(강의) 모듈설치 및 변경",
    "section": "B. 패키지설치",
    "text": "B. 패키지설치\n- mp2024pkg install (=download)\n\n!pip install git+https://github.com/guebin/mp2024pkg.git\n#!pip uninstall -y mp2024pkg # 폴더삭제..\n\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\n\nCollecting git+https://github.com/guebin/mp2024pkg.git\n  Cloning https://github.com/guebin/mp2024pkg.git to /tmp/pip-req-build-h08x6md7\n  Running command git clone --filter=blob:none --quiet https://github.com/guebin/mp2024pkg.git /tmp/pip-req-build-h08x6md7\n  Resolved https://github.com/guebin/mp2024pkg.git to commit bd3e63bfe6a50d78c955b42236511e7c90786291\n  Preparing metadata (setup.py) ... done\n\n\n- 생성된 mp2024pkg 폴더의 내용 – 깃허브에 있는 폴더 그대로 다운로드됨..\n- import\n\nimport mp2024pkg\n\n- 사용\n\nmp2024pkg.show_dict(dct)\n\nDictionary Overview:\nTotal keys: 4\nKeys: ['lst', 'tpl', 'np_array', 'torch']\n\n1. Key: 'lst'\n   - Type: list\n   - Length: 300\n   - Values: [1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, ...\n\n2. Key: 'tpl'\n   - Type: tuple\n   - Length: 3\n   - Values: (2, 3, 4)\n\n3. Key: 'np_array'\n   - Type: ndarray\n   - Length: 100\n   - Values: [ 1.55878131 -1.49421132  1.20362397  0.42548966  0.10022957 -0.17709745\n  1.55826047 -0.91990667 -1...\n\n4. Key: 'torch'\n   - Type: Tensor\n   - Length: 1\n   - Values: tensor([1])\n\n\n\n\nmp2024pkg.show_list(lst)\n\nLevel 1 - Type: list, Length: 4, Content: [[1, 1, 1, 1, 1, 1, 1, 1, ... 'python', (1, 2, [3, 4])]\n     Level 2 - Type: list, Length: 500, Content: [1, 1, 1, 1, 1, 1, 1, 1,  ... , 1, 1, 1, 1, 1, 1, 1, 1]\n     Level 2 - Type: dict, Length: 2, Content: {'a': [2, 2, 2, 2, 2, 2,  ...  2, 2, 2, 2], 'b': '123'}\n     Level 2 - Type: str, Length: 6, Content: 'python'\n     Level 2 - Type: tuple, Length: 3, Content: (1, 2, [3, 4])"
  },
  {
    "objectID": "공부/HF/2024-11-01-(강의) 모듈설치 및 변경.html#c.-패키지변경",
    "href": "공부/HF/2024-11-01-(강의) 모듈설치 및 변경.html#c.-패키지변경",
    "title": "(강의) 모듈설치 및 변경",
    "section": "C. 패키지변경",
    "text": "C. 패키지변경\n- mp2024pkg 폴더로 show_list 함수가 정의된 부분 변경\n- 커널재시작후 다시 import\n\nimport mp2024pkg\n\n- 변경된 내용 확인\n\nmp2024pkg.show_list(lst)\n\nLevel 1 - Type: list, Length: 4, Content: [[1, 1, 1, 1, 1, 1, 1, 1, ... 'python', (1, 2, [3, 4])]\n     Level 2 - Type: list, Length: 500, Content: [1, 1, 1, 1, 1, 1, 1, 1,  ... , 1, 1, 1, 1, 1, 1, 1, 1]\n     Level 2 - Type: dict, Length: 2, Content: {'a': [2, 2, 2, 2, 2, 2,  ...  2, 2, 2, 2], 'b': '123'}\n     Level 2 - Type: str, Length: 6, Content: 'python'\n     Level 2 - Type: tuple, Length: 3, Content: (1, 2, [3, 4])\n\n\n:"
  },
  {
    "objectID": "공부/HF/2024-11-01-(강의) 모듈설치 및 변경.html#d.-패키지로드",
    "href": "공부/HF/2024-11-01-(강의) 모듈설치 및 변경.html#d.-패키지로드",
    "title": "(강의) 모듈설치 및 변경",
    "section": "D. 패키지로드",
    "text": "D. 패키지로드\n# 예시1\n\nimport mp2024pkg \n\n\nmp2024pkg.show_dict({'a':[1,2,3],'b':[2,3,4]})\n\nDictionary Overview:\nTotal keys: 2\nKeys: ['a', 'b']\n\n1. Key: 'a'\n   - Type: list\n   - Length: 3\n   - Values: [1, 2, 3]\n\n2. Key: 'b'\n   - Type: list\n   - Length: 3\n   - Values: [2, 3, 4]\n\n\n\n\nmp2024pkg.show_list([[1],[1,2]])\n\nLevel 1 - Type: list, Length: 2, Content: [[1], [1, 2]]\n     Level 2 - Type: list, Length: 1, Content: [1]\n     Level 2 - Type: list, Length: 2, Content: [1, 2]\n\n\n#\n# 예시2\n\nimport mp2024pkg as mp\n\n\nmp.show_dict({'a':[1,2,3],'b':[2,3,4]})\n\nDictionary Overview:\nTotal keys: 2\nKeys: ['a', 'b']\n\n1. Key: 'a'\n   - Type: list\n   - Length: 3\n   - Values: [1, 2, 3]\n\n2. Key: 'b'\n   - Type: list\n   - Length: 3\n   - Values: [2, 3, 4]\n\n\n\n\nmp.show_list([[1],[1,2]])\n\nLevel 1 - Type: list, Length: 2, Content: [[1], [1, 2]]\n     Level 2 - Type: list, Length: 1, Content: [1]\n     Level 2 - Type: list, Length: 2, Content: [1, 2]\n\n\n#\n# 예시3\n\nfrom mp2024pkg import *\n\n\nshow_dict({'a':[1,2,3],'b':[2,3,4]})\n\nDictionary Overview:\nTotal keys: 2\nKeys: ['a', 'b']\n\n1. Key: 'a'\n   - Type: list\n   - Length: 3\n   - Values: [1, 2, 3]\n\n2. Key: 'b'\n   - Type: list\n   - Length: 3\n   - Values: [2, 3, 4]\n\n\n\n\nshow_list([[1],[1,2]])\n\nLevel 1 - Type: list, Length: 2, Content: [[1], [1, 2]]\n     Level 2 - Type: list, Length: 1, Content: [1]\n     Level 2 - Type: list, Length: 2, Content: [1, 2]\n\n\n\nmp2024pkg.show_dict({'a':[1,2,3],'b':[2,3,4]})\n\nNameError: name 'mp2024pkg' is not defined\n\n\n\nmp2024pkg.show_list([[1],[1,2]])\n\nNameError: name 'mp2024pkg' is not defined\n\n\n#\n# 예시5\n\nfrom mp2024pkg import show_dict, show_list\n\n\nshow_dict({'a':[1,2,3],'b':[2,3,4]})\n\nDictionary Overview:\nTotal keys: 2\nKeys: ['a', 'b']\n\n1. Key: 'a'\n   - Type: list\n   - Length: 3\n   - Values: [1, 2, 3]\n\n2. Key: 'b'\n   - Type: list\n   - Length: 3\n   - Values: [2, 3, 4]\n\n\n\n\nshow_list([[1],[1,2]])\n\nLevel 1 - Type: list, Length: 2, Content: [[1], [1, 2]]\n     Level 2 - Type: list, Length: 1, Content: [1]\n     Level 2 - Type: list, Length: 2, Content: [1, 2]\n\n\n#\n# 예시6\n\nfrom mp2024pkg import show_dict as sd\n\n\nsd({'a':[1,2,3],'b':[2,3,4]})\n\nDictionary Overview:\nTotal keys: 2\nKeys: ['a', 'b']\n\n1. Key: 'a'\n   - Type: list\n   - Length: 3\n   - Values: [1, 2, 3]\n\n2. Key: 'b'\n   - Type: list\n   - Length: 3\n   - Values: [2, 3, 4]\n\n\n\n\nshow_list([[1],[1,2]])\n\nLevel 1 - Type: list, Length: 2, Content: [[1], [1, 2]]\n     Level 2 - Type: list, Length: 1, Content: [1]\n     Level 2 - Type: list, Length: 2, Content: [1, 2]\n\n\n#\n# 예시7\n\nfrom mp2024pkg import show_dict as sd\nfrom mp2024pkg import show_list as sl\n\n\nsd({'a':[1,2,3],'b':[2,3,4]})\n\nDictionary Overview:\nTotal keys: 2\nKeys: ['a', 'b']\n\n1. Key: 'a'\n   - Type: list\n   - Length: 3\n   - Values: [1, 2, 3]\n\n2. Key: 'b'\n   - Type: list\n   - Length: 3\n   - Values: [2, 3, 4]\n\n\n\n\nsl([[1],[1,2]])\n\nLevel 1 - Type: list, Length: 2, Content: [[1], [1, 2]]\n     Level 2 - Type: list, Length: 1, Content: [1]\n     Level 2 - Type: list, Length: 2, Content: [1, 2]\n\n\n#"
  },
  {
    "objectID": "공부/HF/2024-09-08-(강의) 감성분류.html#a.-step1-데이터의-정리",
    "href": "공부/HF/2024-09-08-(강의) 감성분류.html#a.-step1-데이터의-정리",
    "title": "(강의) 감성분류",
    "section": "A. Step1 – 데이터의 정리",
    "text": "A. Step1 – 데이터의 정리\n- 데이터불러오기\n\nfrom datasets import load_dataset\nimdb = load_dataset(\"imdb\") # 텍스트데이터 = 데이터불러오기()\n\n- 토크나이저 생성\n\nfrom transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n\n뭐하는거?\n\ndir(tokenizer) \n\n['SPECIAL_TOKENS_ATTRIBUTES',\n '__annotations__',\n '__call__',\n '__class__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__getstate__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__le__',\n '__len__',\n '__lt__',\n '__module__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n '__weakref__',\n '_add_tokens',\n '_additional_special_tokens',\n '_auto_class',\n '_batch_encode_plus',\n '_bos_token',\n '_call_one',\n '_cls_token',\n '_compile_jinja_template',\n '_convert_encoding',\n '_convert_id_to_token',\n '_convert_token_to_id_with_added_voc',\n '_create_repo',\n '_decode',\n '_decode_use_source_tokenizer',\n '_encode_plus',\n '_eos_token',\n '_eventual_warn_about_too_long_sequence',\n '_eventually_correct_t5_max_length',\n '_from_pretrained',\n '_get_files_timestamps',\n '_get_padding_truncation_strategies',\n '_in_target_context_manager',\n '_mask_token',\n '_pad',\n '_pad_token',\n '_pad_token_type_id',\n '_processor_class',\n '_render_with_assistant_indices',\n '_save_pretrained',\n '_sep_token',\n '_set_processor_class',\n '_switch_to_input_mode',\n '_switch_to_target_mode',\n '_tokenizer',\n '_unk_token',\n '_upload_modified_files',\n 'add_special_tokens',\n 'add_tokens',\n 'added_tokens_decoder',\n 'added_tokens_encoder',\n 'additional_special_tokens',\n 'additional_special_tokens_ids',\n 'all_special_ids',\n 'all_special_tokens',\n 'all_special_tokens_extended',\n 'apply_chat_template',\n 'as_target_tokenizer',\n 'backend_tokenizer',\n 'batch_decode',\n 'batch_encode_plus',\n 'bos_token',\n 'bos_token_id',\n 'build_inputs_with_special_tokens',\n 'can_save_slow_tokenizer',\n 'chat_template',\n 'clean_up_tokenization',\n 'clean_up_tokenization_spaces',\n 'cls_token',\n 'cls_token_id',\n 'convert_added_tokens',\n 'convert_ids_to_tokens',\n 'convert_tokens_to_ids',\n 'convert_tokens_to_string',\n 'create_token_type_ids_from_sequences',\n 'decode',\n 'decoder',\n 'deprecation_warnings',\n 'do_lower_case',\n 'encode',\n 'encode_plus',\n 'eos_token',\n 'eos_token_id',\n 'from_pretrained',\n 'get_added_vocab',\n 'get_chat_template',\n 'get_special_tokens_mask',\n 'get_vocab',\n 'init_inputs',\n 'init_kwargs',\n 'is_fast',\n 'mask_token',\n 'mask_token_id',\n 'max_len_sentences_pair',\n 'max_len_single_sentence',\n 'model_input_names',\n 'model_max_length',\n 'name_or_path',\n 'num_special_tokens_to_add',\n 'pad',\n 'pad_token',\n 'pad_token_id',\n 'pad_token_type_id',\n 'padding_side',\n 'prepare_for_model',\n 'prepare_seq2seq_batch',\n 'pretrained_vocab_files_map',\n 'push_to_hub',\n 'register_for_auto_class',\n 'sanitize_special_tokens',\n 'save_pretrained',\n 'save_vocabulary',\n 'sep_token',\n 'sep_token_id',\n 'set_truncation_and_padding',\n 'slow_tokenizer_class',\n 'special_tokens_map',\n 'special_tokens_map_extended',\n 'split_special_tokens',\n 'tokenize',\n 'train_new_from_iterator',\n 'truncate_sequences',\n 'truncation_side',\n 'unk_token',\n 'unk_token_id',\n 'verbose',\n 'vocab',\n 'vocab_files_names',\n 'vocab_size']\n\n\n\ntokenizer(\"Transformers are really useful for natural language processing.\") # 텍스트 -&gt; 숫자들\n\n{'input_ids': [101, 19081, 2024, 2428, 6179, 2005, 3019, 2653, 6364, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n\n\n- preprocess_function 선언\n\ndef preprocess_function(examples):\n    return tokenizer(examples[\"text\"], truncation=True)\n\n뭐하는함수?\n\ntokenizer(\"Transformers are really useful for natural language processing.\", truncation=True) # ?? 비슷한듯..\n\n{'input_ids': [101, 19081, 2024, 2428, 6179, 2005, 3019, 2653, 6364, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n\n\n\nexamples = imdb['train'][0]\ntokenizer(examples[\"text\"], truncation=True)\n\n{'input_ids': [101, 1045, 12524, 1045, 2572, 8025, 1011, 3756, 2013, 2026, 2678, 3573, 2138, 1997, 2035, 1996, 6704, 2008, 5129, 2009, 2043, 2009, 2001, 2034, 2207, 1999, 3476, 1012, 1045, 2036, 2657, 2008, 2012, 2034, 2009, 2001, 8243, 2011, 1057, 1012, 1055, 1012, 8205, 2065, 2009, 2412, 2699, 2000, 4607, 2023, 2406, 1010, 3568, 2108, 1037, 5470, 1997, 3152, 2641, 1000, 6801, 1000, 1045, 2428, 2018, 2000, 2156, 2023, 2005, 2870, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1996, 5436, 2003, 8857, 2105, 1037, 2402, 4467, 3689, 3076, 2315, 14229, 2040, 4122, 2000, 4553, 2673, 2016, 2064, 2055, 2166, 1012, 1999, 3327, 2016, 4122, 2000, 3579, 2014, 3086, 2015, 2000, 2437, 2070, 4066, 1997, 4516, 2006, 2054, 1996, 2779, 25430, 14728, 2245, 2055, 3056, 2576, 3314, 2107, 2004, 1996, 5148, 2162, 1998, 2679, 3314, 1999, 1996, 2142, 2163, 1012, 1999, 2090, 4851, 8801, 1998, 6623, 7939, 4697, 3619, 1997, 8947, 2055, 2037, 10740, 2006, 4331, 1010, 2016, 2038, 3348, 2007, 2014, 3689, 3836, 1010, 19846, 1010, 1998, 2496, 2273, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2054, 8563, 2033, 2055, 1045, 2572, 8025, 1011, 3756, 2003, 2008, 2871, 2086, 3283, 1010, 2023, 2001, 2641, 26932, 1012, 2428, 1010, 1996, 3348, 1998, 16371, 25469, 5019, 2024, 2261, 1998, 2521, 2090, 1010, 2130, 2059, 2009, 1005, 1055, 2025, 2915, 2066, 2070, 10036, 2135, 2081, 22555, 2080, 1012, 2096, 2026, 2406, 3549, 2568, 2424, 2009, 16880, 1010, 1999, 4507, 3348, 1998, 16371, 25469, 2024, 1037, 2350, 18785, 1999, 4467, 5988, 1012, 2130, 13749, 7849, 24544, 1010, 15835, 2037, 3437, 2000, 2204, 2214, 2879, 2198, 4811, 1010, 2018, 3348, 5019, 1999, 2010, 3152, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1045, 2079, 4012, 3549, 2094, 1996, 16587, 2005, 1996, 2755, 2008, 2151, 3348, 3491, 1999, 1996, 2143, 2003, 3491, 2005, 6018, 5682, 2738, 2084, 2074, 2000, 5213, 2111, 1998, 2191, 2769, 2000, 2022, 3491, 1999, 26932, 12370, 1999, 2637, 1012, 1045, 2572, 8025, 1011, 3756, 2003, 1037, 2204, 2143, 2005, 3087, 5782, 2000, 2817, 1996, 6240, 1998, 14629, 1006, 2053, 26136, 3832, 1007, 1997, 4467, 5988, 1012, 2021, 2428, 1010, 2023, 2143, 2987, 1005, 1056, 2031, 2172, 1997, 1037, 5436, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n\n\n\nexamples = imdb['train'][:2]\ntokenizer(examples[\"text\"], truncation=True)\n\n{'input_ids': [[101, 1045, 12524, 1045, 2572, 8025, 1011, 3756, 2013, 2026, 2678, 3573, 2138, 1997, 2035, 1996, 6704, 2008, 5129, 2009, 2043, 2009, 2001, 2034, 2207, 1999, 3476, 1012, 1045, 2036, 2657, 2008, 2012, 2034, 2009, 2001, 8243, 2011, 1057, 1012, 1055, 1012, 8205, 2065, 2009, 2412, 2699, 2000, 4607, 2023, 2406, 1010, 3568, 2108, 1037, 5470, 1997, 3152, 2641, 1000, 6801, 1000, 1045, 2428, 2018, 2000, 2156, 2023, 2005, 2870, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1996, 5436, 2003, 8857, 2105, 1037, 2402, 4467, 3689, 3076, 2315, 14229, 2040, 4122, 2000, 4553, 2673, 2016, 2064, 2055, 2166, 1012, 1999, 3327, 2016, 4122, 2000, 3579, 2014, 3086, 2015, 2000, 2437, 2070, 4066, 1997, 4516, 2006, 2054, 1996, 2779, 25430, 14728, 2245, 2055, 3056, 2576, 3314, 2107, 2004, 1996, 5148, 2162, 1998, 2679, 3314, 1999, 1996, 2142, 2163, 1012, 1999, 2090, 4851, 8801, 1998, 6623, 7939, 4697, 3619, 1997, 8947, 2055, 2037, 10740, 2006, 4331, 1010, 2016, 2038, 3348, 2007, 2014, 3689, 3836, 1010, 19846, 1010, 1998, 2496, 2273, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2054, 8563, 2033, 2055, 1045, 2572, 8025, 1011, 3756, 2003, 2008, 2871, 2086, 3283, 1010, 2023, 2001, 2641, 26932, 1012, 2428, 1010, 1996, 3348, 1998, 16371, 25469, 5019, 2024, 2261, 1998, 2521, 2090, 1010, 2130, 2059, 2009, 1005, 1055, 2025, 2915, 2066, 2070, 10036, 2135, 2081, 22555, 2080, 1012, 2096, 2026, 2406, 3549, 2568, 2424, 2009, 16880, 1010, 1999, 4507, 3348, 1998, 16371, 25469, 2024, 1037, 2350, 18785, 1999, 4467, 5988, 1012, 2130, 13749, 7849, 24544, 1010, 15835, 2037, 3437, 2000, 2204, 2214, 2879, 2198, 4811, 1010, 2018, 3348, 5019, 1999, 2010, 3152, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1045, 2079, 4012, 3549, 2094, 1996, 16587, 2005, 1996, 2755, 2008, 2151, 3348, 3491, 1999, 1996, 2143, 2003, 3491, 2005, 6018, 5682, 2738, 2084, 2074, 2000, 5213, 2111, 1998, 2191, 2769, 2000, 2022, 3491, 1999, 26932, 12370, 1999, 2637, 1012, 1045, 2572, 8025, 1011, 3756, 2003, 1037, 2204, 2143, 2005, 3087, 5782, 2000, 2817, 1996, 6240, 1998, 14629, 1006, 2053, 26136, 3832, 1007, 1997, 4467, 5988, 1012, 2021, 2428, 1010, 2023, 2143, 2987, 1005, 1056, 2031, 2172, 1997, 1037, 5436, 1012, 102], [101, 1000, 1045, 2572, 8025, 1024, 3756, 1000, 2003, 1037, 15544, 19307, 1998, 3653, 6528, 20771, 19986, 8632, 1012, 2009, 2987, 1005, 1056, 3043, 2054, 2028, 1005, 1055, 2576, 5328, 2024, 2138, 2023, 2143, 2064, 6684, 2022, 2579, 5667, 2006, 2151, 2504, 1012, 2004, 2005, 1996, 4366, 2008, 19124, 3287, 16371, 25469, 2003, 2019, 6882, 13316, 1011, 2459, 1010, 2008, 3475, 1005, 1056, 2995, 1012, 1045, 1005, 2310, 2464, 1054, 1011, 6758, 3152, 2007, 3287, 16371, 25469, 1012, 4379, 1010, 2027, 2069, 3749, 2070, 25085, 5328, 1010, 2021, 2073, 2024, 1996, 1054, 1011, 6758, 3152, 2007, 21226, 24728, 22144, 2015, 1998, 20916, 4691, 6845, 2401, 1029, 7880, 1010, 2138, 2027, 2123, 1005, 1056, 4839, 1012, 1996, 2168, 3632, 2005, 2216, 10231, 7685, 5830, 3065, 1024, 8040, 7317, 5063, 2015, 11820, 1999, 1996, 9478, 2021, 2025, 1037, 17962, 21239, 1999, 4356, 1012, 1998, 2216, 3653, 6528, 20771, 10271, 5691, 2066, 1996, 2829, 16291, 1010, 1999, 2029, 2057, 1005, 2128, 5845, 2000, 1996, 2609, 1997, 6320, 25624, 1005, 1055, 17061, 3779, 1010, 2021, 2025, 1037, 7637, 1997, 5061, 5710, 2006, 9318, 7367, 5737, 19393, 1012, 2077, 6933, 1006, 2030, 20242, 1007, 1000, 3313, 1011, 3115, 1000, 1999, 5609, 1997, 16371, 25469, 1010, 1996, 10597, 27885, 5809, 2063, 2323, 2202, 2046, 4070, 2028, 14477, 6767, 8524, 6321, 5793, 28141, 4489, 2090, 2273, 1998, 2308, 1024, 2045, 2024, 2053, 8991, 18400, 2015, 2006, 4653, 2043, 19910, 3544, 15287, 1010, 1998, 1996, 2168, 3685, 2022, 2056, 2005, 1037, 2158, 1012, 1999, 2755, 1010, 2017, 3227, 2180, 1005, 1056, 2156, 2931, 8991, 18400, 2015, 1999, 2019, 2137, 2143, 1999, 2505, 2460, 1997, 22555, 2030, 13216, 14253, 2050, 1012, 2023, 6884, 3313, 1011, 3115, 2003, 2625, 1037, 3313, 3115, 2084, 2019, 4914, 2135, 2139, 24128, 3754, 2000, 2272, 2000, 3408, 20547, 2007, 1996, 19008, 1997, 2308, 1005, 1055, 4230, 1012, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n\n\n- map 함수 사용\n\ntokenized_imdb = imdb.map(preprocess_function, batched=True)\n\nMap: 100%|██████████| 25000/25000 [00:03&lt;00:00, 7777.72 examples/s]\nMap: 100%|██████████| 25000/25000 [00:03&lt;00:00, 7018.03 examples/s]\nMap: 100%|██████████| 50000/50000 [00:06&lt;00:00, 7553.70 examples/s]\n\n\n뭐한거지?\n\nimdb['train'][0], tokenized_imdb['train'][0]\n\n({'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.&lt;br /&gt;&lt;br /&gt;The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.&lt;br /&gt;&lt;br /&gt;What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.&lt;br /&gt;&lt;br /&gt;I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.',\n  'label': 0},\n {'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.&lt;br /&gt;&lt;br /&gt;The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.&lt;br /&gt;&lt;br /&gt;What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.&lt;br /&gt;&lt;br /&gt;I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.',\n  'label': 0,\n  'input_ids': [101,\n   1045,\n   12524,\n   1045,\n   2572,\n   8025,\n   1011,\n   3756,\n   2013,\n   2026,\n   2678,\n   3573,\n   2138,\n   1997,\n   2035,\n   1996,\n   6704,\n   2008,\n   5129,\n   2009,\n   2043,\n   2009,\n   2001,\n   2034,\n   2207,\n   1999,\n   3476,\n   1012,\n   1045,\n   2036,\n   2657,\n   2008,\n   2012,\n   2034,\n   2009,\n   2001,\n   8243,\n   2011,\n   1057,\n   1012,\n   1055,\n   1012,\n   8205,\n   2065,\n   2009,\n   2412,\n   2699,\n   2000,\n   4607,\n   2023,\n   2406,\n   1010,\n   3568,\n   2108,\n   1037,\n   5470,\n   1997,\n   3152,\n   2641,\n   1000,\n   6801,\n   1000,\n   1045,\n   2428,\n   2018,\n   2000,\n   2156,\n   2023,\n   2005,\n   2870,\n   1012,\n   1026,\n   7987,\n   1013,\n   1028,\n   1026,\n   7987,\n   1013,\n   1028,\n   1996,\n   5436,\n   2003,\n   8857,\n   2105,\n   1037,\n   2402,\n   4467,\n   3689,\n   3076,\n   2315,\n   14229,\n   2040,\n   4122,\n   2000,\n   4553,\n   2673,\n   2016,\n   2064,\n   2055,\n   2166,\n   1012,\n   1999,\n   3327,\n   2016,\n   4122,\n   2000,\n   3579,\n   2014,\n   3086,\n   2015,\n   2000,\n   2437,\n   2070,\n   4066,\n   1997,\n   4516,\n   2006,\n   2054,\n   1996,\n   2779,\n   25430,\n   14728,\n   2245,\n   2055,\n   3056,\n   2576,\n   3314,\n   2107,\n   2004,\n   1996,\n   5148,\n   2162,\n   1998,\n   2679,\n   3314,\n   1999,\n   1996,\n   2142,\n   2163,\n   1012,\n   1999,\n   2090,\n   4851,\n   8801,\n   1998,\n   6623,\n   7939,\n   4697,\n   3619,\n   1997,\n   8947,\n   2055,\n   2037,\n   10740,\n   2006,\n   4331,\n   1010,\n   2016,\n   2038,\n   3348,\n   2007,\n   2014,\n   3689,\n   3836,\n   1010,\n   19846,\n   1010,\n   1998,\n   2496,\n   2273,\n   1012,\n   1026,\n   7987,\n   1013,\n   1028,\n   1026,\n   7987,\n   1013,\n   1028,\n   2054,\n   8563,\n   2033,\n   2055,\n   1045,\n   2572,\n   8025,\n   1011,\n   3756,\n   2003,\n   2008,\n   2871,\n   2086,\n   3283,\n   1010,\n   2023,\n   2001,\n   2641,\n   26932,\n   1012,\n   2428,\n   1010,\n   1996,\n   3348,\n   1998,\n   16371,\n   25469,\n   5019,\n   2024,\n   2261,\n   1998,\n   2521,\n   2090,\n   1010,\n   2130,\n   2059,\n   2009,\n   1005,\n   1055,\n   2025,\n   2915,\n   2066,\n   2070,\n   10036,\n   2135,\n   2081,\n   22555,\n   2080,\n   1012,\n   2096,\n   2026,\n   2406,\n   3549,\n   2568,\n   2424,\n   2009,\n   16880,\n   1010,\n   1999,\n   4507,\n   3348,\n   1998,\n   16371,\n   25469,\n   2024,\n   1037,\n   2350,\n   18785,\n   1999,\n   4467,\n   5988,\n   1012,\n   2130,\n   13749,\n   7849,\n   24544,\n   1010,\n   15835,\n   2037,\n   3437,\n   2000,\n   2204,\n   2214,\n   2879,\n   2198,\n   4811,\n   1010,\n   2018,\n   3348,\n   5019,\n   1999,\n   2010,\n   3152,\n   1012,\n   1026,\n   7987,\n   1013,\n   1028,\n   1026,\n   7987,\n   1013,\n   1028,\n   1045,\n   2079,\n   4012,\n   3549,\n   2094,\n   1996,\n   16587,\n   2005,\n   1996,\n   2755,\n   2008,\n   2151,\n   3348,\n   3491,\n   1999,\n   1996,\n   2143,\n   2003,\n   3491,\n   2005,\n   6018,\n   5682,\n   2738,\n   2084,\n   2074,\n   2000,\n   5213,\n   2111,\n   1998,\n   2191,\n   2769,\n   2000,\n   2022,\n   3491,\n   1999,\n   26932,\n   12370,\n   1999,\n   2637,\n   1012,\n   1045,\n   2572,\n   8025,\n   1011,\n   3756,\n   2003,\n   1037,\n   2204,\n   2143,\n   2005,\n   3087,\n   5782,\n   2000,\n   2817,\n   1996,\n   6240,\n   1998,\n   14629,\n   1006,\n   2053,\n   26136,\n   3832,\n   1007,\n   1997,\n   4467,\n   5988,\n   1012,\n   2021,\n   2428,\n   1010,\n   2023,\n   2143,\n   2987,\n   1005,\n   1056,\n   2031,\n   2172,\n   1997,\n   1037,\n   5436,\n   1012,\n   102],\n  'attention_mask': [1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1]})\n\n\n뭐거 더 추가된 형태\n\nfor i in range(5):\n    print(preprocess_function(imdb['train'][i]))\n\n{'input_ids': [101, 1045, 12524, 1045, 2572, 8025, 1011, 3756, 2013, 2026, 2678, 3573, 2138, 1997, 2035, 1996, 6704, 2008, 5129, 2009, 2043, 2009, 2001, 2034, 2207, 1999, 3476, 1012, 1045, 2036, 2657, 2008, 2012, 2034, 2009, 2001, 8243, 2011, 1057, 1012, 1055, 1012, 8205, 2065, 2009, 2412, 2699, 2000, 4607, 2023, 2406, 1010, 3568, 2108, 1037, 5470, 1997, 3152, 2641, 1000, 6801, 1000, 1045, 2428, 2018, 2000, 2156, 2023, 2005, 2870, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1996, 5436, 2003, 8857, 2105, 1037, 2402, 4467, 3689, 3076, 2315, 14229, 2040, 4122, 2000, 4553, 2673, 2016, 2064, 2055, 2166, 1012, 1999, 3327, 2016, 4122, 2000, 3579, 2014, 3086, 2015, 2000, 2437, 2070, 4066, 1997, 4516, 2006, 2054, 1996, 2779, 25430, 14728, 2245, 2055, 3056, 2576, 3314, 2107, 2004, 1996, 5148, 2162, 1998, 2679, 3314, 1999, 1996, 2142, 2163, 1012, 1999, 2090, 4851, 8801, 1998, 6623, 7939, 4697, 3619, 1997, 8947, 2055, 2037, 10740, 2006, 4331, 1010, 2016, 2038, 3348, 2007, 2014, 3689, 3836, 1010, 19846, 1010, 1998, 2496, 2273, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2054, 8563, 2033, 2055, 1045, 2572, 8025, 1011, 3756, 2003, 2008, 2871, 2086, 3283, 1010, 2023, 2001, 2641, 26932, 1012, 2428, 1010, 1996, 3348, 1998, 16371, 25469, 5019, 2024, 2261, 1998, 2521, 2090, 1010, 2130, 2059, 2009, 1005, 1055, 2025, 2915, 2066, 2070, 10036, 2135, 2081, 22555, 2080, 1012, 2096, 2026, 2406, 3549, 2568, 2424, 2009, 16880, 1010, 1999, 4507, 3348, 1998, 16371, 25469, 2024, 1037, 2350, 18785, 1999, 4467, 5988, 1012, 2130, 13749, 7849, 24544, 1010, 15835, 2037, 3437, 2000, 2204, 2214, 2879, 2198, 4811, 1010, 2018, 3348, 5019, 1999, 2010, 3152, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1045, 2079, 4012, 3549, 2094, 1996, 16587, 2005, 1996, 2755, 2008, 2151, 3348, 3491, 1999, 1996, 2143, 2003, 3491, 2005, 6018, 5682, 2738, 2084, 2074, 2000, 5213, 2111, 1998, 2191, 2769, 2000, 2022, 3491, 1999, 26932, 12370, 1999, 2637, 1012, 1045, 2572, 8025, 1011, 3756, 2003, 1037, 2204, 2143, 2005, 3087, 5782, 2000, 2817, 1996, 6240, 1998, 14629, 1006, 2053, 26136, 3832, 1007, 1997, 4467, 5988, 1012, 2021, 2428, 1010, 2023, 2143, 2987, 1005, 1056, 2031, 2172, 1997, 1037, 5436, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n{'input_ids': [101, 1000, 1045, 2572, 8025, 1024, 3756, 1000, 2003, 1037, 15544, 19307, 1998, 3653, 6528, 20771, 19986, 8632, 1012, 2009, 2987, 1005, 1056, 3043, 2054, 2028, 1005, 1055, 2576, 5328, 2024, 2138, 2023, 2143, 2064, 6684, 2022, 2579, 5667, 2006, 2151, 2504, 1012, 2004, 2005, 1996, 4366, 2008, 19124, 3287, 16371, 25469, 2003, 2019, 6882, 13316, 1011, 2459, 1010, 2008, 3475, 1005, 1056, 2995, 1012, 1045, 1005, 2310, 2464, 1054, 1011, 6758, 3152, 2007, 3287, 16371, 25469, 1012, 4379, 1010, 2027, 2069, 3749, 2070, 25085, 5328, 1010, 2021, 2073, 2024, 1996, 1054, 1011, 6758, 3152, 2007, 21226, 24728, 22144, 2015, 1998, 20916, 4691, 6845, 2401, 1029, 7880, 1010, 2138, 2027, 2123, 1005, 1056, 4839, 1012, 1996, 2168, 3632, 2005, 2216, 10231, 7685, 5830, 3065, 1024, 8040, 7317, 5063, 2015, 11820, 1999, 1996, 9478, 2021, 2025, 1037, 17962, 21239, 1999, 4356, 1012, 1998, 2216, 3653, 6528, 20771, 10271, 5691, 2066, 1996, 2829, 16291, 1010, 1999, 2029, 2057, 1005, 2128, 5845, 2000, 1996, 2609, 1997, 6320, 25624, 1005, 1055, 17061, 3779, 1010, 2021, 2025, 1037, 7637, 1997, 5061, 5710, 2006, 9318, 7367, 5737, 19393, 1012, 2077, 6933, 1006, 2030, 20242, 1007, 1000, 3313, 1011, 3115, 1000, 1999, 5609, 1997, 16371, 25469, 1010, 1996, 10597, 27885, 5809, 2063, 2323, 2202, 2046, 4070, 2028, 14477, 6767, 8524, 6321, 5793, 28141, 4489, 2090, 2273, 1998, 2308, 1024, 2045, 2024, 2053, 8991, 18400, 2015, 2006, 4653, 2043, 19910, 3544, 15287, 1010, 1998, 1996, 2168, 3685, 2022, 2056, 2005, 1037, 2158, 1012, 1999, 2755, 1010, 2017, 3227, 2180, 1005, 1056, 2156, 2931, 8991, 18400, 2015, 1999, 2019, 2137, 2143, 1999, 2505, 2460, 1997, 22555, 2030, 13216, 14253, 2050, 1012, 2023, 6884, 3313, 1011, 3115, 2003, 2625, 1037, 3313, 3115, 2084, 2019, 4914, 2135, 2139, 24128, 3754, 2000, 2272, 2000, 3408, 20547, 2007, 1996, 19008, 1997, 2308, 1005, 1055, 4230, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n{'input_ids': [101, 2065, 2069, 2000, 4468, 2437, 2023, 2828, 1997, 2143, 1999, 1996, 2925, 1012, 2023, 2143, 2003, 5875, 2004, 2019, 7551, 2021, 4136, 2053, 2522, 11461, 2466, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2028, 2453, 2514, 6819, 5339, 8918, 2005, 3564, 27046, 2009, 2138, 2009, 12817, 2006, 2061, 2116, 2590, 3314, 2021, 2009, 2515, 2061, 2302, 2151, 5860, 11795, 3085, 15793, 1012, 1996, 13972, 3310, 2185, 2007, 2053, 2047, 15251, 1006, 4983, 2028, 3310, 2039, 2007, 2028, 2096, 2028, 1005, 1055, 2568, 17677, 2015, 1010, 2004, 2009, 2097, 26597, 2079, 2076, 2023, 23100, 2143, 1007, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2028, 2453, 2488, 5247, 2028, 1005, 1055, 2051, 4582, 2041, 1037, 3332, 2012, 1037, 3392, 3652, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n{'input_ids': [101, 2023, 2143, 2001, 2763, 4427, 2011, 2643, 4232, 1005, 1055, 16137, 10841, 4115, 1010, 10768, 25300, 2078, 1998, 1045, 9075, 2017, 2000, 2156, 2008, 2143, 2612, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1996, 2143, 2038, 2048, 2844, 3787, 1998, 2216, 2024, 1010, 1006, 1015, 1007, 1996, 12689, 3772, 1006, 1016, 1007, 1996, 8052, 1010, 6151, 6810, 2099, 7178, 2135, 2204, 1010, 6302, 1012, 4237, 2013, 2008, 1010, 2054, 9326, 2033, 2087, 2003, 1996, 10866, 5460, 1997, 9033, 21202, 7971, 1012, 14229, 6396, 2386, 2038, 2000, 2022, 2087, 15703, 3883, 1999, 1996, 2088, 1012, 2016, 4490, 2061, 5236, 1998, 2007, 2035, 1996, 16371, 25469, 1999, 2023, 2143, 1010, 1012, 1012, 1012, 2009, 1005, 1055, 14477, 4779, 26884, 1012, 13599, 2000, 2643, 4232, 1005, 1055, 2143, 1010, 7789, 3012, 2038, 2042, 2999, 2007, 28072, 1012, 2302, 2183, 2205, 2521, 2006, 2023, 3395, 1010, 1045, 2052, 2360, 2008, 4076, 2013, 1996, 4489, 1999, 15084, 2090, 1996, 2413, 1998, 1996, 4467, 2554, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1037, 3185, 1997, 2049, 2051, 1010, 1998, 2173, 1012, 1016, 1013, 2184, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n{'input_ids': [101, 2821, 1010, 2567, 1012, 1012, 1012, 2044, 4994, 2055, 2023, 9951, 2143, 2005, 8529, 13876, 12129, 2086, 2035, 1045, 2064, 2228, 1997, 2003, 2008, 2214, 14911, 3389, 2299, 1012, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1000, 2003, 2008, 2035, 2045, 2003, 1029, 1029, 1000, 1012, 1012, 1012, 1045, 2001, 2074, 2019, 2220, 9458, 2043, 2023, 20482, 3869, 2718, 1996, 1057, 1012, 1055, 1012, 1045, 2001, 2205, 2402, 2000, 2131, 1999, 1996, 4258, 1006, 2348, 1045, 2106, 6133, 2000, 13583, 2046, 1000, 9119, 8912, 1000, 1007, 1012, 2059, 1037, 11326, 2012, 1037, 2334, 2143, 2688, 10272, 17799, 1011, 2633, 1045, 2071, 2156, 2023, 2143, 1010, 3272, 2085, 1045, 2001, 2004, 2214, 2004, 2026, 3008, 2020, 2043, 2027, 8040, 7317, 13699, 5669, 2000, 2156, 2009, 999, 999, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1996, 2069, 3114, 2023, 2143, 2001, 2025, 10033, 2000, 1996, 10812, 13457, 1997, 2051, 2001, 2138, 1997, 1996, 27885, 11020, 20693, 2553, 13977, 2011, 2049, 1057, 1012, 1055, 1012, 2713, 1012, 8817, 1997, 2111, 19311, 2098, 2000, 2023, 27136, 2121, 1010, 3241, 2027, 2020, 2183, 2000, 2156, 1037, 3348, 2143, 1012, 1012, 1012, 2612, 1010, 2027, 2288, 7167, 1997, 2485, 22264, 1997, 1043, 11802, 2135, 1010, 16360, 23004, 25430, 18352, 1010, 2006, 1011, 2395, 7636, 1999, 20857, 6023, 25943, 1010, 2004, 5498, 2063, 2576, 3653, 29048, 1012, 1012, 1012, 1998, 7408, 3468, 2040, 1011, 14977, 23599, 3348, 5019, 2007, 7842, 22772, 1010, 5122, 5889, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 3451, 12696, 1010, 4151, 24665, 12502, 1010, 3181, 20785, 1012, 1012, 3649, 2023, 2518, 2001, 1010, 14021, 5596, 2009, 1010, 6402, 2009, 1010, 2059, 4933, 1996, 11289, 1999, 1037, 2599, 3482, 999, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 7069, 9765, 27065, 2229, 2145, 26988, 2000, 2424, 3643, 1999, 2049, 11771, 18404, 6208, 2576, 11867, 7974, 8613, 1012, 1012, 2021, 2065, 2009, 4694, 1005, 1056, 2005, 1996, 15657, 9446, 1010, 2009, 2052, 2031, 2042, 6439, 1010, 2059, 6404, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2612, 1010, 1996, 1000, 1045, 2572, 8744, 1010, 8744, 1000, 1054, 10536, 16921, 7583, 2516, 2001, 5567, 10866, 2135, 2005, 2086, 2004, 1037, 14841, 26065, 3508, 2005, 22555, 2080, 3152, 1006, 1045, 2572, 8025, 1010, 20920, 1011, 2005, 5637, 3152, 1010, 1045, 2572, 8025, 1010, 2304, 1011, 2005, 1038, 2721, 2595, 24759, 28100, 3370, 3152, 1010, 4385, 1012, 1012, 1007, 1998, 2296, 2702, 2086, 2030, 2061, 1996, 2518, 9466, 2013, 1996, 2757, 1010, 2000, 2022, 7021, 2011, 1037, 2047, 4245, 1997, 26476, 2015, 2040, 2215, 2000, 2156, 2008, 1000, 20355, 3348, 2143, 1000, 2008, 1000, 4329, 3550, 1996, 2143, 3068, 1000, 1012, 1012, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 6300, 9953, 1010, 4468, 2066, 1996, 11629, 1012, 1012, 2030, 2065, 2017, 2442, 2156, 2009, 1011, 9278, 1996, 2678, 1998, 3435, 2830, 2000, 1996, 1000, 6530, 1000, 3033, 1010, 2074, 2000, 2131, 2009, 2058, 2007, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n\n\n\nprint(tokenized_imdb['train'][0]['input_ids'])\nprint(tokenized_imdb['train'][1]['input_ids'])\nprint(tokenized_imdb['train'][2]['input_ids'])\nprint(tokenized_imdb['train'][3]['input_ids'])\nprint(tokenized_imdb['train'][4]['input_ids'])\n\n[101, 1045, 12524, 1045, 2572, 8025, 1011, 3756, 2013, 2026, 2678, 3573, 2138, 1997, 2035, 1996, 6704, 2008, 5129, 2009, 2043, 2009, 2001, 2034, 2207, 1999, 3476, 1012, 1045, 2036, 2657, 2008, 2012, 2034, 2009, 2001, 8243, 2011, 1057, 1012, 1055, 1012, 8205, 2065, 2009, 2412, 2699, 2000, 4607, 2023, 2406, 1010, 3568, 2108, 1037, 5470, 1997, 3152, 2641, 1000, 6801, 1000, 1045, 2428, 2018, 2000, 2156, 2023, 2005, 2870, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1996, 5436, 2003, 8857, 2105, 1037, 2402, 4467, 3689, 3076, 2315, 14229, 2040, 4122, 2000, 4553, 2673, 2016, 2064, 2055, 2166, 1012, 1999, 3327, 2016, 4122, 2000, 3579, 2014, 3086, 2015, 2000, 2437, 2070, 4066, 1997, 4516, 2006, 2054, 1996, 2779, 25430, 14728, 2245, 2055, 3056, 2576, 3314, 2107, 2004, 1996, 5148, 2162, 1998, 2679, 3314, 1999, 1996, 2142, 2163, 1012, 1999, 2090, 4851, 8801, 1998, 6623, 7939, 4697, 3619, 1997, 8947, 2055, 2037, 10740, 2006, 4331, 1010, 2016, 2038, 3348, 2007, 2014, 3689, 3836, 1010, 19846, 1010, 1998, 2496, 2273, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2054, 8563, 2033, 2055, 1045, 2572, 8025, 1011, 3756, 2003, 2008, 2871, 2086, 3283, 1010, 2023, 2001, 2641, 26932, 1012, 2428, 1010, 1996, 3348, 1998, 16371, 25469, 5019, 2024, 2261, 1998, 2521, 2090, 1010, 2130, 2059, 2009, 1005, 1055, 2025, 2915, 2066, 2070, 10036, 2135, 2081, 22555, 2080, 1012, 2096, 2026, 2406, 3549, 2568, 2424, 2009, 16880, 1010, 1999, 4507, 3348, 1998, 16371, 25469, 2024, 1037, 2350, 18785, 1999, 4467, 5988, 1012, 2130, 13749, 7849, 24544, 1010, 15835, 2037, 3437, 2000, 2204, 2214, 2879, 2198, 4811, 1010, 2018, 3348, 5019, 1999, 2010, 3152, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1045, 2079, 4012, 3549, 2094, 1996, 16587, 2005, 1996, 2755, 2008, 2151, 3348, 3491, 1999, 1996, 2143, 2003, 3491, 2005, 6018, 5682, 2738, 2084, 2074, 2000, 5213, 2111, 1998, 2191, 2769, 2000, 2022, 3491, 1999, 26932, 12370, 1999, 2637, 1012, 1045, 2572, 8025, 1011, 3756, 2003, 1037, 2204, 2143, 2005, 3087, 5782, 2000, 2817, 1996, 6240, 1998, 14629, 1006, 2053, 26136, 3832, 1007, 1997, 4467, 5988, 1012, 2021, 2428, 1010, 2023, 2143, 2987, 1005, 1056, 2031, 2172, 1997, 1037, 5436, 1012, 102]\n[101, 1000, 1045, 2572, 8025, 1024, 3756, 1000, 2003, 1037, 15544, 19307, 1998, 3653, 6528, 20771, 19986, 8632, 1012, 2009, 2987, 1005, 1056, 3043, 2054, 2028, 1005, 1055, 2576, 5328, 2024, 2138, 2023, 2143, 2064, 6684, 2022, 2579, 5667, 2006, 2151, 2504, 1012, 2004, 2005, 1996, 4366, 2008, 19124, 3287, 16371, 25469, 2003, 2019, 6882, 13316, 1011, 2459, 1010, 2008, 3475, 1005, 1056, 2995, 1012, 1045, 1005, 2310, 2464, 1054, 1011, 6758, 3152, 2007, 3287, 16371, 25469, 1012, 4379, 1010, 2027, 2069, 3749, 2070, 25085, 5328, 1010, 2021, 2073, 2024, 1996, 1054, 1011, 6758, 3152, 2007, 21226, 24728, 22144, 2015, 1998, 20916, 4691, 6845, 2401, 1029, 7880, 1010, 2138, 2027, 2123, 1005, 1056, 4839, 1012, 1996, 2168, 3632, 2005, 2216, 10231, 7685, 5830, 3065, 1024, 8040, 7317, 5063, 2015, 11820, 1999, 1996, 9478, 2021, 2025, 1037, 17962, 21239, 1999, 4356, 1012, 1998, 2216, 3653, 6528, 20771, 10271, 5691, 2066, 1996, 2829, 16291, 1010, 1999, 2029, 2057, 1005, 2128, 5845, 2000, 1996, 2609, 1997, 6320, 25624, 1005, 1055, 17061, 3779, 1010, 2021, 2025, 1037, 7637, 1997, 5061, 5710, 2006, 9318, 7367, 5737, 19393, 1012, 2077, 6933, 1006, 2030, 20242, 1007, 1000, 3313, 1011, 3115, 1000, 1999, 5609, 1997, 16371, 25469, 1010, 1996, 10597, 27885, 5809, 2063, 2323, 2202, 2046, 4070, 2028, 14477, 6767, 8524, 6321, 5793, 28141, 4489, 2090, 2273, 1998, 2308, 1024, 2045, 2024, 2053, 8991, 18400, 2015, 2006, 4653, 2043, 19910, 3544, 15287, 1010, 1998, 1996, 2168, 3685, 2022, 2056, 2005, 1037, 2158, 1012, 1999, 2755, 1010, 2017, 3227, 2180, 1005, 1056, 2156, 2931, 8991, 18400, 2015, 1999, 2019, 2137, 2143, 1999, 2505, 2460, 1997, 22555, 2030, 13216, 14253, 2050, 1012, 2023, 6884, 3313, 1011, 3115, 2003, 2625, 1037, 3313, 3115, 2084, 2019, 4914, 2135, 2139, 24128, 3754, 2000, 2272, 2000, 3408, 20547, 2007, 1996, 19008, 1997, 2308, 1005, 1055, 4230, 1012, 102]\n[101, 2065, 2069, 2000, 4468, 2437, 2023, 2828, 1997, 2143, 1999, 1996, 2925, 1012, 2023, 2143, 2003, 5875, 2004, 2019, 7551, 2021, 4136, 2053, 2522, 11461, 2466, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2028, 2453, 2514, 6819, 5339, 8918, 2005, 3564, 27046, 2009, 2138, 2009, 12817, 2006, 2061, 2116, 2590, 3314, 2021, 2009, 2515, 2061, 2302, 2151, 5860, 11795, 3085, 15793, 1012, 1996, 13972, 3310, 2185, 2007, 2053, 2047, 15251, 1006, 4983, 2028, 3310, 2039, 2007, 2028, 2096, 2028, 1005, 1055, 2568, 17677, 2015, 1010, 2004, 2009, 2097, 26597, 2079, 2076, 2023, 23100, 2143, 1007, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2028, 2453, 2488, 5247, 2028, 1005, 1055, 2051, 4582, 2041, 1037, 3332, 2012, 1037, 3392, 3652, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 102]\n[101, 2023, 2143, 2001, 2763, 4427, 2011, 2643, 4232, 1005, 1055, 16137, 10841, 4115, 1010, 10768, 25300, 2078, 1998, 1045, 9075, 2017, 2000, 2156, 2008, 2143, 2612, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1996, 2143, 2038, 2048, 2844, 3787, 1998, 2216, 2024, 1010, 1006, 1015, 1007, 1996, 12689, 3772, 1006, 1016, 1007, 1996, 8052, 1010, 6151, 6810, 2099, 7178, 2135, 2204, 1010, 6302, 1012, 4237, 2013, 2008, 1010, 2054, 9326, 2033, 2087, 2003, 1996, 10866, 5460, 1997, 9033, 21202, 7971, 1012, 14229, 6396, 2386, 2038, 2000, 2022, 2087, 15703, 3883, 1999, 1996, 2088, 1012, 2016, 4490, 2061, 5236, 1998, 2007, 2035, 1996, 16371, 25469, 1999, 2023, 2143, 1010, 1012, 1012, 1012, 2009, 1005, 1055, 14477, 4779, 26884, 1012, 13599, 2000, 2643, 4232, 1005, 1055, 2143, 1010, 7789, 3012, 2038, 2042, 2999, 2007, 28072, 1012, 2302, 2183, 2205, 2521, 2006, 2023, 3395, 1010, 1045, 2052, 2360, 2008, 4076, 2013, 1996, 4489, 1999, 15084, 2090, 1996, 2413, 1998, 1996, 4467, 2554, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1037, 3185, 1997, 2049, 2051, 1010, 1998, 2173, 1012, 1016, 1013, 2184, 1012, 102]\n[101, 2821, 1010, 2567, 1012, 1012, 1012, 2044, 4994, 2055, 2023, 9951, 2143, 2005, 8529, 13876, 12129, 2086, 2035, 1045, 2064, 2228, 1997, 2003, 2008, 2214, 14911, 3389, 2299, 1012, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1000, 2003, 2008, 2035, 2045, 2003, 1029, 1029, 1000, 1012, 1012, 1012, 1045, 2001, 2074, 2019, 2220, 9458, 2043, 2023, 20482, 3869, 2718, 1996, 1057, 1012, 1055, 1012, 1045, 2001, 2205, 2402, 2000, 2131, 1999, 1996, 4258, 1006, 2348, 1045, 2106, 6133, 2000, 13583, 2046, 1000, 9119, 8912, 1000, 1007, 1012, 2059, 1037, 11326, 2012, 1037, 2334, 2143, 2688, 10272, 17799, 1011, 2633, 1045, 2071, 2156, 2023, 2143, 1010, 3272, 2085, 1045, 2001, 2004, 2214, 2004, 2026, 3008, 2020, 2043, 2027, 8040, 7317, 13699, 5669, 2000, 2156, 2009, 999, 999, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1996, 2069, 3114, 2023, 2143, 2001, 2025, 10033, 2000, 1996, 10812, 13457, 1997, 2051, 2001, 2138, 1997, 1996, 27885, 11020, 20693, 2553, 13977, 2011, 2049, 1057, 1012, 1055, 1012, 2713, 1012, 8817, 1997, 2111, 19311, 2098, 2000, 2023, 27136, 2121, 1010, 3241, 2027, 2020, 2183, 2000, 2156, 1037, 3348, 2143, 1012, 1012, 1012, 2612, 1010, 2027, 2288, 7167, 1997, 2485, 22264, 1997, 1043, 11802, 2135, 1010, 16360, 23004, 25430, 18352, 1010, 2006, 1011, 2395, 7636, 1999, 20857, 6023, 25943, 1010, 2004, 5498, 2063, 2576, 3653, 29048, 1012, 1012, 1012, 1998, 7408, 3468, 2040, 1011, 14977, 23599, 3348, 5019, 2007, 7842, 22772, 1010, 5122, 5889, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 3451, 12696, 1010, 4151, 24665, 12502, 1010, 3181, 20785, 1012, 1012, 3649, 2023, 2518, 2001, 1010, 14021, 5596, 2009, 1010, 6402, 2009, 1010, 2059, 4933, 1996, 11289, 1999, 1037, 2599, 3482, 999, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 7069, 9765, 27065, 2229, 2145, 26988, 2000, 2424, 3643, 1999, 2049, 11771, 18404, 6208, 2576, 11867, 7974, 8613, 1012, 1012, 2021, 2065, 2009, 4694, 1005, 1056, 2005, 1996, 15657, 9446, 1010, 2009, 2052, 2031, 2042, 6439, 1010, 2059, 6404, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2612, 1010, 1996, 1000, 1045, 2572, 8744, 1010, 8744, 1000, 1054, 10536, 16921, 7583, 2516, 2001, 5567, 10866, 2135, 2005, 2086, 2004, 1037, 14841, 26065, 3508, 2005, 22555, 2080, 3152, 1006, 1045, 2572, 8025, 1010, 20920, 1011, 2005, 5637, 3152, 1010, 1045, 2572, 8025, 1010, 2304, 1011, 2005, 1038, 2721, 2595, 24759, 28100, 3370, 3152, 1010, 4385, 1012, 1012, 1007, 1998, 2296, 2702, 2086, 2030, 2061, 1996, 2518, 9466, 2013, 1996, 2757, 1010, 2000, 2022, 7021, 2011, 1037, 2047, 4245, 1997, 26476, 2015, 2040, 2215, 2000, 2156, 2008, 1000, 20355, 3348, 2143, 1000, 2008, 1000, 4329, 3550, 1996, 2143, 3068, 1000, 1012, 1012, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 6300, 9953, 1010, 4468, 2066, 1996, 11629, 1012, 1012, 2030, 2065, 2017, 2442, 2156, 2009, 1011, 9278, 1996, 2678, 1998, 3435, 2830, 2000, 1996, 1000, 6530, 1000, 3033, 1010, 2074, 2000, 2131, 2009, 2058, 2007, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 102]\n\n\n\nimdb.map(preprocess_function, batched=True)는 구조상 map(imdb,preprocess_function,batched=True)와 같을 듯\nmap은 리스트 비슷한 것의 각 원소에 함수를 적용하는 꼴이었음.\nmap의 사용법을 통하여 유추하면, imdb.map은 imdb[0],imdb[1],... 와 같은 원소들에 함수 preprocess 를 처리하는 형태의 문법으로 유추할 수 있다. (유추 불가능하다고 절망할 필요 없음.)"
  },
  {
    "objectID": "공부/HF/2024-09-08-(강의) 감성분류.html#b.-step2-인공지능-생성",
    "href": "공부/HF/2024-09-08-(강의) 감성분류.html#b.-step2-인공지능-생성",
    "title": "(강의) 감성분류",
    "section": "B. Step2 – 인공지능 생성",
    "text": "B. Step2 – 인공지능 생성\n- 모델생성하기\n\nfrom transformers import AutoModelForSequenceClassification\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert/distilbert-base-uncased\"\n)\n\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n\n뭐한거지??\n\nAutoModelForSequenceClassification.from_pretrained 는 인공지능을 만드는 함수임\n인공지능은 보통 웹에 저장되어있음.\n“distilbert/distilbert-base-uncased”는 허깅페이스에서 어떠한 모델이 저장된 경로를 의미함.\n\n\nmodel\n\nDistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)\n\n\n\n파이토치를 많이 다뤄봤다면 이거보고 뭔지 알수도 있음.\n아니라면 일단 넘어가자.\n\n- 모델을 사용하는 방법 (고급편) // 유추불가능한 내용\n\ntext0 = \"This movie was a huge disappointment.\"\ntext1 = \"This was a masterpiece.\"\n\n\nmodel_input = tokenizer(text1, return_tensors='pt', truncation=True)\nmodel_input\n\n{'input_ids': tensor([[  101,  2023,  2001,  1037, 17743,  1012,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}\n\n\n\nmodel.eval() # 문제풀이모드로 전환\nmodel(**model_input).logits\n\ntensor([[-0.1256,  0.0509]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\ntorch.softmax(model(**model_input).logits,dim=1) # 0일확률, 1일확률\n\ntensor([[0.4560, 0.5440]], grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n- 왜 잘 맞춤?\n\n이미 잘맞는애를 데려옴\n\n- 초기화하고 싶다면..?\n\nmodel.classifier = torch.nn.Linear(768,2)\n\n\n끝의 가중치를 날려서 멍청이로 만듦\n\n\nmodel_input = tokenizer(text0, return_tensors='pt', truncation=True)\nmodel_input\n\n{'input_ids': tensor([[  101,  2023,  3185,  2001,  1037,  4121, 10520,  1012,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n\n\n\nmodel.eval()\nmodel(**model_input).logits\n\ntensor([[-0.0302,  0.0913]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\ntorch.softmax(model(**model_input).logits,dim=1) # 0일확률, 1일확률\n\ntensor([[0.4697, 0.5303]], grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n\nmodel.train() # 학습모드로전환 \n\nDistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)"
  },
  {
    "objectID": "공부/HF/2024-09-08-(강의) 감성분류.html#c.-step3-학습하기",
    "href": "공부/HF/2024-09-08-(강의) 감성분류.html#c.-step3-학습하기",
    "title": "(강의) 감성분류",
    "section": "C. Step3 – 학습하기",
    "text": "C. Step3 – 학습하기\n- 트레이너 생성을 위한 재료\n\nfrom transformers import DataCollatorWithPadding, TrainingArguments, Trainer\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\n\nimport evaluate\nimport numpy as np\naccuracy = evaluate.load(\"accuracy\")\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return accuracy.compute(predictions=predictions, references=labels)\n\n- 트레이너 생성 + 학습\n\ntraining_args = TrainingArguments(\n    output_dir=\"my_awesome_model\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    push_to_hub=False,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_imdb[\"train\"],\n    eval_dataset=tokenized_imdb[\"test\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()\n\n\n    \n      \n      \n      [4689/4689 20:26, Epoch 3/3]\n    \n    \n\n\n\nEpoch\nTraining Loss\nValidation Loss\nAccuracy\n\n\n\n\n1\n0.225100\n0.218003\n0.916240\n\n\n2\n0.145600\n0.235620\n0.930880\n\n\n3\n0.087400\n0.274686\n0.932680\n\n\n\n\n\n\nTrainOutput(global_step=4689, training_loss=0.16536911699812049, metrics={'train_runtime': 1226.4332, 'train_samples_per_second': 61.153, 'train_steps_per_second': 3.823, 'total_flos': 9834539051060448.0, 'train_loss': 0.16536911699812049, 'epoch': 3.0})"
  },
  {
    "objectID": "공부/HF/2024-09-08-(강의) 감성분류.html#d.-step4-예측하기",
    "href": "공부/HF/2024-09-08-(강의) 감성분류.html#d.-step4-예측하기",
    "title": "(강의) 감성분류",
    "section": "D. Step4 – 예측하기",
    "text": "D. Step4 – 예측하기\n- 강인공지능 생성\n\nfrom transformers import pipeline\nclassifier = pipeline(\"sentiment-analysis\", model=\"my_awesome_model/checkpoint-1563\")\n\nHardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n\n\n- 강인공지능을 통한 예측\n\ntext = \"This was a masterpiece. Not completely faithful to the books, but enthralling from beginning to end. Might be my favorite of the three.\"\nclassifier(text)\n\n[{'label': 'LABEL_1', 'score': 0.991926908493042}]"
  },
  {
    "objectID": "공부/HF/2024-10-30-(강의) 이상탐지살펴봄.html",
    "href": "공부/HF/2024-10-30-(강의) 이상탐지살펴봄.html",
    "title": "(강의) 이상탐지살펴봄",
    "section": "",
    "text": "# from transformers import AutoImageProcessor, AutoModelForImageClassification\n# from datasets import load_dataset\n# import torch\n\n# # Load the dataset\n# dataset = load_dataset('path/to/medical_mnist')\n\n# # Initialize the model and processor\n# processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n# model = AutoModelForImageClassification.from_pretrained(\"google/vit-base-patch16-224\")\n\n# # Preprocess and classify images\n# def preprocess(batch):\n#     inputs = processor(images=batch[\"image\"], return_tensors=\"pt\")\n#     with torch.no_grad():\n#         outputs = model(**inputs)\n#     return outputs.logits.argmax(dim=-1)\n\n# # Apply to dataset\n# dataset = dataset.map(preprocess, batched=True)\n\n\n# from transformers import AutoImageProcessor, AutoModelForImageClassification\n# from datasets import load_dataset\n\n# # Load the chest x-ray dataset\n# dataset = load_dataset('huggingface/chest_xray')\n\n# # Initialize the processor and model\n# processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n# model = AutoModelForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n\n# # Define the processing function\n# def preprocess(batch):\n#     inputs = processor(images=batch[\"image\"], return_tensors=\"pt\")\n#     outputs = model(**inputs)\n#     batch[\"pred\"] = outputs.logits.argmax(dim=-1).cpu().numpy()\n#     return batch\n\n# # Process dataset\n# dataset = dataset.map(preprocess, batched=True)\n\n\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom datasets import load_dataset\n\n# Load SMS spam dataset\ndataset = load_dataset('sms_spam')\n\n# # Initialize tokenizer and model\n# tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n# model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n\n# # Tokenize and classify messages\n# def preprocess(batch):\n#     inputs = tokenizer(batch[\"message\"], truncation=True, padding=True, return_tensors=\"pt\")\n#     with torch.no_grad():\n#         outputs = model(**inputs)\n#     batch[\"pred\"] = outputs.logits.argmax(dim=-1).cpu().numpy()\n#     return batch\n\n# dataset = dataset.map(preprocess, batched=True)\n\n/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n\n\nimport numpy as np\nnp.array(dataset['train']['label']).mean()\n\n0.1340150699677072\n\n\n\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom datasets import load_dataset\n\n# Load the disaster tweets dataset\ndataset = load_dataset('tweet_eval', 'emotion')\n\n# Initialize tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base\")\n\n# Tokenize and classify tweets\ndef preprocess(batch):\n    inputs = tokenizer(batch[\"text\"], truncation=True, padding=True, return_tensors=\"pt\")\n    with torch.no_grad():\n        outputs = model(**inputs)\n    batch[\"pred\"] = outputs.logits.argmax(dim=-1).cpu().numpy()\n    return batch\n\ndataset = dataset.map(preprocess, batched=True)\n\nDownloading data: 100%|██████████| 233k/233k [00:00&lt;00:00, 321kB/s]\nDownloading data: 100%|██████████| 105k/105k [00:00&lt;00:00, 166kB/s]\nDownloading data: 100%|██████████| 28.6k/28.6k [00:00&lt;00:00, 46.4kB/s]\nGenerating train split: 100%|██████████| 3257/3257 [00:00&lt;00:00, 925908.10 examples/s]\nGenerating test split: 100%|██████████| 1421/1421 [00:00&lt;00:00, 1150155.54 examples/s]\nGenerating validation split: 100%|██████████| 374/374 [00:00&lt;00:00, 522367.53 examples/s]\n\n\nKeyboardInterrupt: \n\n\n\nfrom transformers import AutoProcessor, AutoModelForVideoClassification\n\n\nfrom datasets import load_dataset\n\n\n# Load the anomaly detection dataset\n\n\ndataset = load_dataset(‘path/to/shanghaitech_anomaly’)\n\n\n# Initialize processor and model\n\n\nprocessor = AutoProcessor.from_pretrained(“MCG-NJU/videomae-base”)\n\n\nmodel = AutoModelForVideoClassification.from_pretrained(“MCG-NJU/videomae-base”)\n\n\n# Preprocess and classify videos\n\n\ndef preprocess(batch):\n\n\ninputs = processor(videos=batch[“video”], return_tensors=“pt”)\n\n\nwith torch.no_grad():\n\n\noutputs = model(**inputs)\n\n\nbatch[“pred”] = outputs.logits.argmax(dim=-1).cpu().numpy()\n\n\nreturn batch\n\n\ndataset = dataset.map(preprocess, batched=True)"
  },
  {
    "objectID": "공부/HF/2024-10-01-(강의) 음성분류.html",
    "href": "공부/HF/2024-10-01-(강의) 음성분류.html",
    "title": "(강의) 음성분류",
    "section": "",
    "text": "1. 강의영상\n\n\n2. ref\nref: https://huggingface.co/docs/transformers/tasks/image_classification\n\n\n3. imports\npip install soundfile librosa\n\nimport datasets\nimport transformers\nimport torchvision.transforms\nimport evaluate\nimport numpy as np\n\n/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n\n\n\n4. 코드정리\n\ncommon_voice = datasets.load_dataset(\"mozilla-foundation/common_voice_11_0\", \"en\")\n\n/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/load.py:1486: FutureWarning: The repository for mozilla-foundation/common_voice_11_0 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mozilla-foundation/common_voice_11_0\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n  warnings.warn(\nDownloading builder script: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8.13k/8.13k [00:00&lt;00:00, 33.6MB/s]\nDownloading readme: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14.4k/14.4k [00:00&lt;00:00, 33.2MB/s]\nDownloading extra modules: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3.44k/3.44k [00:00&lt;00:00, 25.9MB/s]\nDownloading extra modules: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 60.9k/60.9k [00:00&lt;00:00, 11.7MB/s]\nDownloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12.2k/12.2k [00:00&lt;00:00, 43.1MB/s]\nDownloading data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [09:00&lt;00:00, 22.52s/files]\nDownloading data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 732M/732M [00:30&lt;00:00, 23.8MB/s]\nDownloading data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 722M/722M [00:26&lt;00:00, 27.8MB/s]\nDownloading data: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.32G/1.32G [00:12&lt;00:00, 109MB/s]\nDownloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.30G/1.30G [00:13&lt;00:00, 94.1MB/s]\nDownloading data: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.37G/1.37G [00:12&lt;00:00, 109MB/s]\nDownloading data: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.28G/1.28G [00:12&lt;00:00, 105MB/s]\nDownloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.42G/1.42G [00:15&lt;00:00, 90.5MB/s]\nDownloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.32G/1.32G [00:13&lt;00:00, 96.9MB/s]\nDownloading data: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.39G/1.39G [00:12&lt;00:00, 108MB/s]\nDownloading data: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 352M/352M [00:03&lt;00:00, 112MB/s]\nDownloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.87G/1.87G [00:35&lt;00:00, 53.2MB/s]\nDownloading data: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.62G/1.62G [00:14&lt;00:00, 110MB/s]\nDownloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2.10G/2.10G [00:22&lt;00:00, 92.8MB/s]\nDownloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2.11G/2.11G [00:24&lt;00:00, 87.7MB/s]\nDownloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.95G/1.95G [01:06&lt;00:00, 29.1MB/s]\nDownloading data: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.65G/1.65G [00:15&lt;00:00, 108MB/s]\nDownloading data: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 460M/460M [00:04&lt;00:00, 112MB/s]\nDownloading data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 243M/243M [00:02&lt;00:00, 87.2MB/s]\nDownloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3.79M/3.79M [00:00&lt;00:00, 54.8MB/s]\nDownloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3.73M/3.73M [00:00&lt;00:00, 52.1MB/s]\nDownloading data: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 69.5M/69.5M [00:00&lt;00:00, 100MB/s]\nDownloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62.3M/62.3M [00:00&lt;00:00, 80.8MB/s]\nGenerating train split: 0 examples [00:00, ? examples/s]\nReading metadata...: 0it [00:00, ?it/s]\nReading metadata...: 37512it [00:00, 375102.47it/s]\nReading metadata...: 75023it [00:00, 369365.98it/s]\nReading metadata...: 111966it [00:00, 363426.94it/s]\nReading metadata...: 148319it [00:00, 360443.91it/s]\nReading metadata...: 184369it [00:00, 353460.10it/s]\nReading metadata...: 219732it [00:00, 352603.80it/s]\nReading metadata...: 255003it [00:00, 349051.08it/s]\nReading metadata...: 289917it [00:00, 344437.13it/s]\nReading metadata...: 324371it [00:00, 340359.70it/s]\nReading metadata...: 358416it [00:01, 332472.48it/s]\nReading metadata...: 392233it [00:01, 334156.97it/s]\nReading metadata...: 425674it [00:01, 331400.04it/s]\nReading metadata...: 458831it [00:01, 328143.08it/s]\nReading metadata...: 491658it [00:01, 326543.71it/s]\nReading metadata...: 524514it [00:01, 327134.40it/s]\nReading metadata...: 557234it [00:01, 325196.57it/s]\nReading metadata...: 589758it [00:01, 324888.13it/s]\nReading metadata...: 622250it [00:01, 324870.98it/s]\nReading metadata...: 654972it [00:01, 325561.51it/s]\nReading metadata...: 688334it [00:02, 327966.84it/s]\nReading metadata...: 721134it [00:02, 322785.27it/s]\nReading metadata...: 755164it [00:02, 327965.10it/s]\nReading metadata...: 789082it [00:02, 331295.97it/s]\nReading metadata...: 822911it [00:02, 333374.62it/s]\nReading metadata...: 856841it [00:02, 335139.61it/s]\nReading metadata...: 890394it [00:02, 335252.14it/s]\nReading metadata...: 948736it [00:02, 335639.02it/s]\nGenerating train split: 948736 examples [01:55, 8207.48 examples/s]\nGenerating validation split: 0 examples [00:00, ? examples/s]\nReading metadata...: 16354it [00:00, 382591.31it/s]\nGenerating validation split: 16354 examples [00:01, 8434.82 examples/s]\nGenerating test split: 0 examples [00:00, ? examples/s]\nReading metadata...: 16354it [00:00, 398092.04it/s]\nGenerating test split: 16354 examples [00:01, 8522.96 examples/s]\nGenerating other split: 0 examples [00:00, ? examples/s]\nReading metadata...: 0it [00:00, ?it/s]\nReading metadata...: 39589it [00:00, 395874.33it/s]\nReading metadata...: 79177it [00:00, 385240.91it/s]\nReading metadata...: 117721it [00:00, 375570.98it/s]\nReading metadata...: 155304it [00:00, 373021.77it/s]\nReading metadata...: 192619it [00:00, 363648.27it/s]\nReading metadata...: 229015it [00:00, 360530.70it/s]\nReading metadata...: 290846it [00:00, 364258.80it/s]\nGenerating other split: 290846 examples [00:30, 9546.82 examples/s] \nGenerating invalidated split: 0 examples [00:00, ? examples/s]\nReading metadata...: 0it [00:00, ?it/s]\nReading metadata...: 39783it [00:00, 397820.89it/s]\nReading metadata...: 79566it [00:00, 387259.68it/s]\nReading metadata...: 118312it [00:00, 370587.63it/s]\nReading metadata...: 155442it [00:00, 365826.32it/s]\nReading metadata...: 192061it [00:00, 361393.10it/s]\nReading metadata...: 252599it [00:00, 363492.61it/s]\nGenerating invalidated split: 252599 examples [00:26, 9676.01 examples/s] \n\n\n\n## Step1 \nminds = datasets.load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")\nminds = minds.train_test_split(test_size=0.2)\nminds = minds.remove_columns([\"path\", \"transcription\", \"english_transcription\", \"lang_id\"])\nminds = minds.cast_column(\"audio\", datasets.Audio(sampling_rate=16_000))\nfeature_extractor = transformers.AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base\")\ndef preprocess_function(examples):\n    audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n    inputs = feature_extractor(\n        audio_arrays, sampling_rate=feature_extractor.sampling_rate, max_length=16000, truncation=True\n    )\n    return inputs\nencoded_minds = minds.map(preprocess_function, remove_columns=\"audio\", batched=True)\nencoded_minds = encoded_minds.rename_column(\"intent_class\", \"label\")\n## Step2 \nlabels = minds[\"train\"].features[\"intent_class\"].names\nlabel2id, id2label = dict(), dict()\nfor i, label in enumerate(labels):\n    label2id[label] = str(i)\n    id2label[str(i)] = label\nnum_labels = len(id2label)\nmodel = transformers.AutoModelForAudioClassification.from_pretrained(\n    \"facebook/wav2vec2-base\", num_labels=num_labels, label2id=label2id, id2label=id2label\n)\n## Step3 \naccuracy = evaluate.load(\"accuracy\")\ndef compute_metrics(eval_pred):\n    predictions = np.argmax(eval_pred.predictions, axis=1)\n    return accuracy.compute(predictions=predictions, references=eval_pred.label_ids)\ntraining_args = transformers.TrainingArguments(\n    output_dir=\"my_awesome_mind_model\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    gradient_accumulation_steps=2,\n    per_device_eval_batch_size=16,\n    num_train_epochs=10,\n    #warmup_ratio=0.1,\n    warmup_steps=500,\n    logging_steps=10,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"accuracy\",\n    push_to_hub=False,\n)\ntrainer = transformers.Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=encoded_minds[\"train\"],\n    eval_dataset=encoded_minds[\"test\"],\n    tokenizer=feature_extractor,\n    compute_metrics=compute_metrics,\n)\ntrainer.train()\n## Step4 \n\n/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/load.py:1486: FutureWarning: The repository for PolyAI/minds14 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/PolyAI/minds14\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n  warnings.warn(\n/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/transformers/configuration_utils.py:302: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n  warnings.warn(\nMap: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 450/450 [00:00&lt;00:00, 924.80 examples/s]\nMap: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 113/113 [00:00&lt;00:00, 976.54 examples/s]\nSome weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n\n\n\n    \n      \n      \n      [140/140 00:54, Epoch 9/10]\n    \n    \n\n\n\nEpoch\nTraining Loss\nValidation Loss\nAccuracy\n\n\n\n\n0\n2.639700\n2.639443\n0.088496\n\n\n2\n2.637600\n2.640823\n0.088496\n\n\n4\n2.635000\n2.643230\n0.070796\n\n\n6\n2.632800\n2.640821\n0.079646\n\n\n8\n2.630400\n2.644272\n0.079646\n\n\n9\n2.626900\n2.643184\n0.079646\n\n\n\n\n\n\nTrainOutput(global_step=140, training_loss=2.6340601103646413, metrics={'train_runtime': 54.9468, 'train_samples_per_second': 81.897, 'train_steps_per_second': 2.548, 'total_flos': 3.9529655577216e+16, 'train_loss': 2.6340601103646413, 'epoch': 9.655172413793103})\n\n\n\n# Step4 \ndataset = datasets.load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")\ndataset = dataset.cast_column(\"audio\", datasets.Audio(sampling_rate=16000))\nsampling_rate = dataset.features[\"audio\"].sampling_rate\naudio_file = dataset[0][\"audio\"][\"path\"]\nclassifier = transformers.pipeline(\"audio-classification\", model=\"my_awesome_mind_model/checkpoint-140\")\nclassifier(audio_file)\n\n/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/datasets/load.py:1486: FutureWarning: The repository for PolyAI/minds14 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/PolyAI/minds14\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n  warnings.warn(\nHardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n\n\n[{'score': 0.07800574600696564, 'label': 'cash_deposit'},\n {'score': 0.07708185911178589, 'label': 'freeze'},\n {'score': 0.0737047791481018, 'label': 'business_loan'},\n {'score': 0.07282004505395889, 'label': 'direct_debit'},\n {'score': 0.0727161318063736, 'label': 'atm_limit'}]\n\n\n\n\n5. 살펴보기"
  },
  {
    "objectID": "공부/HF/2024-11-02-(강의) numpy와 torch의 차이.html",
    "href": "공부/HF/2024-11-02-(강의) numpy와 torch의 차이.html",
    "title": "(강의) numpy와 torch의 차이",
    "section": "",
    "text": "#{{&lt;video https://youtu.be/playlist?list=PLQqh36zP38-zBs464epBRfxPpNBAKqBMS&si=It99ZTYMQHJkCk6z &gt;}}"
  },
  {
    "objectID": "공부/HF/2024-11-02-(강의) numpy와 torch의 차이.html#a.-공통점",
    "href": "공부/HF/2024-11-02-(강의) numpy와 torch의 차이.html#a.-공통점",
    "title": "(강의) numpy와 torch의 차이",
    "section": "A. 공통점",
    "text": "A. 공통점\n- 기본마인드: numpy에서 가능한건 torch에서도 가능하다고 생각하면 된다.\n- 벡터선언 후 브로드캐스팅\n\ntsr = torch.tensor([1,2,3])\ntsr + 1\n\ntensor([2, 3, 4])\n\n\n\narr = np.array([1,2,3])\narr + 1 \n\narray([2, 3, 4])\n\n\n- 형태변환\n\ntsr = torch.tensor([1,2,3])\nprint(\n    f\"텐서값 = {tsr}\\n\"\n    f\"shape = {tsr.shape}\"\n)\n\n텐서값 = tensor([1, 2, 3])\nshape = torch.Size([3])\n\n\n\ntsr2 = tsr.reshape(3,1)\nprint(\n    f\"텐서값 = {tsr2}\\n\"\n    f\"shape = {tsr2.shape}\"\n)\n\n텐서값 = tensor([[1],\n        [2],\n        [3]])\nshape = torch.Size([3, 1])\n\n\n\ntsr3 = tsr.reshape(1,3)\nprint(\n    f\"텐서값 = {tsr3}\\n\"\n    f\"shape = {tsr3.shape}\"\n)\n\n텐서값 = tensor([[1, 2, 3]])\nshape = torch.Size([1, 3])\n\n\n- 기타함수들도 비슷하게 운용됨\n\ntsr1 = torch.tensor([1,2,3])\ntsr2 = torch.tensor([4,5,6])\n\n\ntorch.stack([tsr1,tsr2],axis=1)\n\ntensor([[1, 4],\n        [2, 5],\n        [3, 6]])\n\n\n\ntorch.stack([tsr1,tsr2],axis=0)\n\ntensor([[1, 2, 3],\n        [4, 5, 6]])"
  },
  {
    "objectID": "공부/HF/2024-11-02-(강의) numpy와 torch의 차이.html#b.-차이점1-기본자료형",
    "href": "공부/HF/2024-11-02-(강의) numpy와 torch의 차이.html#b.-차이점1-기본자료형",
    "title": "(강의) numpy와 torch의 차이",
    "section": "B. 차이점1 – 기본자료형",
    "text": "B. 차이점1 – 기본자료형\n- 1/3와 같은 숫자를 저장할때 넘파이의 경우 기본 data type은 float64임.\n\na = np.array(1/3)\na, a.dtype\n\n(array(0.33333333), dtype('float64'))\n\n\n\nprint(\n    f\"값: {a}\\n\"\n    f\"dtype: {a.dtype}\"\n)\n\n값: 0.3333333333333333\ndtype: float64\n\n\n- 그런데 텐서는 기본 data type이 float32임. (그래서 정확하게 저장되지 않음)\n\na = torch.tensor(1/3)\na, a.dtype\n\n(tensor(0.3333), torch.float32)\n\n\n\nprint(\n    f\"값: {a}\\n\"\n    f\"dtype: {a.dtype}\"\n)\n\n값: 0.3333333432674408\ndtype: torch.float32\n\n\n- 억지로 저장할 수는 있음 (그런데 이럴 경우 dtype 꼬리표가 붙음)\n\na = torch.tensor(1/3,dtype=torch.float64) # 텐서인데 억지로 float64형태로 저장\na\n\ntensor(0.3333, dtype=torch.float64)\n\n\n\na = np.array(1/3,dtype=np.float32) # numpy인데 억지로 float32형태로 저장\na\n\narray(0.33333334, dtype=float32)\n\n\n- 자료형 변환시 이러한 기분나쁜 꼬리표가 붙을 수 있음\n# 예시1\n\na = np.array(1/3)\na\n\narray(0.33333333)\n\n\n\ntorch.tensor(a)\n\ntensor(0.3333, dtype=torch.float64)\n\n\n#\n# 예시2\n\na = torch.tensor(1/3)\na\n\ntensor(0.3333)\n\n\n\nnp.array(a)\n\narray(0.33333334, dtype=float32)\n\n\n#\n- torch의 경우 float64로 저장되면 모델이 안돌아갈 수 있으니 (메모리를 많이 차지해서) 반드시 dtype을 float32로 바꾸는 습관을 가지면 좋음\n\na = np.array(1/3)\ntsr = torch.tensor(a)\ntsr\n\ntensor(0.3333, dtype=torch.float64)\n\n\n\ntsr.float() # 바꾸는 방법1\n\ntensor(0.3333)\n\n\n\ntsr.to(torch.float32) # 바꾸는 방법2\n\ntensor(0.3333)\n\n\n- numpy는 할줄알죠?\n\narr = np.array(1/3,dtype=np.float32)\narr\n\narray(0.33333334, dtype=float32)\n\n\n\narr.astype(np.float64)\n\narray(0.33333334)\n\n\n- torch에서 data type을 바꿔주는 메소드는 상당히 유용합니다. (중요하거든요)\n\na = torch.tensor([1,0,1])\na, a.float()\n\n(tensor([1, 0, 1]), tensor([1., 0., 1.]))\n\n\n\na = torch.tensor([1,0,1])\na, a.bool()\n\n(tensor([1, 0, 1]), tensor([ True, False,  True]))\n\n\n\na = torch.tensor([1.0, 0, 1])\na, a.long()\n\n(tensor([1., 0., 1.]), tensor([1, 0, 1]))\n\n\n- torch에서 data type 이 중요한이유?\n\n의미상 맞는 코드인데, dtype이 안맞으면 실행이 안될 수 있다."
  },
  {
    "objectID": "공부/HF/2024-11-02-(강의) numpy와 torch의 차이.html#c.-차이점2-메소드차이",
    "href": "공부/HF/2024-11-02-(강의) numpy와 torch의 차이.html#c.-차이점2-메소드차이",
    "title": "(강의) numpy와 torch의 차이",
    "section": "C. 차이점2 – 메소드차이",
    "text": "C. 차이점2 – 메소드차이\n- torch 와 numpy의 메소드(=자료에 내장된 특수함수)들이 완전히 같지는 않음.\n\ntsr = torch.tensor([1,2,3])\ntsr\n\ntensor([1, 2, 3])\n\n\n\ntsr.numpy() # np.array로 바꿔주는 메소드\n\narray([1, 2, 3])\n\n\n\ntsr.float() # 자료형을 바꿔주는 메소드\n\ntensor([1., 2., 3.])\n\n\n\narr = np.array([1,2,3])\narr\n\narray([1, 2, 3])\n\n\n\narr.numpy()\n\nAttributeError: 'numpy.ndarray' object has no attribute 'numpy'\n\n\n\narr.float()\n\nAttributeError: 'numpy.ndarray' object has no attribute 'float'"
  },
  {
    "objectID": "공부/HF/2024-11-02-(강의) numpy와 torch의 차이.html#d.-차이점3-미분연산지원-star",
    "href": "공부/HF/2024-11-02-(강의) numpy와 torch의 차이.html#d.-차이점3-미분연산지원-star",
    "title": "(강의) numpy와 torch의 차이",
    "section": "D. 차이점3 – 미분연산지원 (\\(\\star\\))",
    "text": "D. 차이점3 – 미분연산지원 (\\(\\star\\))\n# 예제1 – 파이썬을 기본문법을 이용한 미분\n\ndef f(x):\n    return x**2 \n\n\nh=0.001\na=2\n(f(a+h)-f(a))/h\n\n4.000999999999699\n\n\n#\n# 예제2 – torch를 이용한 미분\n\ndef f(x):\n    return x**2 \na = torch.tensor(2.0, requires_grad=True)\nb = f(a)\nb.backward()\na.grad\n\ntensor(4.)\n\n\n#\n# 예제3\n\na = torch.tensor(3.0, requires_grad=True)\na # 토치텐서.. 그런데 이제 미분꼬리표를 곁들인.. \n\ntensor(3., requires_grad=True)\n\n\n\nprint(a.grad) # a에서의 미분값\n\nNone\n\n\n\nb = f(a) # 여기에서도 뭔가 붙어있음.. \nb\n\ntensor(9., grad_fn=&lt;PowBackward0&gt;)\n\n\n\nc = 2*b\n\n\nc.backward() # c=2b=2f(a) 를 미분하세요.. 뭐로?? 미분꼬리표의 근원인 a로! \n\n\na.grad # 2'f(a) \n\ntensor(12.)\n\n\n#\n# 예제4\n\na = torch.tensor(3.0, requires_grad=True)\na # 토치텐서.. 그런데 이제 미분꼬리표를 곁들인.. \n\ntensor(3., requires_grad=True)\n\n\n\nprint(a.grad) # a에서의 미분값\n\nNone\n\n\n\nb = f(a) # 여기에서도 뭔가 붙어있음.. \nb\n\ntensor(9., grad_fn=&lt;PowBackward0&gt;)\n\n\n\nc = 2*b\n\n\nb.backward() # b=f(a) 를 미분하세요.. 뭐로?? 미분꼬리표의 근원인 a로! \n\n\na.grad # f'(a) \n\ntensor(6.)\n\n\n#\n# 예제5\n\na = torch.tensor(3.0, requires_grad=True)\na # 토치텐서.. 미분꼬리표가 있음\n\ntensor(3., requires_grad=True)\n\n\n\nb = f(a) \nb # 추적됨..\n\ntensor(9., grad_fn=&lt;PowBackward0&gt;)\n\n\n\nc = 2*b \nc # 여기까지 추적됨..\n\ntensor(18., grad_fn=&lt;MulBackward0&gt;)\n\n\n\nc = c.detach()\nc # 꼬리표제거! \n\ntensor(18.)\n\n\n\nc.backward() # c=2b=2f(a) 를 미분하세요.. 뭐로?? .. 모르는데??\n\nRuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n\n\n\nb.backward() # 이건가능함..\n\n\na.grad # f'(a) 를 a로 미분한 값이 여기에 있음\n\ntensor(6.)\n\n\n#"
  },
  {
    "objectID": "공부/HF/2024-11-02-(강의) numpy와 torch의 차이.html#e.-차이점4-cuda-차이-star",
    "href": "공부/HF/2024-11-02-(강의) numpy와 torch의 차이.html#e.-차이점4-cuda-차이-star",
    "title": "(강의) numpy와 torch의 차이",
    "section": "E. 차이점4 – cuda 차이 (\\(\\star\\))",
    "text": "E. 차이점4 – cuda 차이 (\\(\\star\\))\n- torch는 cuda을 지원해서 좋다.. (그런데 쓰는 입장에선 불편하다)\n\na = torch.tensor([1.0, 2.0, 3.0])\nb = torch.tensor([2.0, 3.0, 4.0])\na,b\n\n(tensor([1., 2., 3.]), tensor([2., 3., 4.]))\n\n\n\na_cuda = a.to(\"cuda\")\nb_cuda = b.to(\"cuda\") # 각각의 값을 쿠다로 전달\na_cuda,b_cuda\n\n(tensor([1., 2., 3.], device='cuda:0'), tensor([2., 3., 4.], device='cuda:0'))\n\n\n\na,b,a_cuda,b_cuda\n\n(tensor([1., 2., 3.]),\n tensor([2., 3., 4.]),\n tensor([1., 2., 3.], device='cuda:0'),\n tensor([2., 3., 4.], device='cuda:0'))\n\n\n\na_cuda.to(\"cpu\"), b_cuda.to(\"cpu\") # 쿠다의 값은 to(\"cpu\") 로 다시 쿠다에서 내릴 수 있음 \n\n(tensor([1., 2., 3.]), tensor([2., 3., 4.]))\n\n\n- 구분을 위해서 아래와 같이 정의하자.\n\na_cpu = torch.tensor([1.0, 2.0, 3.0])\nb_cpu = torch.tensor([2.0, 3.0, 4.0])\na_cuda = torch.tensor([1.0, 2.0, 3.0]).to(\"cuda\")\nb_cuda = torch.tensor([2.0, 3.0, 4.0]).to(\"cuda\")\n\n\na_cpu,b_cpu,a_cuda,b_cuda\n\n(tensor([1., 2., 3.]),\n tensor([2., 3., 4.]),\n tensor([1., 2., 3.], device='cuda:0'),\n tensor([2., 3., 4.], device='cuda:0'))\n\n\n- cuda는 cuda끼리, cpu는 cpu끼리 연산가능\n\na_cpu + b_cpu\n\ntensor([3., 5., 7.])\n\n\n\ncpu끼리 연산하면 결과도 cpu에…\n\n\na_cpu + b_cuda\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n\n\n\na_cuda + b_cpu\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n\n\n\na_cuda + b_cuda\n\ntensor([3., 5., 7.], device='cuda:0')\n\n\n\ncuda끼리 연산하면 결과도 cuda에.."
  },
  {
    "objectID": "공부/2024-01-26-(공부) 조건부확률.html",
    "href": "공부/2024-01-26-(공부) 조건부확률.html",
    "title": "(공부) 조건부확률, 조건부기대값",
    "section": "",
    "text": "\\(\\mathbb{E}[Y|X]\\)의 의미를 알아보자.\n\n\n1. 엄밀하지 않은 정의\n# 정의 – 조건부확률(이산형)\n\\[P(Y=y|X=x):=\\frac{P(X=x,Y=y)}{P(X=x)}\\]\n#\n# 정의 – 조건부pdf(이산형,연속형)\n\\[f_{2|1}(y|x):=\\frac{f_{1,2}(x,y)}{f_1(x)}\\]\n#\n- 함수 \\(f_{2|1}(y|x)\\) 와 \\(f_{2}(y)\\)는 모두 확률변수 \\(Y\\)의 pdf 조건을 만족한다는 것을 주의하자. 즉 아래가 성립한다.\n\n\\(\\int_{-\\infty}^{\\infty} f_{2}(y)dy=1\\)\n\\(\\int_{-\\infty}^{\\infty} f_{2|1}(y|x)dy=1\\)\n\n# 정의 – 조건부평균(연속형)\n\\[\\mathbb{E}[Y|X=x]:=\\int y f_{2|1}(y|x)dy \\]\n#\n# 정의할 수 없음 – \\(\\mathbb{E}(Y|X)\\)\n학부수준에서는 엄밀하게 정의할수는 없으며, 개념적으로 접근한다.\n\n\\(\\mathbb{E}(Y|X=x)\\)는 \\(x\\)의 값에 따라서 그 값이 바뀌는 함수로 해석할 수 있다.\n1을 다시 표현하면 \\(h(x):=\\mathbb{E}(Y|X=x)\\)를 만족하는 적당한 \\(h\\)가 있다는 의미.\n2번에서 정의된 \\(h\\)에 입력을 \\(x\\)가 아니라 \\(X\\)로 준다면 \\(h(X)\\)와 같은 확률 변수를 생각할 수 있음. 1\n3번과 같은 확률변수를 \\(\\mathbb{E}(Y|X)\\)로 정의하자는 의미\n\n1 \\(X\\)가 확률변수이면 \\(f(X)\\)역시 확률변수라고 배웠으니까학부수준에서는 이정도가 설명의 끝이며 \\(\\mathbb{E}(Y|X)\\)를 수식으로 명확하게 정의하진 않는다.\n#\n# 정의할 수 없음 – \\(\\mathbb{V}(Y|X)\\)\n\\(\\mathbb{E}(Y|X)\\)와 비슷한 방식으로 피해서 정의한다.\n#\n# 예제 – \\(\\mathbb{E}[\\mathbb{E}[Y|X]]=\\mathbb{E}[Y]\\) 의 증명 (\\(\\star\\))\n(풀이)\n헷갈리니까 아래와 같이 치환한다.\n\n\\(\\mathbb{E}[Y|X]=h(X)\\)\n\\(\\mathbb{E}[Y|X=x]=h(x)\\)\n\n그러면 좌변은 아래와 같이 된다.\n\n\\(\\mathbb{E}[h(X)]=\\int h(x) f_1(x)dx = \\int \\mathbb{E}[Y|X=x] f_1(x)dx\\)\n\n그런데 \\(\\mathbb{E}[Y|X=x]\\)는 조건부확률의 정의에 의하여 \\(\\mathbb{E}[Y|X=x]=\\int y f_{2|1}(y|x)dy\\) 이다. 이걸 그대로 넣으면\n\n\\(\\int \\mathbb{E}[Y|X=x] f_1(x)dx=\\int \\int y f_{2|1}(y|x)dy f_1(x)dx=\\int \\int y f_{2|1}(y|x)f_1(x)dydx\\)\n\n이제 조건부 pdf의 정의를 쓰면 \\(f_{2|1}(y|x)f_1(x)=f_{1,2}(x,y)\\)가 된다. 따라서\n\n\\(\\int \\int y f_{2|1}(y|x)f_1(x)dydx=\\int\\int y f_{1,2}(x,y)dydx\\)\n\n푸비니의 정리를 쓰면\n\n\\(\\int\\int y f_{1,2}(x,y)dydx=\\int\\int y f_{1,2}(x,y)dxdy\\)\n\n\\(y\\)를 밖으로 빼고 marginal pdf의 정의2를 이용하면\n2 \\(\\int f_{1,2}(x,y)dx = f_2(y)\\)\n\\(\\int\\int y f_{1,2}(x,y)dxdy=\\int y\\int f_{1,2}(x,y)dxdy=\\int y f_2(y)dy = \\mathbb{E}[y]\\)\n\n그래서 증명이 되었음.\n\n\n2. 엄밀한정의\n# 예제 - 주사위던지기\n- 아래와 같은 상황을 가정하자.\n\n\\(\\Omega = \\{1,2,3,\\dots,6\\}\\)\n\\({\\cal F} = 2^\\Omega\\)\n\\(P: {\\cal F} \\to [0,1]\\) such that \\(P(\\{\\omega\\})=\\frac{1}{6}\\).\n\n이제 \\((\\Omega, {\\cal F})\\) 위에서 아래와 같은 확률변수 \\(X: \\Omega \\to \\mathbb{R}\\)을 정의하자.\n\n\\(X(\\{1\\}) =1\\)\n\\(X(\\{2\\}) =2\\)\n\\(X(\\{3\\}) =3\\)\n\\(X(\\{4\\}) =4\\)\n\\(X(\\{5\\}) =5\\)\n\\(X(\\{6\\}) =6\\)\n\n여기까지는 익숙한 셋팅이며, 이럴때\n\n\\(X\\) is r.v. on \\((\\Omega, {\\cal F})\\)\n\\(X \\in {\\cal F}\\)\n\n와 같이 표현한다.\n- 이제 여기에서 아래와 같이 \\(\\Omega\\)를 disjoin한 \\(\\{B_i\\}\\)로 나누자.\n\n\\(B_1 = \\{1,2\\}\\)\n\\(B_2 = \\{3,4,5,6\\}\\)\n\n그리고 \\(B_1\\), \\(B_2\\)를 measurable하게 만드는 새로운 시그마필드 \\({\\cal F}^*=\\sigma(B_1,B_2)\\)를 아래와 같이 정의하자.\n\n\\({\\cal F}^* = \\{\\emptyset, B_1, B_2, \\Omega\\}\\)3\n\n3 당연히 \\({\\cal F}^* \\subset {\\cal F}\\)이제 아래와 같은 \\(Y: \\Omega\\to\\mathbb{R}\\)를 고려하자.\n\n\\(Y(\\{1\\}) = 1.5\\)\n\\(Y(\\{2\\}) = 1.5\\)\n\\(Y(\\{3\\}) = 4.5\\)\n\\(Y(\\{4\\}) = 4.5\\)\n\\(Y(\\{5\\}) = 4.5\\)\n\\(Y(\\{6\\}) = 4.5\\)\n\n여기에서 \\(Y\\)는 \\((\\Omega, {\\cal F})\\) 에서의 확률변수이기도 하지만 \\((\\Omega, {\\cal F}^*)\\)에서의 확률변수이기도 하다. 즉\n\n\\(Y\\) is r.v. on \\((\\Omega, {\\cal F})\\)\n\\(Y \\in {\\cal F}\\)\n\\(Y\\) is r.v. on \\((\\Omega, {\\cal F}^*)\\)\n\\(Y \\in {\\cal F}^*\\)\n\n이다.4\n4 이렇게 보니까 \\({\\cal F}^* \\subset {\\cal F}\\) 임을 감안하면 \\(Y \\in {\\cal F}^* \\Rightarrow Y \\in {\\cal F}\\) 임이 당연하게 느껴진다. \\(Y \\in {\\cal F}\\)와 같은 기호표현이 너무 이상하게 느껴졌는데, 여기에서 의문이 조금 풀리는 것 같음.또 \\(Y\\)는 아래와 같은 특징이 있다.\n\n\\(\\forall A \\in {\\cal F}^*:~\\int_A X dP = \\int_A Y dP.\\)\n\n이것을 조금만 따져보자. \\(\\int_A X dP = \\int_\\Omega X \\mathbb{1}_A dP\\) 임을 이용하면,\n\ncase1: \\(A = \\emptyset \\Rightarrow 0=0\\):\ncase2: \\(A = B_1 \\Rightarrow \\frac{1+2+0+0+0+0}{6}=\\frac{1.5+1.5+0+0+0+0}{6}\\)\ncase3: \\(A = B_2 \\Rightarrow \\frac{0+0+3+4+5+6}{6}=\\frac{0+0+4.5+4.5+4.5+4.5}{6}\\)\ncase4: \\(A = \\Omega \\Rightarrow \\frac{1+2+3+4+5+6}{6}=\\frac{1.5+1.5+4.5+4.5+4.5+4.5}{6}\\)\n\n이다.\n- 이러한 조건을 만족하는 확률변수 \\(Y\\)를 conditional expectation of \\(X\\) given \\({\\cal F}^*\\)이라고 한다.5\n5 조건부기대값이라고 번역하기는 조금 어색해서 원문그대로 외우는게 나은듯#\n# 정의 – (Klenke 2013, Def 8.11) \\(X \\in {\\cal L}^1(\\Omega, {\\cal F}, P)\\) 이라고 하자. 6 그리고 \\({\\cal F}^*\\)는\n6 \\(X\\)가 \\((\\Omega, {\\cal F})\\)에서의 rv이고 \\(\\int_P XdP &lt;\\infty\\) 라는 의미\n\\({\\cal F}^* \\subset {\\cal F}\\)\n\n을 만족하는 \\(\\Omega\\)에서의 시그마필드라고 하자. 확률변수 \\(Y\\) 가 아래를 만족한다고 하자.\n\n\\(Y \\in {\\cal F}^*\\)\n\\(\\forall A \\in {\\cal F}^*:~ \\int_A X dP = \\int_A Y dP\\)\n\n그러면 \\(Y\\)는 conditional expectation of \\(X\\) given \\({\\cal F}^*\\)라고 하고 기호로는\n\\[Y:=\\mathbb{E}[X|{\\cal F}^*]\\]\n로 표현한다.\n#\n- \\(Y\\)는 \\((\\Omega,{\\cal F}^*)\\)에서의 확률변수이기도 하지만 일단 \\(Y \\in (\\Omega, {\\cal F})\\) 이기도 하다. 가측공간 \\((\\Omega,{\\cal F}^*)\\) 에서는 적절한 확률측도를 정의한적이 없지만 \\((\\Omega,{\\cal F})\\) 에서는 확률측도 \\(P\\)가 이미 정의되어 있다. 이를 이용하여 아래를 계산해보자.\n\n\\(\\mathbb{E}[Y]=\\int Y dP\\)\n\n이것을 정리하면\n\n\\(\\frac{1.5+1.5+4.5+4.5+4.5+4.5}{6}\\)\n\n가 되어서 \\(\\mathbb{E}[X]\\)와 같다. 따라서\n\n\\(\\mathbb{E}[X] = \\mathbb{E}[\\mathbb{E}[X|{\\cal F}^*]]\\)\n\n이다. 여기에서 \\(\\mathbb{E}[X|{\\cal F}^*]\\)은 일단 그 자체로 하나의 기호라 생각하자.\n# Thm – (Klenke 2013, Thm 8.12) \\(X \\in {\\cal L}^1(\\Omega, {\\cal F}, P)\\) 이라고 하자. 7 그리고 \\({\\cal F}^*\\)는\n7 \\(X\\)가 \\((\\Omega, {\\cal F})\\)에서의 rv이고 \\(\\int_P XdP &lt;\\infty\\) 라는 의미\n\\({\\cal F}^* \\subset {\\cal F}\\)\n\n을 만족하는 \\(\\Omega\\)에서의 시그마필드라고 하자. 아래를 만족하는 확률변수 \\(Y\\)는 (\\(P\\)에 대하여) 거의 유일하게 존재한다.\n\n\\(Y \\in {\\cal F}^*\\)\n\\(\\forall A \\in {\\cal F}^*:~ \\int_A X dP = \\int_A Y dP\\)\n\n#\n# 정의 – (Klenke 2013, Def 8.13) 아래와 같은 두 확률변수를 정의하자.\n\nKlenke, Achim. 2013. Probability Theory: A Comprehensive Course. Springer Science & Business Media.\n\n\\(X\\) is rv on \\((\\Omega, {\\cal F})\\) with \\(\\int X dP &lt;\\infty\\).8\n\\(Y\\) is rv on \\((\\Omega, {\\cal F})\\).\n\n8 \\(X \\in {\\cal L}^1(\\Omega, {\\cal F}, P)\\) 이라는 의미아래를 정의하자.\n\\[\\mathbb{E}[X|Y]:=\\mathbb{E}[X|\\sigma(Y)].\\]\n#"
  },
  {
    "objectID": "공부/2023-06-28-(공부&지윤) 퓨리에변환(detailed).html",
    "href": "공부/2023-06-28-(공부&지윤) 퓨리에변환(detailed).html",
    "title": "(공부&지윤) 퓨리에변환(detailed)",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "공부/2023-06-28-(공부&지윤) 퓨리에변환(detailed).html#이론-및-예시",
    "href": "공부/2023-06-28-(공부&지윤) 퓨리에변환(detailed).html#이론-및-예시",
    "title": "(공부&지윤) 퓨리에변환(detailed)",
    "section": "이론 및 예시",
    "text": "이론 및 예시\n- 이론: real-valued signal은 무조건 \\(|X[k]|^2\\)의 그래프가 대칭으로 나옴 (단, \\(X[0]\\)은 제외)\n- 예시1:\n\nx = np.array([1,2,3,4,5])\nX = np.fft.fft(x) \n\n\nplt.plot(abs(X)**2,'o')\n\n\n\n\n\n\n\n\n\n첫항을 제외하고 대칭임\n\n- 예시2:\n\nx = np.array([1,2,3,-3,-2,-1])\nX = np.fft.fft(x) \n\n\nplt.plot(abs(X)**2,'o')\n\n\n\n\n\n\n\n\n\n첫항을 제외하고 대칭임\n\n- 예시3: \\({\\bf x}\\)가 복소수일 경우는 첫항을 제외하고 대칭이 되지 않음\n\nx = np.array([1+1j,2+2j,3+3j,-3-3j,-2-2j,1-1j]) \nX = np.fft.fft(x) \n\n\nplt.plot(abs(X)**2,'o')"
  },
  {
    "objectID": "공부/2023-06-28-(공부&지윤) 퓨리에변환(detailed).html#왜-xn이-실수일-경우만-xk2이-대칭으로-나올까",
    "href": "공부/2023-06-28-(공부&지윤) 퓨리에변환(detailed).html#왜-xn이-실수일-경우만-xk2이-대칭으로-나올까",
    "title": "(공부&지윤) 퓨리에변환(detailed)",
    "section": "왜 \\(x[n]\\)이 실수일 경우만 \\(|X[k]|^2\\)이 대칭으로 나올까?",
    "text": "왜 \\(x[n]\\)이 실수일 경우만 \\(|X[k]|^2\\)이 대칭으로 나올까?\n- 예비학습1\n임의의 \\(0 \\leq \\alpha \\leq 1\\)에 대하여 \\(\\cos(2\\pi \\alpha) =\\cos(2\\pi (1-\\alpha))\\) 가 성립함\n\nalpha = 0.2\nnp.cos(2*np.pi*alpha),np.cos(2*np.pi*(1-alpha))\n\n(0.30901699437494745, 0.30901699437494723)\n\n\n\n그래프를 잘 그려보세여\n\n- 예비학습2\n임의의 \\(0 \\leq \\alpha \\leq 1\\)에 대하여 \\(\\sin(2\\pi \\alpha) = -\\sin(2\\pi (1-\\alpha))\\) 가 성립함\n\nalpha = 0.2\nnp.sin(2*np.pi*alpha),np.sin(2*np.pi*(1-alpha))\n\n(0.9510565162951535, -0.9510565162951536)\n\n\n\n그래프를 잘 그려보세여\n\n- 왜 실수일경우만 대칭인지? (어디 정리된걸 아무리 찾아도 못찾겠어서 그냥 직접 수식을 썼는데요, 이걸 기억할 필요는 없어요.. 아마 제가 쓴것보다 쉽게 설명하는 방법이 있을겁니다)\n(해설) \\(k=0,1,2,\\dots,N-1\\)에 대하여 \\(X[k]\\)는 아래와 같이 표현가능하다.\n\\[X[k] = \\sum_{n=0}^{N-1}x[n]e^{-\\frac{j2\\pi kn}{N}}\\]\n오일러공식을 사용하면 아래와 같이 정리할 수 있다.\n\\[X[k] = \\sum_{n=0}^{N-1}x[n]\\cos\\left(-\\frac{2\\pi kn}{N}\\right) + i \\sum_{n=0}^{N-1}x[n]\\sin\\left(-\\frac{2\\pi kn}{N}\\right)\\]\ncos은 짝함수, sin은 홀함수임을 이용하여 다시정리하면\n\\[X[k] = \\sum_{n=0}^{N-1}x[n]\\cos\\left(\\frac{2\\pi kn}{N}\\right) - i \\sum_{n=0}^{N-1}x[n]\\sin\\left(\\frac{2\\pi kn}{N}\\right)\\]\ncase1 \\(k=1\\) 인 경우와 \\(k=N-1\\)인 경우는 서로 \\(|X[k]|^2\\)이 같음을 보이자.\n\\[X[1] = \\sum_{n=0}^{N-1}x[n]\\cos\\left(\\frac{2\\pi n}{N}\\right) - i \\sum_{n=0}^{N-1}x[n]\\sin\\left(\\frac{2\\pi n}{N}\\right)\\]\n\\[X[N-1] = \\sum_{n=0}^{N-1}x[n]\\cos\\left(\\frac{2\\pi (N-1)n}{N}\\right) - i \\sum_{n=0}^{N-1}x[n]\\sin\\left(\\frac{2\\pi(N-1) n}{N}\\right)\\]\n여기에서 예비학습1,2를 떠올리면 \\(\\cos\\left(\\frac{2\\pi n}{N}\\right)=\\cos\\left(\\frac{2\\pi (N-1)n}{N}\\right)\\) 이고 \\(\\sin\\left(\\frac{2\\pi n}{N}\\right)=-\\sin\\left(\\frac{2\\pi(N-1) n}{N}\\right)\\) 임을 알 수 있다. 따라서 \\(X[1]\\)와 \\(X[N-1]\\)은 켤레복소수이다. 즉\n\\[X[1] = X[N-1]^\\ast, \\quad X[1]^\\ast = X[N-1]\\]\n이다. 그런데 임의의 복소수 \\(x=a+bi\\)에 대하여 \\(|x|^2 = a^2+b^2 = (a+bi)(a-bi)= x x^\\ast\\) 가 성립하므로\n\\[|X[1]|^2 = |X[N-1]|^2\\]\n이 성립한다.\n\n만약에 \\(x[n]\\)이 실수가 아닌경우는 \\(\\cos\\left(\\frac{2\\pi n}{N}\\right)=\\cos\\left(\\frac{2\\pi (N-1)n}{N}\\right)\\) 이고 \\(\\sin\\left(\\frac{2\\pi n}{N}\\right)=-\\sin\\left(\\frac{2\\pi(N-1) n}{N}\\right)\\) 이라고 하여도 \\(X[1]\\)와 \\(X[N-1]\\)은 켤레복소수라고 주장할수 없다.\n\ncase2 \\(k=2\\) 인 경우와 \\(k=N-2\\)인 경우는 서로 \\(|X[k]|^2\\)이 같음도 비슷한 논리로 보일 수 있다."
  },
  {
    "objectID": "공부/2023-06-28-(공부&지윤) 퓨리에변환(detailed).html#허수파트-해석",
    "href": "공부/2023-06-28-(공부&지윤) 퓨리에변환(detailed).html#허수파트-해석",
    "title": "(공부&지윤) 퓨리에변환(detailed)",
    "section": "허수파트 해석",
    "text": "허수파트 해석\n관찰1: 모든 \\(k\\)에 대하여 \\(X[k]\\)의 허수파트는 항상 0이다.\nk=0\n\nk=0\nsin_part_0 = np.array([np.sin(2*np.pi*k*n/N) for n in range(N)])\n\n\nx*sin_part_0\n\narray([ 0.,  0.,  0.,  0., -0., -0., -0., -0., -0., -0., -0., -0.,  0.,\n        0.,  0.])\n\n\n\nsum(x*sin_part_0)\n\n0.0\n\n\nk=1\n\nk=1\nsin_part_1 = np.array([np.sin(2*np.pi*k*n/N) for n in range(N)])\n\n\nx*sin_part_1\n\narray([ 0.        ,  0.37157241,  0.49726095,  0.29389263, -0.10395585,\n       -0.4330127 , -0.47552826, -0.20336832,  0.20336832,  0.47552826,\n        0.4330127 ,  0.10395585, -0.29389263, -0.49726095, -0.37157241])\n\n\n\nsum(x*sin_part_1)\n\n1.0547118733938987e-15\n\n\n약간을 직관을 위해서 그림을 그려보자.\n\nplt.plot(x,'--o')\nplt.plot(sin_part_1,'--o')\n\n\n\n\n\n\n\n\n\\(x\\)가 \\(\\mathbb{R}\\)에서 정의된 연속함수라고 상상하면 \\(\\sum_{n=0}^{N-1}\\cos\\left(\\frac{2\\pi n}{N} \\right)\\sin\\left(\\frac{2\\pi kn}{N}\\right)\\)에 대응하는 식은 \\(\\int_0^{2\\pi}\\cos(t)\\sin(t)dt\\)라고 볼 수 있어서 sum(x*sin_part_1)=0임을 더 쉽게 이해할 수 있다.\nk=2\n\nk=2\nsin_part_2 = np.array([np.sin(2*np.pi*k*n/N) for n in range(N)])\n\n\nplt.plot(x,'--o')\nplt.plot(sin_part_2,'--o')\n\n\n\n\n\n\n\n\n\\(x\\)가 \\(\\mathbb{R}\\)에서 정의된 연속함수라고 상상하면 파란선에 대응하는것은 \\(\\cos(t)\\) 주황선에 대응하는 것은 \\(\\sin(2t)\\)로 볼 수 있는데 둘은 직교하므로 둘을 곱한뒤 적분하면 (더하면) 0이 된다.\n\nsum(x*sin_part_2)\n\n-1.2212453270876722e-15\n\n\n\\(\\cos(t)\\)는 임의의 \\(\\sin(kt)\\)와 항상 직교하므로, 임의의 \\(k\\)에 대하여 허수파트는 항상 0이다.\n따라서 이 경우 \\(X[k]\\)는 아래와 같이 써도 무방하다.\n\\[X[k] = \\sum_{n=0}^{N-1}x[n]\\cos\\left(\\frac{2\\pi kn}{N}\\right)\\]"
  },
  {
    "objectID": "공부/2023-06-28-(공부&지윤) 퓨리에변환(detailed).html#실수파트-해석",
    "href": "공부/2023-06-28-(공부&지윤) 퓨리에변환(detailed).html#실수파트-해석",
    "title": "(공부&지윤) 퓨리에변환(detailed)",
    "section": "실수파트 해석",
    "text": "실수파트 해석\n관찰2: \\(X[k]\\)의 실수파트는 \\(k=1\\)혹은 \\(k=N-1\\)일때 아래와 같이 정리된다.\n\\[\\sum_{n=0}^{N-1}\\cos\\left(\\frac{2\\pi n}{N} \\right)^2\\]\n그외의 경우에는 아래와 같이 된다.\nk=0\n\nk=0\ncos_part_0 = np.array([np.cos(2*np.pi*k*n/N) for n in range(N)])\n\n\nplt.plot(x,'--o')\nplt.plot(cos_part_0,'--o')\n\n\n\n\n\n\n\n\n\n파란선에 대응하는것은 \\(\\cos(t)\\) 주황선에 대응하는 것은 \\(1\\)로 볼 수 있는데 둘은 직교하므로 둘을 곱한뒤 적분하면 (더하면) 0이 된다.\n\nk=2\n\nk=2\ncos_part_2 = np.array([np.cos(2*np.pi*k*n/N) for n in range(N)])\n\n\nplt.plot(x,'--o')\nplt.plot(cos_part_2,'--o')\n\n\n\n\n\n\n\n\n\n파란선에 대응하는것은 \\(\\cos(t)\\) 주황선에 대응하는 것은 \\(\\cos(2t)\\)로 볼 수 있는데 둘은 직교하므로 둘을 곱한뒤 적분하면 (더하면) 0이 된다.\n\n임의의 \\(k\\)에 대하여 \\(\\cos(t)\\)와 \\(\\cos(kt)\\)는 항상 직교하므로 둘을 곱한뒤 적분하면 (더하면) 0이 된다.\n- 요약: 만약에 \\(x[n]\\)이 아래와 같은 꼴이라고 하자.\n\\[x[n] = \\cos\\left(\\frac{2\\pi n}{N} \\right)\\]\n이때 퓨리에변환 \\(X[k]\\)는 아래와 같이 정리된다.\n\\[X[k] = \\sum_{n=0}^{N-1}x[n]\\cos\\left(\\frac{2\\pi kn}{N}\\right) - i \\sum_{n=0}^{N-1}x[n]\\sin\\left(\\frac{2\\pi kn}{N}\\right)\\]\n\\(X[k]\\)의 허수파트는 항상 0이 되고, 실수 파트는 \\(k=1,N-1\\)일 경우에만 값을 가지고 나머지는 0의 값을 가진다.\n\nX = np.fft.fft(x)\nfig, ax = plt.subplots(1,3)\nax[0].plot(x,'o--'); ax[0].set_title('x[n]')\nax[1].plot(np.real(X),'x'); ax[1].set_title('real(X[k])')\nax[2].plot(np.imag(X),'x'); ax[2].set_title('imag(X[k])')\nfig.set_figwidth(15)\n\n\n\n\n\n\n\n\n- 응용: \\(x[n]\\)이 아래와 같은 꼴이라고 하자.\n\\[x[n] = \\cos\\left(\\frac{6\\pi n}{N} \\right)\\]\n퓨리에변환 \\(X[k]\\)는 아래와 같이 정리된다.\n\\[X[k] = \\sum_{n=0}^{N-1}x[n]\\cos\\left(\\frac{2\\pi kn}{N}\\right) - i \\sum_{n=0}^{N-1}x[n]\\sin\\left(\\frac{2\\pi kn}{N}\\right)\\]\n\\(X[k]\\)의 허수파트는 항상 0이 되고, 실수 파트는 \\(k=3,N-3\\)일 경우에만 값을 가지고 나머지는 0의 값을 가진다.\n\nN = 15 \nx = np.array([np.cos(6*np.pi*n/N) for n in range(N)]) \nX = np.fft.fft(x)\nfig, ax = plt.subplots(1,3)\nax[0].plot(x,'o--'); ax[0].set_title('x[n]')\nax[1].plot(np.real(X),'x'); ax[1].set_title('real(X[k])')\nax[2].plot(np.imag(X),'x'); ax[2].set_title('imag(X[k])')\nfig.set_figwidth(15)"
  },
  {
    "objectID": "공부/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html",
    "href": "공부/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html",
    "title": "(공부) CGSP – Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "",
    "text": "using LinearAlgebra, Plots, FFTW, Statistics"
  },
  {
    "objectID": "공부/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html#kronecker-product",
    "href": "공부/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html#kronecker-product",
    "title": "(공부) CGSP – Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "Kronecker product",
    "text": "Kronecker product\n크로네커곱의 정의는 아래와 같다.\n\\[{\\bf A} \\otimes {\\bf B}\n=\\begin{bmatrix}\na_{11}{\\bf B} & a_{12}{\\bf B} & \\dots & a_{1m}{\\bf B} \\\\\na_{21}{\\bf B} & a_{22}{\\bf B} & \\dots & a_{2m}{\\bf B} \\\\\n\\dots & \\dots & \\dots & \\dots \\\\\na_{n1}{\\bf B} & a_{n2}{\\bf B} & \\dots & a_{nm}{\\bf B} \\\\\n\\end{bmatrix}\\]\n두 행렬 \\({\\bf A}_{m\\times n}\\), \\({\\bf B}_{p\\times q}\\)의 크로네커곱 \\({\\bf A}\\otimes {\\bf B}\\)의 차원은 \\(mp \\times nq\\) 가 된다. 계산예시는 아래와 같다.\n\n\n\n위키에서 긁은 예제, 글씨가 좀 작음\n\n\n크로네커곱에 대한 성질들이 위키에 많이 있으니 참고하면 좋다.\n(예제1)\n\nA= [1 2\n    3 4]\nB= [0 5\n    6 7]\nC = kron(A, B)\n\n4×4 Matrix{Int64}:\n  0   5   0  10\n  6   7  12  14\n  0  15   0  20\n 18  21  24  28\n\n\n(예제2)\n\nA= [1 -4 7; -2 3 3]\nB= [8 -9 -6 -5; 1 -3 -4 7; 2 8 -8 -3; 1 2 -5 -1]\nC = kron(A, B)\n\n8×12 Matrix{Int64}:\n   8   -9  -6   -5  -32   36   24   20  56  -63  -42  -35\n   1   -3  -4    7   -4   12   16  -28   7  -21  -28   49\n   2    8  -8   -3   -8  -32   32   12  14   56  -56  -21\n   1    2  -5   -1   -4   -8   20    4   7   14  -35   -7\n -16   18  12   10   24  -27  -18  -15  24  -27  -18  -15\n  -2    6   8  -14    3   -9  -12   21   3   -9  -12   21\n  -4  -16  16    6    6   24  -24   -9   6   24  -24   -9\n  -2   -4  10    2    3    6  -15   -3   3    6  -15   -3"
  },
  {
    "objectID": "공부/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html#khatrirao-product",
    "href": "공부/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html#khatrirao-product",
    "title": "(공부) CGSP – Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "Khatri–Rao product",
    "text": "Khatri–Rao product\n카트리-라오곱은 매트릭스 \\({\\bf A}\\)와 \\({\\bf B}\\)가 같은 차원의 블락매트릭스로 정의될때 각 서브매트릭스의 크로네커 곱으로 정의된다. 정의와 계산예시는 아래와 같다.\n\n\n\n예시1: 위키에서 긁은 그림\n\n\n또 다른 계산예시는 아래와 같다. 이 예제는 중요하니까 구현해보자.\n\n\n\n예시2: 위키에서 긁은 그림\n\n\n(예제1)\n\nC= [1 2 3 \n    4 5 6 \n    7 8 9] \nD= [1 4 7\n    2 5 8\n    3 6 9]\n\n3×3 Matrix{Int64}:\n 1  4  7\n 2  5  8\n 3  6  9\n\n\n\nhcat([kron(C[:,i],D[:,i]) for i in 1:3]...)\n\n9×3 Matrix{Int64}:\n  1   8  21\n  2  10  24\n  3  12  27\n  4  20  42\n  8  25  48\n 12  30  54\n  7  32  63\n 14  40  72\n 21  48  81\n\n\n이건 자주 쓸일이 있을것 같으니까 함수로 저장하자.\n\ncolumnwise_kron = \n(C,D) -&gt; hcat([kron(C[:,i],D[:,i]) for i in 1:size(C)[2]]...)\n\n#181 (generic function with 1 method)\n\n\n\ncolumnwise_kron(C,D)\n\n9×3 Matrix{Int64}:\n  1   8  21\n  2  10  24\n  3  12  27\n  4  20  42\n  8  25  48\n 12  30  54\n  7  32  63\n 14  40  72\n 21  48  81"
  },
  {
    "objectID": "공부/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html#그래프-표현",
    "href": "공부/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html#그래프-표현",
    "title": "(공부) CGSP – Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "그래프 표현",
    "text": "그래프 표현\n아래의 그림을 살펴보자.\n\n\n\n그래프의 개념을 이해하는 필요한 그림, 일단 오른쪽의 \\({\\bf S}\\)는 무시할 것\n\n\n오른쪽의 \\({\\bf S}\\)는 무시하고 왼쪽의 그래프만 살펴보자. 이 그림에는 6개의 노드가 있고 각각의 노드는 저 마다의 연결구조를 가진다. 이러한 연결구조는 \\({\\bf G}=({\\bf N},{\\bf E})\\) 으로 표현할 수 있는데 여기에서 \\({\\bf N}\\)은 노드들의 집합이고 \\({\\bf E}\\)는 엣지들의 집합이다.1 보통 \\({\\cal E}\\)는 복잡하므로 연결정보를 매트릭스 \\({\\bf E}\\)로 표현하는데 이러한 \\({\\bf E}\\)를 인접행렬이라고 부른다. 인접행렬의 각 원소는 \\(E_{ij}= \\begin{cases} 1 & (i,j) \\in {\\cal E} \\\\ 0 & o.w \\end{cases}\\) 와 같이 정의한다. 이 그림의 경우 \\({\\cal N}\\) 와 \\({\\cal E}\\), \\({\\bf E}\\) 는 아래와 같다.\n1 노드 \\(i\\)에서 노드 \\(j\\)로 향하는 연결이 있다면 \\((i,j) \\in {\\cal E}\\)이다.\n\\({\\cal N}=\\{1,2,3,4,5,6\\}\\)\n\\({\\bf E}=\\begin{bmatrix} 0 & 1 & 0 & 0 & 1 & 0 \\\\ 1 & 0 & 1 & 0 & 1 & 0\\\\ 0 & 1 & 0 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 0 & 1 & 1 \\\\ 1 & 1 & 0 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 1 & 0 & 0 \\end{bmatrix}\\)\n\\({\\cal E} = \\{(i,j) : E_{ij}=1 \\}\\)"
  },
  {
    "objectID": "공부/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html#gso",
    "href": "공부/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html#gso",
    "title": "(공부) CGSP – Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "GSO",
    "text": "GSO\n후에 자세히 서술하겠지만 전통적인 시계열분석기법을 그래프신호로 확장하기 위해서는 단지 퓨리에변환 대신에 그래프퓨리에 변환을 사용하면 된다. 즉 퓨리에변환을 일반화한 그래프퓨리에변환을 잘 정의하면 된다.\n전통적인 신호처리 영역에서의 퓨리에변환은 시계열자료의 인접성을 의미하는 행렬 \\({\\bf B}\\)2의 고유행렬의 켤레전치로 정의할 수 있다. 이를 이용하면 그래프 퓨리에변환은 그래프자료의 인접성을 의미하는 행렬3의 고유행렬의 켤레전치로 정의할 수 있음을 유추할 수 있다. 즉 비유클리드 자료에서도 \\({\\bf B}\\)에 대응하는 어떠한 매트릭스가 정의되어야 하는데 (그리고 이 매트릭스는 그래프자료의 인접성에 대한 정보가 있어야 한다) 이 매트릭스를 \\({\\bf S}\\)라고 정의하고 grahp shift operator (GSO) 라고 이름 붙인다.\n2 원래는 평행이동을 의미하는 행렬이지만, 이걸 인접성을 의미하는 행렬로 해석할 수도 있다. 어차피 인접한 곳으로 이동할 수 있으니까..3 예를들면 인접행렬 \\({\\bf E}\\)와 같은 행렬주어진 그래프 \\({\\cal G}=({\\cal N},{\\cal E})\\) 에 대하여 GSO \\({\\bf S}\\)는 \\({\\bf E}+{\\bf I}\\)의 값이 1인 영역에만 값이 있는 어떠한 행렬이다. 다시 아래의 그림을 생각하여 보자.\n\n\n\nGSO의 개념을 이해하는데 필요한 그림\n\n\n왼쪽그래프의 GSO는 오른쪽과 같은 행렬 \\({\\bf S}\\)가 된다. 이제 \\({\\bf S}\\) 의 고유벡터행렬을 구한 뒤에 그것의 켤레전치를 \\({\\bf GFT}\\) 행렬로 정의하면 될 것 같다. 문제는 “\\({\\bf S}\\)의 고유벡터행렬이 항상 존재하는가?” 인데, 사실 이게 항상 존재한다는 보장이 없다. 즉 \\({\\bf S}\\)의 고유벡터 행렬이 존재 안할 수도 있다. 따라서 GSO \\({\\bf S}\\)가 고유분해가능하다는 조건이 추가적으로 필요한데 이러한 조건을 만족하는 GSO를 normal GSO라고 부른다. 우리는 당연히 normal GSO에 대해서만 관심이 있으므로 앞으로 특별한 언급이 없는한 GSO는 모두 normal GSO라고 가정한다."
  },
  {
    "objectID": "공부/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html#periodogram-correlogram-and-ls-estimator",
    "href": "공부/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html#periodogram-correlogram-and-ls-estimator",
    "title": "(공부) CGSP – Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "Periodogram, correlogram, and LS estimator",
    "text": "Periodogram, correlogram, and LS estimator\nFrom \\({\\bf C}_{\\tilde{\\bf x}}:= \\mathbb{E}\\left[\\tilde{\\bf x}\\tilde{\\bf x}^H \\right]=\\mathbb{E}\\left[({\\bf V}^H{\\bf x})({\\bf V}^H{\\bf x})^H \\right]=\\text{diag}({\\bf p})\\) it follows that one may express the PSD as \\({\\bf p}=\\mathbb{E}\\left[|{\\bf V}^H{\\bf x}|^2\\right]\\). That is, the PSD is given by the expected value of the squared frequency components of the random process. This leads to a natural approach for the estimation of \\({\\bf p}\\) from a finite set of \\(R\\) realizations of the process \\({\\bf x}\\). Indeed, we compute the \\({\\bf GFT} \\tilde{\\bf x}_r = {\\bf V}^H{\\bf x}_r\\) of each observed signal \\({\\bf x}_r\\) and estimate \\({\\bf p}\\) as\n\\[\n\\hat{\\bf p}_{pg}:= \\frac{1}{R}\\sum_{r=1}^R|\\tilde{\\bf x}_r|^2=\\frac{1}{R}\\sum_{r=1}^{R}|{\\bf V}^H{\\bf x}_{r}|^2.\n\\]\nThe estimator \\(\\hat{\\bf p}_{pg}\\) is termed periodogram due to its evident similarity with its homonym5 in classical estimation. It is simple to show that \\({\\bf p}_{pg}\\) is an unbiased estimator, that is, \\(\\mathbb{E}[\\hat{\\bf p}_{pg}]= {\\bf p}\\). A more detailed analysis of the performance of \\(\\hat{\\bf p}_{pg}\\), for the case where the observations are Gaussian, is given in Proposition 12.1.6\n5 동음이의어6 Proposition 12.1은 뒤에 다루는데 \\(\\hat{\\bf p}_{pg}\\)의 분산에 대한 서술이 있음. 분산은 \\(\\mathbb{V}[\\hat{\\bf p}_{pg}]=\\frac{2}{R}\\text{diag}^2({\\bf p})\\)와 같음An alternative nonparametric estimation scheme, denominated correlogram, can be devised by starting from the definition of \\({\\bf p}\\) in\n\\[{\\bf p}:=\\text{diag}\\big({\\bf V}^H {\\bf C}_{\\bf x}{\\bf V} \\big).\\]\nNamely, one may substitute \\({\\bf C}_{\\bf x}\\) in above equation by the sample covariance \\(\\hat{\\bf C}_{\\bf x} = \\frac{1}{R}\\sum_{r=1}^R{\\bf x}_r{\\bf x}_r^H\\) computed based on the available observations to obtain\n\\[\\hat{\\bf p}_{cg}:= \\text{diag}\\left({\\bf V}^H \\hat{\\bf C}_{\\bf x}{\\bf V} \\right):=\\text{diag}\\left[{\\bf V}^H\\big[ \\frac{1}{R}\\sum_{r=1}^R{\\bf x}_r{\\bf x}_r^H\\big]{\\bf V} \\right].\\]\nNotice that the matrix \\({\\bf V}^H\\hat{\\bf C}_{\\bf x}{\\bf V}\\) is in general, not diagonal because the eigenbasis of \\(\\hat{\\bf C}_{\\bf x}\\) differs from \\({\\bf V}\\), the eigenbasis of \\({\\bf C}_{\\bf x}\\). Nonetheless, we keep only the diagonal elements \\({\\bf v}_i^H \\hat{\\bf C}_{\\bf x}{\\bf v}_i\\) for \\(i = 1, \\dots , N\\) as our PSD estimator. It can be shown that the correlogram \\({\\bf p}_{cg}\\) and the periodogram \\({\\bf p}_{pg}\\) lead to identical estimators, as is the case in classical signal processing.\nThe correlogram can also be interpreted as an LS estimator. The decomposition in \\({\\bf C}_{\\bf x}={\\bf V}\\text{diag}({\\bf p}){\\bf V}^H\\) allows a linear parameterization of the covariance matrix \\({\\bf C}_{\\bf x}\\) as\n\\[\n{\\bf C}_{\\bf x}({\\bf p})=\\sum_{i=1}^N p_i{\\bf v}_i{\\bf v}_i^H.\n\\]\nThis linear parametrization will also be useful for the sampling schemes developed in Section 12.4. Vectorizing \\({\\bf C}_{\\bf x}\\) in \\({\\bf C}_{\\bf x}({\\bf p})=\\sum_{i=1}^N p_i{\\bf v}_i{\\bf v}_i^H\\) results in a set of \\(N^2\\) equations in \\({\\bf p}\\)\n\\[\n{\\bf c}_{\\bf x} = \\text{vec}({\\bf C}_{\\bf x})=\\sum_{i=1}^{N}p_i \\text{vec}({\\bf v}_i{\\bf v}_i^H)={\\bf G}_{np}{\\bf p},\n\\]\nwhere \\(\\text{vec}({\\bf v}_i{\\bf v}_i^H)={\\bf v}_i^\\ast \\otimes {\\bf v}_i\\). Relying on the Khatri-Rao product, we then form the \\(N^2 \\times N\\) matrix \\({\\bf G}_{np}\\) as\n\\[\n{\\bf G}_{np}:= \\left[{\\bf v}_1^\\ast \\otimes {\\bf v}_1, \\dots, {\\bf v}_N^\\ast \\otimes {\\bf v}_N \\right] = {\\bf V}^\\ast \\odot {\\bf V}.\n\\]\n\nHere \\(\\otimes\\) denote the Kronecker matrix product and \\(\\odot\\) denote the Khatri-Rao matrix product.\n\nUsing the sample covariance matrix \\(\\hat{\\bf C}_{\\bf x}\\) as an estimate of \\({\\bf C}_{\\bf x}\\), we can match the estimated covariance vector \\(\\hat{\\bf c}_{\\bf x}=\\text{vec}(\\hat{\\bf C}_{\\bf x})\\) to the true covariance vector \\({\\bf c}_{\\bf x}\\) in the LS sense as\n\\[\n\\hat{\\bf p}_{ls} = \\underset{\\bf p}{\\operatorname{argmin}} \\|\\hat{\\bf c}_{\\bf x}-{\\bf G}_{np}{\\bf p}\\|_2^2=({\\bf G}_{np}^H{\\bf G}_{np})^{-1}{\\bf G}_{np}^H\\hat{\\bf c}_{\\bf x}.\n\\]\nIn other words, the LS estimator minimizes the squared error \\(\\text{tr}\\left[\\big(\\hat{\\bf C}_{\\bf x} − \\hat{\\bf C}_{\\bf x}({\\bf p})\\big)^T \\big(\\hat{\\bf C}_{\\bf x} − \\hat{\\bf C}_{\\bf x}({\\bf p})\\big)\\right]\\). From expression \\(\\hat{\\bf p}_{ls} = \\underset{\\bf p}{\\operatorname{argmin}} \\|\\hat{\\bf c}_{\\bf x}-{\\bf G}_{np}{\\bf p}\\|_2^2=({\\bf G}_{np}^H{\\bf G}_{np})^{-1}{\\bf G}_{np}^H\\hat{\\bf c}_{\\bf x}\\) it can be shown that the \\(i\\)th element of \\(\\hat{\\bf p}_{ls}\\) is \\({\\bf v}_i^H \\hat{\\bf C}_{\\bf x} {\\bf v}_i\\). Combining this with Eq.\n\\[\\hat{\\bf p}_{cg}:= \\text{diag}\\left({\\bf V}^H \\hat{\\bf C}_{\\bf x}{\\bf V} \\right):=\\text{diag}\\left[{\\bf V}^H\\big[ \\frac{1}{R}\\sum_{r=1}^R{\\bf x}_r{\\bf x}_r^H\\big]{\\bf V} \\right]\\]\nwe get that the LS estimator \\(\\hat{\\bf p}_{ls}\\) and the correlogram \\(\\hat{\\bf p}_{cg}\\) —and hence the periodogram as well— are all identical estimators. The estimators derived in this subsection do not assume any data distribution and are well suited for cases where the data probability density function is not available. In what follows, we provide performance bounds for these estimators under the condition that the observed signals are Gaussian."
  },
  {
    "objectID": "공부/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html#정상시계열을-분석하는-두-가지-흐름-acf와-psd",
    "href": "공부/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html#정상시계열을-분석하는-두-가지-흐름-acf와-psd",
    "title": "(공부) CGSP – Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "정상시계열을 분석하는 두 가지 흐름, ACF와 PSD",
    "text": "정상시계열을 분석하는 두 가지 흐름, ACF와 PSD\n\n전통적인 분석방법\n클래식한 정상시계열은 유한차수의 ARMA로 근사할 수 있음이 알려져 있다7. 유한차수의 ARMA의 계수 \\(p\\),\\(q\\)를 적절하게 추정하기 위해서는 시계열 \\({\\bf x}\\)를 SACF plot 혹은 SPACF plot 을 이용하면 된다. 이때 SACF 혹은 SPACF 의 그림을 살펴보고 적절한 모형을 선택하기 위해서는 유한차수 ARMA의 이론적 ACF의 모양을 알면 되는데,8 이를 바꾸어서 말하면 결국 정상시계열 \\({\\bf x}\\)의 모든 정보는 ACF에 들어있다는 의미가 된다. 즉 정상시계열은 ACF만 잘 추정하면 모든 것이 해결된다.\n7 Wold’s theorem8 예를들어 “coef가 0.9인 AR(1)의 경우 lag=1 에 대한 이론적 ACF값이 0.9, lag=2에 대한 ACF값이 0.81, … 와 같이 되더라~” 하는식의그런데 ACF의 모든 정보는 다시 아래의 행렬에 들어있다.\n\\[{\\bf C}_{\\bf x}=\\mathbb{E}[{\\bf x}{\\bf x}^T]\\]\n여기에서 \\({\\bf x}\\)는 realization이 아니라 확률벡터를 의미함을 유의하자.9 따라서 정상시계열의 경우 \\({\\bf C}_{\\bf x}\\)를 잘 추정하면 모든것이 해결된다고 생각하면 된다.\n9 보통 수리통계에서는 확률변수를 \\(X\\) realization을 \\(x\\)로 표현하지만 여기에서는 매트릭스를 대문자로 쓰고 있어서 그런식으로 표현하기 어렵다, 그래서 그때 그때 이것이 확률변수인지 realization인지 따져봐야 한다\n참고: 정상시계열의 경우 ACF 만 정확하게 알아도 (반대로 PACF만 정확하게 알아도) 이론상 모든 모형을 특정할 수 있다. 즉 정상시계열의 모형을 특정하기 위해서는 ACF plot, PACF plot 하나만 있어도 충분하다. (Wold’s Thm은 떠올리면 모든 정상시계열은 무한MA로 유니크하게 표현할 수 있는데, 이는 PACF plot을 가지고 모든 정상시계열을 유니크하게 특정할 수 있다는 것을 의미한다) 다만 좀 더 모형을 특정하는 과정을 용이하게 하기 위해서 실전에서는 SACF plot 과 SPACF plot 을 함께 보는 것이 유리하다.\n\n(예제) AR(1) 모형\n왜 ACF의 모든정보를 \\({\\bf C}_{\\bf x}\\)로 부터 알수 있는지 코드를 통하여 실습하여 보자. (바로 이해된다면 사실 이 예제는 스킵해도 무방함) 아래와 같은 모형을 가정하자.\n\\[x_{t} = 0.5 x_{t-1} +\\epsilon_t\\]\n여기에서 \\(\\epsilon_t\\)는 서로 독립인 표준정규분포를 따른다. 이 모형에서 길이가 100인 시계열을 임의로 발생시키자.\n\nx = zeros(100*1000)\nx[1] = randn()\nfor t in 2:100\n    x[t] = 0.5*x[t-1] + randn()\nend\n\n모형에서 생성된 하나의 시계열을 시각화 하면 아래와 같다.\n\nplot(x) # 그냥 그려본것임. 별 의미는 없음\n\n\n\n\n\n\n\n\nlag=1일 경우 이 시계열의 SACF를 계산하면 아래와 같다.\n\nx[1:99] .* x[2:100]\n\n99-element Vector{Float64}:\n  1.587897526021493\n  1.130306190921068\n  0.5698214432110668\n  0.4648189302568683\n  0.3099446153360606\n  0.36362604534744775\n  0.8191871414624922\n -0.1720390842292145\n -0.06301214708310766\n  0.026414715508855904\n -0.007988283356933327\n -0.04178812545299474\n  0.22453267567940685\n  ⋮\n  3.931333581073927\n  1.315564948810858\n  0.9096080102581454\n  0.5410986320348997\n  0.29627801400693676\n  1.0673283524686212\n -1.0394649044573636\n  2.80195248208142\n  4.152973765526384\n  2.316315764368524\n  0.978758337765867\n -0.5840281943972468\n\n\n\n이 계산결과는 각 \\(t\\)에 대하여 \\(x_{t-1}x_t\\) 를 계산한 것과 같다.\n\n이 수열들의 평균은 아래와 같다.\n\nx[1:99] .* x[2:100] |&gt; mean\n\n0.5835563885014224\n\n\n\n이 계산결과는 \\(\\frac{1}{99}\\sum_{t=2}^{100} x_{t-1}x_t\\)를 계산한 것과 같다.\n\n이론적인 값인 0.5 근처의 값이 잘 나옴을 알 수 있다.\nlag=2일 경우도 마찬가지로 구할 수 있다.\n\nx[1:98] .* x[3:100] |&gt; mean\n\n0.38420263596668275\n\n\n이러한 숫자들은 그런데 \\({\\bf x}{\\bf x}^T\\)를 이용하여서도 구할 수 있다.10\n10 참고로 여기에서 \\({\\bf x}\\)는 확률벡터가 아니라 realization을 의미함\nx*x'\n\n100×100 Matrix{Float64}:\n  0.760108    1.5879      0.541064   …  -1.57394    -0.472676    0.939172\n  1.5879      3.31719     1.13031       -3.28802    -0.987441    1.96197\n  0.541064    1.13031     0.385143      -1.12037    -0.336463    0.668527\n  0.800507    1.67229     0.569821      -1.65759    -0.497799    0.989089\n  0.441361    0.922022    0.314172      -0.913915   -0.274462    0.545336\n  0.533784    1.1151      0.379961   …  -1.10529    -0.331936    0.659531\n  0.517803    1.08171     0.368586      -1.0722     -0.321998    0.639786\n  1.20252     2.51212     0.855987      -2.49003    -0.747794    1.48581\n -0.108745   -0.227173   -0.0774074      0.225175    0.0676234  -0.134363\n  0.440444    0.920106    0.313519      -0.912016   -0.273892    0.544203\n  0.0455859   0.0952309   0.0324492  …  -0.0943935  -0.0283478   0.0563249\n -0.133198   -0.278257   -0.0948139      0.27581     0.0828298  -0.164577\n  0.238468    0.498169    0.169748      -0.493789   -0.148292    0.294646\n  ⋮                                  ⋱                          \n  2.04697     4.2762      1.45708       -4.2386     -1.27291     2.52919\n  0.488514    1.02053     0.347736      -1.01155    -0.303784    0.603596\n  1.41531     2.95665     1.00746    …  -2.93065    -0.880119    1.74873\n  0.290602    0.60708     0.206858      -0.601742   -0.180712    0.359062\n  0.774954    1.61891     0.551632      -1.60468    -0.481908    0.957516\n  1.04688     2.18698     0.745197      -2.16775    -0.651007    1.2935\n -0.754723   -1.57665    -0.537231       1.56279     0.469328   -0.932519\n -2.82194    -5.89516    -2.00873    …   5.84333     1.75484    -3.48673\n -1.11863    -2.33686    -0.796269       2.31632     0.695624   -1.38215\n -1.57394    -3.28802    -1.12037        3.25911     0.978758   -1.94472\n -0.472676   -0.987441   -0.336463       0.978758    0.293936   -0.584028\n  0.939172    1.96197     0.668527      -1.94472    -0.584028    1.16042\n\n\n여기에서 각 원소들이 의미하는 바는 아래와 같다.\n\n대각선의 원소: \\(x_t^2,~ t=1,2,\\dots,100\\) 을 의미\n대각선 한칸 위, 혹은 한칸 아래: \\(x_{t-1} x_t~ t=2,3,\\dots,100\\) 을 의미\n대각선 두칸 위, 혹은 두칸 아래: \\(x_{t-2} x_t~ t=3,4,\\dots,100\\) 을 의미\n\n\n\n\nx*x'의 계산결과를 캡쳐한 그림, 이것은 \\(\\hat{\\bf C}_{\\bf x}\\)를 의미함\n\n\n확인해보자.\nlag=1, 스크린샷의 노란색\n\n(x[1:99] .* x[2:100])[1:5]\n\n5-element Vector{Float64}:\n 1.587897526021493\n 1.130306190921068\n 0.5698214432110668\n 0.4648189302568683\n 0.3099446153360606\n\n\n\nlag1에 해당하는 숫자들임. 이는 스크린샷에서 노란색으로 표현된 1.589, 1.13031, 0.569821 … 등과 일치한다.\n\nlag=2, 스크린샷의 빨간색\n\n(x[1:98] .* x[3:100])[1:5]\n\n5-element Vector{Float64}:\n 0.5410642277088621\n 1.6722932576420804\n 0.3141719983177106\n 0.5621541352252872\n 0.30066534927151267\n\n\n\nlag2에 해당하는 숫자들임. 이는 스크린샷에서 빨간색으로 표현된 숫자들인 0.54164, 1.67229, 0.31417 … 등과 일치한다.\n\n\n\n스펙트럼 방법\n지금까지는 정상시계열일 경우 ACF를 이용한 간단한 분석방법을 다시 복습했다. 그리고 \\({\\bf C}_{\\bf x}\\)가 ACF를 구함에 필요한 모든정보를 가지고 있음을 이해했다. 한편 \\({\\bf C}_{\\bf x}\\)은 positive definite matrix 이므로 아래와 같이 분해가능하다.\n\\[{\\bf C}_{\\bf x} = {\\bf V} \\text{diag}({\\bf p}) {\\bf V}^H\\]\n이 수식표현을 잘 해석하면 \\({\\bf C}_{\\bf x}\\)의 모든 정보는 \\({\\bf V}\\)와 \\({\\bf p}\\)에 담겨있다는 사실을 이해할 수 있다. 그런데 정상시계열일 경우 한정하여 \\({\\bf C}_{x}\\)의 고유벡터행렬은 \\({\\bf B}\\)의 고유벡터행렬과 일치한다는 사실을 알고 있다. 따라서 \\({\\bf V}\\)는 \\({\\bf B}\\)로 부터 그냥 알 수 있는 정보이다. 따라서 \\({\\bf C}_{\\bf x}\\)의 모든 정보는 \\({\\bf p}\\)에 담겨있다는 사실을 알 수 있다. 이는 적절한 \\({\\bf p}\\)를 추정하는 일은 적절한 \\({\\bf C}_{\\bf x}\\)를 추정하는 것과 같다는 사실을 알려준다.\n요약하면 아래와 같다.\n\n임의의 정상시계열은 이론적인 ACF (혹은 PACF)를 잘 추정하면 유니크하게 특정할 수 있다. (Wold’s Thm)\nACF를 잘 추정한다는 말은 \\({\\bf C}_{\\bf x}\\)를 잘 추정한다는 의미이다.\n그런데 \\({\\bf p}\\)를 잘 추정하면 \\({\\bf C}_{\\bf x}\\)를 잘 추정하는 일이 된다.\n따라서 임의의 정상시계열은 \\({\\bf p}\\)를 잘 추정하면 유니크하게 특정할 수 있다는 결론을 얻는다.\n\n여기에서 \\({\\bf p}\\)를 power spectral density 라고 부른다. 일반적으로 정상시계열을 분석하기 위해서는 \\({\\bf C}_{\\bf x}\\)를 특정하거나, \\({\\bf p}\\)를 특정하면 되는데 여기에서 \\({\\bf p}\\)를 특정한뒤 \\({\\bf p}\\)로 부터 \\({\\bf C}\\)를 역으로 해석하는 방법론을 spectral analysis라고 부른다. 경우에 따라서 \\({\\bf C}_{\\bf x}\\)를 특정하는 것이 용이할 수도 있지만 \\({\\bf p}\\)를 특정하고 해석하는 것이 용이할 때도 있다.\n그렇다면 주어진 시계열 \\({\\bf x}\\)에 대하여 \\({\\bf p}\\)를 어떻게 구할까? 직관적으로 생각하면 단순히 아래의 알고리즘으로 구하면 된다는 것을 알 수 있다.\n\n\\({\\bf C}_{\\bf x}\\)를 알아낸다.\n\\({\\bf C}_{\\bf x}\\)를 고유분해하여 \\({\\bf p}\\)를 구한다.\n\n또 다른 방법으로는 교재에 소개된 바 있는 아래의 수식을 이용하는 것이다.11\n11 이 수식이 성립하는 이유는 조금 손으로 써보면 금방 알 수 있음\\[{\\bf p}=\\mathbb{E}\\left[|{\\bf V}^H{\\bf x}|^2\\right]\\]\n이것을 이용하면 아래와 같은 알고리즘을 떠올릴 수 있다.\n\n\\({\\bf B}\\)의 고유벡터행렬 \\({\\bf V}\\)를 구하고 \\({\\bf V}^H{\\bf x}\\)를 계산한다.\n계산된 결과를 원소별로 제곱하여 \\({\\bf p}\\)를 얻는다.\n\n그런데 \\({\\bf V}^H{\\bf x}= {\\bf DFT} \\cdot {\\bf x}\\) 이므로 1의 과정을 아래와 같이 바꾸어 서술할 수 있다.\n\n\\({\\bf x}\\)를 퓨리에변환하여 \\(\\tilde{\\bf x} = {\\bf DFT} \\cdot {\\bf x}\\) 를 계산한다.\n\\(\\tilde{\\bf x}\\)를 원소별로 제곱하여 \\({\\bf p}\\)를 얻는다.\n\n즉 임의의 시계열을 퓨리에변환한 뒤 제곱하면 \\({\\bf p}\\)를 얻을 수 있다.\n(예제2) – 하나의 realization에서 \\(\\hat{\\bf p}\\)를 구해보자.\n(예제1에 이어서) 아래의 모형에서 생성된 \\({\\bf x}\\)를 다시 고려하자.\n\\[x_{t} = 0.5 x_{t-1} +\\epsilon_t\\]\n\nplot(x)\n\n\n\n\n\n\n\n\n이 자료의 PSD \\({\\bf p}\\)는 아래와 같이 구할 수 있다.\n단계1: \\({\\bf x}\\)의 DFT를 계산\n\nx̃ = fft(x) \n\n100-element Vector{ComplexF64}:\n  -5.756917285643583 + 0.0im\n   -19.0826720904921 - 1.0178306444775302im\n  14.230506824768984 - 11.867854578089997im\n  3.8980118254428726 + 1.2603018602424614im\n -16.157973053188194 + 27.488246322270918im\n   12.32574209329046 - 1.5134316695905219im\n    3.95421224972561 + 15.369129638224624im\n   9.516938110507798 + 19.371467179753544im\n  -19.38292930624831 + 9.49506288623419im\n  -7.853934851478428 + 4.134711886071571im\n -14.072349901900408 - 5.945064076174294im\n -14.596266922162355 + 3.447776409279256im\n   5.857720447482927 + 5.738895112838594im\n                     ⋮\n   5.857720447482924 - 5.738895112838594im\n -14.596266922162352 - 3.4477764092792564im\n -14.072349901900408 + 5.945064076174294im\n   -7.85393485147843 - 4.134711886071569im\n -19.382929306248315 - 9.49506288623419im\n   9.516938110507798 - 19.37146717975354im\n  3.9542122497256105 - 15.36912963822462im\n  12.325742093290458 + 1.5134316695905206im\n -16.157973053188194 - 27.488246322270925im\n  3.8980118254428717 - 1.260301860242461im\n  14.230506824768984 + 11.867854578089993im\n -19.082672090492103 + 1.0178306444775296im\n\n\n\n\\({\\bf B}\\)를 설정하고 고유값분해 하기 귀찮아서 그냥 DFT해주는 패키지 사용함\n\n단계2: \\(\\hat{\\bf p}\\)를 계산\n\np̂ = abs.(x̃).^2\n\n100-element Vector{Float64}:\n   33.14209663374188\n  365.18435333408365\n  343.3532967764883\n   16.782856970223087\n 1016.6837790613963\n  154.21439356883184\n  251.84594035243464\n  465.8258516955045\n  465.85416770456163\n   78.78013503208902\n  233.37481863133453\n  224.93817023139349\n   67.24780595702228\n    ⋮\n   67.24780595702225\n  224.93817023139337\n  233.37481863133453\n   78.78013503208902\n  465.8541677045618\n  465.8258516955044\n  251.84594035243452\n  154.2143935688318\n 1016.6837790613968\n   16.782856970223072\n  343.3532967764882\n  365.1843533340838\n\n\n참고\nfft(x) 대신에 아래의 코드를 이용해도 된다.\n\nN = 100 \nV = [i*j for i in 0:(N-1) for j in 0:(N-1)] |&gt; \n    x -&gt; reshape(x,(N,N)) .|&gt; \n    x -&gt; exp(im * (2π/N) * x)\nV'x\n\n100-element Vector{ComplexF64}:\n  -5.756917285643587 + 0.0im\n -19.082672090492103 - 1.0178306444775291im\n   14.23050682476898 - 11.867854578090007im\n  3.8980118254428824 + 1.2603018602424476im\n  -16.15797305318818 + 27.48824632227092im\n   12.32574209329044 - 1.5134316695905325im\n  3.9542122497256385 + 15.369129638224617im\n    9.51693811050782 + 19.371467179753516im\n  -19.38292930624826 + 9.495062886234233im\n -7.8539348514784155 + 4.134711886071595im\n -14.072349901900417 - 5.945064076174276im\n -14.596266922162371 + 3.447776409279244im\n   5.857720447482956 + 5.7388951128385735im\n                     ⋮\n   5.857720447482839 - 5.738895112838781im\n -14.596266922162307 - 3.4477764092792627im\n  -14.07234990190023 + 5.945064076174198im\n  -7.853934851478599 - 4.134711886071242im\n -19.382929306248577 - 9.49506288623372im\n   9.516938110507212 - 19.371467179753736im\n  3.9542122497250025 - 15.369129638224603im\n  12.325742093290597 + 1.5134316695903638im\n  -16.15797305318867 - 27.488246322270854im\n  3.8980118254424903 - 1.2603018602428118im\n  14.230506824769146 + 11.867854578089572im\n   -19.0826720904922 + 1.0178306444775123im\n\n\n진짜 똑같은지 확인\n\nfft(x)\n\n100-element Vector{ComplexF64}:\n  -5.756917285643583 + 0.0im\n   -19.0826720904921 - 1.0178306444775302im\n  14.230506824768984 - 11.867854578089997im\n  3.8980118254428726 + 1.2603018602424614im\n -16.157973053188194 + 27.488246322270918im\n   12.32574209329046 - 1.5134316695905219im\n    3.95421224972561 + 15.369129638224624im\n   9.516938110507798 + 19.371467179753544im\n  -19.38292930624831 + 9.49506288623419im\n  -7.853934851478428 + 4.134711886071571im\n -14.072349901900408 - 5.945064076174294im\n -14.596266922162355 + 3.447776409279256im\n   5.857720447482927 + 5.738895112838594im\n                     ⋮\n   5.857720447482924 - 5.738895112838594im\n -14.596266922162352 - 3.4477764092792564im\n -14.072349901900408 + 5.945064076174294im\n   -7.85393485147843 - 4.134711886071569im\n -19.382929306248315 - 9.49506288623419im\n   9.516938110507798 - 19.37146717975354im\n  3.9542122497256105 - 15.36912963822462im\n  12.325742093290458 + 1.5134316695905206im\n -16.157973053188194 - 27.488246322270925im\n  3.8980118254428717 - 1.260301860242461im\n  14.230506824768984 + 11.867854578089993im\n -19.082672090492103 + 1.0178306444775296im\n\n\n\n\n전통적인 방법과 스펙트럼 방법의 비교\n시계열자료의 전통적인 분석과 spectral analysis는 대충 아래의 과정으로 비교 설명할 수 있다.\n\n\n\n\n\n\n\n\n단계\n전통적인 방법\n스펙트럴 분석\n\n\n\n\n1\n\\({\\bf x}\\)의 plot을 그려봄\n\\({\\bf x}\\)의 plot을 그려봄\n\n\n2\nSACF plot, SPACF plot 을 그려봄\nPSD plot을 그려봄\n\n\n3\nACF를 추정 (=ARMA(\\(p\\),\\(q\\))에 대응하는 파라메터를 추정)\n\\({\\bf p}\\)를 추정\n\n\n4\n추정된 파라메터를 바탕으로 여러가지 분석 수행\n추정된 파라메터를 바탕으로 여러가지 분석 수행\n\n\n\n눈여겨 볼 점은 PSD plot의 존재이다. 전통적인 시계열에서 SACF plot 과 비슷하게 스펙트럼 방법에서 시계열을 분석하기 위해 필요한 매우 중요한 시각화 이다. 간단하게 비교를 하면 아래와 같다.\nSACF plot\n\nx축: lag=0, lag=1, ….\ny축: lag에 대응하는 상관계수값\n\nPSD plot\n\nx축: \\(\\Omega=\\big\\{\\frac{k}{N}:~ \\text{for}~ k=0,\\dots, N-1\\big\\}\\), 정규화된 freq를 의미함\ny축: 주파수에 대응하는 power값\n\n전통적인 방법에 비하여 스펙트럴 분석이 가지는 장점은 위의 표에서 소개한 일반적인 분석루틴이 시계열이 아닌 그래프신호로 쉽게 확장가능 하다는 점이다12. 따라서 앞으로는 전통적인 시계열 분석방법 대신 스펙트럴 분석만을 다룰 것이다. 스펙트럴 분석의 핵심적인 부분은 \\({\\bf p}\\)를 추정하는 방법과 추정량의 점근적 성질들을 파악하는 것이다. 이 포스트에서는 \\({\\bf p}\\)를 추정하는 방법만을 다룬다.\n12 퓨리에 변환대신에 그래프 퓨리에 변환을 이용하기만 하면된다"
  },
  {
    "objectID": "공부/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html#그래프신호에서의-psd의-추정",
    "href": "공부/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html#그래프신호에서의-psd의-추정",
    "title": "(공부) CGSP – Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "그래프신호에서의 PSD의 추정",
    "text": "그래프신호에서의 PSD의 추정\n이제 그래프 신호에서 \\({\\bf p}\\)를 추정하는 방법에 대하여 살펴보자. 그래프이동변환 (Graph Shift Operator, GSO)13 \\({\\bf S}={\\bf V}{\\bf \\Lambda}{\\bf V}^H\\)에 대하여 정상인 시계열 \\({\\bf x}\\)를 고려한다. 이 신호의 그래프퓨리에 변환14은 아래와 같이 구할 수 있다.\n13 Back shift operator의 일반화 버전14 좀 더 정확하게는 \\({\\bf V}^H\\) 에 대한 그래프 변환이라고 한다\\[\\tilde{\\bf x}={\\bf GFT} {\\bf x} = {\\bf V}^H{\\bf x}\\]\n여기에서 \\(\\tilde{\\bf x}\\)를 \\({\\bf x}\\)의 주파수응답(frequency representation)이라고 부른다.15 우리는 아래의 수식에서 \\({\\bf p}\\)의 값에 관심이 있다.\n15 이 \\(\\tilde{\\bf x}\\)를 그냥 graph Fourier transform이라고 부르는 사람도 많다. 즉 그래프퓨리에변환이 (1) 변환매트릭스 \\({\\bf GFT}\\)자체를 지칭할때도 있고 (2) 트랜스폼된 결과 \\(\\tilde{\\bf x}\\)를 지칭할때도 있음. 교재에서는 변환은 graph Fourier transform, 그리고 변환된 결과는 \\({\\bf x}\\)의 주파수응답이라고 한다.\\[{\\bf C}_{\\bf x}={\\bf V} \\text{diag}({\\bf p}){\\bf V}^H\\]\n여기에서 \\({\\bf p}\\)를 PSD (power spectrum density) 라고 한다. \\({\\bf p}\\)가 포함된 표현식은 위의 수식 이외에도 2개가 더 있다. 이를 모두 요약하면 아래와 같다16\n16 약간의 계산을 통하면 1,2,3이 쉽게 같은 수식임을 알 수 있음\n\\({\\bf C}_{\\bf x}={\\bf V} \\text{diag}({\\bf p}){\\bf V}^H\\)17\n\\({\\bf p}=\\mathbb{E}\\left[|{\\bf V}^H{\\bf x}|^2\\right]\\)\n\\({\\bf c}_{\\bf x} = \\sum_{i=1}^{N}p_i \\text{vec}({\\bf v}_i{\\bf v}_i^H) = {\\bf G}_{np} {\\bf p}\\)\n\n17 이 수식을 살짝 정리하면 \\({\\bf p}=\\text{diag}\\big({\\bf V}^H {\\bf C}_{\\bf x}{\\bf V} \\big)\\) 와 같이 보다 예쁜 수식을 얻을 수 있음위의 표현중 3.에서 \\({\\bf c}_{\\bf x}\\)은 \\({\\bf C}_x\\)를 벡터화한 것이며 \\({\\bf G}_{np}\\)는 \\({\\bf V}^\\ast\\) 와 \\({\\bf V}\\)를 열별-크로네커곱 (column-wise Kronecker product) 이다. 이때 \\({\\bf G}_{np}\\)의 정의가 조금 생소하니 한번 계산하여 보자.\n(예제) 아래와 같은 GSO \\({\\bf B}\\)를 고려하자.\n\nB= [0 1 0 0 \n    0 0 1 0 \n    0 0 0 1 \n    1 0 0 0]\n\n4×4 Matrix{Int64}:\n 0  1  0  0\n 0  0  1  0\n 0  0  0  1\n 1  0  0  0\n\n\n이러한 GSO에 대하여 \\({\\bf G}_{np}\\)는 아래와 같이 구할 수 있다.\n(1) \\({\\bf V}\\)를 정의\n\nV = [i*j for i in 0:3 for j in 0:3] |&gt; \n    x -&gt; reshape(x,(4,4)) .|&gt; \n    x -&gt; exp(im * (2π/4) * x) \n\n4×4 Matrix{ComplexF64}:\n 1.0+0.0im           1.0+0.0im          …           1.0+0.0im\n 1.0+0.0im   6.12323e-17+1.0im             -1.83697e-16-1.0im\n 1.0+0.0im          -1.0+1.22465e-16im             -1.0+3.67394e-16im\n 1.0+0.0im  -1.83697e-16-1.0im              5.51091e-16+1.0im\n\n\n(2) \\({\\bf G}_{np}={\\bf V}^{\\ast} \\odot {\\bf V}\\), 여기에서 \\(\\odot\\)은 열별-크로네커곱을 의미한다.\n\n# columnwise_kron은 위에서 정의한적 있음~\nGₙₚ = columnwise_kron(conj(V),V)\n\n16×4 Matrix{ComplexF64}:\n 1.0+0.0im           1.0+0.0im          …           1.0+0.0im\n 1.0+0.0im   6.12323e-17+1.0im             -1.83697e-16-1.0im\n 1.0+0.0im          -1.0+1.22465e-16im             -1.0+3.67394e-16im\n 1.0+0.0im  -1.83697e-16-1.0im              5.51091e-16+1.0im\n 1.0+0.0im   6.12323e-17-1.0im             -1.83697e-16+1.0im\n 1.0+0.0im           1.0+0.0im          …           1.0+0.0im\n 1.0+0.0im   6.12323e-17+1.0im             -1.83697e-16-1.0im\n 1.0+0.0im          -1.0+1.22465e-16im             -1.0+3.67394e-16im\n 1.0+0.0im          -1.0-1.22465e-16im             -1.0-3.67394e-16im\n 1.0+0.0im   6.12323e-17-1.0im             -1.83697e-16+1.0im\n 1.0+0.0im           1.0+0.0im          …           1.0+0.0im\n 1.0+0.0im   6.12323e-17+1.0im             -1.83697e-16-1.0im\n 1.0+0.0im  -1.83697e-16+1.0im              5.51091e-16-1.0im\n 1.0+0.0im          -1.0-1.22465e-16im             -1.0-3.67394e-16im\n 1.0+0.0im   6.12323e-17-1.0im             -1.83697e-16+1.0im\n 1.0+0.0im           1.0+0.0im          …           1.0+0.0im\n\n\n위에서 언급한 표현식 1,2,3 을 이용하면 \\({\\bf p}\\)를 추정하는 세 가지 방법을 각각 정의할 수 있다. 하나씩 살펴보자.\n\n1. \\({\\bf C}_{\\bf x}={\\bf V} \\text{diag}({\\bf p}){\\bf V}^H\\)\n확률과정 \\({\\bf x}\\)에서 \\(R\\)개의 realization \\(\\{{\\bf x}_1 \\dots {\\bf x}_R\\}\\) 을 관측하였다고 하자. 수식 \\({\\bf C}_{\\bf x}={\\bf V} \\text{diag}({\\bf p}){\\bf V}^H\\)를 적당히 변형하면 아래를 얻을 수 있다.\n\\[{\\bf p}=\\text{diag}\\big({\\bf V}^H {\\bf C}_{\\bf x}{\\bf V} \\big)\\]\n여기에서\n\\[{\\bf C}_{\\bf x}=\\mathbb{E}[{\\bf x}{\\bf x}^H]\\approx \\frac{1}{R}\\sum_{r=1}^R{\\bf x}_t{\\bf x}_r^H\\]\n이므로 이 수식에 근거하여 \\({\\bf p}\\)을 추정한다면 아래와 같이 할 수 있다.\n\\[\\hat{\\bf p}_{cg}:= \\text{diag}\\left({\\bf V}^H \\hat{\\bf C}_{\\bf x}{\\bf V} \\right):=\\text{diag}\\left[{\\bf V}^H\\big[ \\frac{1}{R}\\sum_{r=1}^R{\\bf x}_r{\\bf x}_r^H\\big]{\\bf V} \\right].\\]\n만약에 확률과정 \\({\\bf x}\\)에서 관측한 시계열이 \\({\\bf x}_r\\) 하나라면18, 즉 \\(R=1\\) 이라면 단순히 아래와 같이 쓸 수 있다.\n18 대부분은 관측한 시계열이 하나겠지..\\[\\hat{\\bf p}_{cg}:= \\text{diag}\\left({\\bf V}^H \\hat{\\bf C}_{\\bf x}{\\bf V} \\right):=\\text{diag}\\left[{\\bf V}^H{\\bf x}_r{\\bf x}_r^H{\\bf V} \\right].\\]\n\n주의: 여기에서 \\({\\bf V}^H {\\bf C}_{\\bf x}{\\bf V}\\) 는 항상 대각행렬이지만 \\({\\bf V}^H \\hat{\\bf C}_{\\bf x}{\\bf V}\\) 은 대각행렬이 아닐수도 있음을 유의하자. 즉 이론적인 모수는 대각행렬이지만 sample version은 대각행렬이 아닐 수 있다. 대각선이 아닌 원소는 버리면 된다.)\n\n\n아이디어: 혹시 대각선이 아닌 원소들을 이용하여 오차항 \\(\\epsilon_t\\)의 분산을 추정할 수도 있지 않을까? 이미 연구가 있겠지?\n\n(예제)\n\nN = 100 \nV = [i*j for i in 0:(N-1) for j in 0:(N-1)] |&gt; \n    x -&gt; reshape(x,(N,N)) .|&gt; \n    x -&gt; exp(im * (2π/N) * x)\n\n100×100 Matrix{ComplexF64}:\n 1.0+0.0im       1.0+0.0im        …       1.0+0.0im\n 1.0+0.0im  0.998027+0.0627905im     0.998027-0.0627905im\n 1.0+0.0im  0.992115+0.125333im      0.992115-0.125333im\n 1.0+0.0im  0.982287+0.187381im      0.982287-0.187381im\n 1.0+0.0im  0.968583+0.24869im       0.968583-0.24869im\n 1.0+0.0im  0.951057+0.309017im   …  0.951057-0.309017im\n 1.0+0.0im  0.929776+0.368125im      0.929776-0.368125im\n 1.0+0.0im  0.904827+0.425779im      0.904827-0.425779im\n 1.0+0.0im  0.876307+0.481754im      0.876307-0.481754im\n 1.0+0.0im  0.844328+0.535827im      0.844328-0.535827im\n 1.0+0.0im  0.809017+0.587785im   …  0.809017-0.587785im\n 1.0+0.0im  0.770513+0.637424im      0.770513-0.637424im\n 1.0+0.0im  0.728969+0.684547im      0.728969-0.684547im\n    ⋮                             ⋱  \n 1.0+0.0im  0.728969-0.684547im      0.728969+0.684547im\n 1.0+0.0im  0.770513-0.637424im      0.770513+0.637424im\n 1.0+0.0im  0.809017-0.587785im   …  0.809017+0.587785im\n 1.0+0.0im  0.844328-0.535827im      0.844328+0.535827im\n 1.0+0.0im  0.876307-0.481754im      0.876307+0.481754im\n 1.0+0.0im  0.904827-0.425779im      0.904827+0.425779im\n 1.0+0.0im  0.929776-0.368125im      0.929776+0.368125im\n 1.0+0.0im  0.951057-0.309017im   …  0.951057+0.309017im\n 1.0+0.0im  0.968583-0.24869im       0.968583+0.24869im\n 1.0+0.0im  0.982287-0.187381im      0.982287+0.187381im\n 1.0+0.0im  0.992115-0.125333im      0.992115+0.125333im\n 1.0+0.0im  0.998027-0.0627905im     0.998027+0.0627905im\n\n\n\np̂ = diag(V' * (x*x') * V)\n\n100-element Vector{ComplexF64}:\n 33.142096633741986 + 0.0im\n 365.18435333408354 + 1.5376069362644531e-13im\n  343.3532967764883 + 6.904176529646917e-14im\n 16.782856970223083 - 3.5538396658301444e-14im\n 1016.6837790613963 + 5.475049904926759e-15im\n 154.21439356883144 + 6.4512443306088e-14im\n  251.8459403524346 + 2.1316282072803006e-14im\n 465.82585169550384 + 1.816929057526117e-13im\n 465.85416770456044 + 4.1584439183295984e-14im\n    78.780135032089 + 1.3472456770553478e-14im\n 233.37481863133462 + 6.315728724701355e-14im\n 224.93817023139385 - 3.472109560086835e-14im\n  67.24780595702241 + 7.105427357601002e-14im\n                    ⋮\n   67.2478059570233 + 6.384723798533952e-14im\n 224.93817023139195 + 1.9727655769954595e-14im\n 233.37481863132837 - 2.1872689567834747e-14im\n    78.780135032089 + 1.917599080404094e-14im\n 465.85416770456294 + 4.808950231511622e-14im\n 465.82585169550094 - 4.890486289860305e-14im\n  251.8459403524291 + 2.0146681724568905e-14im\n  154.2143935688347 - 1.0948596967617507e-13im\n 1016.6837790614081 + 1.2114814701286432e-13im\n  16.78285697022108 + 2.376159104534641e-14im\n 343.35329677648286 + 1.1310381241837407e-14im\n 365.18435333408746 + 4.574214786667376e-14im\n\n\n\n\n2. \\({\\bf p}=\\mathbb{E}\\left[|{\\bf V}^H{\\bf x}|^2\\right]\\)\n확률과정 \\({\\bf x}\\)에서 \\(R\\)개의 realization \\(\\{{\\bf x}_1 \\dots {\\bf x}_R\\}\\) 을 관측하였다고 하자. 아래의 수식을 관찰하자.\n\\[{\\bf p}=\\mathbb{E}\\left[|{\\bf V}^H{\\bf x}|^2\\right]\\approx \\frac{1}{R}\\sum_{r=1}^{R} |{\\bf V}^H {\\bf x}_r|^2 \\]\n따라서 \\(\\frac{1}{R}\\sum_{r=1}^{R} |{\\bf V}^H {\\bf x}_r|^2\\) 를 PSD \\({\\bf p}\\)에 대한 추정량이라고 생각할 수 있다. 이러한 추정량을 기호로 \\(\\hat{\\bf p}_{pg}\\)라고 정의하고 periodogram이라고 부른다. 즉\n\\[\\hat{\\bf p}_{pg}=\\frac{1}{R}\\sum_{r=1}^{R} |{\\bf V}^H {\\bf x}_r|^2 \\]\n만약에 확률과정 \\({\\bf x}\\)에서 관측한 시계열이 \\({\\bf x}_r\\) 하나라면, 즉 \\(R=1\\) 이라면 단순히 아래와 같이 쓸 수 있다.\n\\[\\hat{\\bf p}_{pg}=|{\\bf V}^H {\\bf x}_r|^2 \\]\n즉 이 경우 \\(\\hat{\\bf p}_{pg}\\)는 단순히 관측시계열 \\({\\bf x}_r\\)의 그래프 퓨리에 변환 \\(\\tilde{\\bf x}={\\bf V}^H{\\bf x}_r\\) 결과에 절대값을 취하고 제곱한 것과 같다.\n(예제)\n스펙트럼방법챕터 예제2에서 이미 보여준 적 있다. 주어진 시계열 \\({\\bf x}\\)에 대하여 \\(\\hat{\\bf p}_{pg}\\)를 구하는 방법을 요약하면 아래와 같다.\n\nx̃ = fft(x) # 단계1: GFT, 이 신호는 시계열이라서 GFT대신에 DFT를 써도 된다.\np̂ = abs.(x̃).^2 # 단계2: hat p\n\n100-element Vector{Float64}:\n   33.14209663374188\n  365.18435333408365\n  343.3532967764883\n   16.782856970223087\n 1016.6837790613963\n  154.21439356883184\n  251.84594035243464\n  465.8258516955045\n  465.85416770456163\n   78.78013503208902\n  233.37481863133453\n  224.93817023139349\n   67.24780595702228\n    ⋮\n   67.24780595702225\n  224.93817023139337\n  233.37481863133453\n   78.78013503208902\n  465.8541677045618\n  465.8258516955044\n  251.84594035243452\n  154.2143935688318\n 1016.6837790613968\n   16.782856970223072\n  343.3532967764882\n  365.1843533340838\n\n\n\n\n3. \\({\\bf c}_{\\bf x} = {\\bf G}_{np} {\\bf p}\\)\n확률과정 \\({\\bf x}\\)에서 \\(R\\)개의 realization \\(\\{{\\bf x}_1 \\dots {\\bf x}_R\\}\\) 을 관측하였다고 하자. 아래의 수식을 관찰하자.\n\\[{\\bf C}_{\\bf x} = {\\bf V} \\text{diag}({\\bf p}) {\\bf V}^H\\]\n이 수식으로부터 아래를 얻을 수 있다.\n\\[{\\bf c}_{\\bf x} = \\sum_{i=1}^{N}p_i \\text{vec}({\\bf v}_i{\\bf v}_i^H) = {\\bf G}_{np} {\\bf p}\\]\n여기에서 \\({\\bf c}_{\\bf x}\\) 대신에 \\(\\hat{\\bf c}_{\\bf x}\\) 를 대입하면 아래와 같이 생각할 수 있다.\n\\[\\hat{\\bf c}_{\\bf x} \\approx  {\\bf G}_{np} {\\bf p}\\]\n이 문제는 아래와 같은 회귀모형으로 생각할 수 있다.\n\n\n\n\n\n\n\n\n\n회귀모형\n우리의 문제\n\n\n\n\n모형\n\\({\\bf y} \\approx {\\bf X}{\\boldsymbol \\beta}\\)\n\\(\\hat{\\bf c}_{\\bf x} \\approx {\\bf G}_{np}{\\bf p}\\)\n\n\n설명변수\n\\({\\bf X}\\)19\n\\({\\bf G}_{np}\\)20\n\n\n반응변수\n\\({\\bf y}\\)21\n\\(\\hat{\\bf c}_{\\bf x}\\)22\n\n\n추정하고 싶은 파라메터\n\\({\\boldsymbol \\beta}\\)23\n\\(\\hat{\\bf p}\\)24\n\n\n오차항\n대부분 정규분포를 가정\n??? 모르겠는데??\n\n\n\n19 (n,p) matrix20 (N²,N) matrix21 (n,1) col-vector22 (N²,1) col-vector23 (p,1) col-vector24 (N,1) col-vector회귀분석에서 아래의 수식이 익숙하다면\n\\[\n\\hat{\\boldsymbol \\beta}_{ls} = \\underset{\\boldsymbol \\beta}{\\operatorname{argmin}} \\|{\\bf y}-{\\bf X}{\\boldsymbol \\beta}\\|_2^2=({\\bf X}^T{\\bf X})^{-1}{\\bf X}^T{\\bf y}.\n\\]\n\\({\\bf p}\\)를 추정하기 위한 아래의 수식도 쉽게 이해할 수 있다. (의문: 그런데 왜 MSE를 손실함수로 쓰고 있는 거야? 오차항이 설마 정규분포?)\n\\[\n\\hat{\\bf p}_{ls} = \\underset{\\bf p}{\\operatorname{argmin}} \\|\\hat{\\bf c}_{\\bf x}-{\\bf G}_{np}{\\bf p}\\|_2^2=({\\bf G}_{np}^H{\\bf G}_{np})^{-1}{\\bf G}_{np}^H\\hat{\\bf c}_{\\bf x}.\n\\]\n(예제)\n(1) \\({\\bf V}\\)를 정의\n\nN = 100 \nV = [i*j for i in 0:(N-1) for j in 0:(N-1)] |&gt; \n    x -&gt; reshape(x,(N,N)) .|&gt; \n    x -&gt; exp(im * (2π/N) * x)\n\n100×100 Matrix{ComplexF64}:\n 1.0+0.0im       1.0+0.0im        …       1.0+0.0im\n 1.0+0.0im  0.998027+0.0627905im     0.998027-0.0627905im\n 1.0+0.0im  0.992115+0.125333im      0.992115-0.125333im\n 1.0+0.0im  0.982287+0.187381im      0.982287-0.187381im\n 1.0+0.0im  0.968583+0.24869im       0.968583-0.24869im\n 1.0+0.0im  0.951057+0.309017im   …  0.951057-0.309017im\n 1.0+0.0im  0.929776+0.368125im      0.929776-0.368125im\n 1.0+0.0im  0.904827+0.425779im      0.904827-0.425779im\n 1.0+0.0im  0.876307+0.481754im      0.876307-0.481754im\n 1.0+0.0im  0.844328+0.535827im      0.844328-0.535827im\n 1.0+0.0im  0.809017+0.587785im   …  0.809017-0.587785im\n 1.0+0.0im  0.770513+0.637424im      0.770513-0.637424im\n 1.0+0.0im  0.728969+0.684547im      0.728969-0.684547im\n    ⋮                             ⋱  \n 1.0+0.0im  0.728969-0.684547im      0.728969+0.684547im\n 1.0+0.0im  0.770513-0.637424im      0.770513+0.637424im\n 1.0+0.0im  0.809017-0.587785im   …  0.809017+0.587785im\n 1.0+0.0im  0.844328-0.535827im      0.844328+0.535827im\n 1.0+0.0im  0.876307-0.481754im      0.876307+0.481754im\n 1.0+0.0im  0.904827-0.425779im      0.904827+0.425779im\n 1.0+0.0im  0.929776-0.368125im      0.929776+0.368125im\n 1.0+0.0im  0.951057-0.309017im   …  0.951057+0.309017im\n 1.0+0.0im  0.968583-0.24869im       0.968583+0.24869im\n 1.0+0.0im  0.982287-0.187381im      0.982287+0.187381im\n 1.0+0.0im  0.992115-0.125333im      0.992115+0.125333im\n 1.0+0.0im  0.998027-0.0627905im     0.998027+0.0627905im\n\n\n(2) \\({\\bf G}_{np}={\\bf V}^{\\ast} \\odot {\\bf V}\\), 여기에서 \\(\\odot\\)은 열별-크로네커곱을 의미한다.\n\n# columnwise_kron은 위에서 정의한적 있음~\nGₙₚ = columnwise_kron(conj(V),V)\n\n10000×100 Matrix{ComplexF64}:\n 1.0+0.0im       1.0+0.0im        …       1.0+0.0im\n 1.0+0.0im  0.998027+0.0627905im     0.998027-0.0627905im\n 1.0+0.0im  0.992115+0.125333im      0.992115-0.125333im\n 1.0+0.0im  0.982287+0.187381im      0.982287-0.187381im\n 1.0+0.0im  0.968583+0.24869im       0.968583-0.24869im\n 1.0+0.0im  0.951057+0.309017im   …  0.951057-0.309017im\n 1.0+0.0im  0.929776+0.368125im      0.929776-0.368125im\n 1.0+0.0im  0.904827+0.425779im      0.904827-0.425779im\n 1.0+0.0im  0.876307+0.481754im      0.876307-0.481754im\n 1.0+0.0im  0.844328+0.535827im      0.844328-0.535827im\n 1.0+0.0im  0.809017+0.587785im   …  0.809017-0.587785im\n 1.0+0.0im  0.770513+0.637424im      0.770513-0.637424im\n 1.0+0.0im  0.728969+0.684547im      0.728969-0.684547im\n    ⋮                             ⋱  \n 1.0+0.0im  0.770513-0.637424im      0.770513+0.637424im\n 1.0+0.0im  0.809017-0.587785im      0.809017+0.587785im\n 1.0+0.0im  0.844328-0.535827im   …  0.844328+0.535827im\n 1.0+0.0im  0.876307-0.481754im      0.876307+0.481754im\n 1.0+0.0im  0.904827-0.425779im      0.904827+0.425779im\n 1.0+0.0im  0.929776-0.368125im      0.929776+0.368125im\n 1.0+0.0im  0.951057-0.309017im      0.951057+0.309017im\n 1.0+0.0im  0.968583-0.24869im    …  0.968583+0.24869im\n 1.0+0.0im  0.982287-0.187381im      0.982287+0.187381im\n 1.0+0.0im  0.992115-0.125333im      0.992115+0.125333im\n 1.0+0.0im  0.998027-0.0627905im     0.998027+0.0627905im\n 1.0+0.0im       1.0+0.0im                1.0+0.0im\n\n\n(3) \\(\\hat{\\bf p}_{ls}=({\\bf G}_{np}^H{\\bf G}_{np})^{-1}{\\bf G}_{np}^H\\hat{\\bf c}_{\\bf x}\\)\n\nĉₓ = vec(x*x')\np̂ = inv(Gₙₚ' * Gₙₚ) * Gₙₚ' * ĉₓ \n\n100-element Vector{ComplexF64}:\n  0.003314209663374193 - 2.7356277964988863e-19im\n   0.03651843533340838 - 4.01518191768058e-18im\n   0.03433532967764885 + 2.515448157755484e-17im\n 0.0016782856970223292 - 1.0070028487673847e-17im\n   0.10166837790613971 + 3.1129277935880596e-18im\n  0.015421439356883134 + 9.403422807142065e-18im\n  0.025184594035243472 - 3.993782799800785e-18im\n   0.04658258516955039 - 1.850761436988587e-18im\n   0.04658541677045607 + 1.1559103895961936e-17im\n  0.007878013503208905 + 3.559698092088507e-18im\n  0.023337481863133468 + 2.6204945155857973e-18im\n   0.02249381702313939 + 5.304406111488559e-18im\n  0.006724780595702225 - 1.655564138463681e-17im\n                       ⋮\n  0.006724780595702329 + 1.8121162053534517e-18im\n  0.022493817023139205 - 1.0461976779111972e-17im\n   0.02333748186313285 - 6.792203007975684e-18im\n  0.007878013503208907 - 2.3575339315335667e-18im\n  0.046585416770456294 + 1.5392042695643853e-17im\n  0.046582585169550106 - 1.123245521985718e-17im\n  0.025184594035242928 + 1.1628578774983873e-18im\n  0.015421439356883466 + 5.864828990948797e-18im\n   0.10166837790614085 + 2.2712943512935246e-17im\n 0.0016782856970221013 + 4.829637376114682e-18im\n   0.03433532967764831 + 3.3208196889839756e-19im\n  0.036518435333408754 + 1.3795822112205515e-17im\n\n\n\n?? 뭔가 스케일이 안맞음\n\n\nN^2 * p̂\n\n100-element Vector{ComplexF64}:\n  33.14209663374193 - 2.7356277964988864e-15im\n 365.18435333408377 - 4.0151819176805797e-14im\n  343.3532967764885 + 2.515448157755484e-13im\n 16.782856970223293 - 1.0070028487673847e-13im\n 1016.6837790613971 + 3.1129277935880596e-14im\n 154.21439356883135 + 9.403422807142065e-14im\n 251.84594035243472 - 3.9937827998007846e-14im\n  465.8258516955039 - 1.850761436988587e-14im\n  465.8541677045607 + 1.1559103895961937e-13im\n  78.78013503208905 + 3.559698092088507e-14im\n 233.37481863133468 + 2.6204945155857973e-14im\n 224.93817023139388 + 5.304406111488559e-14im\n  67.24780595702225 - 1.655564138463681e-13im\n                    ⋮\n  67.24780595702329 + 1.8121162053534517e-14im\n 224.93817023139206 - 1.0461976779111972e-13im\n  233.3748186313285 - 6.792203007975684e-14im\n  78.78013503208906 - 2.3575339315335666e-14im\n 465.85416770456294 + 1.5392042695643854e-13im\n 465.82585169550106 - 1.123245521985718e-13im\n 251.84594035242927 + 1.1628578774983874e-14im\n 154.21439356883465 + 5.864828990948797e-14im\n 1016.6837790614085 + 2.2712943512935246e-13im\n  16.78285697022101 + 4.8296373761146824e-14im\n  343.3532967764831 + 3.3208196889839758e-15im\n  365.1843533340875 + 1.3795822112205514e-13im\n\n\n\n\\(N^2\\)를 곱해주니까 아까부터 구하던 값이 그대로 잘 나옴. (\\({\\bf DFT}\\) 혹은 \\({\\bf GFT}\\)를 정의할때 \\(\\frac{1}{\\sqrt N}\\)으로 스케일링 하느냐 마느냐 차이때문에 생기는 현상임)"
  },
  {
    "objectID": "공부/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html#의문점",
    "href": "공부/CGSP/2022-12-27-Chap-12.2.1~12.3.1.html#의문점",
    "title": "(공부) CGSP – Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "의문점",
    "text": "의문점\n아래의 그림을 살펴보자.\n\n\n\n그림12.3(교재에서 긁어온 그림): Power spectral density estimation. All estimators are based on the same random process defined on the Karate club network (Zachary 1977). (A) Periodogram estimation with different numbers of observations. (B) Windowed average periodogram from a single realization and a different number of windows. (C) Windowed average periodogram for four windows and a varying number of realizations. (D) Parametric MA estimation for 1 and 10 realizations.\n\n\n이 그림은 다양한 방법으로 true PSD \\({\\bf p}\\)를 추정한 결과를 나타내는 PSD plot 이다25. 우리가 적용한 방법은 (A)에서 \\(R=1\\)일 경우이다. 보는것 처럼 true PSD 를 놀라울 정도로 제대로 추정하지 못한다26. 만약에 우리가 모형에서 하나의 시계열이 아니라 1000개의 정도의 시계열을 관측하였다면 좀 더 합리적으로 추정할 수 있다. 그런데 사실 하나의 모형에서 1000개씩이나 되는 시계열을 관측하는 일은 현실적으로 불가능하다27 따라서 우리는 비교적 적은 \\(R\\)에서 합리적인 PSD의 추정치를 이끌어내야 한다. 그림 (B),(C)는 상대적으로 적은 \\(R\\)에 대해 \\({\\bf p}\\)를 추정하는 windowed periodogram 을 이용하여 PSD를 추정한 결과이다. (C)를 살펴보면 \\(R=1\\) 일경우 \\({\\bf p}\\)를 추정한 값들이 나와있는데 (A)와 비교하면 꽤 합리적으로 보인다.\n25 x축이 freq, y축이 PSD26 맞추는게 없는 것 같은데?27 그리고 대부분 \\(R=1\\)이지..28 약간 바이어스가 있어보이긴 하는데, 우연히 생긴건지 이론적으로 항상 생기는 건지는 잘 모르겠네?29 이런걸 세미파라메트릭 모형이라고 해요30 그래서 플랏을 보면서 적당한 ARMA를 찾을 필요도 없고, AIC 니 BIC 를 따져가면서 모형선택을 할 필요도 없고31 적합이후에 잔차분석 같은거 안해도 된다는 의미문제는 (A)-(C)에서 제안된 방법 모두가 (D)에 제시된 전통적인 방법에 비하여 퍼포먼스가 떨어진다는 것이다. (D)는 parametric 모형을 사용한 결과이다. 파라메트릭 방법이므로 특정 모델을 한정하고 거기에 대응하는 한두개의 모수만 추정하면 되므로 추정이 잘 된다.28 반면 (A)-(C)의 경우 한 두개의 파라메터가 아니라 \\({\\bf p}\\)의 모든 원소를 추정해야하므로 추정할 파라메터가 데이터의 수 \\(N\\)과 같다29. 따라서 추정치의 분산이 크다. 사실 이것은 파라메트릭 방법과 세미파라메트릭 방법이라는 구조적인 차이때문에 어쩔 수 없는 것 같다. 그래도 세미파라메트릭 방법은 머리아프게 모델링을 할 필요가 없고30 내가 적합한 모델이 맞는지 확인할 필요도 없다31는 장점이 있다.\n아래는 나름 PSD를 추정하는 신기술인 것 같다.\n\n\n\n그림12.4(교재에서 긁어온 그림): PSD estimation from a subset of nodes. Estimators are based on a random process defined on the Karate club network (Zachary 1977). (A) Graph sampling for nonparametric PSD estimation. Here, 20 out of 34 nodes are observed. The sampled nodes are highlighted by the circles around the nodes. (B) Nonparametric PSD estimation based on observations from 20 nodes and 100 data snapshots. (C) Graph sampling for parametric MA PSD estimation. Here, 4 out of 34 nodes are observed. (D) Parametric MA PSD estimation based on observations from 4 nodes and 100 data snapshots.\n\nZachary, Wayne W. 1977. “An Information Flow Model for Conflict and Fission in Small Groups.” Journal of Anthropological Research 33 (4): 452–73.\n\n\n그래프신호의 sub-sampling을 이용하는 것 같은데 교재의 뒤쪽에 서술되어있다. \\(R=100\\)임을 고려하여도 퍼포먼스가 좋은 편인듯 하다32.\n\n\n32 내 생각엔 이게 핵심 기술인 것 같음"
  },
  {
    "objectID": "공부/CGSP/2022-12-24-Chap-8.3.html",
    "href": "공부/CGSP/2022-12-24-Chap-8.3.html",
    "title": "(공부) CGSP – Chap 8.3: Discrete Fourier Transform",
    "section": "",
    "text": "using LinearAlgebra, FFTW"
  },
  {
    "objectID": "공부/CGSP/2022-12-24-Chap-8.3.html#cyclic-shfit-operator-bf-b",
    "href": "공부/CGSP/2022-12-24-Chap-8.3.html#cyclic-shfit-operator-bf-b",
    "title": "(공부) CGSP – Chap 8.3: Discrete Fourier Transform",
    "section": "Cyclic shfit operator \\({\\bf B}\\)",
    "text": "Cyclic shfit operator \\({\\bf B}\\)\nThe matrix \\({\\bf B}\\) representing the periodic shift is\n\nB= [0 0 0 0 1\n    1 0 0 0 0 \n    0 1 0 0 0\n    0 0 1 0 0\n    0 0 0 1 0]\n\n5×5 Matrix{Int64}:\n 0  0  0  0  1\n 1  0  0  0  0\n 0  1  0  0  0\n 0  0  1  0  0\n 0  0  0  1  0\n\n\nThis matrix is the cyclic shift.\nnote: \\({\\bf B}\\) is orthogonal matrix.\n\nB'B\n\n5×5 Matrix{Int64}:\n 1  0  0  0  0\n 0  1  0  0  0\n 0  0  1  0  0\n 0  0  0  1  0\n 0  0  0  0  1\n\n\n(ex1) Define \\({\\bf s}\\) as\n\ns = [1,2,3,4,5]\ns\n\n5-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 5\n\n\nObserve that\n\nB*s\n\n5-element Vector{Int64}:\n 5\n 1\n 2\n 3\n 4\n\n\n\nB^2*s\n\n5-element Vector{Int64}:\n 4\n 5\n 1\n 2\n 3\n\n\n\nB^3*s\n\n5-element Vector{Int64}:\n 3\n 4\n 5\n 1\n 2\n\n\nThus we can interprete the matrix \\({\\bf B}\\) as cyclic shift operator such that\n\\[\n{\\bf B}s_n =s_{n-1}\n\\]\nfor \\(n=1,\\dots, N-1\\) and \\({\\bf B}s_0 =s_N\\).\nnote: \\({\\bf B}\\)는 시계열에서 다루는 backshift operator 와 비슷함."
  },
  {
    "objectID": "공부/CGSP/2022-12-24-Chap-8.3.html#dft",
    "href": "공부/CGSP/2022-12-24-Chap-8.3.html#dft",
    "title": "(공부) CGSP – Chap 8.3: Discrete Fourier Transform",
    "section": "DFT",
    "text": "DFT\nThe matrix \\({\\bf B}\\) can be expressed as\n\\({\\bf B}={\\bf DFT}^\\ast \\cdot {\\bf \\Lambda} \\cdot {\\bf DFT}\\)\nwhere \\({\\bf DFT}\\) is unitary and symmetric matrix and \\(\\bf \\Lambda\\) is diagonal matrix.\n\nλ, Ψ = eigen(B)\n\nEigen{ComplexF64, ComplexF64, Matrix{ComplexF64}, Vector{ComplexF64}}\nvalues:\n5-element Vector{ComplexF64}:\n -0.8090169943749472 - 0.5877852522924725im\n -0.8090169943749472 + 0.5877852522924725im\n 0.30901699437494734 - 0.9510565162951536im\n 0.30901699437494734 + 0.9510565162951536im\n  0.9999999999999998 + 0.0im\nvectors:\n5×5 Matrix{ComplexF64}:\n  0.138197+0.425325im   0.138197-0.425325im  …  0.447214+0.0im\n -0.361803-0.262866im  -0.361803+0.262866im     0.447214+0.0im\n  0.447214-0.0im        0.447214+0.0im          0.447214+0.0im\n -0.361803+0.262866im  -0.361803-0.262866im     0.447214+0.0im\n  0.138197-0.425325im   0.138197+0.425325im     0.447214+0.0im\n\n\n\nB ≈ Ψ * Diagonal(λ) * Ψ'\n\ntrue\n\n\nDefine \\({\\boldsymbol \\Psi}^\\ast={\\bf DFT}\\).\n\nDFT = Ψ'\n\n5×5 adjoint(::Matrix{ComplexF64}) with eltype ComplexF64:\n  0.138197-0.425325im  -0.361803+0.262866im  …  0.138197+0.425325im\n  0.138197+0.425325im  -0.361803-0.262866im     0.138197-0.425325im\n -0.361803-0.262866im  -0.361803+0.262866im     0.138197-0.425325im\n -0.361803+0.262866im  -0.361803-0.262866im     0.138197+0.425325im\n  0.447214-0.0im        0.447214-0.0im          0.447214-0.0im\n\n\nNote that the eigenvalues are not ordered in julia.\n\nλ[5], exp(-im* 2π/5 * 0)\n\n(0.9999999999999998 + 0.0im, 1.0 - 0.0im)\n\n\n\nλ[3], exp(-im* 2π/5 * 1)\n\n(0.30901699437494734 - 0.9510565162951536im, 0.30901699437494745 - 0.9510565162951535im)\n\n\n\nλ[1], exp(-im* 2π/5 * 2)\n\n(-0.8090169943749472 - 0.5877852522924725im, -0.8090169943749473 - 0.5877852522924732im)\n\n\n\nλ[2], exp(-im* 2π/5 * 3)\n\n(-0.8090169943749472 + 0.5877852522924725im, -0.8090169943749475 + 0.587785252292473im)"
  },
  {
    "objectID": "공부/CGSP/2022-12-24-Chap-8.3.html#spectral-components-and-frequencies",
    "href": "공부/CGSP/2022-12-24-Chap-8.3.html#spectral-components-and-frequencies",
    "title": "(공부) CGSP – Chap 8.3: Discrete Fourier Transform",
    "section": "Spectral components and Frequencies",
    "text": "Spectral components and Frequencies\nWe remark:\n(1) Spectral components: For \\(k = 0,1,2,\\dots, N-1\\), the \\(k\\)-th column of \\({\\bf DFT}^\\ast\\) is defined by\n\\[\\Psi_k:=\\frac{1}{\\sqrt{N}}\\begin{bmatrix} 1 \\\\ e^{j\\frac{2\\pi}{N}k} \\\\ e^{j\\frac{2\\pi}{N}2k} \\\\ e^{j\\frac{2\\pi}{N}3k} \\\\  \\dots \\\\ e^{j\\frac{2\\pi}{N}(N-1)k} \\end{bmatrix}.\\]\nNote that \\(\\Psi_k\\) can be also interpreted as \\(\\ell\\)-th eigenvector of \\({\\bf A}\\) correspoding \\(\\lambda_\\ell = e^{-j\\frac{2\\pi}{N}k}\\). Those eigenvectors\n\\[\\big\\{{\\bf 1},\\Psi_1,\\Psi_2, \\dots, \\Psi_{N-1}\\big\\}\\]\nform a complete orthonomal basis of \\(\\mathbb{C}^N\\). These vectors are called spectral components.\n(2) Frequencies: The diagonal entries of \\({\\bf \\Lambda}\\) are the eigenvalues of the time shift \\({\\bf B}\\). In Physics and in operator theory, these eigenvalues are the frequencies of the signal. In DSP it is more common to call frequencies\n\\[\\Omega_k=\\frac{-1}{2\\pi j}\\ln\\lambda_k=\\frac{-1}{2\\pi j}\\ln e^{-j \\frac{2\\pi}{N}k}=\\frac{k}{N}, \\quad k=0,1,2,\\dots,N-1.\\]\n\nThe \\(N\\) (time) frequencies \\(\\Omega_k\\) are all distinct, positive, equally spaced, and increasing from \\(0\\) to \\(\\frac{N-1}{N}\\). The spectral components are the complex exponential sinusiodal functions. For example, corresponding to the zero frequency is the DC spectral component (a vector whose entries are constant and all equal to \\(\\frac{1}{\\sqrt{N}}\\))."
  },
  {
    "objectID": "공부/CGSP/2022-12-24-Chap-8.3.html#dft-1",
    "href": "공부/CGSP/2022-12-24-Chap-8.3.html#dft-1",
    "title": "(공부) CGSP – Chap 8.3: Discrete Fourier Transform",
    "section": "DFT",
    "text": "DFT\n일반적으로 우리가 알고있는 DFT1는 아래와 같다. (이 그림은 위키피디아에서 캡쳐한 것이다)\n1 discrete Fourier transform\n\n\n그림1: 위키에서 긁어온 DFT의 정의\n\n\n즉 DFT는 임의의 신호 \\(\\{{\\bf x}_n\\}:=x_0,x_1,\\dots,x_{N-1}\\)를 적당한 규칙2에 따라서 \\(\\{{\\bf X}_k\\}:=X_0,X_1,\\dots,X_{N-1}\\)로 바꾸는 변환을 이라고 이해할 수 있다. 이때 사용되는 적당한 규칙은 구체적으로 아래의 수식을 의미한다.\n2 \\(X_k = \\sum_{n=0}^{N-1}x_n\\cdot e^{-i\\frac{2\\pi}{N}kn}\\)\\[X_k = \\sum_{n=0}^{N-1}x_n\\cdot e^{-i\\frac{2\\pi}{N}kn}\\]\n그런데 매트릭스를 활용하면 위의 수식을 아래와 같이 표현할 수 있다.\n\\[\\begin{bmatrix} X_1 \\\\ X_2 \\\\ X_3 \\\\ \\dots \\\\ X_{N-1} \\end{bmatrix}\n=\\begin{bmatrix}\n1 & 1 & 1 & \\dots & 1 \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 1} & e^{-i \\frac{2\\pi}{N}\\cdot 2} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)}\\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 2} & e^{-i \\frac{2\\pi}{N}\\cdot 4} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)}\\\\\n\\dots & \\dots & \\dots & \\dots & \\dots \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)} & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)^2}\n\\end{bmatrix}\n\\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ \\dots \\\\ x_{N-1} \\end{bmatrix}\\]\n편의상 \\({\\bf X}\\)와 \\({\\bf x}\\)를 \\(N \\times 1\\) col-vec이라고 생각하고 DFT를 아래와 같은 matrix로 정의하자.\n\\[{\\bf DFT} = \\begin{bmatrix}\n1 & 1 & 1 & \\dots & 1 \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 1} & e^{-i \\frac{2\\pi}{N}\\cdot 2} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)}\\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 2} & e^{-i \\frac{2\\pi}{N}\\cdot 4} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)}\\\\\n\\dots & \\dots & \\dots & \\dots & \\dots \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)} & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)^2}\n    \\end{bmatrix}\\]\n그러면\n\\[{\\bf X} = {\\bf DFT} \\cdot {\\bf x}\\]\n와 같이 표현할 수 있고 \\({\\bf x}\\)에서 \\({\\bf X}\\)로 바꾸는 과정을 단순히 \\({\\bf DFT}\\)행렬을 \\({\\bf x}\\)의 왼쪽에 곱하는 과정으로 이해할 수 있다.\n(참고) 사실 아래와 같이 \\({\\bf DFT}\\)를 정의하는 버전도 있다. (둘이 혼용해서 쓰인다)\n\\[{\\bf DFT} = \\frac{1}{\\sqrt{N}}\\begin{bmatrix}\n1 & 1 & 1 & \\dots & 1 \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 1} & e^{-i \\frac{2\\pi}{N}\\cdot 2} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)}\\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 2} & e^{-i \\frac{2\\pi}{N}\\cdot 4} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)}\\\\\n\\dots & \\dots & \\dots & \\dots & \\dots \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)} & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)^2}\n    \\end{bmatrix}\\]\n\n예제1 아래는 위키에서 긁어온 예제이다. 이 예제를 따라가보자.\n\n\n\n그림2: 위키에서 긁어온 예제이미지\n\n\n예제를 풀기위해서 우선 아래와 같은 벡터를 선언하다.\n\nx = [1, 2-im, -im, -1+2im]\n\n4-element Vector{Complex{Int64}}:\n  1 + 0im\n  2 - 1im\n  0 - 1im\n -1 + 2im\n\n\n(풀이1)\n\\(4\\times 4\\)의 크기를 가지는 DFT행렬을 선언한다.\n(step1) 아래의 매트릭스 생성\n\n_DFT = reshape([i*j for i in 0:3 for j in 0:3], (4,4))\n_DFT\n\n4×4 Matrix{Int64}:\n 0  0  0  0\n 0  1  2  3\n 0  2  4  6\n 0  3  6  9\n\n\n(step2) _DFT의 각 원소에 함수 \\(f: x \\to \\exp(-i\\frac{2\\pi}{4}x)\\)를 취함\n\nf = x -&gt; exp(-im * (2π/4) * x)\nDFT = _DFT .|&gt; f\n\n4×4 Matrix{ComplexF64}:\n 1.0-0.0im           1.0-0.0im          …           1.0-0.0im\n 1.0-0.0im   6.12323e-17-1.0im             -1.83697e-16+1.0im\n 1.0-0.0im          -1.0-1.22465e-16im             -1.0-3.67394e-16im\n 1.0-0.0im  -1.83697e-16+1.0im              5.51091e-16-1.0im\n\n\n이제 \\({\\bf X}\\)를 구하면 아래와 같다.\n\nDFT * x\n\n4-element Vector{ComplexF64}:\n                   2.0 + 0.0im\n   -1.9999999999999998 - 2.0000000000000004im\n 8.881784197001252e-16 - 1.9999999999999998im\n    3.9999999999999987 + 4.000000000000001im\n\n\n위키의 답이 잘 나옴\n(풀이2)\n참고로 아래와 같이 패키지를 이용하여 구할 수도 있다.\n\nfft(x)\n\n4-element Vector{ComplexF64}:\n  2.0 + 0.0im\n -2.0 - 2.0im\n  0.0 - 2.0im\n  4.0 + 4.0im"
  },
  {
    "objectID": "공부/CGSP/2022-12-24-Chap-8.3.html#inverse-dft",
    "href": "공부/CGSP/2022-12-24-Chap-8.3.html#inverse-dft",
    "title": "(공부) CGSP – Chap 8.3: Discrete Fourier Transform",
    "section": "Inverse DFT",
    "text": "Inverse DFT\n앞으로는 \\({\\bf DFT}\\)를 아래와 같이 정의하자.\n\\[{\\bf DFT} = \\frac{1}{\\sqrt{N}}\\begin{bmatrix}\n1 & 1 & 1 & \\dots & 1 \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 1} & e^{-i \\frac{2\\pi}{N}\\cdot 2} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)}\\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 2} & e^{-i \\frac{2\\pi}{N}\\cdot 4} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)}\\\\\n\\dots & \\dots & \\dots & \\dots & \\dots \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)} & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)^2}\n    \\end{bmatrix}\\]\n\\({\\bf DFT}\\)행렬에는 몇 가지 특징이 있다.\n특징1: 유니터리행렬이다. 즉 \\({\\bf DFT}^\\ast \\cdot {\\bf DFT} = {\\bf DFT}^\\ast \\cdot{\\bf DFT} = {\\bf I}\\) 이다.\n\n_DFT = reshape([i*j for i in 0:3 for j in 0:3], (4,4))\nf = x -&gt; exp(-im * (2π/4) * x)\nDFT = _DFT .|&gt; f\nDFT # 아까의 예제의 DFT!\n\n4×4 Matrix{ComplexF64}:\n 1.0-0.0im           1.0-0.0im          …           1.0-0.0im\n 1.0-0.0im   6.12323e-17-1.0im             -1.83697e-16+1.0im\n 1.0-0.0im          -1.0-1.22465e-16im             -1.0-3.67394e-16im\n 1.0-0.0im  -1.83697e-16+1.0im              5.51091e-16-1.0im\n\n\n\nDFT = (1/√4)*DFT # 새로운 DFT의 정의 \nDFT'DFT .|&gt; round # 유니터리행렬임을 확인!\n\n4×4 Matrix{ComplexF64}:\n  1.0+0.0im  -0.0-0.0im   0.0-0.0im   0.0-0.0im\n -0.0+0.0im   1.0+0.0im  -0.0-0.0im   0.0-0.0im\n  0.0+0.0im  -0.0+0.0im   1.0+0.0im  -0.0-0.0im\n  0.0+0.0im   0.0+0.0im  -0.0+0.0im   1.0+0.0im\n\n\n특징2: \\({\\bf DFT}\\)는 대칭행렬이다. 따라서 이 행렬의 켤레전치는 DFT의 각 원소에서 단순히 \\(i=\\sqrt{-1}\\) 대신에 \\(-i\\) 를 넣은 것과 같다.\n특징1-2를 조합하면 아래와 같이 \\({\\bf DFT}\\)에서 \\(i\\) 대신에 \\(-i\\)를 넣은 행렬이 변환 DFT를 취소시킬 수 있음을 이해할 수 있다. 3\n3 아래의 행렬은 \\({\\bf DFT}^\\ast\\) 혹은 \\({\\bf DFT}\\)의 conjugate matrix 혹은 \\({\\bf DFT}^{-1}\\)로 생각할 수 있음\\[\\frac{1}{\\sqrt{N}}\\begin{bmatrix}\n1 & 1 & 1 & \\dots & 1 \\\\\n1 & e^{i \\frac{2\\pi}{N}\\cdot 1} & e^{i \\frac{2\\pi}{N}\\cdot 2} & \\dots & e^{i \\frac{2\\pi}{N}\\cdot (N-1)}\\\\\n1 & e^{i \\frac{2\\pi}{N}\\cdot 2} & e^{i \\frac{2\\pi}{N}\\cdot 4} & \\dots & e^{i \\frac{2\\pi}{N}\\cdot 2(N-1)}\\\\\n\\dots & \\dots & \\dots & \\dots & \\dots \\\\\n1 & e^{i \\frac{2\\pi}{N}\\cdot (N-1)} & e^{i \\frac{2\\pi}{N}\\cdot 2(N-1)} & \\dots & e^{i \\frac{2\\pi}{N}\\cdot (N-1)^2}\n    \\end{bmatrix}\\]\n행렬 \\({\\bf DFT}\\)를 discrete Fourier transform으로 생각했듯이 위의 행렬을 inverse discrete Fourier transform으로 해석할 수 있다."
  },
  {
    "objectID": "공부/CGSP/2022-12-24-Chap-8.3.html#dft의-또-다른-정의",
    "href": "공부/CGSP/2022-12-24-Chap-8.3.html#dft의-또-다른-정의",
    "title": "(공부) CGSP – Chap 8.3: Discrete Fourier Transform",
    "section": "DFT의 또 다른 정의",
    "text": "DFT의 또 다른 정의\n이번에는 \\({\\bf DFT}\\)에 대한 다른 정의를 생각해보자. 우선 아래와 같은 행렬 \\({\\bf B}\\)를 고려하자.\n\nB= [0 0 0 1 \n    1 0 0 0 \n    0 1 0 0\n    0 0 1 0]\n\n4×4 Matrix{Int64}:\n 0  0  0  1\n 1  0  0  0\n 0  1  0  0\n 0  0  1  0\n\n\n이것은 길이가 4인 임의의 column vector를 아래로 한칸씩 이동시키는 매트릭스이다.\n\nx = [1, 2-im, -im, -1+2im]\n\n4-element Vector{Complex{Int64}}:\n  1 + 0im\n  2 - 1im\n  0 - 1im\n -1 + 2im\n\n\n\nB*x # 아래로 한칸이동 \n\n4-element Vector{Complex{Int64}}:\n -1 + 2im\n  1 + 0im\n  2 - 1im\n  0 - 1im\n\n\n\nB^2*x # 아래로 두칸이동, B^2*x = B*(Bx) 이므로 \n\n4-element Vector{Complex{Int64}}:\n  0 - 1im\n -1 + 2im\n  1 + 0im\n  2 - 1im\n\n\n한편 이 매트릭스 \\({\\bf B}\\)는 아래와 같이 고유분해가 가능하다.\n\\[ {\\bf B} = {\\bf \\Psi} {\\bf \\Lambda} {\\bf \\Psi}^\\ast\\]\n\n\\({\\bf \\Psi}\\): make \\(\\frac{1}{\\sqrt{N}}[e^{\\sqrt{-1} \\frac{2\\pi}{N} ij}~\\text{ for }~ i=0,1,2,\\dots,N-1~\\text{ for }~j=0,1,2,\\dots,N-1]\\) and apply reshape function with \\((N,N)\\).\n\\({\\bf \\Lambda}\\): make \\([e^{-\\sqrt{-1}\\frac{2\\pi}{N}i}~\\text{ for }~ i=0,1,2\\dots,N-1]\\) and apply Diagonal function.\n\n\nN = 4 \nλ = [exp(-im * (2π/N) *i) for i in 0:(N-1)]\nΛ = Diagonal(λ)\n_Ψ = 1/√N *[exp(im * (2π/N) * i*j) for i in 0:(N-1) for j in 0:(N-1)]\nΨ = reshape(_Ψ, (N,N))\nB ≈ Ψ * Λ * Ψ'\n\ntrue\n\n\n그런데 위에서 정의된 \\({\\bf \\Psi}^\\ast\\)는 우리가 그전에 정의하였던 \\({\\bf DFT}\\)의 행렬과 같다.\n\n_DFT = reshape([i*j for i in 0:3 for j in 0:3], (4,4))\nDFT = _DFT .|&gt; (x -&gt; exp(-im * (2π/4) * x)) \nDFT = DFT * 1/√N\n\n4×4 Matrix{ComplexF64}:\n 0.5-0.0im           0.5-0.0im          …           0.5-0.0im\n 0.5-0.0im   3.06162e-17-0.5im             -9.18485e-17+0.5im\n 0.5-0.0im          -0.5-6.12323e-17im             -0.5-1.83697e-16im\n 0.5-0.0im  -9.18485e-17+0.5im              2.75546e-16-0.5im\n\n\n\nΨ' == DFT \n\ntrue\n\n\n결국 요약하면 길이가 \\(N\\)인 신호의 \\({\\bf DFT}\\)행렬은 아래의 과정으로 구할 수 있음을 알 수 있다.\n\nForward operator \\({\\bf A}\\)를 정의한다.\n\\({\\bf A}\\)의 고유벡터행렬 \\({\\bf \\Psi}\\)을 구한다. 4\n\\({\\bf \\Psi}\\)의 conjugate transpose matrix \\({\\bf \\Psi}^\\ast\\) 를 구한다. 이것이 \\({\\bf DFT}\\) matrix 이다. 5\n\n4 고유벡터행렬은 고유값 \\(e^{-\\sqrt{-1}\\frac{2\\pi}{N}i}\\)에 의하여 정렬되어 있어야 함.5 사실 이미 대칭행렬이므로 conjugate matrix만 구하면 된다."
  },
  {
    "objectID": "공부/CGSP/2022-12-24-Chap-8.3.html#spectral-component-and-frequencies",
    "href": "공부/CGSP/2022-12-24-Chap-8.3.html#spectral-component-and-frequencies",
    "title": "(공부) CGSP – Chap 8.3: Discrete Fourier Transform",
    "section": "Spectral component and Frequencies",
    "text": "Spectral component and Frequencies\n\\({\\bf A}\\)의 고유벡터 \\({\\bf \\Psi}\\)의 각 column을 spectral component라고 부른다.\n\nψ₁ = Ψ[:,1] # ψ₁ is first spectral component \nψ₂ = Ψ[:,2] # ψ₂ is seconde spectral component \nψ₃ = Ψ[:,3] # ψ₃ is third spectral component \nψ₄ = Ψ[:,4] # ψ₄ is last spectral component\n\n그리고 아래와 같은 수열을 \\(\\Omega_{k}=\\frac{k}{N}\\)을 frequency 라고 부른다.\n\nN=4 \nΩ = [k/N for k in 0:(N-1)]\nΩ\n\n4-element Vector{Float64}:\n 0.0\n 0.25\n 0.5\n 0.75"
  },
  {
    "objectID": "규빈.html",
    "href": "규빈.html",
    "title": "규빈",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nJul 17, 2024\n\n\n(연구) graft – tutorial 2\n\n\n신록예찬 \n\n\n\n\nJan 19, 2024\n\n\n(연구) gglitely – 서브플랏\n\n\n신록예찬 \n\n\n\n\nJan 19, 2024\n\n\n(연구) gglitely – 연계\n\n\n신록예찬 \n\n\n\n\nJan 19, 2024\n\n\n(연구) gglitely – 튜토리얼\n\n\n신록예찬 \n\n\n\n\nJan 15, 2024\n\n\n(연구) gglite – 내부기능\n\n\n신록예찬 \n\n\n\n\nJan 15, 2024\n\n\n(연구) gglite – 튜토리얼\n\n\n신록예찬 \n\n\n\n\nNov 9, 2023\n\n\n(연구) graft – tutorial\n\n\n신록예찬 \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "재인.html",
    "href": "재인.html",
    "title": "재인",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nDec 27, 2023\n\n\n(연구&재인) MBTI(정리) – 논문그림정리\n\n\n신록예찬 \n\n\n\n\nDec 22, 2023\n\n\n(연구&재인) MBTI(정리) – 실험결과 시각화\n\n\n신록예찬 \n\n\n\n\nDec 21, 2023\n\n\n(연구&재인) MBTI(정리) – TabularPredictor 실험\n\n\n신록예찬 \n\n\n\n\nDec 20, 2023\n\n\n(연구&재인) MBTI(정리) – 실험셋업 시각화\n\n\n신록예찬 \n\n\n\n\nDec 19, 2023\n\n\n(연구&재인) MBTI(정리) – 실험셋업\n\n\n신록예찬 \n\n\n\n\nDec 13, 2023\n\n\n(연구&재인) MBTI – 추가자료분석 (all)\n\n\n신록예찬 \n\n\n\n\nDec 13, 2023\n\n\n(연구&재인) MBTI – 추가자료분석 (429)\n\n\n신록예찬 \n\n\n\n\nOct 12, 2023\n\n\n(연구&재인) MBTI – MBTI\n\n\n신록예찬 \n\n\n\n\nOct 11, 2023\n\n\n(연구&재인) MBTI – 감성분석\n\n\n신록예찬 \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "서연.html",
    "href": "서연.html",
    "title": "서연",
    "section": "",
    "text": "https://github.com/seoyeonc\nhttps://seoyeonc.github.io/sy_hub/\n\n\n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nAug 14, 2024\n\n\n(연구&서연) Ebayesthresh Layer\n\n\n최규빈 \n\n\n\n\nAug 14, 2024\n\n\n(연구&서연) GODE – Ex2 Distance의분포/Kappa에따른AUC 시각화\n\n\n최규빈 \n\n\n\n\nAug 14, 2024\n\n\n(연구&서연) GODE – Ex2 Kappa에 따른 성능 시각화\n\n\n최규빈 \n\n\n\n\nAug 14, 2024\n\n\n(연구&서연) GODE – Ex2 Kappa에 따른 성능 시각화\n\n\n최규빈 \n\n\n\n\nAug 14, 2024\n\n\n(연구&서연) GODE – Ex2 Distance Histogram 시각화\n\n\n최규빈 \n\n\n\n\nAug 14, 2024\n\n\n(연구&서연) GODE – CLT\n\n\n최규빈 \n\n\n\n\nAug 12, 2024\n\n\n(연구&서연) GODE – 환경설정\n\n\n최규빈 \n\n\n\n\nJan 24, 2024\n\n\n(연구&서연) IT-STGCN – ToyExam\n\n\nSEOYEON CHOI\n\n\n\n\nJan 8, 2024\n\n\n(연구&서연) IT-STGCN – 실험결과시각화\n\n\nSEOYEON CHOI\n\n\n\n\nSep 14, 2023\n\n\n(연구&서연) IT-STGCN – 논문리비전\n\n\n최서연 \n\n\n\n\nApr 27, 2023\n\n\n(연구&서연) IT-STGCN – Toy Example Figure(Intro)\n\n\n최서연 \n\n\n\n\nMar 18, 2023\n\n\n(연구&서연) IT-STGCN – SimualtionPlanner-Tutorial\n\n\nSEOYEON CHOI\n\n\n\n\nMar 17, 2023\n\n\n(연구&서연) IT-STGCN – ITSTGCN-Tutorial\n\n\nSEOYEON CHOI\n\n\n\n\nDec 30, 2022\n\n\n(연구&서연) IT-STGCN – Toy Example\n\n\n신록예찬 \n\n\n\n\nDec 29, 2022\n\n\n(연구&서연) IT-STGCN – Tables\n\n\n신록예찬 \n\n\n\n\nDec 29, 2022\n\n\n(연구&서연) IT-STGCN – Tutorial\n\n\n신록예찬, 최서연\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "연구/교수님이랑/EPT_DISSIM/2023-08-08-(연구) EPT-DISSIM -- 진행사항.html",
    "href": "연구/교수님이랑/EPT_DISSIM/2023-08-08-(연구) EPT-DISSIM -- 진행사항.html",
    "title": "(연구&교수님) EPT-DISSIM – 진행사항",
    "section": "",
    "text": "진행사항\nEPT_DISSIM: visualization (23.08.07) – 현재 중단\n\nPRCP_KOR 자료에 대한 시각화\n\nPRCP_KOR2.csv\n\ndownload: https://github.com/miruetoto/yechan3/blob/main/posts/3_Researches/YECHAN/EPT_DISSIM/PRCP_KOR2.csv\n결측치를 0으로 채움"
  },
  {
    "objectID": "연구/교수님이랑/MS_Review/TPT, TPMA 설명.html",
    "href": "연구/교수님이랑/MS_Review/TPT, TPMA 설명.html",
    "title": "(연구&교수님) 다중척도논문 – TPT, TPMA 설명",
    "section": "",
    "text": "그림을 그리는 코드\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.rcParams['text.usetex'] = True\n\n# 시계열 데이터 생성\nnp.random.seed(0)\nn = 100\nX = np.cumsum(np.random.randn(n))  # AR(1) 프로세스\nY = np.cumsum(np.random.randn(n))  # 백색잡음\n\n# 두꺼운펜변환 함수 (사각펜)\ndef thick_pen_transform(X, tau, gamma=1):\n    n = len(X)\n    U_tau = np.zeros(n)\n    L_tau = np.zeros(n)\n    \n    for t in range(n - tau):\n        U_tau[t] = np.max(X[t:t+tau+1]) + gamma * (tau / 2)\n        L_tau[t] = np.min(X[t:t+tau+1]) - gamma * (tau / 2)\n    \n    # 경계 케이스 처리\n    for t in range(n - tau, n):\n        U_tau[t] = np.max(X[t:n]) + gamma * (tau / 2)\n        L_tau[t] = np.min(X[t:n]) - gamma * (tau / 2)\n    \n    return L_tau, U_tau\n\ntau = 5  # 두께 파라미터 설정\nX_L_tau, X_U_tau = thick_pen_transform(X, tau)\nY_L_tau, Y_U_tau = thick_pen_transform(Y, tau)\n\n# Upper와 Lower 각각 시각화 함수\ndef plot_upper_lower_with_series(X, Y, X_L_tau, X_U_tau, Y_L_tau, Y_U_tau, tau):\n    plt.figure(figsize=(14, 3))\n    plt.plot(X, label=r'Time Series X', color='blue', linewidth=1)\n    plt.plot(Y, label=r'Time Series Y', color='red', linewidth=1)\n    \n    plt.fill_between(range(len(X)), X_L_tau, X_U_tau, color='blue', alpha=0.3, label=r'X Bound ($L_n^{\\tau}(X) \\leq X_n \\leq U_n^{\\tau}(X)$)')\n    plt.fill_between(range(len(Y)), Y_L_tau, Y_U_tau, color='red', alpha=0.3, label=r'Y Bound ($L_n^{\\tau}(Y) \\leq Y_n \\leq U_n^{\\tau}(Y)$)')\n    \n    plt.legend(loc='upper right')\n    plt.title('Original Time Series with Upper and Lower Bounds (Thick-Pen Transform)')\n    plt.show()\n\n# 시각화\nplot_upper_lower_with_series(X, Y, X_L_tau, X_U_tau, Y_L_tau, Y_U_tau, tau)\n\n# min(U,U), max(U,U), min(L,L), max(L,L) 시각화 함수\ndef plot_min_max_with_series(X, Y, X_L_tau, X_U_tau, Y_L_tau, Y_U_tau, tau):\n    plt.figure(figsize=(14, 3))\n    plt.plot(X, color='blue', linewidth=1, alpha=0.1)\n    plt.plot(Y, color='red', linewidth=1, alpha=0.1)\n    \n    min_U = np.minimum(X_U_tau, Y_U_tau)\n    max_U = np.maximum(X_U_tau, Y_U_tau)\n    min_L = np.minimum(X_L_tau, Y_L_tau)\n    max_L = np.maximum(X_L_tau, Y_L_tau)\n    \n    # 오버랩되는 부분을 음영 처리\n    plt.fill_between(range(len(X)), X_L_tau, X_U_tau, color='blue', alpha=0.05)\n    plt.fill_between(range(len(Y)), Y_L_tau, Y_U_tau, color='red', alpha=0.05)\n    \n    plt.plot(min_U, color='green', linestyle='--', linewidth=1, label=r'$\\min(U_n^{\\tau}(X), U_n^{\\tau}(Y))$')\n    plt.plot(max_U, color='orange', linestyle='-.', linewidth=1, label=r'$\\max(U_n^{\\tau}(X), U_n^{\\tau}(Y))$')\n    plt.plot(min_L, color='orange', linestyle='--', linewidth=1, label=r'$\\min(L_n^{\\tau}(X), L_n^{\\tau}(Y))$')\n    plt.plot(max_L, color='green', linestyle='-.', linewidth=1, label=r'$\\max(L_n^{\\tau}(X), L_n^{\\tau}(Y))$')\n    \n    plt.legend(loc='upper right')\n    plt.title('Min/Max Upper and Lower Bounds with Original Time Series')\n    plt.show()\n\n# 시각화\nplot_min_max_with_series(X, Y, X_L_tau, X_U_tau, Y_L_tau, Y_U_tau, tau)\n\n\n# TPMA의 분자와 분모 각각 시각화 함수\ndef plot_tpma_numerator_denominator_with_series(X, Y, X_L_tau, X_U_tau, Y_L_tau, Y_U_tau, tau):\n    plt.figure(figsize=(14, 3))\n    \n    overlap_range = [min(X_U_tau[t], Y_U_tau[t]) - max(X_L_tau[t], Y_L_tau[t]) for t in range(len(X))]\n    spread_range = [max(X_U_tau[t], Y_U_tau[t]) - min(X_L_tau[t], Y_L_tau[t]) for t in range(len(X))]\n    \n    plt.plot(X, color='blue', linewidth=1, alpha=0.1)\n    plt.plot(Y, color='red', linewidth=1, alpha=0.1)\n    \n    # 분자와 분모에 해당하는 음영 추가\n    plt.fill_between(range(len(X)), \n                     [max(X_L_tau[t], Y_L_tau[t]) for t in range(len(X))], \n                     [min(X_U_tau[t], Y_U_tau[t]) for t in range(len(X))], \n                     where=[min(X_U_tau[t], Y_U_tau[t]) - max(X_L_tau[t], Y_L_tau[t]) &gt;= 0 for t in range(len(X))],\n                     color='green', alpha=0.2, label='Overlap Range')\n    \n    plt.fill_between(range(len(X)), \n                     [max(X_L_tau[t], Y_L_tau[t]) for t in range(len(X))], \n                     [min(X_U_tau[t], Y_U_tau[t]) for t in range(len(X))], \n                     where=[min(X_U_tau[t], Y_U_tau[t]) - max(X_L_tau[t], Y_L_tau[t]) &lt; 0 for t in range(len(X))],\n                     facecolor='none', hatch='//', edgecolor='green', label='Negative Overlap Range')\n    \n    plt.fill_between(range(len(X)), \n                     [min(X_L_tau[t], Y_L_tau[t]) for t in range(len(X))], \n                     [max(X_U_tau[t], Y_U_tau[t]) for t in range(len(X))], \n                     color='orange', alpha=0.2, label='Spread Range')\n    \n    plt.plot(overlap_range, color='green', linestyle='--', linewidth=1, label=r'Overlap ($\\min(U_n^{\\tau}(X), U_n^{\\tau}(Y)) - \\max(L_n^{\\tau}(X), L_n^{\\tau}(Y))$)')\n    plt.plot(spread_range, color='orange', linestyle='-', linewidth=1, label=r'Spread ($\\max(U_n^{\\tau}(X), U_n^{\\tau}(Y)) - \\min(L_n^{\\tau}(X), L_n^{\\tau}(Y))$)')\n    \n    plt.legend(loc='upper right')\n    plt.title('TPMA Overlap and Spread Ranges with Original Time Series')\n    plt.show()\n# 시각화\nplot_tpma_numerator_denominator_with_series(X, Y, X_L_tau, X_U_tau, Y_L_tau, Y_U_tau, tau)\n\n# 두꺼운펜 변환 상관계수 계산 함수\ndef rho_tau(X, Y, X_L_tau, X_U_tau, Y_L_tau, Y_U_tau):\n    rho_tau_t = np.zeros(len(X))\n    \n    for t in range(len(X)):\n        min_U = min(X_U_tau[t], Y_U_tau[t])\n        max_L = max(X_L_tau[t], Y_L_tau[t])\n        max_U = max(X_U_tau[t], Y_U_tau[t])\n        min_L = min(X_L_tau[t], Y_L_tau[t])\n        \n        rho_tau_t[t] = (min_U - max_L) / (max_U - min_L)\n    \n    return rho_tau_t\n\n# TPMA 계산\nrho_values = rho_tau(X, Y, X_L_tau, X_U_tau, Y_L_tau, Y_U_tau)\n\n# TPMA 값 시각화 함수\ndef plot_tpma_values_with_series(X, Y, rho_values):\n    plt.figure(figsize=(14, 3))\n    \n    #plt.plot(X, label='Time Series X', color='blue', linewidth=1)\n    #plt.plot(Y, label='Time Series Y', color='red', linewidth=1)\n    plt.plot(rho_values, label='TPMA = Overlap/Spread ', color='purple', linewidth=1)\n    \n    plt.legend(loc='upper right')\n    plt.title('TPMA Values with Original Time Series')\n    plt.show()\n\n# 시각화\nplot_tpma_values_with_series(X, Y, rho_values)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npdf 저장하는 코드\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.backends.backend_pdf import PdfPages\nplt.rcParams['text.usetex'] = True\n\n# 시계열 데이터 생성\nnp.random.seed(0)\nn = 100\nX = np.cumsum(np.random.randn(n))  # AR(1) 프로세스\nY = np.cumsum(np.random.randn(n))  # 백색잡음\n\n# 두꺼운펜변환 함수 (사각펜)\ndef thick_pen_transform(X, tau, gamma=1):\n    n = len(X)\n    U_tau = np.zeros(n)\n    L_tau = np.zeros(n)\n    \n    for t in range(n - tau):\n        U_tau[t] = np.max(X[t:t+tau+1]) + gamma * (tau / 2)\n        L_tau[t] = np.min(X[t:t+tau+1]) - gamma * (tau / 2)\n    \n    # 경계 케이스 처리\n    for t in range(n - tau, n):\n        U_tau[t] = np.max(X[t:n]) + gamma * (tau / 2)\n        L_tau[t] = np.min(X[t:n]) - gamma * (tau / 2)\n    \n    return L_tau, U_tau\n\ntau = 5  # 두께 파라미터 설정\nX_L_tau, X_U_tau = thick_pen_transform(X, tau)\nY_L_tau, Y_U_tau = thick_pen_transform(Y, tau)\n\n# TPMA 계산 함수\ndef rho_tau(X, Y, X_L_tau, X_U_tau, Y_L_tau, Y_U_tau):\n    rho_tau_t = np.zeros(len(X))\n    \n    for t in range(len(X)):\n        min_U = min(X_U_tau[t], Y_U_tau[t])\n        max_L = max(X_L_tau[t], Y_L_tau[t])\n        max_U = max(X_U_tau[t], Y_U_tau[t])\n        min_L = min(X_L_tau[t], Y_L_tau[t])\n        \n        rho_tau_t[t] = (min_U - max_L) / (max_U - min_L)\n    \n    return rho_tau_t\n\n# TPMA 계산\nrho_values = rho_tau(X, Y, X_L_tau, X_U_tau, Y_L_tau, Y_U_tau)\n\n# 플롯을 생성하는 함수\ndef create_plots():\n    fig, axs = plt.subplots(4, 1, figsize=(10, 12))\n    \n    # Upper와 Lower 각각 시각화\n    axs[0].plot(X, label=r'Time Series X', color='blue', linewidth=1)\n    axs[0].plot(Y, label=r'Time Series Y', color='red', linewidth=1)\n    axs[0].fill_between(range(len(X)), X_L_tau, X_U_tau, color='blue', alpha=0.3, label=r'X Bound ($L_n^{\\tau}(X) \\leq X_n \\leq U_n^{\\tau}(X)$)')\n    axs[0].fill_between(range(len(Y)), Y_L_tau, Y_U_tau, color='red', alpha=0.3, label=r'Y Bound ($L_n^{\\tau}(Y) \\leq Y_n \\leq U_n^{\\tau}(Y)$)')\n    axs[0].legend(loc='upper right')\n    axs[0].set_title('Original Time Series with Upper and Lower Bounds (Thick-Pen Transform)')\n\n    # min(U,U), max(U,U), min(L,L), max(L,L) 시각화\n    min_U = np.minimum(X_U_tau, Y_U_tau)\n    max_U = np.maximum(X_U_tau, Y_U_tau)\n    min_L = np.minimum(X_L_tau, Y_L_tau)\n    max_L = np.maximum(X_L_tau, Y_L_tau)\n    axs[1].plot(X, color='blue', linewidth=1, alpha=0.1)\n    axs[1].plot(Y, color='red', linewidth=1, alpha=0.1)\n    axs[1].fill_between(range(len(X)), X_L_tau, X_U_tau, color='blue', alpha=0.05)\n    axs[1].fill_between(range(len(Y)), Y_L_tau, Y_U_tau, color='red', alpha=0.05)\n    axs[1].plot(min_U, color='green', linestyle='--', linewidth=1, label=r'$\\min(U_n^{\\tau}(X), U_n^{\\tau}(Y))$')\n    axs[1].plot(max_U, color='orange', linestyle='-.', linewidth=1, label=r'$\\max(U_n^{\\tau}(X), U_n^{\\tau}(Y))$')\n    axs[1].plot(min_L, color='orange', linestyle='--', linewidth=1, label=r'$\\min(L_n^{\\tau}(X), L_n^{\\tau}(Y))$')\n    axs[1].plot(max_L, color='green', linestyle='-.', linewidth=1, label=r'$\\max(L_n^{\\tau}(X), L_n^{\\tau}(Y))$')\n    axs[1].legend(loc='upper right')\n    axs[1].set_title('Min/Max Upper and Lower Bounds with Original Time Series')\n\n    # TPMA의 분자와 분모 각각 시각화\n    overlap_range = [min(X_U_tau[t], Y_U_tau[t]) - max(X_L_tau[t], Y_L_tau[t]) for t in range(len(X))]\n    spread_range = [max(X_U_tau[t], Y_U_tau[t]) - min(X_L_tau[t], Y_L_tau[t]) for t in range(len(X))]\n    axs[2].plot(X, color='blue', linewidth=1, alpha=0.1)\n    axs[2].plot(Y, color='red', linewidth=1, alpha=0.1)\n    \n    # 분자와 분모에 해당하는 음영 추가\n    axs[2].fill_between(range(len(X)), \n                     [max(X_L_tau[t], Y_L_tau[t]) for t in range(len(X))], \n                     [min(X_U_tau[t], Y_U_tau[t]) for t in range(len(X))], \n                     where=[min(X_U_tau[t], Y_U_tau[t]) - max(X_L_tau[t], Y_L_tau[t]) &gt;= 0 for t in range(len(X))],\n                     color='green', alpha=0.2, label='Overlap Range')\n    \n    axs[2].fill_between(range(len(X)), \n                     [max(X_L_tau[t], Y_L_tau[t]) for t in range(len(X))], \n                     [min(X_U_tau[t], Y_U_tau[t]) for t in range(len(X))], \n                     where=[min(X_U_tau[t], Y_U_tau[t]) - max(X_L_tau[t], Y_L_tau[t]) &lt; 0 for t in range(len(X))],\n                     facecolor='none', hatch='//', edgecolor='green', label='Negative Overlap Range')\n    \n    axs[2].fill_between(range(len(X)), \n                     [min(X_L_tau[t], Y_L_tau[t]) for t in range(len(X))], \n                     [max(X_U_tau[t], Y_U_tau[t]) for t in range(len(X))], \n                     color='orange', alpha=0.2, label='Spread Range')\n    \n    axs[2].plot(overlap_range, color='green', linestyle='--', linewidth=1, label=r'Overlap ($\\min(U_n^{\\tau}(X), U_n^{\\tau}(Y)) - \\max(L_n^{\\tau}(X), L_n^{\\tau}(Y))$)')\n    axs[2].plot(spread_range, color='orange', linestyle='-', linewidth=1, label=r'Spread ($\\max(U_n^{\\tau}(X), U_n^{\\tau}(Y)) - \\min(L_n^{\\tau}(X), L_n^{\\tau}(Y))$)')\n    axs[2].legend(loc='upper right')\n    axs[2].set_title('TPMA Overlap and Spread Ranges with Original Time Series')\n\n    # TPMA 값 시각화\n    axs[3].plot(rho_values, label='TPMA = Overlap/Spread', color='purple', linewidth=1)\n    axs[3].legend(loc='upper right')\n    axs[3].set_title('TPMA Values with Original Time Series')\n\n    plt.tight_layout()\n    return fig\n\n# PDF로 저장하는 코드\nwith PdfPages('./Dropbox/03_Yechan3/연구/교수님이랑/MS_Review/tpt_tpma.pdf') as pdf:\n    fig = create_plots()\n    pdf.savefig(fig, bbox_inches='tight')  # 모든 페이지 저장\n    plt.close(fig)"
  },
  {
    "objectID": "연구/교수님이랑/MS_Review/TPT-FirstFig.html",
    "href": "연구/교수님이랑/MS_Review/TPT-FirstFig.html",
    "title": "(연구&교수님) 다중척도논문 – TPT-FirstFig",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.backends.backend_pdf import PdfPages\nplt.rcParams.update({\n    \"text.usetex\": True,\n#    \"font.family\": \"Helvetica\"\n})\n# Generate data\nnp.random.seed(0)\nn = 1000\nx = np.arange(0, n)\ny = np.random.normal(0, 1, n)\n\n# Creating a sine wave for the second half\ny[n//2:] = np.sin(2 * np.pi * (x[n//2:] - n//2) / (n // 2))\n\n# Plot data\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n\n# First subplot (conventional plot)\nax1.plot(x, y, color='black', solid_capstyle='round')\nax1.set_title(\"Conventional Plot\")\n\n# Second subplot (varying thickness)\nax2.plot(x[:n//2], y[:n//2], color='black', solid_capstyle='round')\nax2.plot(x[n//2:], y[n//2:], color='black', linewidth=15, solid_capstyle='round')\nax2.set_title(\"Unconventional Plot with Varying Thickness\")\n\n# Save the figure\nplt.savefig('./Dropbox/03_Yechan3/연구/교수님이랑/MS_Review/tpt_firstfig.pdf')\n\n# Display plot\nplt.show()"
  },
  {
    "objectID": "연구/교수님이랑/MS_Review/EMD2.html",
    "href": "연구/교수님이랑/MS_Review/EMD2.html",
    "title": "(연구&교수님) 다중척도논문 – EMD 2",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt \nplt.rcParams['text.usetex'] = True\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom emd import sift\n\n# Define the time vector\nt = np.linspace(1, 1000, 2000) / 2000\n\n# Compute the signal components\ny1 = np.cos(62 * np.pi * t)\ny2 = np.cos(58 * np.pi * t)\ny3 = 2 * np.cos(10 * np.pi * t)\ny = y1 + y2 + y3\n\n# Perform Empirical Mode Decomposition (EMD)\nimfs = sift.sift(y)\n\n# Check the shape of the IMFs\nprint(f\"Shape of IMFs: {imfs.shape}\")  # It should be (len(t), number_of_imfs)\n\n# Determine the y-axis limits for consistent scaling\ny_min = min(y.min(), imfs.min())\ny_max = max(y.max(), imfs.max())\n\n# Plot the original signal and the IMFs\nfig, axs = plt.subplots(4, 1, figsize=(8, 8), tight_layout=True)\n\n# Plot the original signal\naxs[0].plot(t, y, color='black', linewidth=0.5)\naxs[0].set_title('Original Signal')\naxs[0].set_xlabel('Time [s]')\naxs[0].set_ylabel('Amplitude')\naxs[0].set_ylim(y_min, y_max)\n\n# Plot each IMF and label the last one as residual\nfor i in range(3):  # Only the first 3 IMFs\n    axs[i + 1].plot(t, imfs[:, i], color='black', linewidth=0.5)\n    if i == 2:\n        axs[i + 1].set_title('Residual')\n    else:\n        axs[i + 1].set_title(f'IMF {i + 1}')\n    axs[i + 1].set_xlabel('Time [s]')\n    axs[i + 1].set_ylabel('Amplitude')\n    axs[i + 1].set_ylim(y_min, y_max)\n\nplt.tight_layout()\nplt.savefig('./Dropbox/03_Yechan3/연구/교수님이랑/MS_Review/beatEMD.pdf')\nplt.show()\n\nShape of IMFs: (2000, 3)"
  },
  {
    "objectID": "연구/교수님이랑/MS_Review/FFT.html",
    "href": "연구/교수님이랑/MS_Review/FFT.html",
    "title": "(연구&교수님) 다중척도논문 – FFT",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.fft import fft\nplt.rcParams['text.usetex'] = True\n\n\n# Define the function to compute the Fourier Transform and spectra\ndef spec(y):\n    n = len(y)\n    spec = np.abs(fft(y)) / n\n    omega = np.arange(n) / n\n    if n % 2 == 0:\n        m = (n // 2) + 1\n    else:\n        m = (n - 1) // 2 + 1\n    spec = np.concatenate((spec[m:], spec[:m]))\n    omega = np.concatenate((omega[m:] - 1, omega[:m])) - 1 / n\n    return omega * 2 * np.pi, spec\n\n# Define the time series\nt = np.arange(1, 41) / 40\neps = np.random.normal(size=40)\nconst = -2 + t * 0\nlow = 9 * np.sin(2 * np.pi * t)\nhigh = 4 * np.cos(4 * 2 * np.pi * t)\nytrue = const + low + high\ny = ytrue + eps\n\n# Compute spectra\nfreq, y_spec = spec(y)\n_, const_spec = spec(const)\n_, low_spec = spec(low)\n_, high_spec = spec(high)\n_, eps_spec = spec(eps)\n\n# Plotting\nfig, axs = plt.subplots(5, 2, figsize=(12, 10))\n\n# Time series and their spectra\ndef plot_series(ax, t, series, title=\"\"):\n    ax.plot(t, series, 'gray', marker='o', markersize=2)\n    ax.set_title(title)\n    ax.set_xlim(0, 1)  # Setting x-axis limits\n\ndef plot_spectrum(ax, freq, spectrum, title=\"\"):\n    ax.stem(freq, spectrum, 'k-', basefmt=\" \", markerfmt='ko')\n    ax.set_ylim(0, 5.5)\n    ax.set_xlim(-np.pi, np.pi)  # Setting x-axis limits for frequency\n    ax.set_title(title)\n\nplot_series(axs[0, 0], t, y, \"Time Series ($y_n$)\")\nplot_spectrum(axs[0, 1], freq, y_spec, \"Frequency Spectrum ($y_n$)\")\n\nplot_series(axs[1, 0], t, const, \"Time Series (const)\")\nplot_spectrum(axs[1, 1], freq, const_spec, \"Frequency Spectrum (const)\")\n\nplot_series(axs[2, 0], t, low, \"Time Series ($l_n$)\")\nplot_spectrum(axs[2, 1], freq, low_spec, \"Frequency Spectrum ($l_n$)\")\n\nplot_series(axs[3, 0], t, high, \"Time Series ($h_n$)\")\nplot_spectrum(axs[3, 1], freq, high_spec, \"Frequency Spectrum ($h_n$)\")\n\nplot_series(axs[4, 0], t, eps, r\"Time Series ($\\epsilon_n$)\")\nplot_spectrum(axs[4, 1], freq, eps_spec, \"Frequency Spectrum ($\\epsilon_n$)\")\n\nplt.tight_layout()\nplt.savefig(\"/home/cgb2/Dropbox/03_Yechan3/연구/교수님이랑/MS_Review/time_series_spectrum_analysis.pdf\")\n\n&lt;&gt;:58: SyntaxWarning: invalid escape sequence '\\e'\n&lt;&gt;:58: SyntaxWarning: invalid escape sequence '\\e'\n/tmp/ipykernel_2519670/2657843074.py:58: SyntaxWarning: invalid escape sequence '\\e'\n  plot_spectrum(axs[4, 1], freq, eps_spec, \"Frequency Spectrum ($\\epsilon_n$)\")\n\n\n\n\n\n\n\n\n\nThis example demonstrates the generation of a time series data and its Fourier transform to analyze the frequency spectrum. The time series data consists of various components: a constant, a low-frequency sine wave, a high-frequency cosine wave, and noise. The Fourier transform is used to visualize both the time domain and frequency domain representations of each component.\nFirst, we generate a time series data of 40 points. This time series data is composed of the following components: a constant component, \\(\\text{const} = -2\\); a low-frequency sine wave component, \\(\\text{low} = 9 \\sin\\left(2 \\pi t_i\\right)\\); a high-frequency cosine wave component, \\(\\text{high} = 4 \\cos\\left(8 \\pi t_i\\right)\\); and a noise component, \\(\\epsilon_i\\), which is normally distributed random noise with mean 0 and standard deviation 1. The entire time series data \\(y\\) is expressed as the sum of these components:\n\\[\ny_i = \\text{const} + \\text{low}_i + \\text{high}_i + \\epsilon_i\n\\]\nwhere \\(t_i\\) represents the discrete time steps.\nThe Fourier transform is used to convert the time-domain representation of the time series data into the frequency domain, revealing the magnitude of each frequency component. The frequency spectrum is a collection of these magnitude values for each frequency.\nEach row of the figure contains two graphs. The left graph shows the time-domain representation of the time series data, and the right graph shows the frequency spectrum obtained from the Fourier transform.\nIn the first row, the left graph shows the entire time series data \\(y\\) plotted against time. The gray solid line represents the actual data \\(y\\), which is the sum of the constant, low-frequency sine wave, high-frequency cosine wave, and noise components. The dotted line represents the ideal data \\(y_{\\text{true}}\\), without the noise:\n\\[\ny_{\\text{true}, i} = \\text{const} + \\text{low}_i + \\text{high}_i\n\\]\nThe right graph shows the frequency spectrum of the entire time series data \\(y\\). It reveals the mixed frequency components present in the data.\nIn the second row, the left graph shows the constant component of the time series data plotted against time. The graph remains at a constant value over time. The right graph shows the frequency spectrum of the constant component. It shows a large value at frequency 0 and near-zero values at other frequencies, indicating that the constant component is equivalent to the DC component (0 Hz) in the frequency domain.\nIn the third row, the left graph shows the low-frequency sine wave component of the time series data plotted against time. It has a long periodic sine wave shape:\n\\[\n\\text{low}_i = 9 \\sin\\left(2 \\pi t_i\\right)\n\\]\nThe right graph shows the frequency spectrum of the low-frequency sine wave component. It shows large values at specific low frequencies, with near-zero values at other frequencies.\nIn the fourth row, the left graph shows the high-frequency cosine wave component of the time series data plotted against time. It has a short periodic cosine wave shape:"
  },
  {
    "objectID": "연구/교수님이랑/MS_Review/TPT, 미국지수분석 (2).html",
    "href": "연구/교수님이랑/MS_Review/TPT, 미국지수분석 (2).html",
    "title": "(연구&교수님) 다중척도논문 – TPT, 미국지수분석 (2)",
    "section": "",
    "text": "import yfinance as yf\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n#plt.rcParams['text.usetex'] = True\n\n\n# 두꺼운펜변환 함수 (사각펜)\ndef thick_pen_transform(X, taus, gamma=0.001):\n    n = len(X)\n    result = {}\n    \n    for tau in taus:\n        U_tau = np.zeros(n)\n        L_tau = np.zeros(n)\n        \n        for t in range(n - tau):\n            U_tau[t] = np.max(X[t:t+tau+1]) + gamma * (tau / 2)\n            L_tau[t] = np.min(X[t:t+tau+1]) - gamma * (tau / 2)\n        \n        # 경계 케이스 처리\n        for t in range(n - tau, n):\n            U_tau[t] = np.max(X[t:n]) + gamma * (tau / 2)\n            L_tau[t] = np.min(X[t:n]) - gamma * (tau / 2)\n        \n        result[tau] = (L_tau, U_tau)\n    \n    return result\n\n# 두꺼운펜 변환 상관계수 계산 함수\ndef rho_tau(X, Y, taus):\n    rho_values = {}\n    \n    X_result = thick_pen_transform(X, taus)\n    Y_result = thick_pen_transform(Y, taus)\n    \n    for tau in taus:\n        rho_tau_t = np.zeros(len(X))\n        \n        L_tau_X, U_tau_X = X_result[tau]\n        L_tau_Y, U_tau_Y = Y_result[tau]\n        \n        for t in range(len(X)):\n            min_U = min(U_tau_X[t], U_tau_Y[t])\n            max_L = max(L_tau_X[t], L_tau_Y[t])\n            max_U = max(U_tau_X[t], U_tau_Y[t])\n            min_L = min(L_tau_X[t], L_tau_Y[t])\n            \n            rho_tau_t[t] = (min_U - max_L) / (max_U - min_L)\n        \n        rho_values[tau] = rho_tau_t\n    \n    return rho_values\n\ndef plot_correlations(indices, start_date, end_date, taus):\n    # 데이터 다운로드 및 전처리\n    data_dict = {}\n    min_length = float('inf')\n\n    for name, ticker in indices.items():\n        data = yf.download(ticker, start=start_date, end=end_date)\n        close_prices = data['Close'].values\n        dates = data.index\n\n        # 로그 변환\n        log_prices = np.log(close_prices)\n\n        # 차분\n        differenced_log_prices = np.diff(log_prices)\n\n        # 표준화\n        mean_diff = np.mean(differenced_log_prices)\n        std_diff = np.std(differenced_log_prices)\n        standardized_diff = (differenced_log_prices - mean_diff) / std_diff\n\n        data_dict[name] = standardized_diff\n        if len(standardized_diff) &lt; min_length:\n            min_length = len(standardized_diff)\n\n    # 데이터 길이를 최소 길이로 맞춤\n    for name in data_dict:\n        data_dict[name] = data_dict[name][:min_length]\n\n    all_rho_values = []\n\n    # 데이터 딕셔너리에서 처음 7개의 항목만 선택\n    selected_indices = list(data_dict.keys())\n\n    for i, name1 in enumerate(selected_indices):\n        for j, name2 in enumerate(selected_indices):\n            if name1 != name2:  # 자기 자신과의 상관계수는 계산하지 않음\n                rho_values = rho_tau(data_dict[name1], data_dict[name2], taus)\n                \n                rho_matrix = np.zeros((len(taus), min_length))\n\n                for k, tau in enumerate(taus):\n                    rho_matrix[k, :] = rho_values[tau]\n                \n                all_rho_values.append(rho_matrix)\n    # 전체 데이터의 상위 x% 임계값 계산\n    all_rho_values = np.concatenate(all_rho_values)\n    global_threshold = np.percentile(all_rho_values, 0)\n\n    covid_start = pd.Timestamp('2020-03-11')\n    covid_end = pd.Timestamp('2021-12-31')\n\n    # 날짜 데이터 추출 (첫 번째 지수의 날짜를 사용)\n    dates = yf.download(indices[selected_indices[0]], start=start_date, end=end_date).index\n\n    # 이벤트 기간을 인덱스로 변환\n    covid_start_idx = np.where(dates &gt;= covid_start)[0][0]\n    covid_end_idx = np.where(dates &lt;= covid_end)[0][-1]\n\n    # X축 레이블 설정을 위해 연도로 변환\n    years = dates.year\n\n    n = len(selected_indices)\n    fig, axes = plt.subplots(nrows=n, ncols=n, figsize=(25, 25))\n    for i, name1 in enumerate(selected_indices):\n        for j, name2 in enumerate(selected_indices):\n            ax = axes[i, j]\n            \n            if name1 == name2:  # 자기 자신과의 상관계수 위치에 'X' 표시\n                ax.text(0.5, 0.5, 'X', fontsize=40, ha='center', va='center')\n                ax.axis('off')\n            else:\n                rho_values = rho_tau(data_dict[name1], data_dict[name2], taus)\n                rho_matrix = np.zeros((len(taus), min_length))\n\n                for k, tau in enumerate(taus):\n                    rho_matrix[k, :] = rho_values[tau]\n\n                # 전역 임계값을 사용하여 마스크 생성\n                mask = rho_matrix &lt; global_threshold\n\n                # 마스크를 적용한 데이터 생성\n                masked_data = np.ma.array(rho_matrix, mask=mask)\n\n                im = ax.imshow(masked_data, cmap='magma', origin='lower', extent=[0, min_length, min(taus), max(taus)], alpha=0.5)\n                ax.set_aspect('auto')\n                \n                # 코로나19 팬데믹 기간 표시\n                ax.axvline(x=covid_start_idx, color='r', linestyle='--', linewidth=0.5); # ax.axvline(x=covid_end_idx, color='r', linestyle='--', linewidth=0.5)\n                \n                ax.set_title(f'{name1} vs {name2}', fontsize=8)\n                ax.set_xlabel('Time (Years)', fontsize=6)\n                ax.set_ylabel('Tau', fontsize=6)\n                ax.tick_params(axis='both', which='major', labelsize=6)\n                \n                # X축에 연도 레이블 추가\n                ax.set_xticks(np.linspace(0, min_length, len(set(years))))\n                ax.set_xticklabels(sorted(set(years)))\n\n            if i == 6 and j == 6:  # 마지막 셀에만 컬러바 추가\n                plt.colorbar(im, ax=ax, orientation='horizontal', pad=0.2, aspect=30, shrink=0.8)\n\n    # 범례 추가\n    fig.legend(['COVID-19'], loc='upper right', bbox_to_anchor=(0.99, 0.99), fontsize=8)\n\n    plt.show()\n    plt.tight_layout()  \n\ndef plot_correlations2(indices, start_date, end_date, taus, sigma=1):\n    # 데이터 다운로드 및 전처리\n    data_dict = {}\n    min_length = float('inf')\n\n    for name, ticker in indices.items():\n        data = yf.download(ticker, start=start_date, end=end_date)\n        close_prices = data['Close'].values\n        dates = data.index\n\n        # 로그 변환\n        log_prices = np.log(close_prices)\n\n        # 차분\n        differenced_log_prices = np.diff(log_prices)\n\n        # 표준화\n        mean_diff = np.mean(differenced_log_prices)\n        std_diff = np.std(differenced_log_prices)\n        standardized_diff = (differenced_log_prices - mean_diff) / std_diff\n\n        data_dict[name] = standardized_diff\n        if len(standardized_diff) &lt; min_length:\n            min_length = len(standardized_diff)\n\n    # 데이터 길이를 최소 길이로 맞춤\n    for name in data_dict:\n        data_dict[name] = data_dict[name][:min_length]\n\n    all_rho_values = []\n\n    # 데이터 딕셔너리에서 처음 7개의 항목만 선택\n    selected_indices = list(data_dict.keys())\n\n    for i, name1 in enumerate(selected_indices):\n        for j, name2 in enumerate(selected_indices):\n            if name1 != name2:  # 자기 자신과의 상관계수는 계산하지 않음\n                rho_values = rho_tau(data_dict[name1], data_dict[name2], taus)\n                \n                rho_matrix = np.zeros((len(taus), min_length))\n\n                for k, tau in enumerate(taus):\n                    rho_matrix[k, :] = rho_values[tau]\n                \n                all_rho_values.append(rho_matrix)\n    # 전체 데이터의 상위 x% 임계값 계산\n    all_rho_values = np.concatenate(all_rho_values)\n    global_threshold = np.percentile(all_rho_values, 0)\n\n    # Min-Max 스케일링\n    min_val = np.min(all_rho_values)\n    max_val = np.max(all_rho_values)\n\n    covid_start = pd.Timestamp('2020-03-11')\n    #covid_end = pd.Timestamp('2021-12-31')\n\n    # 날짜 데이터 추출 (첫 번째 지수의 날짜를 사용)\n    dates = yf.download(indices[selected_indices[0]], start=start_date, end=end_date).index\n\n    # 이벤트 기간을 인덱스로 변환\n    covid_start_idx = np.where(dates &gt;= covid_start)[0][0]\n    #covid_end_idx = np.where(dates &lt;= covid_end)[0][-1]\n\n    # X축 레이블 설정을 위해 연도로 변환\n    years = dates.year\n\n    n = len(selected_indices)\n    fig, axes = plt.subplots(nrows=n, ncols=n, figsize=(25, 25))\n    for i, name1 in enumerate(selected_indices):\n        for j, name2 in enumerate(selected_indices):\n            ax = axes[i, j]\n            \n            if name1 == name2:  # 자기 자신과의 상관계수 위치에 'X' 표시\n                ax.text(0.5, 0.5, 'X', fontsize=40, ha='center', va='center')\n                ax.axis('off')\n            else:\n                rho_values = rho_tau(data_dict[name1], data_dict[name2], taus)\n                rho_matrix = np.zeros((len(taus), min_length))\n\n                for k, tau in enumerate(taus):\n                    rho_matrix[k, :] = rho_values[tau]\n\n                # 시간별로 스무딩 적용\n                smoothed_rho_matrix = gaussian_filter(rho_matrix, sigma=sigma)\n\n                # 전역 임계값을 사용하여 마스크 생성\n                mask = smoothed_rho_matrix &lt; global_threshold\n\n                # 마스크를 적용한 데이터 생성\n                masked_data = np.ma.array(smoothed_rho_matrix, mask=mask)\n\n                im = ax.imshow(masked_data, cmap='magma', origin='lower', extent=[0, min_length, min(taus), max(taus)], alpha=0.8)\n                ax.set_aspect('auto')\n                \n                # 코로나19 팬데믹 기간 표시\n                ax.axvline(x=covid_start_idx, color='lime', linestyle='--', linewidth=1.5)#; ax.axvline(x=covid_end_idx, color='lime', linestyle='--', linewidth=1.5)\n                \n                ax.set_title(f'{name1} vs {name2}', fontsize=8)\n                ax.set_xlabel('Time (Years)', fontsize=6)\n                ax.set_ylabel('Tau', fontsize=6)\n                ax.tick_params(axis='both', which='major', labelsize=6)\n                \n                # X축에 연도 레이블 추가\n                ax.set_xticks(np.linspace(0, min_length, len(set(years))))\n                ax.set_xticklabels(sorted(set(years)))\n\n            if i == 6 and j == 6:  # 마지막 셀에만 컬러바 추가\n                plt.colorbar(im, ax=ax, orientation='horizontal', pad=0.2, aspect=30, shrink=0.8)\n\n    # 범례 추가\n    fig.legend(['COVID-19'], loc='upper right', bbox_to_anchor=(0.99, 0.99), fontsize=8)\n\n    plt.show()  \n    plt.tight_layout()  \n\n\n# 예시 사용법\nindices = {\n    'Apple Inc.': 'AAPL',\n    'Microsoft Corporation': 'MSFT',\n    'Nvidia Corporation': 'NVDA',\n    'Alphabet Inc. (Google)': 'GOOGL',\n    'Amazon.com Inc.': 'AMZN',\n    'Tesla Inc.': 'TSLA',\n    'Meta Platforms Inc.': 'META'\n}\nstart_date = '2019-06-25'\nend_date = '2024-06-25'\ntaus = list(range(5, 300, 5))\n\nplot_correlations2(indices, start_date, end_date, taus)\n\n[*********************100%%**********************]  1 of 1 completed\n[*********************100%%**********************]  1 of 1 completed\n[*********************100%%**********************]  1 of 1 completed\n[*********************100%%**********************]  1 of 1 completed\n[*********************100%%**********************]  1 of 1 completed\n[*********************100%%**********************]  1 of 1 completed\n[*********************100%%**********************]  1 of 1 completed\n[*********************100%%**********************]  1 of 1 completed"
  },
  {
    "objectID": "연구/교수님이랑/MS_Review/EMD.html",
    "href": "연구/교수님이랑/MS_Review/EMD.html",
    "title": "(연구&교수님) 다중척도논문 – EMD",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.interpolate import CubicSpline\ndef sift_once(signal, t):\n    # 최대값과 최소값을 찾기\n    max_peaks = [j for j in range(1, len(signal)-1) if signal[j-1] &lt; signal[j] &gt; signal[j+1]]\n    min_peaks = [j for j in range(1, len(signal)-1) if signal[j-1] &gt; signal[j] &lt; signal[j+1]]\n\n    # 최대값과 최소값의 위치에 대해 cubic spline 보간\n    if len(max_peaks) &gt; 1 and len(min_peaks) &gt; 1:\n        upper_env = CubicSpline(t[max_peaks], signal[max_peaks])(t)\n        lower_env = CubicSpline(t[min_peaks], signal[min_peaks])(t)\n        \n        # 평균 곡선 계산\n        mean_env = (upper_env + lower_env) / 2\n        \n        # IMF 갱신\n        imf = signal - mean_env\n        \n        return imf, upper_env, lower_env, mean_env\n    else:\n        return signal, np.zeros_like(signal), np.zeros_like(signal), np.zeros_like(signal)\n\n\nfrom matplotlib.backends.backend_pdf import PdfPages\nplt.rcParams.update({\n    \"text.usetex\": True,\n#    \"font.family\": \"Helvetica\"\n})\n\n\n# 초기 신호 설정\n# 샘플링 주파수 및 시간 축 설정\nfs = 1000\nt = np.linspace(0, 1, 2 * fs, endpoint=False)\n\n# 두 개의 주파수를 가진 신호 생성\nsignal = np.sin(2 * np.pi * 5 * t) + 0.5 * np.sin(2 * np.pi * 25 * t)\n\n\n이산형 신호\n이산형 신호는 특정한 샘플링 주파수 \\(f_s\\) 에서 샘플링된 신호를 의미합니다. 여기서는 \\(f_s = 1000\\) Hz로 샘플링된 신호를 사용하고 있습니다.\n\\[ x[n] = \\sin\\left(2 \\pi \\cdot 5 \\cdot \\frac{n}{f_s}\\right) + 0.5 \\cdot \\sin\\left(2 \\pi \\cdot 25 \\cdot \\frac{n}{f_s}\\right) \\]\n여기서: - \\(n\\) 은 샘플 인덱스 (정수) - \\(f_s\\) 는 샘플링 주파수 (1000 Hz)\n\n\n연속형 신호\n연속형 신호는 시간 \\(t\\) 에 대한 신호를 의미합니다.\n\\[ x(t) = \\sin(2 \\pi \\cdot 5 \\cdot t) + 0.5 \\cdot \\sin(2 \\pi \\cdot 25 \\cdot t) \\]\n여기서: - \\(t\\)는 시간 (초 단위)\n두 수식은 기본적으로 같은 신호를 나타내지만, 하나는 이산형(디지털) 신호를 나타내고 다른 하나는 연속형(아날로그) 신호를 나타냅니다.\n\n\n체거름과정 시각화\n\n# 두 개의 주파수를 가진 신호 생성\nsignal = np.sin(2 * np.pi * 5 * t) + 0.5 * np.sin(2 * np.pi * 25 * t)\nresidual = signal\nimfs = []\nimf, upper_env, lower_env, mean_env = sift_once(residual, t)\nimfs.append(imf)\n\nplt.figure(figsize=(10, 10))\n\nplt.subplot(5, 1, 1)\nplt.plot(t, residual, 'k', label=r'Original Signal $s^{(1)}_n$')\nplt.plot(t, upper_env, 'orange', label=r'Upper Envelope $u^{(1)}_n$', linestyle='dotted')\nplt.plot(t, lower_env, 'orange', label=r'Lower Envelope $l^{(1)}_n$', linestyle='dotted')\nplt.plot(t, mean_env, 'r', label=r'Mean $m^{(1)}_n$', linestyle='dashed')\nplt.title(f\"Sifting Process Iteration 1\")\nplt.xlabel(\"Time [s]\")\nplt.ylabel(\"Amplitude\")\nplt.legend()\n\nplt.subplot(5, 1, 2)\nplt.plot(t, imf, 'k', label='IMF1 $h^{(1)}_n=s^{(1)}_n-m^{(1)}_n$')\nplt.title(f\"Intrinsic Mode Function 1\")\nplt.xlabel(\"Time [s]\")\nplt.ylabel(\"Amplitude\")\nplt.legend()\n\n# 남은 신호 업데이트\nresidual -= imf\nimf, upper_env, lower_env, mean_env = sift_once(residual, t)\nimfs.append(imf)\n\nplt.subplot(5, 1, 3)\nplt.plot(t, residual, 'k', label=r'$s^{(2)}_n=s^{(1)}_n-h^{(1)}_n$')\nplt.plot(t, upper_env, 'orange', label='Upper Envelope $u^{(2)}_n$', linestyle='dotted')\nplt.plot(t, lower_env, 'orange', label='Lower Envelope $l^{(2)}_n$', linestyle='dotted')\nplt.plot(t, mean_env, 'r', label='Mean $m^{(2)}_n$', linestyle='dashed')\nplt.title(r\"Sifting Process Iteration 2\")\nplt.xlabel(\"Time [s]\")\nplt.ylabel(\"Amplitude\")\nplt.legend()\n\nplt.subplot(5, 1, 4)\nplt.plot(t, imf, 'k', label='IMF2 $h^{(2)}_n=s^{(2)}_n-m^{(2)}_n$')\nplt.title(f\"Intrinsic Mode Function 2\")\nplt.xlabel(\"Time [s]\")\nplt.ylabel(\"Amplitude\")\nplt.legend()\n\n# 남은 신호 업데이트\nresidual -= imf\nimf, upper_env, lower_env, mean_env = sift_once(residual, t)\nimfs.append(imf)\n\nplt.subplot(5, 1, 5)\nplt.plot(t, residual, 'k', label='Residual $s^{(3)}_n=s^{(2)}_n-h^{(2)}_n$')\nplt.title(f\"Sifting Process Iteration 3\")\nplt.xlabel(\"Time [s]\")\nplt.ylabel(\"Amplitude\")\nplt.legend()\n\nplt.tight_layout()\nfig = plt.gcf()\n\nwith PdfPages('./Dropbox/03_Yechan3/연구/교수님이랑/MS_Review/sifting_process.pdf') as pdf:\n    pdf.savefig(fig, dpi=100)\n    plt.close(fig)\n\nfig"
  },
  {
    "objectID": "연구/교수님이랑/MS_Review/TPT, 미국지수분석.html",
    "href": "연구/교수님이랑/MS_Review/TPT, 미국지수분석.html",
    "title": "(연구&교수님) 다중척도논문 – TPT, 미국지수분석",
    "section": "",
    "text": "MS vs APPL\n\nimport yfinance as yf\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.rcParams.update({\n    \"text.usetex\": True,\n#    \"font.family\": \"Helvetica\"\n})\n# 데이터 크롤링 (최근 8년)\nstart_date = '2016-01-01'\nend_date = '2024-01-01'\nmicrosoft = yf.download('MSFT', start=start_date, end=end_date)\napple = yf.download('AAPL', start=start_date, end=end_date)\n\n# 로그 변환 및 차분\nlog_microsoft = np.log(microsoft['Close'])\nlog_apple = np.log(apple['Close'])\ndiff_log_microsoft = log_microsoft.diff().dropna()\ndiff_log_apple = log_apple.diff().dropna()\n\n# 표준화 함수\ndef standardize(series):\n    return (series - series.mean()) / series.std()\n\n# 차분 데이터 표준화\nstd_diff_log_microsoft = standardize(diff_log_microsoft)\nstd_diff_log_apple = standardize(diff_log_apple)\n\n# 두꺼운펜변환 함수 (사각펜)\ndef thick_pen_transform(X, tau, gamma=0.001):\n    n = len(X)\n    U_tau = np.zeros(n)\n    L_tau = np.zeros(n)\n    \n    for t in range(n - tau):\n        U_tau[t] = np.max(X[t:t+tau+1]) + gamma * (tau / 2)\n        L_tau[t] = np.min(X[t:t+tau+1]) - gamma * (tau / 2)\n    \n    # 경계 케이스 처리\n    for t in range(n - tau, n):\n        U_tau[t] = np.max(X[t:n]) + gamma * (tau / 2)\n        L_tau[t] = np.min(X[t:n]) - gamma * (tau / 2)\n    \n    return L_tau, U_tau\n\ntau = 5  # 두께 파라미터 설정\nX = std_diff_log_microsoft.values\nY = std_diff_log_apple.values\ndates = diff_log_microsoft.index\n\nX_L_tau, X_U_tau = thick_pen_transform(X, tau)\nY_L_tau, Y_U_tau = thick_pen_transform(Y, tau)\n\n# 코로나 시작 지점 설정\ncovid_start = '2020-03-01'\ncovid_start_idx = np.where(dates &gt;= covid_start)[0][0]\n\n# Upper와 Lower 각각 시각화 함수\ndef plot_series(X, Y, X_L_tau, X_U_tau, Y_L_tau, Y_U_tau, dates, tau):\n    plt.figure(figsize=(14, 5))\n    plt.plot(dates[tau:-tau], X[tau:-tau], label='Microsoft', color='blue', linewidth=1)\n    plt.plot(dates[tau:-tau], Y[tau:-tau], label='Apple', color='red', linewidth=1)\n    \n    # 코로나 시작 지점 하이라이트\n    plt.axvline(dates[covid_start_idx], color='k', linewidth=5, alpha=0.5, label='COVID-19')\n\n    plt.legend(loc='upper right')\n    plt.title('Microsoft and Apple Time Series')\n    plt.xlabel('Year')\n    plt.ylabel('Standardized Log Difference')\n    plt.show()\n\n# 시각화\nplot_series(X, Y, X_L_tau, X_U_tau, Y_L_tau, Y_U_tau, dates, tau)\n\n\n# Upper와 Lower 각각 시각화 함수\ndef plot_upper_lower_with_series(X, Y, X_L_tau, X_U_tau, Y_L_tau, Y_U_tau, dates, tau):\n    plt.figure(figsize=(14, 5))\n    plt.plot(dates[tau:-tau], X[tau:-tau], label='Microsoft', color='blue', linewidth=1)\n    plt.plot(dates[tau:-tau], Y[tau:-tau], label='Apple', color='red', linewidth=1)\n    \n    plt.fill_between(dates[tau:-tau], X_L_tau[tau:-tau], X_U_tau[tau:-tau], color='blue', alpha=0.3, label='Microsoft Bound')\n    plt.fill_between(dates[tau:-tau], Y_L_tau[tau:-tau], Y_U_tau[tau:-tau], color='red', alpha=0.3, label='Apple Bound')\n    \n    # 코로나 시작 지점 하이라이트\n    plt.axvline(dates[covid_start_idx], color='k', linewidth=5, alpha=0.5, label='COVID-19')\n    \n    plt.legend(loc='upper right')\n    plt.title('Original Time Series with Upper and Lower Bounds (Thick-Pen Transform)')\n    plt.xlabel('Year')\n    plt.ylabel('Standardized Log Difference')\n    plt.show()\n\n# 시각화\nplot_upper_lower_with_series(X, Y, X_L_tau, X_U_tau, Y_L_tau, Y_U_tau, dates, tau)\n\n# TPMA의 분자와 분모 각각 시각화 함수\ndef plot_tpma_numerator_denominator_with_series(X, Y, X_L_tau, X_U_tau, Y_L_tau, Y_U_tau, dates, tau):\n    plt.figure(figsize=(14, 5))\n    \n    overlap_range = [min(X_U_tau[t], Y_U_tau[t]) - max(X_L_tau[t], Y_L_tau[t]) for t in range(len(X))]\n    spread_range = [max(X_U_tau[t], Y_U_tau[t]) - min(X_L_tau[t], Y_L_tau[t]) for t in range(len(X))]\n    \n    plt.plot(dates[tau:-tau], X[tau:-tau], color='blue', linewidth=1, alpha=0.1)\n    plt.plot(dates[tau:-tau], Y[tau:-tau], color='red', linewidth=1, alpha=0.1)\n    \n    # 분자와 분모에 해당하는 음영 추가\n    plt.fill_between(dates[tau:-tau], [max(X_L_tau[t], Y_L_tau[t]) for t in range(tau, len(X)-tau)], \n                     [min(X_U_tau[t], Y_U_tau[t]) for t in range(tau, len(X)-tau)], color='green', alpha=0.2, label='Overlap Range')\n    plt.fill_between(dates[tau:-tau], [min(X_L_tau[t], Y_L_tau[t]) for t in range(tau, len(X)-tau)], \n                     [max(X_U_tau[t], Y_U_tau[t]) for t in range(tau, len(X)-tau)], color='orange', alpha=0.2, label='Spread Range')\n    \n    plt.plot(dates[tau:-tau], overlap_range[tau:-tau], color='green', linestyle='--', linewidth=1, label='Overlap')\n    plt.plot(dates[tau:-tau], spread_range[tau:-tau], color='orange', linestyle='-', linewidth=1, label='Spread')\n    \n    # 코로나 시작 지점 하이라이트\n    plt.axvline(dates[covid_start_idx], color='k', linewidth=5, alpha=0.5, label='COVID-19')\n\n    plt.legend(loc='upper right')\n    plt.title('TPMA Overlap and Spread Ranges with Original Time Series')\n    plt.xlabel('Year')\n    plt.ylabel('Range')\n    plt.show()\n\n# 시각화\nplot_tpma_numerator_denominator_with_series(X, Y, X_L_tau, X_U_tau, Y_L_tau, Y_U_tau, dates, tau)\n\n# 두꺼운펜 변환 상관계수 계산 함수\ndef rho_tau(X, Y, X_L_tau, X_U_tau, Y_L_tau, Y_U_tau):\n    rho_tau_t = np.zeros(len(X))\n    \n    for t in range(len(X)):\n        min_U = min(X_U_tau[t], Y_U_tau[t])\n        max_L = max(X_L_tau[t], Y_L_tau[t])\n        max_U = max(X_U_tau[t], Y_U_tau[t])\n        min_L = min(X_L_tau[t], Y_L_tau[t])\n        \n        rho_tau_t[t] = (min_U - max_L) / (max_U - min_L)\n    \n    return rho_tau_t\n\n# TPMA 계산\nrho_values = rho_tau(X, Y, X_L_tau, X_U_tau, Y_L_tau, Y_U_tau)\n\n# TPMA 값 시각화 함수\ndef plot_tpma_values_with_series(rho_values, dates, tau):\n    plt.figure(figsize=(14, 5))\n    \n    # 원본 TPMA 값 플로팅\n    plt.plot(dates[tau:-tau], rho_values[tau:-tau], label='TPMA = Overlap/Spread', color='purple', linewidth=1, alpha=0.1)\n    \n    # Smoothed line 추가 (이동 평균)\n    window_size = 120\n    smoothed_rho = np.convolve(rho_values[tau:-tau], np.ones(window_size)/window_size, mode='valid')\n    plt.plot(dates[tau + window_size//2: -tau - window_size//2 + 1], smoothed_rho, label='Smoothed TPMA', color='purple', linewidth=2)\n    \n    # 코로나 시작 지점 하이라이트\n    plt.axvline(dates[covid_start_idx], color='k', linewidth=5, alpha=0.5, label='COVID-19')\n    \n    plt.legend(loc='upper right')\n    plt.title('TPMA Values with Original Time Series')\n    plt.xlabel('Year')\n    plt.ylabel('TPMA Value')\n    plt.show()\n\n# 시각화\nplot_tpma_values_with_series(rho_values, dates, tau)\n\n[*********************100%%**********************]  1 of 1 completed\n[*********************100%%**********************]  1 of 1 completed\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMS vs Meta\n\n# 데이터 크롤링 (최근 8년)\nstart_date = '2016-01-01'\nend_date = '2024-01-01'\ngoogle = yf.download('GOOGL', start=start_date, end=end_date)\nmeta = yf.download('META', start=start_date, end=end_date)\n\n# 로그 변환 및 차분\nlog_google = np.log(google['Close'])\nlog_meta = np.log(meta['Close'])\ndiff_log_google = log_google.diff().dropna()\ndiff_log_meta = log_meta.diff().dropna()\n\n# 표준화\nstd_diff_log_google = standardize(diff_log_google)\nstd_diff_log_meta = standardize(diff_log_meta)\n\ntau = 5  # 두께 파라미터 설정\nX = std_diff_log_google.values\nY = std_diff_log_meta.values\ndates = diff_log_google.index\n\nX_L_tau, X_U_tau = thick_pen_transform(X, tau)\nY_L_tau, Y_U_tau = thick_pen_transform(Y, tau)\n\n# 코로나 시작 지점 설정\ncovid_start = '2020-03-01'\ncovid_start_idx = np.where(dates &gt;= covid_start)[0][0]\n\n# Upper와 Lower 각각 시각화 함수\ndef plot_series(X, Y, X_L_tau, X_U_tau, Y_L_tau, Y_U_tau, dates, tau):\n    plt.figure(figsize=(14, 5))\n    plt.plot(dates[tau:-tau], X[tau:-tau], label='Google', color='blue', linewidth=1)\n    plt.plot(dates[tau:-tau], Y[tau:-tau], label='Meta', color='red', linewidth=1)\n    \n    # 코로나 시작 지점 하이라이트\n    plt.axvline(dates[covid_start_idx], color='k', linewidth=5, alpha=0.5, label='COVID-19')\n\n    plt.legend(loc='upper right')\n    plt.title('Google and Meta Time Series')\n    plt.xlabel('Year')\n    plt.ylabel('Standardized Log Difference')\n    plt.show()\n\n# 시각화\nplot_series(X, Y, X_L_tau, X_U_tau, Y_L_tau, Y_U_tau, dates, tau)\n\n# Upper와 Lower 각각 시각화 함수\ndef plot_upper_lower_with_series(X, Y, X_L_tau, X_U_tau, Y_L_tau, Y_U_tau, dates, tau):\n    plt.figure(figsize=(14, 5))\n    plt.plot(dates[tau:-tau], X[tau:-tau], label='Google', color='blue', linewidth=1)\n    plt.plot(dates[tau:-tau], Y[tau:-tau], label='Meta', color='red', linewidth=1)\n    \n    plt.fill_between(dates[tau:-tau], X_L_tau[tau:-tau], X_U_tau[tau:-tau], color='blue', alpha=0.3, label='Google Bound')\n    plt.fill_between(dates[tau:-tau], Y_L_tau[tau:-tau], Y_U_tau[tau:-tau], color='red', alpha=0.3, label='Meta Bound')\n    \n    # 코로나 시작 지점 하이라이트\n    plt.axvline(dates[covid_start_idx], color='k', linewidth=5, alpha=0.5, label='COVID-19')\n    \n    plt.legend(loc='upper right')\n    plt.title('Original Time Series with Upper and Lower Bounds (Thick-Pen Transform)')\n    plt.xlabel('Year')\n    plt.ylabel('Standardized Log Difference')\n    plt.show()\n\n# 시각화\nplot_upper_lower_with_series(X, Y, X_L_tau, X_U_tau, Y_L_tau, Y_U_tau, dates, tau)\n\n# TPMA의 분자와 분모 각각 시각화 함수\ndef plot_tpma_numerator_denominator_with_series(X, Y, X_L_tau, X_U_tau, Y_L_tau, Y_U_tau, dates, tau):\n    plt.figure(figsize=(14, 5))\n    \n    overlap_range = [min(X_U_tau[t], Y_U_tau[t]) - max(X_L_tau[t], Y_L_tau[t]) for t in range(len(X))]\n    spread_range = [max(X_U_tau[t], Y_U_tau[t]) - min(X_L_tau[t], Y_L_tau[t]) for t in range(len(X))]\n    \n    plt.plot(dates[tau:-tau], X[tau:-tau], color='blue', linewidth=1, alpha=0.1)\n    plt.plot(dates[tau:-tau], Y[tau:-tau], color='red', linewidth=1, alpha=0.1)\n    \n    # 분자와 분모에 해당하는 음영 추가\n    plt.fill_between(dates[tau:-tau], [max(X_L_tau[t], Y_L_tau[t]) for t in range(tau, len(X)-tau)], \n                     [min(X_U_tau[t], Y_U_tau[t]) for t in range(tau, len(X)-tau)], color='green', alpha=0.2, label='Overlap Range')\n    plt.fill_between(dates[tau:-tau], [min(X_L_tau[t], Y_L_tau[t]) for t in range(tau, len(X)-tau)], \n                     [max(X_U_tau[t], Y_U_tau[t]) for t in range(tau, len(X)-tau)], color='orange', alpha=0.2, label='Spread Range')\n    \n    plt.plot(dates[tau:-tau], overlap_range[tau:-tau], color='green', linestyle='--', linewidth=1, label='Overlap')\n    plt.plot(dates[tau:-tau], spread_range[tau:-tau], color='orange', linestyle='-', linewidth=1, label='Spread')\n    \n    # 코로나 시작 지점 하이라이트\n    plt.axvline(dates[covid_start_idx], color='k', linewidth=5, alpha=0.5, label='COVID-19')\n\n    plt.legend(loc='upper right')\n    plt.title('TPMA Overlap and Spread Ranges with Original Time Series')\n    plt.xlabel('Year')\n    plt.ylabel('Range')\n    plt.show()\n\n# 시각화\nplot_tpma_numerator_denominator_with_series(X, Y, X_L_tau, X_U_tau, Y_L_tau, Y_U_tau, dates, tau)\n\nrho_values = rho_tau(X, Y, X_L_tau, X_U_tau, Y_L_tau, Y_U_tau)\n# TPMA 값 시각화 함수\ndef plot_tpma_values_with_series(rho_values, dates, tau):\n    plt.figure(figsize=(14, 5))\n    \n    # 원본 TPMA 값 플로팅\n    plt.plot(dates[tau:-tau], rho_values[tau:-tau], label='TPMA = Overlap/Spread', color='purple', linewidth=1, alpha=0.1)\n    \n    # Smoothed line 추가 (이동 평균)\n    window_size = 120\n    smoothed_rho = np.convolve(rho_values[tau:-tau], np.ones(window_size)/window_size, mode='valid')\n    plt.plot(dates[tau + window_size//2: -tau - window_size//2 + 1], smoothed_rho, label='Smoothed TPMA', color='orange', linewidth=2)\n    \n    # 코로나 시작 지점 하이라이트\n    plt.axvline(dates[covid_start_idx], color='k', linewidth=5, alpha=0.5, label='COVID-19')\n    \n    plt.legend(loc='upper right')\n    plt.title('TPMA Values with Original Time Series')\n    plt.xlabel('Year')\n    plt.ylabel('TPMA Value')\n    plt.show()\n\n# 시각화\nplot_tpma_values_with_series(rho_values, dates, tau)\n\n[*********************100%%**********************]  1 of 1 completed\n[*********************100%%**********************]  1 of 1 completed\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n테슬라와 NVIDIA\n\nimport yfinance as yf\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# 데이터 크롤링 (최근 8년)\nstart_date = '2016-01-01'\nend_date = '2024-01-01'\ntesla = yf.download('TSLA', start=start_date, end=end_date)\nnvidia = yf.download('NVDA', start=start_date, end=end_date)\n\n# 로그 변환 및 차분\nlog_tesla = np.log(tesla['Close'])\nlog_nvidia = np.log(nvidia['Close'])\ndiff_log_tesla = log_tesla.diff().dropna()\ndiff_log_nvidia = log_nvidia.diff().dropna()\n\n# 표준화\nstd_diff_log_tesla = standardize(diff_log_tesla)\nstd_diff_log_nvidia = standardize(diff_log_nvidia)\n\ntau = 30  # 두께 파라미터 설정\nX = std_diff_log_tesla.values\nY = std_diff_log_nvidia.values\ndates = diff_log_tesla.index\n\nX_L_tau, X_U_tau = thick_pen_transform(X, tau)\nY_L_tau, Y_U_tau = thick_pen_transform(Y, tau)\n\n# 코로나 시작 지점 설정\ncovid_start = '2020-03-01'\ncovid_start_idx = np.where(dates &gt;= covid_start)[0][0]\n\n# Upper와 Lower 각각 시각화 함수\ndef plot_series(X, Y, X_L_tau, X_U_tau, Y_L_tau, Y_U_tau, dates, tau):\n    plt.figure(figsize=(14, 5))\n    plt.plot(dates[tau:-tau], X[tau:-tau], label='Tesla', color='blue', linewidth=1)\n    plt.plot(dates[tau:-tau], Y[tau:-tau], label='Nvidia', color='red', linewidth=1)\n    \n    # 코로나 시작 지점 하이라이트\n    plt.axvline(dates[covid_start_idx], color='k', linewidth=5, alpha=0.5, label='COVID-19')\n\n    plt.legend(loc='upper right')\n    plt.title('Tesla and Nvidia Time Series')\n    plt.xlabel('Year')\n    plt.ylabel('Standardized Log Difference')\n    plt.show()\n\n# 시각화\nplot_series(X, Y, X_L_tau, X_U_tau, Y_L_tau, Y_U_tau, dates, tau)\n\n# Upper와 Lower 각각 시각화 함수\ndef plot_upper_lower_with_series(X, Y, X_L_tau, X_U_tau, Y_L_tau, Y_U_tau, dates, tau):\n    plt.figure(figsize=(14, 5))\n    plt.plot(dates[tau:-tau], X[tau:-tau], label='Tesla', color='blue', linewidth=1)\n    plt.plot(dates[tau:-tau], Y[tau:-tau], label='Nvidia', color='red', linewidth=1)\n    \n    plt.fill_between(dates[tau:-tau], X_L_tau[tau:-tau], X_U_tau[tau:-tau], color='blue', alpha=0.3, label='Tesla Bound')\n    plt.fill_between(dates[tau:-tau], Y_L_tau[tau:-tau], Y_U_tau[tau:-tau], color='red', alpha=0.3, label='Nvidia Bound')\n    \n    # 코로나 시작 지점 하이라이트\n    plt.axvline(dates[covid_start_idx], color='k', linewidth=5, alpha=0.5, label='COVID-19')\n    \n    plt.legend(loc='upper right')\n    plt.title('Original Time Series with Upper and Lower Bounds (Thick-Pen Transform)')\n    plt.xlabel('Year')\n    plt.ylabel('Standardized Log Difference')\n    plt.show()\n\n# 시각화\nplot_upper_lower_with_series(X, Y, X_L_tau, X_U_tau, Y_L_tau, Y_U_tau, dates, tau)\n\n# TPMA의 분자와 분모 각각 시각화 함수\ndef plot_tpma_numerator_denominator_with_series(X, Y, X_L_tau, X_U_tau, Y_L_tau, Y_U_tau, dates, tau):\n    plt.figure(figsize=(14, 5))\n    \n    overlap_range = [min(X_U_tau[t], Y_U_tau[t]) - max(X_L_tau[t], Y_L_tau[t]) for t in range(len(X))]\n    spread_range = [max(X_U_tau[t], Y_U_tau[t]) - min(X_L_tau[t], Y_L_tau[t]) for t in range(len(X))]\n    \n    plt.plot(dates[tau:-tau], X[tau:-tau], color='blue', linewidth=1, alpha=0.1)\n    plt.plot(dates[tau:-tau], Y[tau:-tau], color='red', linewidth=1, alpha=0.1)\n    \n    # 분자와 분모에 해당하는 음영 추가\n    plt.fill_between(dates[tau:-tau], [max(X_L_tau[t], Y_L_tau[t]) for t in range(tau, len(X)-tau)], \n                     [min(X_U_tau[t], Y_U_tau[t]) for t in range(tau, len(X)-tau)], color='green', alpha=0.2, label='Overlap Range')\n    plt.fill_between(dates[tau:-tau], [min(X_L_tau[t], Y_L_tau[t]) for t in range(tau, len(X)-tau)], \n                     [max(X_U_tau[t], Y_U_tau[t]) for t in range(tau, len(X)-tau)], color='orange', alpha=0.2, label='Spread Range')\n    \n    plt.plot(dates[tau:-tau], overlap_range[tau:-tau], color='green', linestyle='--', linewidth=1, label='Overlap')\n    plt.plot(dates[tau:-tau], spread_range[tau:-tau], color='orange', linestyle='-', linewidth=1, label='Spread')\n    \n    # 코로나 시작 지점 하이라이트\n    plt.axvline(dates[covid_start_idx], color='k', linewidth=5, alpha=0.5, label='COVID-19')\n\n    plt.legend(loc='upper right')\n    plt.title('TPMA Overlap and Spread Ranges with Original Time Series')\n    plt.xlabel('Year')\n    plt.ylabel('Range')\n    plt.show()\n\n# 시각화\nplot_tpma_numerator_denominator_with_series(X, Y, X_L_tau, X_U_tau, Y_L_tau, Y_U_tau, dates, tau)\n\nrho_values = rho_tau(X, Y, X_L_tau, X_U_tau, Y_L_tau, Y_U_tau)\n# TPMA 값 시각화 함수\ndef plot_tpma_values_with_series(rho_values, dates, tau):\n    plt.figure(figsize=(14, 5))\n    \n    # 원본 TPMA 값 플로팅\n    plt.plot(dates[tau:-tau], rho_values[tau:-tau], label='TPMA = Overlap/Spread', color='purple', linewidth=1, alpha=0.1)\n    \n    # Smoothed line 추가 (이동 평균)\n    window_size = 120\n    smoothed_rho = np.convolve(rho_values[tau:-tau], np.ones(window_size)/window_size, mode='valid')\n    plt.plot(dates[tau + window_size//2: -tau - window_size//2 + 1], smoothed_rho, label='Smoothed TPMA', color='orange', linewidth=2)\n    \n    # 코로나 시작 지점 하이라이트\n    plt.axvline(dates[covid_start_idx], color='k', linewidth=5, alpha=0.5, label='COVID-19')\n    \n    plt.legend(loc='upper right')\n    plt.title('TPMA Values with Original Time Series')\n    plt.xlabel('Year')\n    plt.ylabel('TPMA Value')\n    plt.show()\n\n# 시각화\nplot_tpma_values_with_series(rho_values, dates, tau)\n\n[*********************100%%**********************]  1 of 1 completed\n[*********************100%%**********************]  1 of 1 completed\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n논문에 쓰는 그림\n\n# 서브플롯 설정\nfig, axs = plt.subplots(3, 1, figsize=(8,9))\n\n# 첫 번째 서브플롯 - Original Time Series\naxs[0].plot(dates[tau:-tau], X[tau:-tau], label='Microsoft', color='blue', linewidth=1)\naxs[0].plot(dates[tau:-tau], Y[tau:-tau], label='Apple', color='red', linewidth=1)\naxs[0].axvline(dates[covid_start_idx], color='k', linewidth=5, alpha=0.5, label='COVID-19')\naxs[0].legend(loc='upper right')\naxs[0].set_title('Microsoft and Apple Time Series')\naxs[0].set_xlabel('Year')\naxs[0].set_ylabel('Standardized Log Difference')\n\n# 두 번째 서브플롯 - TPMA Overlap and Spread Ranges\noverlap_range = [min(X_U_tau[t], Y_U_tau[t]) - max(X_L_tau[t], Y_L_tau[t]) for t in range(len(X))]\nspread_range = [max(X_U_tau[t], Y_U_tau[t]) - min(X_L_tau[t], Y_L_tau[t]) for t in range(len(X))]\n\n# axs[1].fill_between(dates[tau:-tau], [max(X_L_tau[t], Y_L_tau[t]) for t in range(tau, len(X)-tau)], \n#                      [min(X_U_tau[t], Y_U_tau[t]) for t in range(tau, len(X)-tau)], color='green', alpha=0.2, label='Overlap Range')\n# axs[1].fill_between(dates[tau:-tau], [min(X_L_tau[t], Y_L_tau[t]) for t in range(tau, len(X)-tau)], \n#                      [max(X_U_tau[t], Y_U_tau[t]) for t in range(tau, len(X)-tau)], color='orange', alpha=0.2, label='Spread Range')\naxs[1].plot(dates[tau:-tau], overlap_range[tau:-tau], color='green', linestyle='--', linewidth=1, label='Overlap')\naxs[1].plot(dates[tau:-tau], spread_range[tau:-tau], color='orange', linestyle='-', linewidth=1, label='Spread')\naxs[1].axvline(dates[covid_start_idx], color='k', linewidth=5, alpha=0.5, label='COVID-19')\naxs[1].legend(loc='upper right')\naxs[1].set_title('TPMA Overlap and Spread Ranges with Original Time Series')\naxs[1].set_xlabel('Year')\naxs[1].set_ylabel('Range')\n\n# 세 번째 서브플롯 - TPMA Values\naxs[2].plot(dates[tau:-tau], rho_values[tau:-tau], label='TPMA = Overlap/Spread', color='purple', linewidth=1, alpha=0.1)\nwindow_size = 120\nsmoothed_rho = np.convolve(rho_values[tau:-tau], np.ones(window_size)/window_size, mode='valid')\naxs[2].plot(dates[tau + window_size//2: -tau - window_size//2 + 1], smoothed_rho, label='Smoothed TPMA', color='purple', linewidth=2)\naxs[2].axvline(dates[covid_start_idx], color='k', linewidth=5, alpha=0.5, label='COVID-19')\naxs[2].legend(loc='upper right')\naxs[2].set_title('TPMA Values with Original Time Series')\naxs[2].set_xlabel('Year')\naxs[2].set_ylabel('TPMA Value')\n\n# 전체 그림 저장\nplt.tight_layout()\nplt.savefig('./Dropbox/03_Yechan3/연구/교수님이랑/MS_Review/tpt_MSAPPL.pdf')\nplt.show()"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-07-30-ECGVIS.html",
    "href": "연구/교수님이랑/EBT/2024-07-30-ECGVIS.html",
    "title": "(연구&교수님) EBT – ECG 자료 시각화",
    "section": "",
    "text": "library(devtools)\ninstall_github(\"guebin/EBT\",force=TRUE)\nlibrary(tidyverse)\nlibrary(ebt)\nlibrary(wavelets)\nlibrary(phonTools)\nlibrary(fields)\nlibrary(viridis)\nlibrary(wavScalogram)\nlibrary(magick)\n\nDownloading GitHub repo guebin/EBT@HEAD\n\n\n\n── R CMD build ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n✔  checking for file ‘/tmp/RtmpnL4DDZ/remotes920376f46111/guebin-EBT-f065664/DESCRIPTION’\n─  preparing ‘ebt’:\n✔  checking DESCRIPTION meta-information\n─  checking for LF line-endings in source and make files and shell scripts\n─  checking for empty or unneeded directories\n   Omitted ‘LazyData’ from DESCRIPTION\n─  building ‘ebt_0.1.0.tar.gz’"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-07-30-ECGVIS.html#a.-signal",
    "href": "연구/교수님이랑/EBT/2024-07-30-ECGVIS.html#a.-signal",
    "title": "(연구&교수님) EBT – ECG 자료 시각화",
    "section": "A. signal",
    "text": "A. signal\n\ndata(ecg)\nf&lt;-as.vector(ecg)\nt&lt;-seq(0,11.37,length=2048)\nfs&lt;-180 \nmaxtau=225\nlen&lt;-length(f)\n#ecg_mvmap &lt;- mvmap(f,maxtau = maxtau)\n#save(ecg_mvmap, file = \"./Dropbox/03_Yechan3/연구/교수님이랑/EBT/ecg_mvmap_0730.RData\")\nload(\"./Dropbox/03_Yechan3/연구/교수님이랑/EBT/ecg_mvmap_0730.RData\")\nv_map&lt;-ecg_mvmap$vmap\ntemp&lt;-spectrogram(f,fs=180,windowlength = 612.5,show=F)$spectrogram\nspec_rslt &lt;-spectrogram(f,fs=180,windowlength = 612.5,show=F)$spectrogram\nscalo_rslt &lt;- abs(cwt_wst(f,makefigure=FALSE)$coef)\n\n\n#pdf(\"./Dropbox/03_Yechan3/연구/교수님이랑/EBT/ecg_comparevis.pdf\",width=14,height=18)\npar(mfrow=c(4,1))\npar(mar=c(4,2.5,2.5,8.5))\nplot(t,f, main = \"ECG signal\", xlab = \"Time [s]\", ylab = \"Amplitude\",type='l')\npar(mar=c(4,3.5,2.5,2.5))\nimage.plot(\n    x=t,y=50:215,z=v_map[1:length(f),50:215],\n    xlab = \"Time [s]\", ylab = \"Scale\", main = \"Vmap\",\n    legend.mar=5, \n    col=viridis(256, option = \"magma\")\n)\npar(mar=c(4,3.5,2.5,2.5))\nimage.plot(\n    x=seq(0,11.37,length=941),y=seq(0,90,length=617),z=spec_rslt[1:941,1:617],\n    xlab = \"Time [s]\", ylab = \"Frequency (Hz)\", main = \"Spectrogram\",\n    col=viridis(256, option = \"magma\")\n)\npar(mar=c(4,3.5,2.5,2.5))\nimage.plot(\n    x=t,z=scalo_rslt,\n    xlab = \"Time [s]\", ylab = \"Scale\", main = \"Scalogram\",\n    col = colorRampPalette(c(\"purple\", \"green\"))(256)\n)\npar(mfrow=c(1,1))\n#dev.off()\n\n\n\n\n\n\n\n\n\npng(\"./Dropbox/03_Yechan3/연구/교수님이랑/EBT/ecg_comparevis.png\",width=2100,height=1800,res=300)\npar(mfrow=c(4,1))\npar(mar=c(4,4.5,2.5,8.5))\nplot(t,f, main = \"ECG signal\", xlab = \"Time [s]\", ylab = \"Amplitude\",type='l')\npar(mar=c(4,5.5,2.5,2.5))\nimage.plot(\n    x=t,y=50:215,z=v_map[1:length(f),50:215],\n    xlab = \"Time [s]\", ylab = \"Scale\", main = \"Vmap\",\n    legend.mar=5, \n    col=viridis(256, option = \"magma\")\n)\npar(mar=c(4,5.5,2.5,2.5))\nimage.plot(\n    x=seq(0,11.37,length=941),y=seq(0,90,length=617),z=spec_rslt[1:941,1:617],\n    xlab = \"Time [s]\", ylab = \"Frequency (Hz)\", main = \"Spectrogram\",\n    col=viridis(256, option = \"magma\")\n)\npar(mar=c(4,5.5,2.5,2.5))\nimage.plot(\n    x=t,z=scalo_rslt,\n    xlab = \"Time [s]\", ylab = \"Scale\", main = \"Scalogram\",\n    col = colorRampPalette(c(\"purple\", \"green\"))(256)\n)\npar(mfrow=c(1,1))\ndev.off()\n\npng: 2\n\n\n\nlibrary(phonTools)\nlibrary(fields)\nlibrary(viridis)\nlibrary(wavScalogram)\n\n# Function to save plots as PNGs\nsave_plot &lt;- function(filename, plot_func) {\n  png(filename, width=1400, height=350, res=150)\n  plot_func()\n  dev.off()\n}\n\n# Define the plot functions\nplot1 &lt;- function() {\n  par(mar=c(4,4.5,2.5,8.5))\n  plot(t, f, main=\"ECG signal\", xlab=\"Time [s]\", ylab=\"Amplitude\", type='l', cex.lab=1.5, cex.axis=1.5, cex.main=1.5)\n}\n\nplot2 &lt;- function() {\n  par(mar=c(4,5.5,2.5,2.5))\n  image.plot(\n    x=t, y=50:215, z=v_map[1:length(f), 50:215],\n    xlab=\"Time [s]\", ylab=\"Scale\", main=\"Vmap\",\n    col=viridis(256, option=\"magma\"), cex.lab=1.5, cex.axis=1.5, cex.main=1.5\n  )\n}\n\nplot3 &lt;- function() {\n  par(mar=c(4,5.5,2.5,2.5))\n  image.plot(\n    x=seq(0, 11.37, length=941), y=seq(0, 90, length=617), z=spec_rslt[1:941, 1:617],\n    xlab=\"Time [s]\", ylab=\"Frequency (Hz)\", main=\"Spectrogram\",\n    col=viridis(256, option=\"magma\"), cex.lab=1.5, cex.axis=1.5, cex.main=1.5\n  )\n}\n\nplot4 &lt;- function() {\n  par(mar=c(4,5.5,2.5,2.5))\n  image.plot(\n    x=t, z=scalo_rslt,\n    xlab=\"Time [s]\", ylab=\"Scale\", main=\"Scalogram\",\n    col=colorRampPalette(c(\"purple\", \"green\"))(256), cex.lab=1.5, cex.axis=1.5, cex.main=1.5\n  )\n}\n\n# Save each plot as a high-resolution PNG\nsave_plot(\"./Dropbox/03_Yechan3/연구/교수님이랑/EBT/ecg_comparevis_plot1.png\", plot1)\nsave_plot(\"./Dropbox/03_Yechan3/연구/교수님이랑/EBT/ecg_comparevis_plot2.png\", plot2)\nsave_plot(\"./Dropbox/03_Yechan3/연구/교수님이랑/EBT/ecg_comparevis_plot3.png\", plot3)\nsave_plot(\"./Dropbox/03_Yechan3/연구/교수님이랑/EBT/ecg_comparevis_plot4.png\", plot4)\nlibrary(magick)\n\n# Read the images\nimg1 &lt;- image_read(\"./Dropbox/03_Yechan3/연구/교수님이랑/EBT/ecg_comparevis_plot1.png\")\nimg2 &lt;- image_read(\"./Dropbox/03_Yechan3/연구/교수님이랑/EBT/ecg_comparevis_plot2.png\")\nimg3 &lt;- image_read(\"./Dropbox/03_Yechan3/연구/교수님이랑/EBT/ecg_comparevis_plot3.png\")\nimg4 &lt;- image_read(\"./Dropbox/03_Yechan3/연구/교수님이랑/EBT/ecg_comparevis_plot4.png\")\n\n# Combine images into a single PDF\ncombined &lt;- image_append(c(img1, img2, img3, img4), stack = TRUE)\nimage_write(combined, path = \"./Dropbox/03_Yechan3/연구/교수님이랑/EBT/ecg_comparevis.pdf\", format = \"pdf\")\n\npng: 2\n\n\npng: 2\n\n\npng: 2\n\n\npng: 2"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-11-27-논문재현.html",
    "href": "연구/교수님이랑/EBT/2024-11-27-논문재현.html",
    "title": "(연구&교수님) EBT – 첫 논문 재현 // 11월28일 다시~!",
    "section": "",
    "text": "getwd()\nlibrary(devtools)\ninstall_github(\"guebin/EBT\",force=TRUE)\ninstall_github(\"seoyeonc/gglite\",force=TRUE)\nlibrary(ebt)\nlibrary(gglite)\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(patchwork)"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-11-27-논문재현.html#a.-signal",
    "href": "연구/교수님이랑/EBT/2024-11-27-논문재현.html#a.-signal",
    "title": "(연구&교수님) EBT – 첫 논문 재현 // 11월28일 다시~!",
    "section": "A. Signal",
    "text": "A. Signal\nfs=1000\nt=-2000:2000/fs\nv1=sin(2*pi*t)\nv2=cos(20*pi*t)\nf=v1*v2\ngglite()+line(t,f)+coord_cartesian(xlim=c(-0.22,0.22))+xlab(\"\")+ylab(\"\")"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-11-27-논문재현.html#b.-ebt",
    "href": "연구/교수님이랑/EBT/2024-11-27-논문재현.html#b.-ebt",
    "title": "(연구&교수님) EBT – 첫 논문 재현 // 11월28일 다시~!",
    "section": "B. EBT",
    "text": "B. EBT\nout1&lt;-ebt(t,f,tau=60)\ni1&lt;-out1$sampled_index[[1]]\ni2&lt;-out1$sampled_index[[20]]\ni3&lt;-out1$sampled_index[[40]]\nout2&lt;-ebt(t,f,tau=80)\ni4&lt;-out2$sampled_index[[1]]\ni5&lt;-out2$sampled_index[[20]]\ni6&lt;-out2$sampled_index[[40]]"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-11-27-논문재현.html#c.-fig1a---fig1f",
    "href": "연구/교수님이랑/EBT/2024-11-27-논문재현.html#c.-fig1a---fig1f",
    "title": "(연구&교수님) EBT – 첫 논문 재현 // 11월28일 다시~!",
    "section": "C. fig1a - fig1f",
    "text": "C. fig1a - fig1f\nfigsize(4,3,300)\nfig1a = gglite() + \npoint(t,f,col=\"gray60\",cex=0.1) + \nggtitle(\"Original Signal\")+xlab(\"\")+ylab(\"\")+\ncoord_cartesian(xlim=c(-0.22,0.22))\nfig1a\nfig1b = fig1a + ggtitle(\"Single Touch of Dessin\") + \npoint(t[i1],out1$band[,1][i1],cex=2,col=2) + # band1, point\nline(t[i1],out1$band[,1][i1],col=2,alpha=0.2,lwd=1) # band1, line\nfig1b\nfig1c = fig1a + ggtitle(\"Three Touches\") + \npoint(t[i1],out1$band[,1][i1],cex=2,col=2)+ # band1, point\nline(t[i1],out1$band[,1][i1],col=2,alpha=0.2,lwd=1)+ # band1, line \npoint(t[i2],out1$band[,20][i2],cex=2,col=4)+ # band20, point \nline(t[i2],out1$band[,20][i2],col=4,alpha=0.2,lwd=1)+ # band20, line\npoint(t[i3],out1$band[,40][i3],cex=2,col=3)+ # band40, point\nline(t[i3],out1$band[,40][i3],col=3,alpha=0.2,lwd=1) # band40, line\nfig1c\nfig1d &lt;- fig1c + line(t,out1$band,col=\"gray60\",lwd=0.05) + ggtitle(\"All Possible Touches\")\nfig1d\nfig1e &lt;- fig1a + point(t[i4],out2$band[,1][i4],cex=2,col=2)+ # band1, point\nline(t[i4],out2$band[,1][i4],col=2,alpha=0.2,lwd=1)+ # band1, line \npoint(t[i5],out2$band[,20][i5],cex=2,col=4)+ # band20, point \nline(t[i5],out2$band[,20][i5],col=4,alpha=0.2,lwd=1)+ # band20, line\npoint(t[i6],out2$band[,40][i6],cex=2,col=3)+ # band40, point\nline(t[i6],out2$band[,40][i6],col=3,alpha=0.2,lwd=1)+ # band40, line\nggtitle(\"Three Touches (With Larger Interval)\")\nfig1e\nfig1f &lt;- fig1e + line(t,out2$band,col=\"gray60\",lwd=0.05) + ggtitle(\"All Possible Touches (With Larger Interval)\")\nfig1f"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-11-27-논문재현.html#d.-fig1a---fig1f",
    "href": "연구/교수님이랑/EBT/2024-11-27-논문재현.html#d.-fig1a---fig1f",
    "title": "(연구&교수님) EBT – 첫 논문 재현 // 11월28일 다시~!",
    "section": "D. fig1a - fig1f",
    "text": "D. fig1a - fig1f\nfig1 &lt;- (fig1a|fig1b)/(fig1c|fig1d)/(fig1e|fig1f)\nfig1"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-11-27-논문재현.html#e.-ggsave",
    "href": "연구/교수님이랑/EBT/2024-11-27-논문재현.html#e.-ggsave",
    "title": "(연구&교수님) EBT – 첫 논문 재현 // 11월28일 다시~!",
    "section": "E. ggsave",
    "text": "E. ggsave\nfig1d &lt;- fig1c + line(t,out1$band[,1:60],col=\"gray60\",lwd=0.05,alpha=0.2) + ggtitle(\"All Possible Touches\")\nfig1f &lt;- fig1e + line(t,out2$band[,1:80],col=\"gray60\",lwd=0.05,alpha=0.2) + ggtitle(\"All Possible Touches (With Larger Interval)\")\nfig1 &lt;- (fig1a|fig1b)/(fig1c|fig1d)/(fig1e|fig1f)\nggsave(\"fig1.pdf\",fig1,width = 8, height = 6, dpi = 150)"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-11-27-논문재현.html#a.-signal-1",
    "href": "연구/교수님이랑/EBT/2024-11-27-논문재현.html#a.-signal-1",
    "title": "(연구&교수님) EBT – 첫 논문 재현 // 11월28일 다시~!",
    "section": "A. signal",
    "text": "A. signal\nfs=10\nt=-30:30/fs\nf=cos(pi*t^2)\ngglite()+point(t,f)+line(t,f)+xlim(0,2)+xlab(\"\")+ylab(\"\")"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-11-27-논문재현.html#b.-ebt-linear-fig2ace",
    "href": "연구/교수님이랑/EBT/2024-11-27-논문재현.html#b.-ebt-linear-fig2ace",
    "title": "(연구&교수님) EBT – 첫 논문 재현 // 11월28일 다시~!",
    "section": "B. EBT: linear – fig2a,c,e",
    "text": "B. EBT: linear – fig2a,c,e\nout&lt;-ebt(t,f,tau=3)\ni1&lt;-out$sampled_index[[1]]\ni2&lt;-out$sampled_index[[2]]\ni3&lt;-out$sampled_index[[3]]\nfig2_base = gglite()+point(t,out$f)+xlim(0,2)+xlab(\"\")+ylab(\"\")\nfig2a = fig2_base + point(t[i1],out$band[,1][i1],col=2,cex=5,pch=1)+line(t,out$band[,1],col=2,lwd=1)+ggtitle(\"(a)\")\nfig2a\nfig2c = fig2_base + point(t[i2],out$band[,2][i2],col=3,cex=5,pch=1) + line(t,out$band[,2],col=3,lwd=1)+ggtitle(\"(c)\")\nfig2c\nfig2e = fig2_base + point(t[i3],out$band[,3][i3],col=4,cex=5,pch=1) + line(t,out$band[,3],col=4,lwd=1)+ggtitle(\"(e)\")\nfig2e"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-11-27-논문재현.html#c.-ebt-cubic-fig2bdf",
    "href": "연구/교수님이랑/EBT/2024-11-27-논문재현.html#c.-ebt-cubic-fig2bdf",
    "title": "(연구&교수님) EBT – 첫 논문 재현 // 11월28일 다시~!",
    "section": "C. EBT: cubic – fig2b,d,f",
    "text": "C. EBT: cubic – fig2b,d,f\nout&lt;-ebt(t,f,tau=3,inter_method='cubic')\ni1&lt;-out$sampled_index[[1]]\ni2&lt;-out$sampled_index[[2]]\ni3&lt;-out$sampled_index[[3]]\nfig2_base = gglite()+point(t,out$f)+xlim(0,2)+xlab(\"\")+ylab(\"\")\nfig2b = fig2_base + point(t[i1],out$band[,1][i1],col=2,cex=5,pch=1)+line(t,out$band[,1],col=2,lwd=1)+ggtitle(\"(b)\")\nfig2b\nfig2d = fig2_base + point(t[i2],out$band[,2][i2],col=3,cex=5,pch=1) + line(t,out$band[,2],col=3,lwd=1)+ggtitle(\"(d)\")\nfig2d\nfig2f = fig2_base + point(t[i3],out$band[,3][i3],col=4,cex=5,pch=1) + line(t,out$band[,3],col=4,lwd=1)+ggtitle(\"(f)\")\nfig2f"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-11-27-논문재현.html#d.-fig2",
    "href": "연구/교수님이랑/EBT/2024-11-27-논문재현.html#d.-fig2",
    "title": "(연구&교수님) EBT – 첫 논문 재현 // 11월28일 다시~!",
    "section": "D. fig2",
    "text": "D. fig2\nfig2 &lt;- (fig2a|fig2b)/(fig2c|fig2d)/(fig2e|fig2f)\nfig2"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-11-27-논문재현.html#e.-ggsave-1",
    "href": "연구/교수님이랑/EBT/2024-11-27-논문재현.html#e.-ggsave-1",
    "title": "(연구&교수님) EBT – 첫 논문 재현 // 11월28일 다시~!",
    "section": "E. ggsave",
    "text": "E. ggsave\nggsave(\"fig2.pdf\",fig2, height = 6.67/1.5)"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-11-27-논문재현.html#a.-signal-2",
    "href": "연구/교수님이랑/EBT/2024-11-27-논문재현.html#a.-signal-2",
    "title": "(연구&교수님) EBT – 첫 논문 재현 // 11월28일 다시~!",
    "section": "A. signal",
    "text": "A. signal\n# FIG 1\nfs=100\nt=-200:200/fs\nv1=cos(2*pi*t)\nv2=cos(3*pi*t)\nf=v1+v2\nfig3_base &lt;- gglite()+point(t,f,size=0.5,col=\"gray20\")+xlim(c(-1,1))+xlab(\"\")+ylab(\"\")\nfig3_base"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-11-27-논문재현.html#b.-ebt-1",
    "href": "연구/교수님이랑/EBT/2024-11-27-논문재현.html#b.-ebt-1",
    "title": "(연구&교수님) EBT – 첫 논문 재현 // 11월28일 다시~!",
    "section": "B. EBT",
    "text": "B. EBT\nout1&lt;-ebt(t,f,tau=30)\nout2&lt;-ebt(t,f,tau=45)\nout3&lt;-ebt(t,f,tau=60)"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-11-27-논문재현.html#c.-fig3",
    "href": "연구/교수님이랑/EBT/2024-11-27-논문재현.html#c.-fig3",
    "title": "(연구&교수님) EBT – 첫 논문 재현 // 11월28일 다시~!",
    "section": "C. fig3",
    "text": "C. fig3\nfig3a &lt;- gglite()+point(t,f,size=0.5)+xlim(c(-1,1))+xlab(\"\")+ylab(\"\")+ggtitle(\"(a)\")\nfig3b &lt;- fig3a+line(t,out1$band,col=2,lwd=0.01)+ggtitle(\"(b)\")\nfig3c &lt;- fig3a+line(t,out2$band,col=3,lwd=0.01)+ggtitle(\"(c)\")\nfig3d &lt;- fig3a+line(t,out3$band,col=4,lwd=0.01)+ggtitle(\"(d)\")\nfig3e &lt;- gglite()+xlim(c(-1,1))+point(t,f,alpha=0)+xlab(\"\")+ylab(\"\")+line(t,out1$M,lwd=1,col=2)+line(t,out2$M,lwd=1,col=3)+line(t,out3$M,lwd=1,col=4)+ggtitle(\"(e)\")\nfig3f &lt;- gglite()+xlim(c(-1,1))+line(t,out1$V,col=2)+line(t,out2$V,col=3)+line(t,out3$V,col=4)+ggtitle(\"(f)\")+xlab(\"\")+ylab(\"\")\nfig3 &lt;- (fig3a|fig3b)/(fig3c|fig3d)/(fig3e|fig3f)\nfig3"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-11-27-논문재현.html#d.-ggsave",
    "href": "연구/교수님이랑/EBT/2024-11-27-논문재현.html#d.-ggsave",
    "title": "(연구&교수님) EBT – 첫 논문 재현 // 11월28일 다시~!",
    "section": "D. ggsave",
    "text": "D. ggsave\nfig3a &lt;- gglite()+point(t,f,size=0.5)+xlim(c(-1,1))+xlab(\"\")+ylab(\"\")+ggtitle(\"(a)\")\nfig3b &lt;- fig3a+line(t,out1$band,col=2,lwd=0.01,alpha=0.1)+ggtitle(\"(b)\")\nfig3c &lt;- fig3a+line(t,out2$band,col=3,lwd=0.01,alpha=0.1)+ggtitle(\"(c)\")\nfig3d &lt;- fig3a+line(t,out3$band,col=4,lwd=0.01,alpha=0.1)+ggtitle(\"(d)\")\nfig3e &lt;- gglite()+xlim(c(-1,1))+point(t,f,alpha=0)+xlab(\"\")+ylab(\"\")+line(t,out1$M,lwd=1,col=2)+line(t,out2$M,lwd=1,col=3)+line(t,out3$M,lwd=1,col=4)+ggtitle(\"(e)\")\nfig3f &lt;- gglite()+xlim(c(-1,1))+line(t,out1$V,col=2)+line(t,out2$V,col=3)+line(t,out3$V,col=4)+ggtitle(\"(f)\")+xlab(\"\")+ylab(\"\")\nfig3 &lt;- (fig3a|fig3b)/(fig3c|fig3d)/(fig3e|fig3f)\nggsave(\"fig3.pdf\",fig3,height = 6.67/1.2)"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-11-27-논문재현.html#a.-signal-3",
    "href": "연구/교수님이랑/EBT/2024-11-27-논문재현.html#a.-signal-3",
    "title": "(연구&교수님) EBT – 첫 논문 재현 // 11월28일 다시~!",
    "section": "A. signal",
    "text": "A. signal\nset.seed(100)\nv1&lt;-rnorm(150,mean=0,sd=0.5) # ~150\nv2&lt;-rnorm(150,mean=0,sd=0.5) # ~300\nv3&lt;-rnorm(150,mean=1.5,sd=3) # ~450\nv4&lt;-rnorm(150,mean=1.5,sd=3) # ~600\nv5&lt;-rnorm(150,mean=1.5,sd=2) # ~750\nv6&lt;-rnorm(150,mean=1.5,sd=1) # ~900\nv7&lt;-rnorm(150,mean=3.0,sd=1) # ~1050\nv8&lt;-rnorm(150,mean=4.5,sd=1) # ~1200\nv9&lt;-rnorm(150,mean=6.0,sd=1) # ~1350\nv10&lt;-rnorm(150,mean=7.5,sd=1) # ~1500\nf&lt;-c(v1,v2,v3,v4,v5,v6,v7,v8,v9,v10) \ngglite()+line(f,col='gray60')+xlab(\"\")+ylab(\"\")"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html",
    "title": "(연구&교수님) EBT – 첫 논문 재현 // 2024년 8월",
    "section": "",
    "text": "getwd()\n\n'/home/cgb2/Dropbox/03_Yechan4/연구/교수님이랑/EBT'\nlibrary(devtools)\ninstall_github(\"guebin/EBT\",force=TRUE)\ninstall_github(\"seoyeonc/gglite\",force=TRUE)\nlibrary(ebt)\nlibrary(gglite)\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(patchwork)\n\nLoading required package: usethis\n\nUsing GitHub PAT from the git credential store.\n\nDownloading GitHub repo guebin/EBT@HEAD\n\nUsing GitHub PAT from the git credential store.\n\nDownloading GitHub repo seoyeonc/gglite@HEAD\n\n\nAttaching package: ‘gglite’\n\n\nThe following objects are masked from ‘package:stats’:\n\n    density, line, smooth, step\n\n\nThe following object is masked from ‘package:graphics’:\n\n    boxplot\n\n\nThe following objects are masked from ‘package:base’:\n\n    col, jitter\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n── R CMD build ─────────────────────────────────────────────────────────────────\n* checking for file ‘/tmp/Rtmp5gj2qk/remotes8f6a02e3d2b03/guebin-EBT-4e0b00a/DESCRIPTION’ ... OK\n* preparing ‘ebt’:\n* checking DESCRIPTION meta-information ... OK\n* checking for LF line-endings in source and make files and shell scripts\n* checking for empty or unneeded directories\nOmitted ‘LazyData’ from DESCRIPTION\n* building ‘ebt_0.1.0.tar.gz’\n\n── R CMD build ─────────────────────────────────────────────────────────────────\n* checking for file ‘/tmp/Rtmp5gj2qk/remotes8f6a0bd4bd6a/seoyeonc-gglite-3ca7b3b/DESCRIPTION’ ... OK\n* preparing ‘gglite’:\n* checking DESCRIPTION meta-information ... OK\n* checking for LF line-endings in source and make files and shell scripts\n* checking for empty or unneeded directories\nOmitted ‘LazyData’ from DESCRIPTION\n* building ‘gglite_0.1.0.tar.gz’"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html#a.-signal",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html#a.-signal",
    "title": "(연구&교수님) EBT – 첫 논문 재현 // 2024년 8월",
    "section": "A. signal",
    "text": "A. signal\n\nfs=1000\nt=-2000:2000/fs\nv1=sin(2*pi*t)\nv2=cos(20*pi*t)\nf=v1*v2\n\n\nfigsize(4,3,300)\ngglite()+line(t,f)+coord_cartesian(xlim=c(-0.22,0.22))+xlab(\"\")+ylab(\"\")"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html#b.-ebt",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html#b.-ebt",
    "title": "(연구&교수님) EBT – 첫 논문 재현 // 2024년 8월",
    "section": "B. EBT",
    "text": "B. EBT\n\nout1&lt;-ebt(t,f,tau=60)\ni1&lt;-out1$sampled_index[[1]]\ni2&lt;-out1$sampled_index[[20]]\ni3&lt;-out1$sampled_index[[40]]\nout2&lt;-ebt(t,f,tau=80)\ni4&lt;-out2$sampled_index[[1]]\ni5&lt;-out2$sampled_index[[20]]\ni6&lt;-out2$sampled_index[[40]]"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html#c.-fig1a---fig1f",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html#c.-fig1a---fig1f",
    "title": "(연구&교수님) EBT – 첫 논문 재현 // 2024년 8월",
    "section": "C. fig1a - fig1f",
    "text": "C. fig1a - fig1f\n\nfigsize(4,3,300)\nfig1a = gglite() + \npoint(t,f,col=\"gray60\",cex=0.1) + \nggtitle(\"Original Signal\")+xlab(\"\")+ylab(\"\")+\ncoord_cartesian(xlim=c(-0.22,0.22))\nfig1a\n\n\n\n\n\n\n\n\n\nfig1b = fig1a + ggtitle(\"Single Touch of Dessin\") + \npoint(t[i1],out1$band[,1][i1],cex=2,col=2) + # band1, point\nline(t[i1],out1$band[,1][i1],col=2,alpha=0.2,lwd=1) # band1, line\nfig1b\n\n\n\n\n\n\n\n\n\nfig1c = fig1a + ggtitle(\"Three Touches\") + \npoint(t[i1],out1$band[,1][i1],cex=2,col=2)+ # band1, point\nline(t[i1],out1$band[,1][i1],col=2,alpha=0.2,lwd=1)+ # band1, line \npoint(t[i2],out1$band[,20][i2],cex=2,col=4)+ # band20, point \nline(t[i2],out1$band[,20][i2],col=4,alpha=0.2,lwd=1)+ # band20, line\npoint(t[i3],out1$band[,40][i3],cex=2,col=3)+ # band40, point\nline(t[i3],out1$band[,40][i3],col=3,alpha=0.2,lwd=1) # band40, line\nfig1c\n\n\n\n\n\n\n\n\n\nfig1d &lt;- fig1c + line(t,out1$band,col=\"gray60\",lwd=0.05) + ggtitle(\"All Possible Touches\")\nfig1d\n\n\n\n\n\n\n\n\n\nfig1e &lt;- fig1a + point(t[i4],out2$band[,1][i4],cex=2,col=2)+ # band1, point\nline(t[i4],out2$band[,1][i4],col=2,alpha=0.2,lwd=1)+ # band1, line \npoint(t[i5],out2$band[,20][i5],cex=2,col=4)+ # band20, point \nline(t[i5],out2$band[,20][i5],col=4,alpha=0.2,lwd=1)+ # band20, line\npoint(t[i6],out2$band[,40][i6],cex=2,col=3)+ # band40, point\nline(t[i6],out2$band[,40][i6],col=3,alpha=0.2,lwd=1)+ # band40, line\nggtitle(\"Three Touches (With Larger Interval)\")\nfig1e\n\n\n\n\n\n\n\n\n\nfig1f &lt;- fig1e + line(t,out2$band,col=\"gray60\",lwd=0.05) + ggtitle(\"All Possible Touches (With Larger Interval)\")\nfig1f"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html#d.-fig1",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html#d.-fig1",
    "title": "(연구&교수님) EBT – 첫 논문 재현 // 2024년 8월",
    "section": "D. fig1",
    "text": "D. fig1\n\nfigsize(10,6,300)\nfig1 &lt;- (fig1a|fig1b)/(fig1c|fig1d)/(fig1e|fig1f)\nfig1"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html#e.-ggsave",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html#e.-ggsave",
    "title": "(연구&교수님) EBT – 첫 논문 재현 // 2024년 8월",
    "section": "E. ggsave",
    "text": "E. ggsave\n\nfig1d &lt;- fig1c + line(t,out1$band[,1:60],col=\"gray60\",lwd=0.05,alpha=0.2) + ggtitle(\"All Possible Touches\")\nfig1f &lt;- fig1e + line(t,out2$band[,1:80],col=\"gray60\",lwd=0.05,alpha=0.2) + ggtitle(\"All Possible Touches (With Larger Interval)\")\nfig1 &lt;- (fig1a|fig1b)/(fig1c|fig1d)/(fig1e|fig1f)\nggsave(\"fig1.pdf\",fig1,width = 8, height = 6, dpi = 150)"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html#a.-signal-1",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html#a.-signal-1",
    "title": "(연구&교수님) EBT – 첫 논문 재현 // 2024년 8월",
    "section": "A. signal",
    "text": "A. signal\n\nfigsize(10,6,300)\ngglite()+point(t,f)+line(t,f)+xlim(0,2)+xlab(\"\")+ylab(\"\")\n\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_line()`).”"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html#b.-ebt-linear-fig2ace",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html#b.-ebt-linear-fig2ace",
    "title": "(연구&교수님) EBT – 첫 논문 재현 // 2024년 8월",
    "section": "B. EBT: linear – fig2a,c,e",
    "text": "B. EBT: linear – fig2a,c,e\n\nout&lt;-ebt(t,f,tau=3)\ni1&lt;-out$sampled_index[[1]]\ni2&lt;-out$sampled_index[[2]]\ni3&lt;-out$sampled_index[[3]]\n\n\nfig2_base = gglite()+point(t,out$f)+xlim(0,2)+xlab(\"\")+ylab(\"\")\nfig2a = fig2_base + point(t[i1],out$band[,1][i1],col=2,cex=5,pch=1)+line(t,out$band[,1],col=2,lwd=1)+ggtitle(\"(a)\")\nfig2a\n\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 667 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_line()`).”\n\n\n\n\n\n\n\n\n\n\nfig2c = fig2_base + point(t[i2],out$band[,2][i2],col=3,cex=5,pch=1) + line(t,out$band[,2],col=3,lwd=1)+ggtitle(\"(c)\")\nfig2c\n\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 668 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_line()`).”\n\n\n\n\n\n\n\n\n\n\nfig2e = fig2_base + point(t[i3],out$band[,3][i3],col=4,cex=5,pch=1) + line(t,out$band[,3],col=4,lwd=1)+ggtitle(\"(e)\")\nfig2e\n\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 667 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_line()`).”"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html#c.-ebt-cubic-fig2bdf",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html#c.-ebt-cubic-fig2bdf",
    "title": "(연구&교수님) EBT – 첫 논문 재현 // 2024년 8월",
    "section": "C. EBT: cubic – fig2b,d,f",
    "text": "C. EBT: cubic – fig2b,d,f\n\nout&lt;-ebt(t,f,tau=3,inter_method='cubic')\ni1&lt;-out$sampled_index[[1]]\ni2&lt;-out$sampled_index[[2]]\ni3&lt;-out$sampled_index[[3]]\n\n\nfig2_base = gglite()+point(t,out$f)+xlim(0,2)+xlab(\"\")+ylab(\"\")\nfig2b = fig2_base + point(t[i1],out$band[,1][i1],col=2,cex=5,pch=1)+line(t,out$band[,1],col=2,lwd=1)+ggtitle(\"(b)\")\nfig2b\n\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 667 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_line()`).”\n\n\n\n\n\n\n\n\n\n\nfig2d = fig2_base + point(t[i2],out$band[,2][i2],col=3,cex=5,pch=1) + line(t,out$band[,2],col=3,lwd=1)+ggtitle(\"(d)\")\nfig2d\n\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 668 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_line()`).”\n\n\n\n\n\n\n\n\n\n\nfig2f = fig2_base + point(t[i3],out$band[,3][i3],col=4,cex=5,pch=1) + line(t,out$band[,3],col=4,lwd=1)+ggtitle(\"(f)\")\nfig2f\n\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 667 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_line()`).”"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html#d.-fig2",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html#d.-fig2",
    "title": "(연구&교수님) EBT – 첫 논문 재현 // 2024년 8월",
    "section": "D. fig2",
    "text": "D. fig2\n\nfigsize(10,6,300)\nfig2 &lt;- (fig2a|fig2b)/(fig2c|fig2d)/(fig2e|fig2f)\nfig2\n\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 667 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_line()`).”\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 667 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_line()`).”\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 668 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_line()`).”\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 668 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_line()`).”\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 667 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_line()`).”\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 667 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_line()`).”"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html#e.-ggsave-1",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html#e.-ggsave-1",
    "title": "(연구&교수님) EBT – 첫 논문 재현 // 2024년 8월",
    "section": "E. ggsave",
    "text": "E. ggsave\n\nggsave(\"fig2.pdf\",fig2, height = 6.67/1.5)\n\nSaving 7 x 4.45 in image\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 667 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_line()`).”\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 667 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_line()`).”\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 668 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_line()`).”\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 668 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_line()`).”\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 667 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_line()`).”\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 667 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 2000 rows containing missing values or values outside the scale range\n(`geom_line()`).”"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html#a.-signal-2",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html#a.-signal-2",
    "title": "(연구&교수님) EBT – 첫 논문 재현 // 2024년 8월",
    "section": "A. signal",
    "text": "A. signal\n\n# FIG 1\nfs=100\nt=-200:200/fs\nv1=cos(2*pi*t)\nv2=cos(3*pi*t)\nf=v1+v2\n\n\nfigsize(4,3,300)\nfig3_base &lt;- gglite()+point(t,f,size=0.5,col=\"gray20\")+xlim(c(-1,1))+xlab(\"\")+ylab(\"\")\nfig3_base\n\nWarning message:\n“Removed 200 rows containing missing values or values outside the scale range\n(`geom_point()`).”"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html#b.-ebt-1",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html#b.-ebt-1",
    "title": "(연구&교수님) EBT – 첫 논문 재현 // 2024년 8월",
    "section": "B. EBT",
    "text": "B. EBT\n\nout1&lt;-ebt(t,f,tau=30)\nout2&lt;-ebt(t,f,tau=45)\nout3&lt;-ebt(t,f,tau=60)"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html#c.-fig3",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html#c.-fig3",
    "title": "(연구&교수님) EBT – 첫 논문 재현 // 2024년 8월",
    "section": "C. fig3",
    "text": "C. fig3\n\nfig3a &lt;- gglite()+point(t,f,size=0.5)+xlim(c(-1,1))+xlab(\"\")+ylab(\"\")+ggtitle(\"(a)\")\nfig3b &lt;- fig3a+line(t,out1$band,col=2,lwd=0.01)+ggtitle(\"(b)\")\nfig3c &lt;- fig3a+line(t,out2$band,col=3,lwd=0.01)+ggtitle(\"(c)\")\nfig3d &lt;- fig3a+line(t,out3$band,col=4,lwd=0.01)+ggtitle(\"(d)\")\nfig3e &lt;- gglite()+xlim(c(-1,1))+point(t,f,alpha=0)+xlab(\"\")+ylab(\"\")+line(t,out1$M,lwd=1,col=2)+line(t,out2$M,lwd=1,col=3)+line(t,out3$M,lwd=1,col=4)+ggtitle(\"(e)\")\nfig3f &lt;- gglite()+xlim(c(-1,1))+line(t,out1$V,col=2)+line(t,out2$V,col=3)+line(t,out3$V,col=4)+ggtitle(\"(f)\")+xlab(\"\")+ylab(\"\")\n\n\nfigsize(10,6,300)\nfig3 &lt;- (fig3a|fig3b)/(fig3c|fig3d)/(fig3e|fig3f)\nfig3\nfigsize()\n\nWarning message:\n“Removed 200 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 200 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 6000 rows containing missing values or values outside the scale range\n(`geom_line()`).”\nWarning message:\n“Removed 200 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 9000 rows containing missing values or values outside the scale range\n(`geom_line()`).”\nWarning message:\n“Removed 200 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 12000 rows containing missing values or values outside the scale range\n(`geom_line()`).”\nWarning message:\n“Removed 200 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 200 rows containing missing values or values outside the scale range\n(`geom_line()`).”\nWarning message:\n“Removed 200 rows containing missing values or values outside the scale range\n(`geom_line()`).”\nWarning message:\n“Removed 200 rows containing missing values or values outside the scale range\n(`geom_line()`).”\nWarning message:\n“Removed 200 rows containing missing values or values outside the scale range\n(`geom_line()`).”\nWarning message:\n“Removed 200 rows containing missing values or values outside the scale range\n(`geom_line()`).”\nWarning message:\n“Removed 200 rows containing missing values or values outside the scale range\n(`geom_line()`).”"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html#d.-ggsave",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html#d.-ggsave",
    "title": "(연구&교수님) EBT – 첫 논문 재현 // 2024년 8월",
    "section": "D. ggsave",
    "text": "D. ggsave\n\nfig3a &lt;- gglite()+point(t,f,size=0.5)+xlim(c(-1,1))+xlab(\"\")+ylab(\"\")+ggtitle(\"(a)\")\nfig3b &lt;- fig3a+line(t,out1$band,col=2,lwd=0.01,alpha=0.1)+ggtitle(\"(b)\")\nfig3c &lt;- fig3a+line(t,out2$band,col=3,lwd=0.01,alpha=0.1)+ggtitle(\"(c)\")\nfig3d &lt;- fig3a+line(t,out3$band,col=4,lwd=0.01,alpha=0.1)+ggtitle(\"(d)\")\nfig3e &lt;- gglite()+xlim(c(-1,1))+point(t,f,alpha=0)+xlab(\"\")+ylab(\"\")+line(t,out1$M,lwd=1,col=2)+line(t,out2$M,lwd=1,col=3)+line(t,out3$M,lwd=1,col=4)+ggtitle(\"(e)\")\nfig3f &lt;- gglite()+xlim(c(-1,1))+line(t,out1$V,col=2)+line(t,out2$V,col=3)+line(t,out3$V,col=4)+ggtitle(\"(f)\")+xlab(\"\")+ylab(\"\")\nfig3 &lt;- (fig3a|fig3b)/(fig3c|fig3d)/(fig3e|fig3f)\nggsave(\"fig3.pdf\",fig3,height = 6.67/1.2)\n\nSaving 7 x 5.56 in image\nWarning message:\n“Removed 200 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 200 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 6000 rows containing missing values or values outside the scale range\n(`geom_line()`).”\nWarning message:\n“Removed 200 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 9000 rows containing missing values or values outside the scale range\n(`geom_line()`).”\nWarning message:\n“Removed 200 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 12000 rows containing missing values or values outside the scale range\n(`geom_line()`).”\nWarning message:\n“Removed 200 rows containing missing values or values outside the scale range\n(`geom_point()`).”\nWarning message:\n“Removed 200 rows containing missing values or values outside the scale range\n(`geom_line()`).”\nWarning message:\n“Removed 200 rows containing missing values or values outside the scale range\n(`geom_line()`).”\nWarning message:\n“Removed 200 rows containing missing values or values outside the scale range\n(`geom_line()`).”\nWarning message:\n“Removed 200 rows containing missing values or values outside the scale range\n(`geom_line()`).”\nWarning message:\n“Removed 200 rows containing missing values or values outside the scale range\n(`geom_line()`).”\nWarning message:\n“Removed 200 rows containing missing values or values outside the scale range\n(`geom_line()`).”"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html#a.-signal-3",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html#a.-signal-3",
    "title": "(연구&교수님) EBT – 첫 논문 재현 // 2024년 8월",
    "section": "A. signal",
    "text": "A. signal\n\nset.seed(100)\nv1&lt;-rnorm(150,mean=0,sd=0.5) # ~150\nv2&lt;-rnorm(150,mean=0,sd=0.5) # ~300\nv3&lt;-rnorm(150,mean=1.5,sd=3) # ~450\nv4&lt;-rnorm(150,mean=1.5,sd=3) # ~600\nv5&lt;-rnorm(150,mean=1.5,sd=2) # ~750\nv6&lt;-rnorm(150,mean=1.5,sd=1) # ~900\nv7&lt;-rnorm(150,mean=3.0,sd=1) # ~1050\nv8&lt;-rnorm(150,mean=4.5,sd=1) # ~1200\nv9&lt;-rnorm(150,mean=6.0,sd=1) # ~1350\nv10&lt;-rnorm(150,mean=7.5,sd=1) # ~1500\nf&lt;-c(v1,v2,v3,v4,v5,v6,v7,v8,v9,v10) \n\n\ngglite()+line(f,col='gray60')+xlab(\"\")+ylab(\"\")\n\nERROR: Error in gglite(): could not find function \"gglite\""
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html#b.",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현 (cgb2-desktop's conflicted copy 2024-11-28).html#b.",
    "title": "(연구&교수님) EBT – 첫 논문 재현 // 2024년 8월",
    "section": "B.",
    "text": "B.\n\nMM1&lt;-Mmap(f,maxtau=maxtau,M=\"mean\",V=\"var\")\nVM1&lt;-Vmap(f,maxtau=maxtau,M=\"mean\",V=\"var\")\ndMM1_t&lt;-diff(MM1)\ndVM1_t&lt;-diff(VM1)\n\n\n# #########################################################################################################################################\n# # ELASTIC BAND TRANSFORM\n# ## Sattistics of Elastic-Bands\n# #########################################################################################################################################\n\n# # FIG 2\n# len=500\n# tau&lt;-5\n# h&lt;-c(rep(0,len-(tau-1)),1:tau,(tau-1):1,rep(0,len-tau))/tau^2\n# omega_hat&lt;-seq(from=-pi,to=pi,len=len*2)\n# #pdf(paste(PATH, \"2-2]Homega.pdf\", sep=\"\"), width=7, height=3)\n# par(mar=c(2.5,2.5,2.5,2.5))\n# par(mfrow=c(1,3))\n# plot(omega_hat,c(abs(fft(h))[501:1000],abs(fft(h))[1:500]),type='l',xlab=\"\",ylab=\"\",main=\"(a)\")\n# tau&lt;-10\n# h&lt;-c(rep(0,len-(tau-1)),1:tau,(tau-1):1,rep(0,len-tau))/tau^2\n# omega_hat&lt;-seq(from=-pi,to=pi,len=len*2)\n# plot(omega_hat,c(abs(fft(h))[501:1000],abs(fft(h))[1:500]),type='l',xlab=\"\",ylab=\"\",main=\"(b)\")\n# tau&lt;-30\n# h&lt;-c(rep(0,len-(tau-1)),1:tau,(tau-1):1,rep(0,len-tau))/tau^2\n# omega_hat&lt;-seq(from=-pi,to=pi,len=len*2)\n# plot(omega_hat,c(abs(fft(h))[501:1000],abs(fft(h))[1:500]),type='l',xlab=\"\",ylab=\"\",main=\"(c)\")\n# #dev.off()\n\n# #########################################################################################################################################\n# # ELASTIC BAND TRANSFORM\n# ## Visualization\n# #########################################################################################################################################\n# # FIG 1\n# set.seed(100)\n# v1&lt;-rnorm(150,mean=0,sd=0.5) # ~150\n# v2&lt;-rnorm(150,mean=0,sd=0.5) # ~300\n# v3&lt;-rnorm(150,mean=1.5,sd=3) # ~450\n# v4&lt;-rnorm(150,mean=1.5,sd=3) # ~600\n# v5&lt;-rnorm(150,mean=1.5,sd=2) # ~750\n# v6&lt;-rnorm(150,mean=1.5,sd=1) # ~900\n# v7&lt;-rnorm(150,mean=3.0,sd=1) # ~1050\n# v8&lt;-rnorm(150,mean=4.5,sd=1) # ~1200\n# v9&lt;-rnorm(150,mean=6.0,sd=1) # ~1350\n# v10&lt;-rnorm(150,mean=7.5,sd=1) # ~1500\n# f&lt;-c(v1,v2,v3,v4,v5,v6,v7,v8,v9,v10) \n# maxtau=200\n# len&lt;-length(f)\n\n# MM1&lt;-Mmap(f,maxtau=maxtau,M=\"mean\",V=\"var\")\n# VM1&lt;-Vmap(f,maxtau=maxtau,M=\"mean\",V=\"var\")\n# dMM1_t&lt;-diff(MM1)\n# dVM1_t&lt;-diff(VM1)\n\n# library(fields)\n# #pdf(paste(PATH, \"2-3]MmapVmap.pdf\", sep=\"\"), width=7, height=5)\n# par(mar=c(2.5,3,3,4))\n# par(mfrow=c(3,2))\n# plot(f,xlab=\"\",ylab=\"\",main=\"(a)\",type='l')\n# par(mar=c(2.5,3,3,1))\n# mintau&lt;-10\n# maxtau&lt;-200\n# image.plot(x=1:len,y=mintau:maxtau,z=MM1[1:len,mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(b)\")\n# abline(v=c(300,900,1050,1200,1350),lty=2,lwd=1)\n# par(mar=c(2.5,2.5,2.5,1))\n# mintau&lt;-50\n# maxtau&lt;-100\n# image.plot(x=1:len,y=mintau:maxtau,z=dMM1_t[1:(len-1),mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(c)\")\n# abline(v=c(300,900,1050,1200,1350),lty=2,lwd=1)\n# par(mar=c(2.5,2.5,2.5,1))\n# mintau&lt;-50\n# maxtau&lt;-200\n# image.plot(x=1:len,y=mintau:maxtau,z=VM1[1:len,mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(d)\")\n# abline(v=c(300,600,750),lty=2,lwd=1)\n# mintau&lt;-50\n# maxtau&lt;-200\n# image.plot(x=1:len,y=mintau:maxtau,z=abs(dVM1_t[1:(len-1),mintau:maxtau]),xlab=\"\",ylab=\"\",main=\"(e)\")\n# abline(v=c(300,600,750),lty=2,lwd=1)\n# par(mar=c(2.5,2.5,2.5,1))\n# mintau&lt;-100\n# maxtau&lt;-200\n# image.plot(x=1:len,y=mintau:maxtau,z=dMM1_t[1:(len-1),mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(f)\")\n# abline(v=c(300,900,1050,1200,1350),lty=2,lwd=1)\n# #dev.off() \n\n# # FIG 2\n# library(wavelets)\n# data(ecg)\n# f&lt;-as.vector(ecg)\n# t&lt;-seq(0,11.37,length=2048)\n# maxtau=180\n# len&lt;-length(f)\n# MM2&lt;-Mmap(f,maxtau=maxtau,M=\"mean\",V=\"var\")\n# VM2&lt;-Vmap(f,maxtau=maxtau,M=\"mean\",V=\"var\")\n# dMM2_t&lt;-diff(MM1)\n# dMM2_tau&lt;-t(diff(t(MM2)))\n# dVM2_t&lt;-diff(VM2)\n# dVM2_tau&lt;-t(diff(t(VM2)))\n# # \n# # #pdf(paste(PATH, \"2-3]MmapVmapECG.pdf\", sep=\"\"), width=7, height=5)\n# # par(mfrow=c(3,2))\n# # par(mar=c(2.5,2.5,2.5,4))\n# # plot(t,f,xlab=\"\",ylab=\"\",main=\"(a)\",type='l')\n# # \n# # par(mar=c(2.5,2.5,2.5,1))\n# # mintau&lt;-5\n# # maxtau&lt;-180\n# # image.plot(x=t,y=mintau:maxtau,z=MM2[1:len,mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(b)\",legend.mar=10)\n# # mintau&lt;-50\n# # maxtau&lt;-175\n# # par(mar=c(2.5,2.5,2.5,1))\n# # image.plot(x=t,y=mintau:maxtau,z=VM2[1:len,mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(c)\",legend.mar=5)\n# # par(mar=c(2.5,2.5,2.5,1))\n# # mintau&lt;-50\n# # maxtau&lt;-100\n# # image.plot(x=t,y=mintau:maxtau,z=dVM2_t[1:(len-1),mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(d)\",legend.mar=10)\n# # par(mar=c(2.5,2.5,2.5,1))\n# # mintau&lt;-50\n# # maxtau&lt;-175\n# # image.plot(x=t,y=mintau:maxtau,z=dVM2_tau[1:len,mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(e)\",legend.mar=5)\n# # library(phonTools)\n# # library(fields)\n# # temp&lt;-spectrogram(f,fs=180,windowlength = 5*22050/180,show=F)$spectrogram\n# # par(mar=c(2.5,2.5,2.5,1))\n# # image.plot(x=seq(0,11.37,length=941),y=seq(0,90,length=617),z=temp[1:941,1:617],xlab=\"\",ylab=\"\",main=\"(f)\",legend.mar=10)\n# # #dev.off() \n# # \n\n\n# pdf(paste(\"MmapVmapECG.png\", sep=\"\"), width=7, height=5*2/3)\n# par(mfrow=c(2,2))\n# par(mar=c(2.5,2.5,2.5,4))\n# plot(t,f,xlab=\"\",ylab=\"\",main=\"(a)\",type='l')\n\n# par(mar=c(2.5,2.5,2.5,1))\n# mintau&lt;-5\n# maxtau&lt;-180\n# image.plot(x=t,y=mintau:maxtau,z=MM2[1:len,mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(b)\",legend.mar=10)\n# mintau&lt;-50\n# maxtau&lt;-175\n# par(mar=c(2.5,2.5,2.5,1))\n# image.plot(x=t,y=mintau:maxtau,z=VM2[1:len,mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(c)\",legend.mar=5)\n# par(mar=c(2.5,2.5,2.5,1))\n# # mintau&lt;-50\n# # maxtau&lt;-100\n# # image.plot(x=t,y=mintau:maxtau,z=dVM2_t[1:(len-1),mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(d)\",legend.mar=10)\n# # par(mar=c(2.5,2.5,2.5,1))\n# mintau&lt;-50\n# maxtau&lt;-175\n# image.plot(x=t,y=mintau:maxtau,z=dVM2_tau[1:len,mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(d)\",legend.mar=10)\n# library(phonTools)\n# library(fields)\n# # temp&lt;-spectrogram(f,fs=180,windowlength = 5*22050/180,show=F)$spectrogram\n# # par(mar=c(2.5,2.5,2.5,1))\n# # image.plot(x=seq(0,11.37,length=941),y=seq(0,90,length=617),z=temp[1:941,1:617],xlab=\"\",ylab=\"\",main=\"(f)\",legend.mar=10)\n# dev.off() \n\n# # FIG 2-1\n# library(wavelets)\n# data(ecg)\n# f&lt;-as.vector(ecg)\n# t&lt;-seq(0,11.37,length=2048)\n# maxtau=180\n# len&lt;-length(f)\n# MM2&lt;-Mmap(f,maxtau=maxtau,M=\"mean\",V=\"volume\")\n# VM2&lt;-Vmap(f,maxtau=maxtau,M=\"mean\",V=\"volume\")\n# dMM2_t&lt;-diff(MM1)\n# dMM2_tau&lt;-t(diff(t(MM2)))\n# dVM2_t&lt;-diff(VM2)\n# dVM2_tau&lt;-t(diff(t(VM2)))\n\n# #pdf(paste(PATH, \"2-3]MmapVmapECG_1.pdf\", sep=\"\"), width=7, height=2.3)\n# par(mfrow=c(1,2))\n# par(mar=c(2.5,2.5,2.5,1))\n# image.plot(x=t,y=mintau:maxtau,z=VM2[1:len,mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(a)\",legend.mar=5)\n# par(mar=c(2.5,2.5,2.5,1))\n# mintau&lt;-50\n# maxtau&lt;-100\n# image.plot(x=t,y=mintau:maxtau,z=dVM2_t[1:(len-1),mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(b)\",legend.mar=10)\n# par(mar=c(2.5,2.5,2.5,1))\n# mintau&lt;-50\n# maxtau&lt;-175\n# #dev.off() \n\n# #########################################################################################################################################\n# # ELASTIC BAND TRANSFORM\n# ## Useful Applications of Elastic-Band Transform\n# ### Testing Chage of Cycle in Cyclostationary Stochastic Process\n# #########################################################################################################################################\n# # FIG 6\n# set.seed(2)\n# # fs&lt;-90\n# # Ts&lt;-1/90\n# # t=seq(-10,10,length=20*fs)\n# # vartau&lt;-seq(from=90,to=95,by=2)\n# # truetau&lt;-90;\n# # len&lt;-length(t)\n# # lenhalf&lt;-round(len*0.5)\n# # \n# # u1&lt;-c(cos(fs/truetau*2*pi*t[1:lenhalf]),rep(0,len-lenhalf))\n# # u2&lt;-c(rep(0,lenhalf),cos(fs/vartau[freqindex]*2*pi*t[(lenhalf+1):len]))\n# # u&lt;-u1+u2\n# # \n# # v1&lt;-swave(truetau/2,lenhalf)\n# # v2&lt;-swave(vartau[freqindex]/2,len-lenhalf)\n# # v&lt;-c(v1,v2)\n# # \n# # snr&lt;-2\n# # noise1&lt;-rnorm(len,mean=0,sd=sd((u)/snr))  \n# # noise2&lt;-rnorm(len,mean=0,sd=sd((v)/snr))  \n# # f=u+noise1\n# # g=v+noise2\n\n# ecgmat&lt;-read.csv(\"C:/Users/gbchoi/Desktop/data/ecgdata.csv\",head=T)\n# noise&lt;-rnorm(1800,mean=0,sd=sd(ecgmat[,1])/2)\n# a.ecg1&lt;-c(ecgmat[,1],ecgmat[,1])+noise\n# a.ecg2&lt;-c(ecgmat[,1],ecgmat[,2])+noise\n# a.ecg3&lt;-c(ecgmat[,1],ecgmat[,3])+noise\n# a.ecg4&lt;-c(ecgmat[,1],ecgmat[,4])+noise\n# a.ecg5&lt;-c(ecgmat[,1],ecgmat[,5])+noise\n# t=seq(0,20,length=20*90)\n\n# # VMf&lt;-Vmap(f,maxtau=150,M=\"mean\",V=\"var\")\n# # VMg&lt;-Vmap(g,maxtau=150,M=\"mean\",V=\"var\")\n\n# VMecg1&lt;-Vmap(a.ecg1,maxtau=150,M=\"mean\",V=\"volume\")\n# VMecg5&lt;-Vmap(a.ecg5,maxtau=150,M=\"mean\",V=\"volume\")\n\n# pdf(paste(PATH, \"2-3]periodchange.pdf\", sep=\"\"), width=10, height=6)\n# par(mfrow=c(2,2))\n# par(mar=c(2.5, 2.5, 2.5, 3))\n# plot(t,a.ecg1,xlab=\"\",ylab=\"\",main=\"(a)\",type='l')\n# plot(t,a.ecg5,xlab=\"\",ylab=\"\",main=\"(b)\",type='l')\n\n# library(fields)\n# # mintau&lt;-20\n# # maxtau&lt;-150\n# # par(mar=c(2.5, 2.5, 2.5, 1))\n# # image.plot(x=t,y=mintau:maxtau,z=VMf[1:len,mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(c)\",legend.mar=5)\n# # par(mar=c(2.5, 2.5, 2.5, 1))\n# # mintau&lt;-20\n# # maxtau&lt;-150\n# # image.plot(x=t,y=mintau:maxtau,z=VMg[1:len,mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(d)\",legend.mar=5)\n# par(mar=c(2.5, 2.5, 2.5, 1))\n# mintau&lt;-20\n# maxtau&lt;-120\n# image.plot(x=t,y=mintau:maxtau,z=VMecg1[1:length(a.ecg1),mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(c)\",legend.mar=5)\n# image.plot(x=t,y=mintau:maxtau,z=VMecg5[1:length(a.ecg5),mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(d)\",legend.mar=5)\n# dev.off() \n# # \n# # library(phonTools)\n# # temp1&lt;-spectrogram(f,fs=fs,windowlength = 5*22050/fs,show=F)$spectrogram\n# # temp2&lt;-spectrogram(g,fs=fs,windowlength = 5*22050/fs,show=F)$spectrogram\n# # par(mar=c(2.5,2.5,2.5,1))\n# # image.plot(x=seq(-10,10,length=958),y=seq(0,fs/2,length=617),z=temp1[1:958,1:617],xlab=\"\",ylab=\"\",main=\"(f)\",legend.mar=10)\n# # image.plot(x=seq(-10,,length=958),y=seq(0,fs/2,length=617),z=temp2[1:958,1:617],xlab=\"\",ylab=\"\",main=\"(f)\",legend.mar=10)\n# set.seed(7)\n# ITER&lt;-100\n# pval&lt;-rep(0,ITER*5); dim(pval)&lt;-c(ITER,5)\n# a.ecg&lt;-list()\n# for(iter in 1:ITER)\n# {\n#   for(f1index in 1:5)\n#     {\n#       noise&lt;-rnorm(1800,mean=0,sd=sd(ecgmat[,1])/2)\n#       a.ecg[[f1index]]&lt;-c(ecgmat[,1],ecgmat[,f1index])+noise\n#       hat_tau&lt;-tauest(a.ecg[[f1index]],taulist=80:120,V=\"volume\")\n#       pval[iter,f1index]&lt;-st.test(hat_tau[200:1600])\n#     }\n# }\n# round(1-apply(pval,2,mean),3)\n# action&lt;-pval&lt;0.05\n# round(apply(action,c(2,3),mean),3)\n\n\n# #########################################################################################################################################\n# # ELASTIC BAND TRANSFORM\n# ## Useful Applications of Elastic-Band Transform\n# ### Change Point Detections\n# #########################################################################################################################################\n# ## FIG 1\n# pdf(paste(PATH, \"2-4]CPsignal.pdf\", sep=\"\"), width=7, height=4)\n# par(mar=c(2.5,2.5,2.5,2.5))\n# par(mfrow=c(2,2))\n# set.seed(1)\n# f1&lt;-c(rnorm(400,0,0.5),\n#       rnorm(20,0,0.7),\n#       rnorm(20,0,0.9),\n#       rnorm(20,0,1.1),\n#       rnorm(20,0,1.3),\n#       rnorm(20,0,1.5),\n#       rnorm(20,0,1.7),\n#       rnorm(20,0,1.9),\n#       rnorm(20,0,2.1),\n#       rnorm(20,0,2.3),\n#       rnorm(20,0,2.5),\n#       rnorm(800,0,3.5))\n# plot(f1[101:(1200-100)],type='l',main=\"(a)\")\n# set.seed(1)\n# f2&lt;-c(rnorm(400,0,0.5),\n#       rnorm(20,0,0.7),\n#       rnorm(20,0,0.9),\n#       rnorm(20,0,1.1),\n#       rnorm(20,0,1.3),\n#       rnorm(20,0,1.5),\n#       rnorm(20,0,1.7),\n#       rnorm(20,0,1.9),\n#       rnorm(20,0,2.1),\n#       rnorm(20,0,2.3),\n#       rnorm(20,0,2.5),\n#       rnorm(800,0,3.5*2))\n# plot(f2[101:(1200-100)],type='l',main=\"(b)\")\n# set.seed(1)\n# f3&lt;-c(rnorm(400,0,0.5),\n#       rnorm(20,0,0.7),\n#       rnorm(20,0,0.9),\n#       rnorm(20,0,1.1),\n#       rnorm(20,0,1.3),\n#       rnorm(20,0,1.5),\n#       rnorm(20,0,1.7),\n#       rnorm(20,0,1.9),\n#       rnorm(20,0,2.1),\n#       rnorm(20,0,2.3),\n#       rnorm(20,0,2.5),\n#       rnorm(800,0,3.5*3))\n# plot(f3[101:(1200-100)],type='l',main=\"(c)\")\n# set.seed(1)\n# f4&lt;-c(rnorm(400,0,0.5),\n#       rnorm(20,0,0.7),\n#       rnorm(20,0,0.9),\n#       rnorm(20,0,1.1),\n#       rnorm(20,0,1.3),\n#       rnorm(20,0,1.5),\n#       rnorm(20,0,1.7),\n#       rnorm(20,0,1.9),\n#       rnorm(20,0,2.1),\n#       rnorm(20,0,2.3),\n#       rnorm(20,0,2.5),\n#       rnorm(800,0,3.5*4))\n# plot(f4[101:(1200-100)],type='l',main=\"(d)\")\n# dev.off() \n\n# ## TABLE 1\n# J=4; Tau=8; ITER=1;\n# cp&lt;-rep(0,ITER*Tau*J); dim(cp)&lt;-c(ITER,Tau,J)\n# set.seed(1000); \n# # sim.result3&lt;-generate.gaussian(Tx=1000,nsim=1000);\n# for(iter in 1:ITER)\n# {\n#   for(j in 1:J)\n#   {\n#     f&lt;-c(rnorm(400,0,1.5),\n#           rnorm(20,0,1.6),\n#           rnorm(20,0,1.7),\n#           rnorm(20,0,1.8),\n#           rnorm(20,0,1.9),\n#           rnorm(20,0,2.0),\n#           rnorm(20,0,2.1),\n#           rnorm(20,0,2.2),\n#           rnorm(20,0,2.3),\n#           rnorm(20,0,2.4),\n#           rnorm(20,0,2.5),\n#           rnorm(800,0,3.5*j))\n#     taulist&lt;-c(5,10,15,20,25,30,35,40) \n#     for(tau in 1:Tau)\n#     {\n#       ebtres&lt;-ebt(f,tau=taulist[tau])\n#       fV&lt;-ebtres$V[101:1100]\n#       cp[iter,tau,j]&lt;-cp.find(x=fV,sim.result=sim.result3)\n#       par(mfrow=c(2,1))\n#       plot(f[101:1100],type='l'); abline(v=cp[iter,tau,j],col=2); plot(f[101:1100],type='l',main=cp[iter,tau,j]); abline(v=cp[iter,tau,j],col=2);\n#       par(mfrow=c(1,1))\n#     }\n#   }\n# }\n# #cp\n# t(apply(cp,c(2,3),median))\n\n# #########################################################################################################################################\n# # Extracting Periodic signals\n# ## AM-demodulation via Elastic-Band Transform\n# #########################################################################################################################################\n# # FIG 1\n# fs=1000\n# t=-2000:2000/fs\n# v1=0.4*sin(2*pi*t)+1\n# v2=2*cos(20*pi*t)\n# v3=2*cos(20*pi*t)-2\n# f1=v1*v2;\n# f2=v1*v3;\n# AMebt1&lt;-ebt(f1,t,tau=100,V=\"volume\")\n# AMebt2&lt;-ebt(f2,t,tau=100,V=\"volume\")\n\n# pdf(paste(PATH, \"3-1]AM.pdf\", sep=\"\"), width=10, height=5)\n# par(mar=c(2.5,2.5,2.5,2.5))\n# par(mfrow=c(1,2))\n# vis(AMebt1,M=F,V=F,xlim=c(t[1500],t[2500]),band=1:100,ylim=c(-3,3),obs=\"lines\",bandlwd=0.5,main=\"(a)\")\n# lines(t,v1,col=2,lwd=2)\n# lines(t,AMebt1$U,col=4,lty=2,lwd=2)\n# lines(t,AMebt1$U/2,col=4,lty=2,lwd=2)\n# vis(AMebt2,M=F,V=F,xlim=c(t[1500],t[2500]),band=1:100,ylim=c(-8,2),obs=\"lines\",bandlwd=0.5,main=\"(b)\")\n# lines(t,v1,col=2,lwd=2)\n# lines(t,AMebt2$L,col=4,lty=2,lwd=2)\n# lines(t,AMebt2$L/(-4),col=4,lty=2,lwd=2)\n# dev.off() \n\n# #########################################################################################################################################\n# # Extracting Periodic signals\n# ## Decomposition\n# ### Noise Free Setting\n# #########################################################################################################################################\n# # FIG 1 \n# t=-2000:2000/1000\n# v1=cos(14*pi*t) #tau=142.8571\n# v2=cos(80*pi*t) #tau=25\n# f=v1+v2\n# ylim1&lt;-c(-2.5,2.5)\n# ebt1&lt;-ebt(f,t,tau=25,V=\"volume\")\n# ebt2&lt;-ebt(f-ebt1$M,t,tau=25,V=\"volume\")\n\n# pdf(paste(PATH, \"3-2]SignalExtraction_fig1.pdf\", sep=\"\"), width=7.5, height=4.5)\n# par(mar=c(2.5,2.5,2.5,2.5))\n# par(mfrow=c(3,2))\n# plot(t,v1,xlim=c(-0.5,0.5),ylim=ylim1, type='l',col=1, xlab=\"\",ylab=\"\",main=\"(a)\")\n# plot(t,v2,xlim=c(-0.5,0.5),ylim=ylim1, type='l',col=1, xlab=\"\",ylab=\"\",main=\"(b)\")\n# plot(t,v1+v2,xlim=c(-0.5,0.5),ylim=ylim1, type='l',col=1, xlab=\"\",ylab=\"\",main=\"(c)\")\n# plot(t,v1+v2,xlim=c(-0.5,0.5),ylim=ylim1, type='l', xlab=\"\",ylab=\"\",lwd=2,col=\"gray60\",main=\"(d)\")\n# lines(t,ebt1$M,col=2)\n# lines(t,ebt1$M+ebt1$V/2,col=3)\n# lines(t,ebt1$M-ebt1$V/2,col=3)\n# plot(t,f-ebt1$M,xlim=c(-0.5,0.5),ylim=ylim1 ,type='l',col=1 ,xlab=\"\",ylab=\"\",main=\"(e)\")\n# plot(t,f-ebt1$M-ebt2$M,xlim=c(-0.5,0.5),ylim=ylim1 ,type='l',col=1 ,xlab=\"\",ylab=\"\",main=\"(f)\")\n# dev.off() \n\n# # FIG 2\n# t=-2000:2000/1000\n# v1=swave(20,4001) #tau=40\n# v2=cos(7*pi*t) #tau=100\n# f=v1+v2\n# ylim1&lt;-c(-2.5,2.5)\n# ebt1&lt;-ebt(f,t,tau=40,V=\"volume\")\n# ebt2&lt;-ebt(f-ebt1$M,t,tau=40,V=\"volume\")\n\n# pdf(paste(PATH, \"3-2]SignalExtraction_fig2.pdf\", sep=\"\"), width=7.5, height=4.5)\n# par(mar=c(2.5,2.5,2.5,2.5))\n# par(mfrow=c(3,2))\n# plot(t,v1,xlim=c(-0.5,0.5),ylim=ylim1, type='l',col=1, xlab=\"\",ylab=\"\",lwd=1,main=\"(a)\")\n# plot(t,v2,xlim=c(-0.5,0.5),ylim=ylim1, type='l',col=1, xlab=\"\",ylab=\"\",lwd=1,main=\"(b)\")\n# plot(t,v1+v2,xlim=c(-0.5,0.5),ylim=ylim1, type='l',col=1, xlab=\"\",ylab=\"\",lwd=1,main=\"(c)\")\n# plot(t,v1+v2,xlim=c(-0.5,0.5),ylim=ylim1, type='l', xlab=\"\",ylab=\"\",lwd=1,col=\"gray60\",main=\"(d)\")\n# lines(t,ebt1$M,col=2,lwd=2)\n# lines(t,ebt1$M+ebt1$V/2,col=3,lwd=1)\n# lines(t,ebt1$M-ebt1$V/2,col=3,lwd=1)\n# plot(t,f-ebt1$M,xlim=c(-0.5,0.5),ylim=ylim1 ,type='l',col=1 ,xlab=\"\",ylab=\"\",lwd=1,main=\"(e)\")\n# plot(t,f-ebt1$M-ebt2$M,xlim=c(-0.5,0.5),ylim=ylim1 ,type='l',col=1 ,xlab=\"\",ylab=\"\",lwd=1,main=\"(f)\")\n# dev.off() \n\n# # FIG 3 \n# t=-2000:2000/1000\n# v1=cos(5*pi*t) #tau=100\n# v2=cos(50*pi*t) #tau=40\n# v3=cos(80*pi*t) #tau=25\n# f=v1+v2+v3\n# exf&lt;-extract.hfreq(t,f,tau=40,tol=0.00001,iter=0)\n# exf2&lt;-extract.hfreq(t,f,tau=40,tol=0.00001,iter=5)\n# exf3&lt;-extract.hfreq(t,f,tau=40,tol=0.00001,iter=20)\n# exf4&lt;-extract.hfreq(t,f,tau=40,tol=0.00001,iter=150)\n\n\n# pdf(paste(PATH, \"3-2]SignalExtraction_fig3.pdf\", sep=\"\"), width=7.5, height=4)\n# par(mar=c(2.5,2.5,2.5,2.5))\n# par(mfrow=c(2,3))\n# plot(t,f,xlim=c(-0.5,0.5),ylim=c(-3.5,3.5),type='l',col=1, xlab=\"\",ylab=\"\",main=\"(a)\",lwd=0.7)\n# plot(t,v2,xlim=c(-0.5,0.5),ylim=c(-3.5,3.5), type='l',col=1, xlab=\"\",ylab=\"\",main=\"(b)\",lwd=0.7)\n# plot(t,exf,xlim=c(-0.5,0.5),ylim=c(-3.5,3.5) ,type='l',col=1 ,xlab=\"\",ylab=\"\",main=\"(c)\",lwd=0.7)\n# plot(t,exf2,xlim=c(-0.5,0.5),ylim=c(-3.5,3.5) ,type='l',col=1 ,xlab=\"\",ylab=\"\",main=\"(d)\",lwd=0.7)\n# plot(t,exf3,xlim=c(-0.5,0.5),ylim=c(-3.5,3.5) ,type='l',col=1 ,xlab=\"\",ylab=\"\",main=\"(e)\",lwd=0.7)\n# plot(t,exf4,xlim=c(-0.5,0.5),ylim=c(-3.5,3.5) ,type='l',col=1,xlab=\"\",ylab=\"\",main=\"(f)\",lwd=0.7)\n# dev.off() \n\n# # FIG 4 \n# t=-2000:2000/1000\n# v1=cos(5*pi*t) #tau=100\n# v2=cos(50*pi*t) #tau=40\n# v3=cos(80*pi*t) #tau=25\n# f=v1+v2+v3\n# mode1&lt;-extract.hfreq(t,f,tau=25,tol=0.000000001,iter=10)\n# mode2&lt;-extract.hfreq(t,f-mode1,tau=40,tol=0.000000001,iter=1)\n# mode3&lt;-f-mode1-mode2\n\n# pdf(paste(PATH, \"3-2]SignalExtraction_fig4.pdf\", sep=\"\"), width=7.5, height=5)\n# m &lt;- matrix(c(1,2,2,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11),nrow = 4,ncol = 4,byrow = TRUE)\n# layout(mat = m)\n# par(mar=c(2.5,2.5,2.5,2.5))\n# plot(1, type=\"n\", axes=F, xlab=\"\", ylab=\"\")\n# plot(t,f,xlim=c(-0.5,0.5),ylim=c(-4,4),xlab=\"\",ylab=\"\",type='l',main=\"(a)\")\n# plot(1, type=\"n\", axes=F, xlab=\"\", ylab=\"\")\n# plot(t,v1,xlim=c(-0.5,0.5),ylim=c(-4,4),type='l',col=1, xlab=\"\",ylab=\"\",main=\"(b)\")\n# plot(t,mode3,xlim=c(-0.5,0.5),ylim=c(-4,4) ,type='l',col=1 ,xlab=\"\",ylab=\"\",main=\"(c)\")\n# plot(t,v2,xlim=c(-0.5,0.5),ylim=c(-4,4), type='l',col=1, xlab=\"\",ylab=\"\",main=\"(d)\")\n# plot(t,mode2,xlim=c(-0.5,0.5),ylim=c(-4,4) ,type='l',col=1 ,xlab=\"\",ylab=\"\",main=\"(e)\")\n# plot(t,v3,xlim=c(-0.5,0.5),ylim=c(-4,4) ,type='l',col=1 ,xlab=\"\",ylab=\"\",main=\"(f)\")\n# plot(t,mode1,xlim=c(-0.5,0.5),ylim=c(-4,4) ,type='l',xlab=\"\",ylab=\"\",main=\"(g)\")\n# dev.off() \n\n# # FIG 5 \n# t=-2000:2000/1000\n# v1=cos(2*pi*t) \n# v2=c(rep(0,1500),0.5*cos(40*pi*t[1500:1600]),rep(0,2400)) # tau=50\n# v3=c(rep(0,2000),0.5*cos(40*pi*t[2000:2200]),rep(0,1800)) # tau=50\n# v4=c(rep(0,2500),0.5*cos(40*pi*t[2500:2700]),rep(0,1300)) \n# f=v1+v2+v3+v4;\n# plot(t,f,xlim=c(-1,1),type='l')\n# plot(t,v2+v3+v4,xlim=c(-1,1),type='l')\n# ext3&lt;-extract.hfreq(t,f,tau=200)\n\n# library(EMD)\n# try &lt;- emd(f, t, boundary=\"wave\")\n# # \n# # ### Ploting the IMF's\n# # par(mfrow=c(try$nimf+1, 1), mar=c(2,1,2,1))\n# # rangeimf &lt;- range(try$imf)\n# # for(i in 1:try$nimf) {\n# #   plot(t, try$imf[,i], type=\"l\", xlab=\"\", ylab=\"\", ylim=rangeimf,\n# #        main=paste(i, \"-th IMF\", sep=\"\")); abline(h=0)\n# # }\n# # plot(t, try$residue, xlab=\"\", ylab=\"\", main=\"residue\", type=\"l\", axes=FALSE); box()\n\n# pdf(paste(PATH, \"3-2]SignalExtraction_fig5.pdf\", sep=\"\"), width=7.5, height=7)\n# m &lt;- matrix(c(1,2,2,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11),nrow = 5,ncol = 4,byrow = TRUE)\n# layout(mat = m)\n# par(mar=c(2.5,2.5,2.5,2.5))\n# plot(1, type=\"n\", axes=F, xlab=\"\", ylab=\"\")\n# plot(t,f,xlim=c(-1,1),ylim=c(-1.8,1.5),xlab=\"\",ylab=\"\",type='l',main=\"(a)\")\n# plot(1, type=\"n\", axes=F, xlab=\"\", ylab=\"\")\n# plot(t,ext3,xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',xlab=\"\",ylab=\"\",lty=1,main=\"(b)\")\n# plot(t,try$imf[,1],xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',main=\"(c)\")\n# plot(t,f-ext3,xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',xlab=\"\",ylab=\"\",lty=1,main=\"(d)\")\n# plot(t,try$imf[,2],xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',main=\"(e)\")\n# plot(1, type=\"n\", axes=F, xlab=\"\", ylab=\"\")\n# plot(t,try$imf[,3],xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',main=\"(f)\")\n# plot(1, type=\"n\", axes=F, xlab=\"\", ylab=\"\")\n# plot(t,try$residue,xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',main=\"(g)\")\n# dev.off()\n\n# # FIG 6\n# t=-2000:2000/1000\n# v1=t*c(cos(14*pi*t[1:2000]),rep(0,2001))\n# v2=-t*c(rep(0,2000),cos(80*pi*t[2001:4001]))\n# f=v1+v2;\n# ext3&lt;-extract.hfreq(t,f,tau=25)\n# try &lt;- emd(f, t, boundary=\"wave\")\n# # ### Ploting the IMF's\n# # par(mfrow=c(try$nimf+1, 1), mar=c(2,1,2,1))\n# # rangeimf &lt;- range(try$imf)\n# # for(i in 1:try$nimf) {\n# #   plot(t, try$imf[,i], type=\"l\", xlab=\"\", ylab=\"\", ylim=rangeimf,\n# #        main=paste(i, \"-th IMF\", sep=\"\")); abline(h=0)\n# # }\n# # plot(t, try$residue, xlab=\"\", ylab=\"\", main=\"residue\", type=\"l\", axes=FALSE); box()\n\n\n# pdf(paste(PATH, \"3-2]SignalExtraction_fig6.pdf\", sep=\"\"), width=7.5, height=8)\n# m &lt;- matrix(c(1,2,2,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11,12,12,13,13),nrow = 6,ncol = 4,byrow = TRUE)\n# layout(mat = m)\n# par(mar=c(2.5,2.5,2.5,2.5))\n# plot(1, type=\"n\", axes=F, xlab=\"\", ylab=\"\")\n# plot(t,f,xlim=c(-1,1),ylim=c(-1.8,1.5),xlab=\"\",ylab=\"\",type='l',main=\"(a)\")\n# plot(1, type=\"n\", axes=F, xlab=\"\", ylab=\"\")\n# plot(t,ext3,xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',xlab=\"\",ylab=\"\",lty=1,main=\"(b)\")\n# plot(t,try$imf[,1],xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',main=\"(c)\")\n# plot(t,f-ext3,xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',xlab=\"\",ylab=\"\",lty=1,main=\"(d)\")\n# plot(t,try$imf[,2],xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',main=\"(e)\")\n# plot(1, type=\"n\", axes=F, xlab=\"\", ylab=\"\")\n# plot(t,try$imf[,3],xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',main=\"(f)\")\n# plot(1, type=\"n\", axes=F, xlab=\"\", ylab=\"\")\n# plot(t,try$imf[,4],xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',main=\"(g)\")\n# plot(1, type=\"n\", axes=F, xlab=\"\", ylab=\"\")\n# plot(t,try$residue,xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',main=\"(h)\")\n# dev.off() \n\n\n# #########################################################################################################################################\n# # Designing Filter by Elastic Band Transform \n# ## Extracting Signal with Noise\n# #########################################################################################################################################\n# # FIG 1 \n# pdf(paste(PATH, \"4-2]DenoisingPeriodicSignal_fig1.pdf\", sep=\"\"), width=7, height=7)\n# par(mar=c(2.3,2.3,2.3,2.3))\n# par(mfrow=c(4,1))\n# t=-2000:2000/1000\n# v1=cos(200*pi*t) #tau=10\n# v2=swave(5,4001) #tau=10\n# snr&lt;-3\n# noise1&lt;-rnorm(4001,mean=0,sd=sd((v1)/snr))  \n# noise2&lt;-rnorm(4001,mean=0,sd=sd((v2)/snr))  \n# f1=v1+noise\n# f2=v2+noise\n# plot(t,f1,xlim=c(-0.1,0.1),type='l',ylim=c(-2.5,2.5),main=\"(a)\")\n# plot(t,f1,xlim=c(-0.1,0.1),ylim=c(-2.5,2.5),col=\"gray60\",xlab=\"\",ylab=\"\",cex=0.9,main=\"(b)\")\n# lines(t,v1hat,col=2)\n# lines(t,v1,col=1, lty=2)\n# plot(t,f2,xlim=c(-0.1,0.1),type='l',ylim=c(-2.5,2.5),main=\"(c)\")\n# # v1hat&lt;-extract.hfreq(t,f1,tau=10,tol=0.00000000000000005,iter=1000)\n# # v2hat&lt;-extract.hfreq(t,f2,tau=10,tol=0.00000000000000005,iter=1000)\n# plot(t,f2,xlim=c(-0.1,0.1),ylim=c(-2.5,2.5),col=\"gray60\",xlab=\"\",ylab=\"\",cex=0.9,main=\"(d)\")\n# lines(t,v2hat,col=2)\n# lines(t,v2,col=1, lty=2)\n# dev.off() \n\n\n# #########################################################################################################################################\n# # Denosing technique with elastic band transform\n# ## Nadaraya-Watson Kernel Estimator\n# #########################################################################################################################################\n# # FIG 1 \n# t=-2000:2000/1000\n# f1&lt;-25\n# v1=cos(f1*pi*t) #tau=40\n# snr&lt;-3\n# set.seed(1)\n# noise&lt;-rnorm(4001,mean=0,sd=sd(v1)/snr)\n# f=v1+noise\n# len=length(f)\n# omega_hat&lt;-seq(from=0,to=pi,len=ceiling(len/2))\n# fft_f&lt;-c(1-(1-abs(fft(f))[((len+1)/2):len]),1-(1-abs(fft(f))[1:((len+1)/2-1)]))/len\n# lwd=1.5\n# col=\"gray40\"\n\n# pdf(paste(PATH, \"4-1]NadarayaWatsonKernelEstimator_fig1.pdf\", sep=\"\"), width=7, height=5)\n# xlim=c(-0.05,0.05)\n# par(mar=c(2.5,2.5,2.5,2.5))\n# par(mfrow=c(4,2))\n# plot(t,f,xlim=xlim,ylim=c(-1.5,1.5),col=col,xlab=\"\",ylab=\"\",cex=0.9)\n# lines(t,v1,lty=2)\n# lines(t,ebt(f,tau=5)$M,col=2)\n# get.h(f,tau=5,plot=T,log=T)\n# lines(omega_hat,fft_f[ceiling(len/2):1],col=col,lwd=lwd)\n\n# plot(t,f,xlim=xlim,ylim=c(-1.5,1.5),col=col,xlab=\"\",ylab=\"\",cex=0.9)\n# lines(t,v1,lty=2)\n# lines(t,ebt(f,tau=20)$M,col=2)\n# get.h(f,tau=20,plot=T,log=T)\n# lines(omega_hat,fft_f[ceiling(len/2):1],col=col,lwd=lwd)\n\n# plot(t,f,xlim=xlim,ylim=c(-1.5,1.5),col=col,xlab=\"\",ylab=\"\",cex=0.9)\n# lines(t,v1,lty=2)\n# lines(t,ebt(f,tau=40)$M,col=2)\n# get.h(f,tau=40,plot=T,log=T)\n# lines(omega_hat,fft_f[ceiling(len/2):1],col=col,lwd=lwd)\n\n# plot(t,f,xlim=xlim,ylim=c(-1.5,1.5),col=col,xlab=\"\",ylab=\"\",cex=0.9)\n# lines(t,v1,lty=2)\n# lines(t,ebt(f,tau=60)$M,col=2)\n# get.h(f,tau=60,plot=T,log=T)\n# lines(omega_hat,fft_f[ceiling(len/2):1],col=col,lwd=lwd)\n# dev.off() \n# # \n# # # FIG 2\n# # t=-2000:2000/1000\n# # f1&lt;-25\n# # v1=cos(f1*pi*t) #tau=40\n# # snr&lt;-3\n# # set.seed(1)\n# # noise&lt;-rnorm(4001,mean=0,sd=sd(v1)/snr)\n# # f=v1+noise\n# # \n# # \n# # pdf(paste(PATH, \"5-1]NadarayaWatsonKernelEstimator_fig2.pdf\", sep=\"\"), width=7, height=4)\n# # par(mar=c(2.5,2.5,2.5,2.5))\n# # par(mfrow=c(3,2))\n# # plot(omega_hat,fft_f,type='l',xlab=\"\",ylab=\"\",main=\"(a)\",col=\"gray60\",ylim=c(0,1)) ## plot \n# # get.h(f,tau=5,main=\"(b)\",plot=T)\n# # lines(omega_hat,fft_f,col=\"gray60\")\n# # get.h(f,tau=20,main=\"(c)\",plot=T)\n# # lines(omega_hat,fft_f,col=\"gray60\")\n# # get.h(f,tau=40,main=\"(d)\",plot=T)\n# # lines(omega_hat,fft_f,col=\"gray60\")\n# # get.h(f,tau=60,main=\"(e)\",plot=T)\n# # lines(omega_hat,fft_f,col=\"gray60\")\n# # get.h(f,tau=80,main=\"(f)\",plot=T)\n# # lines(omega_hat,fft_f,col=\"gray60\")\n# # dev.off() \n\n# #########################################################################################################################################\n# # Denosing technique with elastic band transform\n# ## Design Denoising Filter\n# #########################################################################################################################################\n\n# # FIG 1\n# len=4001\n# pdf(paste(PATH, \"4-2]DesignDenoisingFilter_fig1.pdf\", sep=\"\"), width=8, height=3)\n# par(mar=c(2.5,2.5,2.5,2.5))\n# par(mfrow=c(2,2))\n# main=c(\"(a)\",\"(b)\",\"(c)\",\"(d)\")\n# taulist=c(5,20,40,60)\n# for(k in 1:4)\n# {\n#   h&lt;-c(rep(0,len-(taulist[k]-1)),1:taulist[k],(taulist[k]-1):1,rep(0,len-taulist[k]))/taulist[k]^2\n#   omega_hat&lt;-seq(from=-pi,to=pi,len=len*2)\n#   iter=1\n#   H&lt;-c(1-(1-abs(fft(h))[(len+1):(2*len)])^iter,1-(1-abs(fft(h))[1:len])^iter)\n#   plot(omega_hat[omega_hat&gt;0],H[omega_hat&gt;0],type='l',xlab=\"\",ylab=\"\",main=main[k],log=\"x\")\n#   index1&lt;-which((H^2-0.5)^2==min((H^2-0.5)^2))[1]\n#   index2&lt;-8000-index1\n#   Ideal&lt;-0*H\n#   Ideal[index1:index2]&lt;-1\n#   lines(omega_hat[omega_hat&gt;0],Ideal[omega_hat&gt;0],col=2,lty=2,lwd=1)\n# }\n# dev.off()\n\n# # FIG 2\n# t=-2000:2000/1000\n# f1&lt;-25\n# v1=cos(f1*pi*t) #tau=40\n# snr&lt;-3\n# set.seed(1)\n# noise&lt;-rnorm(4001,mean=0,sd=sd(v1)/snr)\n# f=v1+noise\n# len=length(f)\n# omega_hat&lt;-seq(from=-pi,to=pi,len=len)\n# fft_f&lt;-c(1-(1-abs(fft(f))[((len+1)/2):len]),1-(1-abs(fft(f))[1:((len+1)/2-1)]))/len\n# df1_tau20&lt;-ebt(f,t,tau=20)$M\n# df2_tau20&lt;-f-extract.hfreq(t,f,tau=20,iter=1)\n# df3_tau20&lt;-f-extract.hfreq(t,f,tau=20,iter=2)\n# df4_tau20&lt;-f-extract.hfreq(t,f,tau=20,iter=3)\n\n# df1_tau40&lt;-ebt(f,t,tau=40)$M\n# df2_tau40&lt;-f-extract.hfreq(t,f,tau=40,iter=1)\n# df3_tau40&lt;-f-extract.hfreq(t,f,tau=40,iter=2)\n# df4_tau40&lt;-f-extract.hfreq(t,f,tau=40,iter=3)\n\n# pdf(paste(PATH, \"4-2]DesignDenoisingFilter_fig2.pdf\", sep=\"\"), width=8, height=6)\n# par(mar=c(2.5,2.5,2.5,2.5))\n# par(mfrow=c(4,2))\n# plot(t,f,xlim=xlim,col=\"gray60\",xlab=\"\",ylab=\"\")\n# lines(t,v1,col=1,lty=2)\n# lines(t,df1_tau20,col=2,lwd=1)\n# lines(t,df1_tau40,col=4,lwd=1)\n# get.h(f,tau=20,plot=T,iter=1,log=T,col=2)\n# h40&lt;-get.h(f,tau=40,plot=F,iter=1,log=F);\n# lines(h40$omega_hat[h40$omega_hat&gt;0],h40$H_iter[h40$omega_hat&gt;0],col=4)\n# lines(omega_hat[h40$omega_hat&gt;0],fft_f[h40$omega_hat&gt;0],col=\"gray60\")\n\n# plot(t,f,xlim=xlim,col=\"gray60\",xlab=\"\",ylab=\"\")\n# lines(t,v1,col=1,lty=2)\n# lines(t,df2_tau20,col=2,lwd=1)\n# lines(t,df2_tau40,col=4,lwd=1)\n# get.h(f,tau=20,plot=T,iter=2,log=T,col=2)\n# h40&lt;-get.h(f,tau=40,plot=F,iter=2,log=F);\n# lines(h40$omega_hat[h40$omega_hat&gt;0],h40$H_iter[h40$omega_hat&gt;0],col=4)\n# lines(omega_hat[h40$omega_hat&gt;0],fft_f[h40$omega_hat&gt;0],col=\"gray60\")\n\n# plot(t,f,xlim=xlim,col=\"gray60\",xlab=\"\",ylab=\"\")\n# lines(t,v1,col=1,lty=2)\n# lines(t,df3_tau20,col=2,lwd=1)\n# lines(t,df3_tau40,col=4,lwd=1)\n# get.h(f,tau=20,plot=T,iter=3,log=T,col=2)\n# h40&lt;-get.h(f,tau=40,plot=F,iter=3,log=F);\n# lines(h40$omega_hat[h40$omega_hat&gt;0],h40$H_iter[h40$omega_hat&gt;0],col=4)\n# lines(omega_hat[h40$omega_hat&gt;0],fft_f[h40$omega_hat&gt;0],col=\"gray60\")\n\n# plot(t,f,xlim=xlim,col=\"gray60\",xlab=\"\",ylab=\"\")\n# lines(t,v1,col=1,lty=2)\n# lines(t,df4_tau20,col=2,lwd=1)\n# lines(t,df4_tau40,col=4,lwd=1)\n# get.h(f,tau=20,plot=T,iter=4,log=T,col=2)\n# h40&lt;-get.h(f,tau=40,plot=F,iter=4,log=F);\n# lines(h40$omega_hat[h40$omega_hat&gt;0],h40$H_iter[h40$omega_hat&gt;0],col=4)\n# lines(omega_hat[h40$omega_hat&gt;0],fft_f[h40$omega_hat&gt;0],col=\"gray60\")\n# dev.off() \n\n# # \n# # # FIG 3\n# # t=-2000:2000/1000\n# # f1&lt;-25\n# # v1=cos(f1*pi*t) #tau=40\n# # snr&lt;-3\n# # set.seed(1)\n# # noise&lt;-rnorm(4001,mean=0,sd=sd(v1)/snr)\n# # f=v1+noise\n# # len=length(f)\n# # omega_hat&lt;-seq(from=-pi,to=pi,len=len)\n# # fft_f&lt;-c(1-(1-abs(fft(f))[((len+1)/2):len]),1-(1-abs(fft(f))[1:((len+1)/2-1)]))/len\n# # df1&lt;-ebt(f,t,tau=40)$M\n# # df2&lt;-f-extract.hfreq(t,f,tau=40,iter=1)\n# # df3&lt;-f-extract.hfreq(t,f,tau=40,iter=2)\n# # df4&lt;-f-extract.hfreq(t,f,tau=40,iter=3)\n# # \n# # pdf(paste(PATH, \"5-2]DesignDenoisingFilter_fig3.pdf\", sep=\"\"), width=8, height=6)\n# # par(mar=c(2.5,2.5,2.5,2.5))\n# # par(mfrow=c(4,2))\n# # plot(t,f,xlim=xlim,col=\"gray60\",xlab=\"\",ylab=\"\",main=\"(a)\")\n# # lines(t,v1,col=1,lty=2)\n# # lines(t,df1,col=2,lwd=1)\n# # get.h(f,tau=40,main=\"(b)\",plot=T,iter=1)\n# # lines(omega_hat,fft_f,col=\"gray60\")\n# # plot(t,f,xlim=xlim,col=\"gray60\",xlab=\"\",ylab=\"\",main=\"(c)\")\n# # lines(t,v1,col=1,lty=2)\n# # lines(t,df2,col=2,lwd=1)\n# # get.h(f,tau=40,main=\"(d)\",plot=T,iter=2)\n# # lines(omega_hat,fft_f,col=\"gray60\")\n# # plot(t,f,xlim=xlim,col=\"gray60\",xlab=\"\",ylab=\"\",main=\"(e)\")\n# # lines(t,v1,col=1,lty=2)\n# # lines(t,df3,col=2,lwd=1)\n# # get.h(f,tau=40,main=\"(f)\",plot=T,iter=3)\n# # lines(omega_hat,fft_f,col=\"gray60\")\n# # plot(t,f,xlim=xlim,col=\"gray60\",xlab=\"\",ylab=\"\",main=\"(g)\")\n# # lines(t,v1,col=1,lty=2)\n# # lines(t,df4,col=2,lwd=1)\n# # get.h(f,tau=40,main=\"(h)\",plot=T,iter=4)\n# # lines(omega_hat,fft_f,col=\"gray60\")\n# # dev.off() \n\n\n# #########################################################################################################################################\n# # Denosing technique with elastic band transform\n# ## Data-adaptive $\\tau$ selection  \n# #########################################################################################################################################\n# # FIG 1 \n# library(wavethresh)\n# donoho.noise&lt;-DJ.EX(n=1000, signal=1, rsnr=5, noisy=TRUE, plotfn=FALSE)\n# donoho&lt;-DJ.EX(n=1000, signal=1, rsnr=5, noisy=FALSE, plotfn=FALSE)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n\n# VM&lt;-list()\n# df&lt;-list()\n# lambda&lt;-c(0.08,0.2,0.045,0.06)\n# iter&lt;-c(1,1,4,1)\n# pdf(paste(PATH, \"4-3]DataAdaptiveTauSelection_fig1.pdf\", sep=\"\"), width=8, height=6)\n# par(mfrow=c(4,3))\n# for(i in 1:4)\n# {\n#   par(mar=c(2.5,2.5,2.5,2.5))\n#   f&lt;-donoho.noise[[i]]\n#   plot(f,type='l',xlab=\"\",ylab=\"\",col=\"gray60\")\n#   maxtau=50\n#   len&lt;-length(f)\n#   VM[[i]]&lt;-Vmap(f,maxtau=maxtau,M=\"mean\",V=\"var\")\n#   mintau&lt;-5\n#   par(mar=c(2.5,1,2.5,3.5))\n#   image.plot(x=1:len,y=mintau:maxtau,z=VM[[i]][1:len,mintau:maxtau],xlab=\"\",ylab=\"\",legend.mar=2)\n#   #contour(x=1:len,y=mintau:maxtau,z=VM[[i]][1:len,mintau:maxtau],add = TRUE, nlevels = 3)\n#   par(mar=c(2.5,3.5,2.5,2.5))\n#   df[[i]]&lt;-denoise3(t=1:1000,donoho.noise[[i]],tau.list=50:3,lambda=lambda[i],iter=iter[i])\n#   plot(df[[i]],type='l',ylab=\"\")\n#   lines(donoho.noise[[i]],col=\"gray60\",lwd=0.7)\n#   lines(df[[i]],lwd=1.2)\n# }\n# par(mfrow=c(1,1))\n# dev.off() \n\n\n# #########################################################################################################################################\n# # Real Data Analysis\n# #########################################################################################################################################\n\n# library(wavelets)\n# data(ecg)\n# ecg&lt;-as.vector(ecg)\n# t=1:length(ecg)\n# ext&lt;-extract.hfreq(t,ecg,tau=132)\n# ext.df1&lt;-denoise3(t,ext,tau.list=35:2,tol=0.005,lambda=0.01)\n# ext.df2&lt;-denoise3(t,ext,tau.list=35:2,tol=0.005,lambda=0.02)\n# ext.df3&lt;-denoise3(t,ext,tau.list=35:2,tol=0.0005,lambda=0.035)\n# ext.df4&lt;-denoise3(t,ext,tau.list=15:2,tol=0.05,lambda=0.1)\n\n# pdf(paste(PATH, \"5]RealDataAnalysis_fig1.pdf\", sep=\"\"), width=10,height=10)\n# par(mar=c(2.5,2.5,2.5,2.5))\n# par(mfrow=c(4,1))\n# plot(t,ecg,type='l',xlab=\"\",ylab=\"\",ylim=c(-1.5,1.8),main=\"(a)\")\n# plot(t,ecg-ext,type='l',xlab=\"\",ylab=\"\",ylim=c(-1.5,1.8),lwd=1,main=\"(b)\")\n# plot(t,ext,type='l',xlab=\"\",ylab=\"\",ylim=c(-1.5,1.8),lwd=1,main=\"(c)\")\n# plot(t,ext.df4,type='l',xlab=\"\",ylab=\"\",ylim=c(-1.5,1.8),lwd=1,main=\"(d)\")\n# #plot(t,ext-ext.df3,type='l',xlab=\"\",ylab=\"\",ylim=c(-1.5,1.5),lwd=1,main=\"(e)\")\n# dev.off()"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-08-03-HST example 2 (3).html",
    "href": "연구/교수님이랑/HST/2021-08-03-HST example 2 (3).html",
    "title": "(연구&교수님) HST example 2 (3)",
    "section": "",
    "text": "import heavysnow as hs \nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt \nfrom sklearn.decomposition import PCA \nimport rpy2 \n%load_ext rpy2.ipython\n%run pybase\n\n\n### Example 2\nnp.random.seed(777)\nimport math\npi=math.pi\nn=59\nang=np.linspace(-pi,pi-2*pi/n,n)\nV=np.arange(n)+1\nr=1\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=vx*0\n\nf2=vx*0\nf2[vy&lt;0]=3+np.random.normal(size=sum(vy&lt;0),scale=0.1)\nf2[vy&gt;0]= -3+np.random.normal(size=sum(vy&gt;0),scale=0.1)\n\n\n# Edg setting\nΣ=l2distance(np.matrix([vx,vy]).T)\nθ=0.05\nW=np.exp(-Σ**2/(2*θ**2))\nE=W&gt;0\nplt.plot(W[0,:].T)\n# color\nimport matplotlib.cm as cm\ncol=list(np.array(cm.rainbow((ang+pi)/2/pi)))\n\n\n\n\n\n\n\n\n\n%R -i ang,vx,vy,n\n\n\n%%R\nlibrary(latex2exp)\nlibrary(gridExtra)\nlibrary(tidyverse)\n\nR[write to console]: ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\nR[write to console]: ✔ ggplot2 3.3.5     ✔ purrr   0.3.4\n✔ tibble  3.1.2     ✔ dplyr   1.0.7\n✔ tidyr   1.1.3     ✔ stringr 1.4.0\n✔ readr   1.4.0     ✔ forcats 0.5.1\n\nR[write to console]: ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::combine() masks gridExtra::combine()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n\n\n\n\n%%R -w 450 -h 300 -r 100\nex2df&lt;-data.frame(cbind(ang,vx,vy))\nnames(ex2df)&lt;-c(\"ang\",\"vx\",\"vy\")\nex2plt &lt;- ggplot(data=ex2df,aes(x=vx,y=vy))+\n            geom_point(col=\"gray60\",cex=1.5,alpha=0.7)+\n            geom_point(data=ex2df[1:n,],aes(x=vx,y=vy,col=ang),cex=1.5,alpha=0.7)+\n            xlab(\"\")+ylab(\"\")+scale_colour_gradientn(colours=rainbow(7))+labs(col=TeX(\"$\\\\phi$\"))+theme_classic()+\n            theme(legend.key.width = unit(2,\"mm\"))\nshow(ex2plt)\n\n\n\n\n\n\n\n\n\ngs1=hs.GraphSignal(V,W,f1)\ngs2=hs.GraphSignal(V,W,f2)\n\n\nplt.imshow(W)\n\n\n\n\n\n\n\n\n\nDiffusion distance\n\nP=W/W.round(3).sum(axis=0)[0]\nprint(P)\nplt.imshow(P)\n\n[[2.20167327e-01 2.14586355e-01 1.46335569e-01 ... 2.83862880e-02\n  1.46335569e-01 2.14586355e-01]\n [2.14586355e-01 2.20167327e-01 2.14586355e-01 ... 3.69898283e-04\n  2.83862880e-02 1.46335569e-01]\n [1.46335569e-01 2.14586355e-01 2.20167327e-01 ... 4.82347874e-08\n  3.69898283e-04 2.83862880e-02]\n ...\n [2.83862880e-02 3.69898283e-04 4.82347874e-08 ... 2.20167327e-01\n  2.14586355e-01 1.46335569e-01]\n [1.46335569e-01 2.83862880e-02 3.69898283e-04 ... 2.14586355e-01\n  2.20167327e-01 2.14586355e-01]\n [2.14586355e-01 1.46335569e-01 2.83862880e-02 ... 1.46335569e-01\n  2.14586355e-01 2.20167327e-01]]\n\n\n\n\n\n\n\n\n\n\nplt.imshow(P@P@P@P)\n\n\n\n\n\n\n\n\n\nP4=P@P@P@P\ndiffusion_distance=l2distance(P4)\nplt.imshow(diffusion_distance)\n\n\n\n\n\n\n\n\n\n\nSnow distance\n\nhs1=hs.HeavySnowTransform(gs1)\nhs2=hs.HeavySnowTransform(gs2)\n\n\nhs1.snow(tau=40000,b=0.1)\nhs2.snow(tau=40000,b=0.1)\n\nHST (tau= 40000, b=0.1)\n40000/40000\nHST completed and all history is recorded.\nHST (tau= 40000, b=0.1)\n40000/40000\nHST completed and all history is recorded.\n\n\n\nfrom sklearn.decomposition import PCA \np1=PCA(n_components=3)\np2=PCA(n_components=3)\np3=PCA(n_components=3)\np4=PCA(n_components=3)\np5=PCA(n_components=3)\np6=PCA(n_components=3)\n\n\np1.fit(hs1.eucliddistance)\np2.fit(diffusion_distance)\np3.fit(hs1.snowdistance)\np4.fit(hs2.eucliddistance)\np5.fit(diffusion_distance)\np6.fit(hs2.snowdistance)\n\nr1=p1.transform(hs1.eucliddistance)\nr2=p2.transform(diffusion_distance)\nr3=p3.transform(hs1.snowdistance)\nr4=p4.transform(hs2.eucliddistance)\nr5=p5.transform(diffusion_distance)\nr6=p6.transform(hs2.snowdistance)\n\n/home/cgb4/anaconda3/envs/py38r40/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:470: RuntimeWarning: invalid value encountered in true_divide\n  explained_variance_ratio_ = explained_variance_ / total_var\n\n\n\n# 1. \np=plt.figure(figsize=(12,4), dpi=70)  # Make figure object \n\n# 2. \nax1=p.add_subplot(2,4,1, projection='3d')\nax2=p.add_subplot(2,4,2, projection='3d')\nax3=p.add_subplot(2,4,3, projection='3d')\nax4=p.add_subplot(2,4,4, projection='3d')\nax5=p.add_subplot(2,4,5, projection='3d')\nax6=p.add_subplot(2,4,6, projection='3d')\nax7=p.add_subplot(2,4,7, projection='3d')\nax8=p.add_subplot(2,4,8, projection='3d')\n\n# 3. \nax1.grid(False)\nax1.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax1.scatter3D(vx, vy, f1, c=col,alpha=1)\nax1.set_xlim(-1,1)\nax1.set_ylim(-1,1)\nax1.set_zlim(-5,5)\n\nax2.grid(False)\nax2.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax2.scatter3D(r1[:,0],r1[:,1],r1[:,2],s=20,c=col,alpha=1)\n\nax3.grid(False)\nax3.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax3.scatter3D(r2[:,0],r2[:,1],r2[:,2],s=20,c=col,alpha=1)\n\nax4.grid(False)\nax4.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax4.scatter3D(r3[:,0],r3[:,1],r3[:,2],s=20,c=col,alpha=1)\n\n\nax5.grid(False)\nax5.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\ntop = -f2\nbottom = np.zeros_like(top)\nwidth=depth=0.05\nax5.bar3d(vx, vy, bottom, width, depth, top, shade=False,color=col)\nax5.set_xlim(-1,1)\nax5.set_ylim(-1,1)\nax5.set_zlim(-5,5)\n\nax6.grid(False)\nax6.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax6.scatter3D(r4[:,0],r4[:,1],r4[:,2],s=20,c=col,alpha=1)\n\nax7.grid(False)\nax7.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax7.scatter3D(r5[:,0],r5[:,1],r5[:,2],s=20,c=col,alpha=1)\n\nax8.grid(False)\nax8.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax8.scatter3D(r6[:,0],r6[:,1],r6[:,2],s=20,c=col,alpha=1)\np.tight_layout(h_pad=2.6) #rect : tuple (left, bottom, right, top), optional"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-08-09-HST example 2 (3).html",
    "href": "연구/교수님이랑/HST/2021-08-09-HST example 2 (3).html",
    "title": "(연구&교수님) HST example 2 (3)",
    "section": "",
    "text": "import heavysnow as hs \nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt \nfrom sklearn.decomposition import PCA \nimport rpy2 \n%load_ext rpy2.ipython\n%run pybase\n\n\n### Example 2\nnp.random.seed(777)\nimport math\npi=math.pi\nn=60\nang=np.linspace(-pi,pi-2*pi/n,n)\nV=np.arange(n)+1\nr=1\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=vx*0\n\nf2=vx*0\nf2[vy&lt;0]=3+np.random.normal(size=sum(vy&lt;0),scale=0.1)\nf2[vy&gt;=0]= -3+np.random.normal(size=sum(vy&gt;=0),scale=0.1)\n\n\n# Edg setting\nΣ=l2distance(np.matrix([vx,vy]).T)\nθ=0.1\nW=np.exp(-Σ**2/(2*θ**2))-np.eye(n,n)\nE=W&gt;0\nplt.plot(W[0,:].T)\n# color\nimport matplotlib.cm as cm\ncol=list(np.array(cm.rainbow((ang+pi)/2/pi)))\n\n\n\n\n\n\n\n\n\ngs1=hs.GraphSignal(V,W,f1)\ngs2=hs.GraphSignal(V,W,f2)\n\n\nDiffusion distance\n\nP=W/W.round(3).sum(axis=0)[0]\nprint(P)\nplt.imshow(P)\n\n[[0.         0.17910199 0.16376818 ... 0.11159368 0.16376818 0.17910199]\n [0.17910199 0.         0.17910199 ... 0.0404101  0.11159368 0.16376818]\n [0.16376818 0.17910199 0.         ... 0.00497348 0.0404101  0.11159368]\n ...\n [0.11159368 0.0404101  0.00497348 ... 0.         0.17910199 0.16376818]\n [0.16376818 0.11159368 0.0404101  ... 0.17910199 0.         0.17910199]\n [0.17910199 0.16376818 0.11159368 ... 0.16376818 0.17910199 0.        ]]\n\n\n\n\n\n\n\n\n\n\nplt.imshow(P@P@P@P)\n\n\n\n\n\n\n\n\n\nP4=P@P@P@P\ndiffusion_distance=l2distance(P4)\nplt.imshow(diffusion_distance)\n\n\n\n\n\n\n\n\n\n\nSnow distance\n\nhs1=hs.HeavySnowTransform(gs1)\nhs2=hs.HeavySnowTransform(gs2)\n\n\nhs1.snow(tau=100000,b=0.05)\nhs2.snow(tau=100000,b=0.05)\n\nHST (tau= 100000, b=0.05)\n100000/100000\nHST completed and all history is recorded.\nHST (tau= 100000, b=0.05)\n100000/100000\nHST completed and all history is recorded.\n\n\n\nfrom sklearn.decomposition import PCA \np1=PCA(n_components=3)\np2=PCA(n_components=3)\np3=PCA(n_components=3)\np4=PCA(n_components=3)\np5=PCA(n_components=3)\np6=PCA(n_components=3)\n\n\np1.fit(hs1.eucliddistance)\np2.fit(diffusion_distance)\np3.fit(hs1.snowdistance)\np4.fit(hs2.eucliddistance)\np5.fit(diffusion_distance)\np6.fit(hs2.snowdistance)\n\nr1=p1.transform(hs1.eucliddistance)\nr2=p2.transform(diffusion_distance)\nr3=p3.transform(hs1.snowdistance)\nr4=p4.transform(hs2.eucliddistance)\nr5=p5.transform(diffusion_distance)\nr6=p6.transform(hs2.snowdistance)\n\n/home/cgb4/anaconda3/envs/py38r40/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:470: RuntimeWarning: invalid value encountered in true_divide\n  explained_variance_ratio_ = explained_variance_ / total_var\n\n\n\n# 1. \np=plt.figure(figsize=(12,4), dpi=70)  # Make figure object \n\n# 2. \nax1=p.add_subplot(2,4,1, projection='3d')\nax2=p.add_subplot(2,4,2, projection='3d')\nax3=p.add_subplot(2,4,3, projection='3d')\nax4=p.add_subplot(2,4,4, projection='3d')\nax5=p.add_subplot(2,4,5, projection='3d')\nax6=p.add_subplot(2,4,6, projection='3d')\nax7=p.add_subplot(2,4,7, projection='3d')\nax8=p.add_subplot(2,4,8, projection='3d')\n\n# 3. \nax1.grid(False)\nax1.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax1.scatter3D(vx, vy, f1, c=col,alpha=1)\nax1.set_xlim(-1,1)\nax1.set_ylim(-1,1)\nax1.set_zlim(-5,5)\n\nax2.grid(False)\nax2.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax2.scatter3D(r1[:,0],r1[:,1],r1[:,2],s=20,c=col,alpha=1)\n\nax3.grid(False)\nax3.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax3.scatter3D(r2[:,0],r2[:,1],r2[:,2],s=20,c=col,alpha=1)\n\nax4.grid(False)\nax4.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax4.scatter3D(r3[:,0],r3[:,1],r3[:,2],s=20,c=col,alpha=1)\n\n\nax5.grid(False)\nax5.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\ntop = -f2\nbottom = np.zeros_like(top)\nwidth=depth=0.05\nax5.bar3d(vx, vy, bottom, width, depth, top, shade=False,color=col)\nax5.set_xlim(-1,1)\nax5.set_ylim(-1,1)\nax5.set_zlim(-5,5)\n\nax6.grid(False)\nax6.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax6.scatter3D(r4[:,0],r4[:,1],r4[:,2],s=20,c=col,alpha=1)\n\nax7.grid(False)\nax7.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax7.scatter3D(r5[:,0],r5[:,1],r5[:,2],s=20,c=col,alpha=1)\n\nax8.grid(False)\nax8.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax8.scatter3D(r6[:,0],r6[:,1],r6[:,2],s=20,c=col,alpha=1)\np.tight_layout(h_pad=2.6) #rect : tuple (left, bottom, right, top), optional"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-07-14-HST old exam (R).html",
    "href": "연구/교수님이랑/HST/2021-07-14-HST old exam (R).html",
    "title": "(연구&교수님) HST old exam (R)",
    "section": "",
    "text": "논문에서 Definition 6을 보면 Xi와 Xj 사이의 dissimilarity를 기댓값의 형태로 정의하게 되는데요. 정의에 의해 importance를 계산할 때도 기댓값을 구해야 가능하게 된다고 생각됩니다. 그런데 기댓값을 직접 계산하기 어려워 보이는 형태라서, 뒤에 simulated example이나 지하철 example에서 importance plot을 그릴 때에 importance를 어떻게 구하셨는지 궁금합니다.\n\n원래 목적은 아날래틱하게 평균을 계산하려 하였으나 그렇게 하지 못하고 sample mean으로 대체하였습니다. 즉 hst를 여러번 독립적으로 수행하여 \\(\\rho(\\{Y_{i,\\tau}\\}_{\\tau=0}^{T},\\{Y_{j,\\tau}\\}_{\\tau=0}^{T})\\) 를 구하고, 그것들의 sample mean으로 대체하였습니다.\n\n\n사실 대부분 \\(\\rho(\\{Y_{i,\\tau}\\}_{\\tau=0}^{T},\\{Y_{j,\\tau}\\}_{\\tau=0}^{T})\\)의 값이 비슷하게 나와서 dissimilarity의 정의에서 기대값을 제외하여도 상관없을 것입니다. (저는 나중에 제외했어요)\n\n\n\n\n4.3.1에서의 simulated example을 다루실 때 b = 0.02*sqrt(V{Xi})로 정의하셨는데, 이렇게 정하신 특별한 이유가 있을까요?\n\n없습니다.\n\n\n현재는 제가 임의로 정한 고정값을 사용중입니다. b=0.06 이런식으로요. b의 값은 너무 크게 설정하지만 않으면 결과에 크게 민감하지 않습니다.\n\n또한, definition5에서 tau가 1씩 증가하면서 Y값을 얻어낼 때, snowdrift를 더함으로써 얻게 되는데, 이 과정에서 epsilon을 generate할 때 사용되는 b가 위에서의 값으로 고정인지, 아니면 tau-1일 때 얻은 Y들을 대상으로 0.02*sqrt(V{Yi})로 다시 update 하는 것인지 궁금합니다.\n\n고정입니다.\n\n(제가 example 4.1을 재현해보고 있는데 figure 4.4의 두번째 row에서 tau=10인 경우의 특징이었던 three straight lines가 보이지 않아서 b의 설정을 혹시 잘못한 것인지 궁금하여 여쭤봅니다.)\n\n참고하시라고 제가 예전에 구현했었던 코드를 뒤져서 복원해봤습니다. (포스트 뒤쪽에 확인할 수 있습니다) figure 4.4에 해당하는 코드는 아니고 다른 예제입니다. 아마 TEST DATA만 바꿔서 돌리시면 3개의 straight line이 비슷하게 나올겁니다.\n\n\n\n\n4.3.2에서 지하철 데이터로 분석을 하실 때에 특정 시간, 특정 역에서 승차하는 사람 수를 Xi로 이해하였는데, 해당시간을 t, 해당 역을 서울대입구역이라고 한다면, (서울대입구역, t-1), (서울대입구역, t+1), (낙성대역, t), (봉천역, t) 이렇게 4 point들이 Xi와 linked 되어있다고 하고 HST를 진행하신 결과인가요?\n\n맞습니다.\n\n그 외에 Epsilon의 generation을 설정하기 위한 b값이나 pij 값이 지하철 예시의 경우에는 논문에서 찾기 어려워 어떻게 setting하고 분석을 진행하셨는지 궁금합니다.\n\n\\(p_{ij}\\)는 linked 된 노드들은 동일한 확률로 이동가능하다고 설정했습니다. 즉 4개의 point를 1/4의 확률로요.\n\n\n\\(b\\)는 자세히 기억나지 않는데 \\(b=2\\) 였던 것 같습니다. (즉 평균이 1이 되도록요) 제 생각에서는 \\(\\epsilon_k\\)를 굳이 유니폼에서 뽑지 않고 고정값 1로 사용하여도 거의 똑같은 결과가 나올것 같습니다. (실제로 요즘은 이렇게 하고 있어요)\n\n\n\n\n논문을 읽고 HST라는 multiscale method가 굉장히 재밌게 느껴져서 열심히 공부해보려고 합니다. 답변 주시면 정말 감사하겠습니다 교수님.\n\n재미있게 관심가져주셔서 감사합니다. 사실 제가 학위논문 작성할 당시에는 원시적인 아이디어 정도만 간단하게 서술하였습니다. 현재는 조금 다른 형태로 제가 나름대로 연구하고 있습니다. 최근에 작업중인 드래프트를 보내드릴 생각도 있어서 오희석교수님께 지금 작업중인 버전을 보여주는게 어떻겠냐고 여쭤봤었는데 교수님께서는 저와는 완전히 다른 학생만의 방식으로 논문을 다시 발전시키기를 원하시는것 같습니다. 그래서 일부러 원시형태의 논문을 읽어보라고 하셨던 것 같아요. \\(\\newline\\) 논문에 자세하게 서술하지는 못했지만 오희석 교수님께서는 눈이 쌓이는 모양이 재미있다고 생각하신 것 같습니다. 그 이유는 눈이 쌓인 정도에 따라서 우리가 보는 지형의 모양이 달라질 텐데 이것이 다양한 다중척도 방법과 관련이 있다고 여기신 것 같습니다. HST는 오희석 교수님의 직관을 제 나름대로 해석하여 구체화한 것이지 이러한 방식이 정답은 아닙니다. 학위논문 그대로의 방식보다 학생만의 방식으로 좀 더 색다르게 바꿔보는 것도 좋을것 같아요."
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-07-14-HST old exam (R).html#response",
    "href": "연구/교수님이랑/HST/2021-07-14-HST old exam (R).html#response",
    "title": "(연구&교수님) HST old exam (R)",
    "section": "",
    "text": "논문에서 Definition 6을 보면 Xi와 Xj 사이의 dissimilarity를 기댓값의 형태로 정의하게 되는데요. 정의에 의해 importance를 계산할 때도 기댓값을 구해야 가능하게 된다고 생각됩니다. 그런데 기댓값을 직접 계산하기 어려워 보이는 형태라서, 뒤에 simulated example이나 지하철 example에서 importance plot을 그릴 때에 importance를 어떻게 구하셨는지 궁금합니다.\n\n원래 목적은 아날래틱하게 평균을 계산하려 하였으나 그렇게 하지 못하고 sample mean으로 대체하였습니다. 즉 hst를 여러번 독립적으로 수행하여 \\(\\rho(\\{Y_{i,\\tau}\\}_{\\tau=0}^{T},\\{Y_{j,\\tau}\\}_{\\tau=0}^{T})\\) 를 구하고, 그것들의 sample mean으로 대체하였습니다.\n\n\n사실 대부분 \\(\\rho(\\{Y_{i,\\tau}\\}_{\\tau=0}^{T},\\{Y_{j,\\tau}\\}_{\\tau=0}^{T})\\)의 값이 비슷하게 나와서 dissimilarity의 정의에서 기대값을 제외하여도 상관없을 것입니다. (저는 나중에 제외했어요)\n\n\n\n\n4.3.1에서의 simulated example을 다루실 때 b = 0.02*sqrt(V{Xi})로 정의하셨는데, 이렇게 정하신 특별한 이유가 있을까요?\n\n없습니다.\n\n\n현재는 제가 임의로 정한 고정값을 사용중입니다. b=0.06 이런식으로요. b의 값은 너무 크게 설정하지만 않으면 결과에 크게 민감하지 않습니다.\n\n또한, definition5에서 tau가 1씩 증가하면서 Y값을 얻어낼 때, snowdrift를 더함으로써 얻게 되는데, 이 과정에서 epsilon을 generate할 때 사용되는 b가 위에서의 값으로 고정인지, 아니면 tau-1일 때 얻은 Y들을 대상으로 0.02*sqrt(V{Yi})로 다시 update 하는 것인지 궁금합니다.\n\n고정입니다.\n\n(제가 example 4.1을 재현해보고 있는데 figure 4.4의 두번째 row에서 tau=10인 경우의 특징이었던 three straight lines가 보이지 않아서 b의 설정을 혹시 잘못한 것인지 궁금하여 여쭤봅니다.)\n\n참고하시라고 제가 예전에 구현했었던 코드를 뒤져서 복원해봤습니다. (포스트 뒤쪽에 확인할 수 있습니다) figure 4.4에 해당하는 코드는 아니고 다른 예제입니다. 아마 TEST DATA만 바꿔서 돌리시면 3개의 straight line이 비슷하게 나올겁니다.\n\n\n\n\n4.3.2에서 지하철 데이터로 분석을 하실 때에 특정 시간, 특정 역에서 승차하는 사람 수를 Xi로 이해하였는데, 해당시간을 t, 해당 역을 서울대입구역이라고 한다면, (서울대입구역, t-1), (서울대입구역, t+1), (낙성대역, t), (봉천역, t) 이렇게 4 point들이 Xi와 linked 되어있다고 하고 HST를 진행하신 결과인가요?\n\n맞습니다.\n\n그 외에 Epsilon의 generation을 설정하기 위한 b값이나 pij 값이 지하철 예시의 경우에는 논문에서 찾기 어려워 어떻게 setting하고 분석을 진행하셨는지 궁금합니다.\n\n\\(p_{ij}\\)는 linked 된 노드들은 동일한 확률로 이동가능하다고 설정했습니다. 즉 4개의 point를 1/4의 확률로요.\n\n\n\\(b\\)는 자세히 기억나지 않는데 \\(b=2\\) 였던 것 같습니다. (즉 평균이 1이 되도록요) 제 생각에서는 \\(\\epsilon_k\\)를 굳이 유니폼에서 뽑지 않고 고정값 1로 사용하여도 거의 똑같은 결과가 나올것 같습니다. (실제로 요즘은 이렇게 하고 있어요)\n\n\n\n\n논문을 읽고 HST라는 multiscale method가 굉장히 재밌게 느껴져서 열심히 공부해보려고 합니다. 답변 주시면 정말 감사하겠습니다 교수님.\n\n재미있게 관심가져주셔서 감사합니다. 사실 제가 학위논문 작성할 당시에는 원시적인 아이디어 정도만 간단하게 서술하였습니다. 현재는 조금 다른 형태로 제가 나름대로 연구하고 있습니다. 최근에 작업중인 드래프트를 보내드릴 생각도 있어서 오희석교수님께 지금 작업중인 버전을 보여주는게 어떻겠냐고 여쭤봤었는데 교수님께서는 저와는 완전히 다른 학생만의 방식으로 논문을 다시 발전시키기를 원하시는것 같습니다. 그래서 일부러 원시형태의 논문을 읽어보라고 하셨던 것 같아요. \\(\\newline\\) 논문에 자세하게 서술하지는 못했지만 오희석 교수님께서는 눈이 쌓이는 모양이 재미있다고 생각하신 것 같습니다. 그 이유는 눈이 쌓인 정도에 따라서 우리가 보는 지형의 모양이 달라질 텐데 이것이 다양한 다중척도 방법과 관련이 있다고 여기신 것 같습니다. HST는 오희석 교수님의 직관을 제 나름대로 해석하여 구체화한 것이지 이러한 방식이 정답은 아닙니다. 학위논문 그대로의 방식보다 학생만의 방식으로 좀 더 색다르게 바꿔보는 것도 좋을것 같아요."
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-07-14-HST old exam (R).html#간단한-구현예제",
    "href": "연구/교수님이랑/HST/2021-07-14-HST old exam (R).html#간단한-구현예제",
    "title": "(연구&교수님) HST old exam (R)",
    "section": "간단한 구현예제",
    "text": "간단한 구현예제\n\n필요한 패키지 및 함수 정의\n\nlibrary(gridExtra)\nhst1d&lt;-function(f,tau,b=sd(f)*0.01,prob=c(1/3,1/3,1/3)) # prob=c(l,c,r)\n{\n  lprob&lt;-prob[1]\n  cprob&lt;-prob[2]\n  rprob&lt;-prob[3]\n  len&lt;-length(f)\n  hstresult&lt;-rep(0,len*tau); dim(hstresult)&lt;-c(len,tau)\n  hlen&lt;-round(len/2)\n  oldf&lt;-f\n  f&lt;-c(f[hlen:1],f,f[len:(len-hlen+1)])\n  \n  ls&lt;-landshape(f)\n  f_before&lt;-f\n  f_after&lt;-f*0\n  L&lt;-length(f)\n\n  for(i in 1:tau)\n  {\n    minindex&lt;-which(ls==\"minimum\")\n    maxindex&lt;-which(ls==\"maximum\")\n    incindex&lt;-which(ls==\"increasing\")\n    decindex&lt;-which(ls==\"decreasing\")\n    flatindex&lt;-which(ls==\"flat\")\n    epsilon&lt;-runif(1)*b\n    f_after[minindex]&lt;-f_before[minindex]+epsilon+epsilon*lprob+epsilon*rprob\n    f_after[maxindex]&lt;-f_before[maxindex]+epsilon*cprob\n    f_after[incindex]&lt;-f_before[incindex]+epsilon*(cprob+rprob)+epsilon*(lprob)\n    f_after[decindex]&lt;-f_before[decindex]+epsilon*(cprob+lprob)+epsilon*(rprob)\n    f_after[flatindex]&lt;-f_before[flatindex]+epsilon*cprob+epsilon*rprob*0.5+epsilon*lprob*0.5\n    ls&lt;-landshape(f_after)\n    f_before&lt;-f_after\n    hstresult[,i]&lt;-f_after[(hlen+1):(L-hlen)]\n  }\n  cbind(oldf,hstresult)\n}\n\nlandshape&lt;-function(f)\n{\n  len&lt;-length(f)\n  ls&lt;-f*0\n  ls[c(1,len)]&lt;-\"flat\"\n  for(i in 2:(len-1))\n  {\n    if((f[i]&gt;f[i-1])&(f[i]&lt;f[i+1])) ls[i]&lt;-\"increasing\"\n    else if((f[i]&lt;f[i-1])&(f[i]&gt;f[i+1])) ls[i]&lt;-\"decreasing\"\n    else if(mean(c(f[i-1],f[i+1]))&lt;f[i]) ls[i]&lt;-\"maximum\"\n    else if(mean(c(f[i-1],f[i+1]))&gt;f[i]) ls[i]&lt;-\"minimum\"\n    else ls[i]&lt;-\"flat\"\n  }\n  ls\n}\n    \ng_legend&lt;-function(a.gplot){\n    tmp &lt;- ggplot_gtable(ggplot_build(a.gplot))\n    leg &lt;- which(sapply(tmp$grobs, function(x) x$name) == \"guide-box\")\n    legend &lt;- tmp$grobs[[leg]]\n    return(legend)}\n      \n\n\n\nTEST DATA\n- 분석에 사용할 test data 입니다.\n\n#collapse-hide\nseq1&lt;-c(1,2,3,2);\nf1&lt;-c(rep(seq1,33),1);\nlocalstr&lt;-landshape(f1)\nlocalstr[1]&lt;-\"minimum\"\nlocalstr[133]&lt;-\"minimum\"\nf2&lt;-c(1:23,22:2,1:23,22:2,1:23,22:2,1)/2 # trend \nglobalstr&lt;-landshape(f2)\nglobalstr[1]&lt;-\"minimum\"\nglobalstr[133]&lt;-\"minimum\" \nf&lt;-f1+f2 \nf&lt;-f+rnorm(length(f),0,sd=0.1)\ndata_multiscalegrouping&lt;-data.frame(localstr=localstr,globalstr=globalstr,f=f)\nlibrary(ggplot2)\nggplot(data_multiscalegrouping, aes(x=1:length(f), y=f,label=1:133))+ geom_text(size=3)+geom_line()\n\n\n\n\n\n\n\n\n- 그림을 보면 아시겠지만 톱니모양으로 되어있습니다.\n\nGlobal view\n- 1,45,89,133 의 관측치가 minimum 23,67,111번 관측치가 maximum 입니다.\n- 2,3,…,22 는 우상향 트렌드에 있고 24,25,…,44 는 우하향 트렌드에 있습니다.\n- 정리하면 아래그림과 같음\n\n#collapse-hide\nggplot(data_multiscalegrouping, aes(x=1:length(f), y=f,label=1:133))+ geom_text(size=3) + geom_line()+ \n    geom_point(aes(x=1:length(f), y=f, colour=globalstr),size=10,alpha=0.2,shape=16)+\n    xlab(\"\")+ylab(\"\")+\n    theme_bw()+theme(panel.border=element_blank(),axis.line=element_line(colour=\"Black\"))+\n    theme(panel.grid.major=element_blank())+\n    labs(colour=\"Global Structure\")\n\n\n\n\n\n\n\n\n\n\nLocal view\n- 3,7, 과 같은 관측치도 maximum으로 분류할 수 있습니다.\n- 정리해보면 아래와 같음\n\n#collapse-hide\nggplot(data_multiscalegrouping, aes(x=1:length(f), y=f,label=1:133))+ geom_text(size=3)+geom_line()+ \n    geom_point(aes(x=1:length(f), y=f, colour=localstr),size=5,alpha=0.5,shape=16)+\n    xlab(\"\")+ylab(\"\")+\n    theme_bw()+theme(panel.border=element_blank(),axis.line=element_line(colour=\"Black\"))+\n    theme(panel.grid.major=element_blank())+\n    labs(colour=\"Local Structure\")\n\n\n\n\n\n\n\n\n\n\n\nHST 수행\n\nHST를 하는 목적\n- 특정자료는 좀더 미시적인 관점에서 보느냐, 아니면 거시적인 관점에서 보느냐에 따라서 해석이 달라짐\n- 예를들어 3,7,11 등과 같은 자료는 적은 연결 (극단적으로 본인자신과 좌우1개씩) 만을 고려하면 극대점으로 해석할 수 있으나 좀더 많은 연결을 고려하면 그렇지 않음\n- \\(\\tau\\)가 작을때는 local 한 관점에서의 structure가, \\(\\tau\\)가 클때는 global한 structure가 보였으면 좋겠음\n\n\nHST 수행\n\nhst1d_rslt&lt;-hst1d(f,b=sd(f)*0.05,tau=130,prob=c(1/3,1/3,1/3))\n\n\n\nHST \\(\\to\\) PCA\n- \\(\\tau=5,15,30,60,120\\)\n\n### hst result\nPC5&lt;-princomp(hst1d_rslt[,1:5])\nPC5plotdf&lt;-data.frame(PC1=PC5$score[,1],PC2=PC5$score[,2],\n                      localstr=localstr,globalstr=globalstr)\n  \nPC15&lt;-princomp(hst1d_rslt[,1:15])\nPC15plotdf&lt;-data.frame(PC1=PC15$score[,1],PC2=PC15$score[,2],\n                       localstr=localstr,globalstr=globalstr)\n  \nPC30&lt;-princomp(hst1d_rslt[,1:30])\nPC30plotdf&lt;-data.frame(PC1=PC30$score[,1],PC2=PC30$score[,2],\n                       localstr=localstr,globalstr=globalstr)        \n  \nPC60&lt;-princomp(hst1d_rslt[,1:60])\nPC60plotdf&lt;-data.frame(PC1=PC60$score[,1],PC2=PC60$score[,2],\n                       localstr=localstr,globalstr=globalstr)\n  \nPC90&lt;-princomp(hst1d_rslt[,1:90])\nPC90plotdf&lt;-data.frame(PC1=PC90$score[,1],PC2=PC90$score[,2],\n                       localstr=localstr,globalstr=globalstr)\n  \nPC120&lt;-princomp(hst1d_rslt[,1:120])\nPC120plotdf&lt;-data.frame(PC1=PC120$score[,1],PC2=PC120$score[,2],\n                        localstr=localstr,globalstr=globalstr)\n\n\n\n\n결과 시각화 및 해석\n\nglobal view\n\n#collapse-hide\nggplot(data_multiscalegrouping, aes(x=1:length(f), y=f,label=1:133))+ geom_text(size=3) + geom_line()+ \n    geom_point(aes(x=1:length(f), y=f, colour=globalstr),size=10,alpha=0.2,shape=16)+\n    xlab(\"\")+ylab(\"\")+\n    theme_bw()+theme(panel.border=element_blank(),axis.line=element_line(colour=\"Black\"))+\n    theme(panel.grid.major=element_blank())+\n    labs(colour=\"Global Structure\")\n\n\n\n\n\n\n\n\n\n#collapse-hide\nglobal5&lt;-ggplot(PC5plotdf, aes(x=PC1, y=PC2,label=1:133))+ geom_text(size=3)+\n    geom_point(aes(x=PC1, y=PC2, colour=globalstr),size=10,alpha=0.2,shape=16)+\n    xlab(\"\")+ylab(\"\")+\n    theme_bw()+theme(panel.border=element_blank(),axis.line=element_line(colour=\"Black\"))+\n    theme(panel.grid.major=element_blank())+\n    labs(colour=\"Global Structure\")+\n    ggtitle(expression(paste(tau,\"=\",5)))+\n    theme(plot.title=element_text(size=rel(1.5),lineheight=0.9,face=\"bold.italic\",hjust=0.5))+\n    theme(plot.margin = unit(c(3,3,3,3), \"mm\"))\n  \nglobal15&lt;-ggplot(PC15plotdf, aes(x=PC1, y=PC2,label=1:133))+ geom_text(size=3)+\n    geom_point(aes(x=PC1, y=PC2, colour=globalstr),size=10,alpha=0.2,shape=16)+\n    xlab(\"\")+ylab(\"\")+\n    theme_bw()+theme(panel.border=element_blank(),axis.line=element_line(colour=\"Black\"))+\n    theme(panel.grid.major=element_blank())+\n    labs(colour=\"Global Structure\")+\n    ggtitle(expression(paste(tau,\"=\",15)))+\n    theme(plot.title=element_text(size=rel(1.5),lineheight=0.9,face=\"bold.italic\",hjust=0.5))+\n    theme(plot.margin = unit(c(3,3,3,3), \"mm\"))\n  \nglobal30&lt;-ggplot(PC30plotdf, aes(x=PC1, y=PC2,label=1:133))+ geom_text(size=3)+\n    geom_point(aes(x=PC1, y=PC2, colour=globalstr),size=10,alpha=0.2,shape=16)+\n    xlab(\"\")+ylab(\"\")+\n    theme_bw()+theme(panel.border=element_blank(),axis.line=element_line(colour=\"Black\"))+\n    theme(panel.grid.major=element_blank())+\n    labs(colour=\"Global Structure\")+\n    ggtitle(expression(paste(tau,\"=\",30)))+\n    theme(plot.title=element_text(size=rel(1.5),lineheight=0.9,face=\"bold.italic\",hjust=0.5))+\n    theme(plot.margin = unit(c(3,3,3,3), \"mm\"))\n  \nglobal60&lt;-ggplot(PC60plotdf, aes(x=PC1, y=PC2,label=1:133))+ geom_text(size=3)+\n    geom_point(aes(x=PC1, y=PC2, colour=globalstr),size=10,alpha=0.2,shape=16)+\n    xlab(\"\")+ylab(\"\")+\n    theme_bw()+theme(panel.border=element_blank(),axis.line=element_line(colour=\"Black\"))+\n    theme(panel.grid.major=element_blank())+\n    labs(colour=\"Global Structure\")+\n    ggtitle(expression(paste(tau,\"=\",60)))+\n    theme(plot.title=element_text(size=rel(1.5),lineheight=0.9,face=\"bold.italic\",hjust=0.5))+\n    theme(plot.margin = unit(c(3,3,3,3), \"mm\"))\n  \n  \nglobal90&lt;-ggplot(PC90plotdf, aes(x=PC1, y=PC2,label=1:133))+ geom_text(size=3)+\n    geom_point(aes(x=PC1, y=PC2, colour=globalstr),size=10,alpha=0.2,shape=16)+\n    xlab(\"\")+ylab(\"\")+\n    theme_bw()+theme(panel.border=element_blank(),axis.line=element_line(colour=\"Black\"))+\n    theme(panel.grid.major=element_blank())+\n    labs(colour=\"Global Structure\")+\n    ggtitle(expression(paste(tau,\"=\",90)))+\n    theme(plot.title=element_text(size=rel(1.5),lineheight=0.9,face=\"bold.italic\",hjust=0.5))+\n    theme(plot.margin = unit(c(3,3,3,3), \"mm\"))\n  \nglobal120&lt;-ggplot(PC120plotdf, aes(x=PC1, y=PC2,label=1:133))+ geom_text(size=3)+\n    geom_point(aes(x=PC1, y=PC2, colour=globalstr),size=10,alpha=0.2,shape=16)+\n    xlab(\"\")+ylab(\"\")+\n    theme_bw()+theme(panel.border=element_blank(),axis.line=element_line(colour=\"Black\"))+\n    theme(panel.grid.major=element_blank())+\n    labs(colour=\"Global Structure\")+\n    ggtitle(expression(paste(tau,\"=\",120)))+\n    theme(plot.title=element_text(size=rel(1.5),lineheight=0.9,face=\"bold.italic\",hjust=0.5))+\n    theme(plot.margin = unit(c(3,3,3,3), \"mm\"))\ngloballegend&lt;-g_legend(global5+ theme(legend.position=\"bottom\"))\nglobal&lt;-grid.arrange(arrangeGrob(global5 + theme(legend.position=\"none\"),\n                            global15 + theme(legend.position=\"none\"),\n                            global30 + theme(legend.position=\"none\"),\n                            global60 + theme(legend.position=\"none\"),\n                            global90 + theme(legend.position=\"none\"),\n                            global120 + theme(legend.position=\"none\"),\n                            nrow=2,ncol=3),\n                            globallegend, nrow=2,heights=c(10, 1))\n\n\n\n\n\n\n\n\n- \\(\\tau=120\\)에서의 결과가 global view에서의 자료구조를 잘 파악함. - 1,45,89,133이 거시적인 관점에서 보면 valley 인데 이러한 점들이 잘 구분되어 있음 (보라색) - 23,67,111과 같은 peaks 역시 잘 드러남 (파란색)\n\n\nlocal view\n- 동일한 자료를 local view로 본다면 작은 \\(\\tau\\)가 해석에 용이함\n\n#collapse-hide\nlibrary(gridExtra)\nlocal5&lt;-ggplot(PC5plotdf, aes(x=PC1, y=PC2,label=1:133))+ geom_text(size=3)+\n    geom_point(aes(x=PC1, y=PC2, colour=localstr),size=5,alpha=0.5,shape=16)+\n    xlab(\"\")+ylab(\"\")+\n    theme_bw()+theme(panel.border=element_blank(),axis.line=element_line(colour=\"Black\"))+\n    theme(panel.grid.major=element_blank())+\n    labs(colour=\"Local Structure\")+\n    ggtitle(expression(paste(tau,\"=\",5)))+\n    theme(plot.title=element_text(size=rel(1.5),lineheight=0.9,face=\"bold.italic\",hjust=0.5))+\n    theme(plot.margin = unit(c(3,3,3,3), \"mm\"))\n  \nlocal15&lt;-ggplot(PC15plotdf, aes(x=PC1, y=PC2,label=1:133))+ geom_text(size=3)+\n    geom_point(aes(x=PC1, y=PC2, colour=localstr),size=5,alpha=0.5,shape=16)+\n    xlab(\"\")+ylab(\"\")+\n    theme_bw()+theme(panel.border=element_blank(),axis.line=element_line(colour=\"Black\"))+\n    theme(panel.grid.major=element_blank())+\n    labs(colour=\"Local Structure\")+\n    ggtitle(expression(paste(tau,\"=\",15)))+\n    theme(plot.title=element_text(size=rel(1.5),lineheight=0.9,face=\"bold.italic\",hjust=0.5))+\n    theme(plot.margin = unit(c(3,3,3,3), \"mm\"))\n  \nlocal30&lt;-ggplot(PC30plotdf, aes(x=PC1, y=PC2,label=1:133))+ geom_text(size=3)+\n    geom_point(aes(x=PC1, y=PC2, colour=localstr),size=5,alpha=0.5,shape=16)+\n    xlab(\"\")+ylab(\"\")+\n    theme_bw()+theme(panel.border=element_blank(),axis.line=element_line(colour=\"Black\"))+\n    theme(panel.grid.major=element_blank())+\n    labs(colour=\"Local Structure\")+\n    ggtitle(expression(paste(tau,\"=\",30)))+\n    theme(plot.title=element_text(size=rel(1.5),lineheight=0.9,face=\"bold.italic\",hjust=0.5))+\n    theme(plot.margin = unit(c(3,3,3,3), \"mm\"))\n  \n\nlocal60&lt;-ggplot(PC60plotdf, aes(x=PC1, y=PC2,label=1:133))+ geom_text(size=3)+\n    geom_point(aes(x=PC1, y=PC2, colour=localstr),size=5,alpha=0.5,shape=16)+\n    xlab(\"\")+ylab(\"\")+\n    theme_bw()+theme(panel.border=element_blank(),axis.line=element_line(colour=\"Black\"))+\n    theme(panel.grid.major=element_blank())+\n    labs(colour=\"Local Structure\")+\n    ggtitle(expression(paste(tau,\"=\",60)))+\n    theme(plot.title=element_text(size=rel(1.5),lineheight=0.9,face=\"bold.italic\",hjust=0.5))+\n    theme(plot.margin = unit(c(3,3,3,3), \"mm\"))\n\n  \nlocal90&lt;-ggplot(PC90plotdf, aes(x=PC1, y=PC2,label=1:133))+ geom_text(size=3)+\n    geom_point(aes(x=PC1, y=PC2, colour=localstr),size=5,alpha=0.5,shape=16)+\n    xlab(\"\")+ylab(\"\")+\n    theme_bw()+theme(panel.border=element_blank(),axis.line=element_line(colour=\"Black\"))+\n    theme(panel.grid.major=element_blank())+\n    labs(colour=\"Local Structure\")+\n    ggtitle(expression(paste(tau,\"=\",90)))+\n    theme(plot.title=element_text(size=rel(1.5),lineheight=0.9,face=\"bold.italic\",hjust=0.5))+\n    theme(plot.margin = unit(c(3,3,3,3), \"mm\"))\n\nlocal120&lt;-ggplot(PC120plotdf, aes(x=PC1, y=PC2,label=1:133))+ geom_text(size=3)+\n    geom_point(aes(x=PC1, y=PC2, colour=localstr),size=5,alpha=0.5,shape=16)+\n    xlab(\"\")+ylab(\"\")+\n    theme_bw()+theme(panel.border=element_blank(),axis.line=element_line(colour=\"Black\"))+\n    theme(panel.grid.major=element_blank())+\n    labs(colour=\"Local Structure\")+\n    ggtitle(expression(paste(tau,\"=\",120)))+\n    theme(plot.title=element_text(size=rel(1.5),lineheight=0.9,face=\"bold.italic\",hjust=0.5))+\n    theme(plot.margin = unit(c(3,3,3,3), \"mm\"))\n\nlocallegend&lt;-g_legend(local5+ theme(legend.position=\"bottom\"))\n \nlocal&lt;-grid.arrange(arrangeGrob(local5 + theme(legend.position=\"none\"),\n                           local15 + theme(legend.position=\"none\"),\n                           local30 + theme(legend.position=\"none\"),\n                           local60 + theme(legend.position=\"none\"),\n                           local90 + theme(legend.position=\"none\"),\n                           local120 + theme(legend.position=\"none\"),\n                           nrow=2,ncol=3),\n                           locallegend, nrow=2,heights=c(10, 1))\n\n\n\n\n\n\n\n\n- \\(\\tau=5\\) 일때가 재미있음. pc2에 의해서 점들은 3개의 그룹으로 나누어짐. - minimum (보라색) - maximum (파란색) - incresing \\(\\cup\\) decreasing (초록색, 빨간색)\n- \\(\\tau\\)가 커질수록 이러한 구분은 무의미함\n\n\n\n결론\n- 작은 \\(\\tau\\)는 자료를 local view로 보았을 경우 특징을 잡아낸다. 반면에 큰 \\(\\tau\\)는 자료를 global view로 보았을 경우 특징을 잡아냄\n- 이 예제를 파이썬으로 구현한것은 아래에 있음.\nhttps://miruetoto.github.io/yechan/%EB%85%BC%EB%AC%B8%EC%97%B0%EA%B5%AC/2021/07/14/(%EC%97%B0%EA%B5%AC)-HST-old-example-(Python)-%EB%85%BC%EB%AC%B8%EC%97%B0%EA%B5%AC.html\n\nHST의 정의가 R에서 구현한 방식과 아주 조금 다르긴한데 (요즘 제가 정의를 자주 바꾸고 있어서요) 거의 비슷한 효과가 나오도록 제가 파라메터를 조정했습니다.\n바뀐 정의의 특성상 낮은 \\(\\tau\\)에서 관찰가능한 선명한 3개의 직선은 나오지 않지만 어느정도 비슷한 결론을 줍니다."
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-07-27-HST example 2.html",
    "href": "연구/교수님이랑/HST/2021-07-27-HST example 2.html",
    "title": "(연구&교수님) HST example 2",
    "section": "",
    "text": "import heavysnow as hs \nimport numpy as np\nimport pandas as pd \nimport pybase as pb\nimport matplotlib.pyplot as plt \nfrom sklearn.decomposition import PCA \nimport rpy2 \n%load_ext rpy2.ipython\n\n\n### Example 2\nnp.random.seed(777)\nimport math\npi=math.pi\nn=59\nang=np.linspace(-pi,pi-2*pi/n,n)\nV=np.arange(n)+1\nr=1\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=vx*0\n\nf2=vx*0\nf2[vy&lt;0]=3+np.random.normal(size=sum(vy&lt;0),scale=0.1)\nf2[vy&gt;0]= -3+np.random.normal(size=sum(vy&gt;0),scale=0.1)\n\n\n# Edg setting\nΣ=pb.l2distance(np.matrix([vx,vy]).T)\nθ=0.05\nW=np.exp(-Σ**2/(2*θ**2))\nE=W&gt;0\nplt.plot(W[0,:].T)\n# color\nimport matplotlib.cm as cm\ncol=list(np.array(cm.rainbow((ang+pi)/2/pi)))\n\n\n\n\n\n\n\n\n\n%R -i ang\n%R -i vx\n%R -i vy\n%R -i n\n\n\n%%R\nlibrary(latex2exp)\nlibrary(gridExtra)\nlibrary(tidyverse)\n\nR[write to console]: ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\nR[write to console]: ✔ ggplot2 3.3.5     ✔ purrr   0.3.4\n✔ tibble  3.1.2     ✔ dplyr   1.0.7\n✔ tidyr   1.1.3     ✔ stringr 1.4.0\n✔ readr   1.4.0     ✔ forcats 0.5.1\n\nR[write to console]: ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::combine() masks gridExtra::combine()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n\n\n\n\n%%R -w 450 -h 300 -r 100\nex2df&lt;-data.frame(cbind(ang,vx,vy))\nnames(ex2df)&lt;-c(\"ang\",\"vx\",\"vy\")\nex2plt &lt;- ggplot(data=ex2df,aes(x=vx,y=vy))+\n            geom_point(col=\"gray60\",cex=1.5,alpha=0.7)+\n            geom_point(data=ex2df[1:n,],aes(x=vx,y=vy,col=ang),cex=1.5,alpha=0.7)+\n            xlab(\"\")+ylab(\"\")+scale_colour_gradientn(colours=rainbow(7))+labs(col=TeX(\"$\\\\phi$\"))+theme_classic()+\n            theme(legend.key.width = unit(2,\"mm\"))\nshow(ex2plt)\n\n\n\n\n\n\n\n\n\ngs1=hs.GraphSignal(V,W,f1)\ngs2=hs.GraphSignal(V,W,f2)\n\n\nhs1=hs.HeavySnowTransform(gs1)\nhs2=hs.HeavySnowTransform(gs2)\n\n\nhs1.snow(tau=40000,b=0.3)\nhs2.snow(tau=40000,b=0.3)\n\nHST (tau= 40000, b=0.3)\n40000/40000\nHST completed and all history is recorded.\nHST (tau= 40000, b=0.3)\n40000/40000\nHST completed and all history is recorded.\n\n\n\nfrom sklearn.decomposition import PCA \np1=PCA(n_components=3)\np2=PCA(n_components=3)\n\np1.fit(hs1.snowdistance)\np2.fit(hs2.snowdistance)\n\nr1=p1.transform(hs1.snowdistance)\nr2=p2.transform(hs2.snowdistance)\n\n\n# 1. \np=plt.figure(figsize=(12,4), dpi=70)  # Make figure object \n\n# 2. \nax1=p.add_subplot(2,4,1, projection='3d')\nax2=p.add_subplot(2,4,2, projection='3d')\nax3=p.add_subplot(2,4,3, projection='3d')\nax4=p.add_subplot(2,4,4, projection='3d')\nax5=p.add_subplot(2,4,5, projection='3d')\nax6=p.add_subplot(2,4,6, projection='3d')\nax7=p.add_subplot(2,4,7, projection='3d')\nax8=p.add_subplot(2,4,8, projection='3d')\n\n# 3. \nax1.grid(False)\nax1.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax1.scatter3D(vx, vy, f1, c=col,alpha=1)\nax1.set_xlim(-1,1)\nax1.set_ylim(-1,1)\nax1.set_zlim(-5,5)\n\nax2.grid(False)\nax2.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax2.scatter3D(r1[:,0],r1[:,1],r1[:,2],s=50,c=col,alpha=1)\n\nax3.grid(False)\nax3.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax3.scatter3D(r1[:,0],r1[:,1],r1[:,2],s=50,c=col,alpha=1)\n\nax4.grid(False)\nax4.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax4.scatter3D(r1[:,0],r1[:,1],r1[:,2],s=50,c=col,alpha=1)\n\n\nax5.grid(False)\nax5.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\ntop = -f2\nbottom = np.zeros_like(top)\nwidth=depth=0.05\nax5.bar3d(vx, vy, bottom, width, depth, top, shade=False,color=col)\nax5.set_xlim(-1,1)\nax5.set_ylim(-1,1)\nax5.set_zlim(-5,5)\n\nax6.grid(False)\nax6.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax6.scatter3D(r2[:,0],r2[:,1],r2[:,2],s=50,c=col,alpha=1)\n\nax7.grid(False)\nax7.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax7.scatter3D(r2[:,0],r2[:,1],r2[:,2],s=50,c=col,alpha=1)\n\nax8.grid(False)\nax8.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax8.scatter3D(r2[:,0],r2[:,1],r2[:,2],s=50,c=col,alpha=1)\np.tight_layout(h_pad=2.6) #rect : tuple (left, bottom, right, top), optional"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-08-02-HST example 1 (7).html",
    "href": "연구/교수님이랑/HST/2021-08-02-HST example 1 (7).html",
    "title": "(연구&교수님) HST example 1 (7)",
    "section": "",
    "text": "Import\n\nimport heavysnow as hs\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport rpy2 \n%load_ext rpy2.ipython\n%run pybase\n\n\n\nData\n\nf=np.array([-1,-1,-1,1,-1,-1,-1,1,1,1,-1,1,1,1])*1.0\nn=len(f)\nV=list(range(n))\nW=np.zeros([n,n])\nfor i in range(n):\n    for j in range(n):\n        if abs(i-j)==1: W[i,j]=1\nW[0,0]=1\nW[n-1,n-1]=1\n\n\ngs=hs.GraphSignal(V,W,f)\n\n\ngs.initdist=np.array([1/n]*n)\n\n\n\nHST\n\nhst=hs.HeavySnowTransform(gs)\nhst.snow(tau=80000,b=0.03)\n\nHST (tau= 80000, b=0.03)\n80000/80000\nHST completed and all history is recorded.\n\n\n\nplt.imshow(hst.snowweight)\n\n\n\n\n\n\n\n\n\n\n시각화를 위해서 R로 자료를 옮김\n\nmaxtau=hst.tau\nW_Graph=hst.graphweight\nW_Euclid=hst.euclidweight\nW_HST=hst.snowweight\nV=np.array(hst.V)\nf=hst.f\nn=hst.n\n%R -i maxtau,W_Graph,W_Euclid,W_HST,V,f,n\n\n\n\nR을 활용한 시각화 (1): 원래자료\n\n%%R -w 2000 -h 800 -r 100\nlibrary(tidyverse)\nlibrary(latex2exp)\nlibrary(gridExtra)\nsource('rbase.R')\nVtext=str_c('node ',V+1)\nfig0&lt;-ggplot(data=tibble(V=V,f=f,Vtext=Vtext),aes(x=V,y=f,label=Vtext))+\ngeom_col(aes(fill=(f&gt;0)),width=0.1)+geom_hline(aes(yintercept=0),col=\"gray60\",lty=2)+\ngeom_text(fontface = 4,size=8)+\nxlab(\"\")+ylab(\"\")+guides(fill=FALSE)+theme(plot.title=element_text(face=\"bold.italic\"))+theme_bw()+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 15, color = \"black\", face = \"bold.italic\"))+\nylim(-1.2,1.2)+\ntheme(plot.title=element_text(face=\"bold.italic\"))\n#ggsave(plot=p0,\"./fig/2021-0217_fig0.pdf\",width=20,height=6)\nfig0\n\nR[write to console]: ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\nR[write to console]: ✔ ggplot2 3.3.5     ✔ purrr   0.3.4\n✔ tibble  3.1.3     ✔ dplyr   1.0.7\n✔ tidyr   1.1.3     ✔ stringr 1.4.0\n✔ readr   2.0.1     ✔ forcats 0.5.1\n\nR[write to console]: ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nR[write to console]: \nAttaching package: ‘gridExtra’\n\n\nR[write to console]: The following object is masked from ‘package:dplyr’:\n\n    combine\n\n\nR[write to console]: \nAttaching package: ‘lubridate’\n\n\nR[write to console]: The following objects are masked from ‘package:base’:\n\n    date, intersect, setdiff, union\n\n\n\n\n\n\n\n\n\n\n\n\n\nR을 활용한 시각화 (2): Weight matrix 와 Eigen plot\n- ggplot에서 geom_tile을 사용하기 위해서 매트릭스 형태인 W_Graph, W_Euclid, W_HST를 길게 펼친다. 결과를 각각 W_Graph_long, W_Euclid_long, W_HST_long에 저장한다.\n\n%%R\ngrid&lt;-expand.grid(x=1:n,y=1:n)\nW_Graph_long&lt;-as_tibble(cbind(grid,as.vector(W_Graph)));names(W_Graph_long)&lt;-c(\"x\",\"y\",\"W\")\nW_Euclid_long&lt;-as_tibble(cbind(grid,as.vector(W_Euclid)));names(W_Euclid_long)&lt;-c(\"x\",\"y\",\"W\")\nW_HST_long&lt;-as_tibble(cbind(grid,as.vector(W_HST)));names(W_HST_long)&lt;-c(\"x\",\"y\",\"W\")\n\n- 그래프퓨리에 변환: \\((\\bf{f},\\bf{W})\\)에 그래프 퓨리에 변환을 수행함.\n\n%%R\nsource('heavysnow.R')\ngfftrslt_Euclid&lt;-gfft(f,W_Euclid)\ngfftrslt_Graph&lt;-gfft(f,W_Graph)\ngfftrslt_HST&lt;-gfft(f,W_HST)\n\nR[write to console]: \nAttaching package: ‘kohonen’\n\n\nR[write to console]: The following object is masked from ‘package:purrr’:\n\n    map\n\n\nR[write to console]: \nAttaching package: ‘igraph’\n\n\nR[write to console]: The following objects are masked from ‘package:lubridate’:\n\n    %--%, union\n\n\nR[write to console]: The following objects are masked from ‘package:dplyr’:\n\n    as_data_frame, groups, union\n\n\nR[write to console]: The following objects are masked from ‘package:purrr’:\n\n    compose, simplify\n\n\nR[write to console]: The following object is masked from ‘package:tidyr’:\n\n    crossing\n\n\nR[write to console]: The following object is masked from ‘package:tibble’:\n\n    as_data_frame\n\n\nR[write to console]: The following objects are masked from ‘package:stats’:\n\n    decompose, spectrum\n\n\nR[write to console]: The following object is masked from ‘package:base’:\n\n    union\n\n\n\n\n- 그래프 퓨리에 변환의 결과 고유치, 고유벡터, \\(\\bf{\\bar{f}}\\)가 반환됨.\n\n%%R\nhead(gfftrslt_HST)\n\n$λ\n [1] 1.000000e+00 4.105614e-07 2.709080e-07 5.104859e-08 3.770892e-08\n [6] 3.316426e-09 5.516926e-13 2.800406e-13 1.826920e-15 3.896899e-17\n[11] 4.026254e-22 3.136459e-28 9.621581e-31 8.205729e-41\n\n$Ψ\n               [,1]          [,2]          [,3]          [,4]          [,5]\n [1,] -4.872398e-21 -2.277947e-23  1.217956e-17 -7.070951e-01  1.591941e-20\n [2,] -4.872291e-21 -2.277897e-23  1.217945e-17  7.071184e-01  1.591858e-20\n [3,] -2.220446e-16 -1.038104e-18  1.084613e-13 -1.702405e-10 -4.878917e-19\n [4,]  3.239842e-22 -2.071665e-16  1.500257e-17 -2.539346e-33 -3.705267e-16\n [5,] -1.355253e-20 -7.005055e-17 -1.603870e-12  1.429643e-32 -7.891712e-02\n [6,]  1.626303e-19 -2.278466e-17  1.341385e-10 -1.428760e-33  8.945444e-01\n [7,]  9.583941e-16 -3.376154e-17 -2.317701e-09  2.397739e-34 -4.399573e-01\n [8,]  4.648033e-04 -5.301741e-21  7.887639e-01  2.435898e-33  2.480182e-09\n [9,] -9.999999e-01 -4.451367e-24  1.931258e-04 -5.240705e-30  2.573975e-12\n[10,]  2.822440e-04 -7.083369e-21 -6.146962e-01  1.479158e-33  5.036776e-09\n[11,]  5.926393e-19  1.522706e-22  9.765278e-12  2.828446e-48  1.117961e-16\n[12,]  1.184712e-33  1.120097e-16  1.187607e-27  6.208720e-63 -7.004156e-35\n[13,]  1.270666e-50 -7.071068e-01  1.500706e-30 -3.962613e-74 -6.108070e-35\n[14,] -2.604954e-57  7.071068e-01 -1.500706e-30  3.949298e-74  6.108070e-35\n               [,6]          [,7]          [,8]          [,9]         [,10]\n [1,]  1.228684e-17 -7.485555e-13  7.071184e-01 -2.304566e-15 -5.485654e-12\n [2,]  1.228653e-17 -7.485391e-13  7.070951e-01 -2.304516e-15 -5.485534e-12\n [3,] -2.114733e-18 -3.411312e-08 -3.103222e-05 -1.050235e-10 -2.499919e-07\n [4,]  1.043364e-15 -8.608235e-13 -9.036792e-24 -2.134150e-08 -5.709179e-08\n [5,]  4.964222e-01 -3.077535e-04 -1.319654e-17 -7.382555e-09  8.644865e-01\n [6,] -3.474563e-01 -1.000479e-04  7.451451e-18 -2.401260e-09  2.811841e-01\n [7,] -7.955119e-01 -1.482069e-04  2.231338e-17 -3.558126e-09  4.166514e-01\n [8,]  6.807945e-08  6.146960e-01 -4.815712e-17 -1.868431e-12  2.187902e-04\n [9,]  5.712388e-11  5.083367e-04 -1.191193e-20 -1.545137e-15  1.809330e-07\n[10,]  9.028034e-08  7.887639e-01  3.752961e-17 -2.397514e-12  2.807450e-04\n[11,]  2.198639e-15 -6.153941e-06 -5.859021e-28  1.176328e-15 -3.111288e-05\n[12,] -1.427874e-32 -7.499323e-22 -7.127268e-44 -2.517192e-08 -2.149603e-16\n[13,] -2.918848e-30 -3.747748e-19  1.184696e-39  7.071068e-01  6.038560e-09\n[14,]  2.918848e-30 -3.329404e-19 -1.184696e-39  7.071068e-01  6.038561e-09\n             [,11]         [,12]         [,13]         [,14]\n [1,] 2.194333e-05 -4.280149e-09  2.446234e-09  4.755196e-18\n [2,] 2.194285e-05 -4.280055e-09  2.446181e-09  4.755092e-18\n [3,] 1.000000e+00 -1.950547e-04  1.114796e-04  2.167035e-13\n [4,] 7.012320e-05 -2.004276e-01 -9.797085e-01 -8.634163e-09\n [5,] 2.218480e-07  2.633910e-05 -5.438784e-06 -5.731230e-14\n [6,] 7.215858e-08  8.567094e-06 -1.769026e-06 -1.864148e-14\n [7,] 1.069228e-07  1.269450e-05 -2.621298e-06 -2.762247e-14\n [8,] 2.183267e-08  3.712699e-06 -7.595512e-07 -8.015646e-15\n [9,] 1.805511e-11  3.070304e-09 -6.281288e-10 -6.628728e-18\n[10,] 2.801536e-08  4.764066e-06 -9.746419e-07 -1.028553e-14\n[11,] 2.134403e-04  9.797085e-01 -2.004276e-01 -2.115140e-09\n[12,] 8.402050e-13  3.416960e-10 -8.882894e-09  1.000000e+00\n[13,] 7.532262e-11 -3.024428e-09 -1.478454e-08  1.779923e-08\n[14,] 7.532262e-11 -3.024428e-09 -1.478454e-08  1.779923e-08\n\n$fbar\n [1] -9.992528e-01 -1.887886e-08  1.742609e-01 -2.327415e-05 -3.756699e-01\n [6]  6.465461e-01  1.404530e+00 -1.414183e+00  1.414214e+00 -1.561791e+00\n[11] -1.000188e+00 -1.179980e+00 -7.793844e-01  1.000000e+00\n\n\n\n- 시각화코드\n\n%%R -w 1000 -h 800 -r 100\nlibrary(gridExtra)\n\nfig1_1&lt;-ggplot()+geom_tile(data=W_Euclid_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"red\",high=\"blue\",mid=\"purple\",midpoint=0.25,breaks=c(0,0.5,0.99))+\nlabs(fill=TeX('$W$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(a) Euclid\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_2&lt;-ggplot()+geom_tile(data=W_Graph_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"red\",high=\"blue\",mid=\"purple\",midpoint=0.5,breaks=c(0,0.5,0.99))+\nlabs(fill=TeX('$\\\\hat{W}$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(b) Graph\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_3&lt;-ggplot()+geom_tile(data=W_HST_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"red\",high=\"blue\",mid=\"purple\",midpoint=0.5,breaks=c(0,0.5,0.99))+\nlabs(fill=TeX('$\\\\hat{W}(\\\\tau)$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(c) HST\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_4&lt;-eigenplot(gfftrslt_Euclid)+ylim(0,2)+theme_light()\nfig1_5&lt;-eigenplot(gfftrslt_Graph)+ylim(0,2)+theme_light()\nfig1_6&lt;-eigenplot(gfftrslt_HST)+ylim(0,2)+theme_light()\nfig1=grid.arrange(fig1_1,fig1_2,fig1_3,fig1_4,fig1_5,fig1_6,ncol=3,nrow=2)\nfig1\n#ggsave(plot=grid.arrange(p1_a,p1_b,p1_c,ncol=3),\"2021-07-22_fig1.png\",width=20,height=4)\n\nTableGrob (2 x 3) \"arrange\": 6 grobs\n  z     cells    name           grob\n1 1 (1-1,1-1) arrange gtable[layout]\n2 2 (1-1,2-2) arrange gtable[layout]\n3 3 (1-1,3-3) arrange gtable[layout]\n4 4 (2-2,1-1) arrange gtable[layout]\n5 5 (2-2,2-2) arrange gtable[layout]\n6 6 (2-2,3-3) arrange gtable[layout]\n\n\n\n\n\n\n\n\n\n\n\nR을 활용한 시각화 (3): Decomposition\n- 디콤포지션을 수행하고 결과를 저장: \\((\\bf{f},\\bf{W})\\)에 decomposition을 수행하고 그 결과를 각각 decomprslt_Euclid, decomprslt_Graph, decomprslt_HST에 저장한다.\n\n%%R \ndecomprslt_Euclid&lt;-decompose(f,W_Euclid,V=1:n) # 0, 35000, 60000, 80000\ndecomprslt_Graph&lt;-decompose(f,W_Graph,V=1:n) # 0, 35000, 60000, 80000\ndecomprslt_HST&lt;-decompose(f,W_HST,V=1:n) # 0, 35000, 60000, 80000\n\nNote: Using an external vector in selections is ambiguous.\nℹ Use `all_of(n)` instead of `n` to silence this message.\nℹ See &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;.\nThis message is displayed once per session.\n\n\n- 디콤포지션 결과는 아래와 같은 형태임\n\n%%R\nhead(decomprslt_Euclid)\n\n# A tibble: 6 × 5\n      V Vindex eigenvectorindex      fhat eigenvalue\n  &lt;int&gt;  &lt;int&gt;            &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1     1      1                1  1.45e-32   3.28e-18\n2     2      2                1  2.48e-17   3.28e-18\n3     3      3                1 -2.02e-16   3.28e-18\n4     4      4                1  1   e+ 0   3.28e-18\n5     5      5                1  8.73e-17   3.28e-18\n6     6      6                1 -6.32e-17   3.28e-18\n\n\n\n%%R \ndecomprslt_Euclid$method=\"Euclid\"\ndecomprslt_Graph$method=\"Graph\"\ndecomprslt_HST$method=\"HST\"\ndecomprslt&lt;-rbind(decomprslt_Euclid,decomprslt_Graph,decomprslt_HST)\n\n- 디콤포지션결과를 시각화한다. geom_col과 facet_grid를 이용.\n\n%%R -w 2000 -h 500 -r 100\nfig2&lt;-ggplot(data=decomprslt,aes(x=V,y=fhat))+\ngeom_col(aes(fill=fhat&gt;0),width=0.7)+facet_grid(method~eigenvectorindex)+geom_hline(aes(yintercept=0),col=\"gray60\",lty=2)+\nxlab(\"\")+ylab(\"\")+guides(fill=FALSE)+theme(plot.title=element_text(face=\"bold.italic\"))+theme_bw()+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 15, color = \"black\", face = \"bold.italic\"))+\nylim(-1.5,1.5)+\ntheme(plot.title=element_text(face=\"bold.italic\"))\nfig2\n#ggsave(plot=fig2,\"./fig/2021-0514_fig2.pdf\",width=20,height=6)"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-08-03-HST example 2 (4), 결과좋다.html",
    "href": "연구/교수님이랑/HST/2021-08-03-HST example 2 (4), 결과좋다.html",
    "title": "(연구&교수님) HST example 2 (4), 결과좋다",
    "section": "",
    "text": "import heavysnow as hs \nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt \nfrom sklearn.decomposition import PCA \nimport rpy2 \n%load_ext rpy2.ipython\n%run pybase\n\n\n### Example 2\nnp.random.seed(777)\nimport math\npi=math.pi\nn=59\nang=np.linspace(-pi,pi-2*pi/n,n)\nV=np.arange(n)+1\nr=1\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=vx*0\n\nf2=vx*0\nf2[vy&lt;0]=3+np.random.normal(size=sum(vy&lt;0),scale=0.1)\nf2[vy&gt;0]= -3+np.random.normal(size=sum(vy&gt;0),scale=0.1)\n\n\n# Edg setting\nΣ=l2distance(np.matrix([vx,vy]).T)\nθ=0.05\nW=np.exp(-Σ**2/(2*θ**2))\nE=W&gt;0\nplt.plot(W[0,:].T)\n# color\nimport matplotlib.cm as cm\ncol=list(np.array(cm.rainbow((ang+pi)/2/pi)))\n\n\n\n\n\n\n\n\n\n%R -i ang,vx,vy,n\n\n\n%%R\nlibrary(latex2exp)\nlibrary(gridExtra)\nlibrary(tidyverse)\n\nR[write to console]: ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\nR[write to console]: ✔ ggplot2 3.3.5     ✔ purrr   0.3.4\n✔ tibble  3.1.2     ✔ dplyr   1.0.7\n✔ tidyr   1.1.3     ✔ stringr 1.4.0\n✔ readr   1.4.0     ✔ forcats 0.5.1\n\nR[write to console]: ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::combine() masks gridExtra::combine()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n\n\n\n\n%%R -w 450 -h 300 -r 100\nex2df&lt;-data.frame(cbind(ang,vx,vy))\nnames(ex2df)&lt;-c(\"ang\",\"vx\",\"vy\")\nex2plt &lt;- ggplot(data=ex2df,aes(x=vx,y=vy))+\n            geom_point(col=\"gray60\",cex=1.5,alpha=0.7)+\n            geom_point(data=ex2df[1:n,],aes(x=vx,y=vy,col=ang),cex=1.5,alpha=0.7)+\n            xlab(\"\")+ylab(\"\")+scale_colour_gradientn(colours=rainbow(7))+labs(col=TeX(\"$\\\\phi$\"))+theme_classic()+\n            theme(legend.key.width = unit(2,\"mm\"))\nshow(ex2plt)\n\n\n\n\n\n\n\n\n\ngs1=hs.GraphSignal(V,W,f1)\ngs2=hs.GraphSignal(V,W,f2)\n\n\nplt.imshow(W)\n\n\n\n\n\n\n\n\n\nDiffusion distance\n\nP=W/W.round(3).sum(axis=0)[0]\nprint(P)\nplt.imshow(P)\n\n[[2.20167327e-01 2.14586355e-01 1.46335569e-01 ... 2.83862880e-02\n  1.46335569e-01 2.14586355e-01]\n [2.14586355e-01 2.20167327e-01 2.14586355e-01 ... 3.69898283e-04\n  2.83862880e-02 1.46335569e-01]\n [1.46335569e-01 2.14586355e-01 2.20167327e-01 ... 4.82347874e-08\n  3.69898283e-04 2.83862880e-02]\n ...\n [2.83862880e-02 3.69898283e-04 4.82347874e-08 ... 2.20167327e-01\n  2.14586355e-01 1.46335569e-01]\n [1.46335569e-01 2.83862880e-02 3.69898283e-04 ... 2.14586355e-01\n  2.20167327e-01 2.14586355e-01]\n [2.14586355e-01 1.46335569e-01 2.83862880e-02 ... 1.46335569e-01\n  2.14586355e-01 2.20167327e-01]]\n\n\n\n\n\n\n\n\n\n\nplt.imshow(P@P@P@P)\n\n\n\n\n\n\n\n\n\nP4=P@P@P@P\ndiffusion_distance=l2distance(P4)\nplt.imshow(diffusion_distance)\n\n\n\n\n\n\n\n\n\n\nSnow distance\n\nhs1=hs.HeavySnowTransform(gs1)\nhs2=hs.HeavySnowTransform(gs2)\n\n\nhs1.snow(tau=50000,b=0.1)\nhs2.snow(tau=50000,b=0.1)\n\nHST (tau= 50000, b=0.1)\n50000/50000\nHST completed and all history is recorded.\nHST (tau= 50000, b=0.1)\n50000/50000\nHST completed and all history is recorded.\n\n\n\nfrom sklearn.decomposition import PCA \np1=PCA(n_components=3)\np2=PCA(n_components=3)\np3=PCA(n_components=3)\np4=PCA(n_components=3)\np5=PCA(n_components=3)\np6=PCA(n_components=3)\n\n\np1.fit(hs1.eucliddistance)\np2.fit(diffusion_distance)\np3.fit(hs1.snowdistance)\np4.fit(hs2.eucliddistance)\np5.fit(diffusion_distance)\np6.fit(hs2.snowdistance)\n\nr1=p1.transform(hs1.eucliddistance)\nr2=p2.transform(diffusion_distance)\nr3=p3.transform(hs1.snowdistance)\nr4=p4.transform(hs2.eucliddistance)\nr5=p5.transform(diffusion_distance)\nr6=p6.transform(hs2.snowdistance)\n\n/home/cgb4/anaconda3/envs/py38r40/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:470: RuntimeWarning: invalid value encountered in true_divide\n  explained_variance_ratio_ = explained_variance_ / total_var\n\n\n\n# 1. \np=plt.figure(figsize=(12,4), dpi=70)  # Make figure object \n\n# 2. \nax1=p.add_subplot(2,4,1, projection='3d')\nax2=p.add_subplot(2,4,2, projection='3d')\nax3=p.add_subplot(2,4,3, projection='3d')\nax4=p.add_subplot(2,4,4, projection='3d')\nax5=p.add_subplot(2,4,5, projection='3d')\nax6=p.add_subplot(2,4,6, projection='3d')\nax7=p.add_subplot(2,4,7, projection='3d')\nax8=p.add_subplot(2,4,8, projection='3d')\n\n# 3. \nax1.grid(False)\nax1.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax1.scatter3D(vx, vy, f1, c=col,alpha=1)\nax1.set_xlim(-1,1)\nax1.set_ylim(-1,1)\nax1.set_zlim(-5,5)\n\nax2.grid(False)\nax2.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax2.scatter3D(r1[:,0],r1[:,1],r1[:,2],s=20,c=col,alpha=1)\n\nax3.grid(False)\nax3.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax3.scatter3D(r2[:,0],r2[:,1],r2[:,2],s=20,c=col,alpha=1)\n\nax4.grid(False)\nax4.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax4.scatter3D(r3[:,0],r3[:,1],r3[:,2],s=20,c=col,alpha=1)\n\n\nax5.grid(False)\nax5.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\ntop = -f2\nbottom = np.zeros_like(top)\nwidth=depth=0.05\nax5.bar3d(vx, vy, bottom, width, depth, top, shade=False,color=col)\nax5.set_xlim(-1,1)\nax5.set_ylim(-1,1)\nax5.set_zlim(-5,5)\n\nax6.grid(False)\nax6.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax6.scatter3D(r4[:,0],r4[:,1],r4[:,2],s=20,c=col,alpha=1)\n\nax7.grid(False)\nax7.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax7.scatter3D(r5[:,0],r5[:,1],r5[:,2],s=20,c=col,alpha=1)\n\nax8.grid(False)\nax8.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax8.scatter3D(r6[:,0],r6[:,1],r6[:,2],s=20,c=col,alpha=1)\np.tight_layout(h_pad=2.6) #rect : tuple (left, bottom, right, top), optional"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-08-14-HST example 1, Appendix 추가 (1).html",
    "href": "연구/교수님이랑/HST/2021-08-14-HST example 1, Appendix 추가 (1).html",
    "title": "(연구&교수님) HST example 1, Appendix 추가 (1)",
    "section": "",
    "text": "Import\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib\nmatplotlib.rc('image', cmap='Greys')\nimport rpy2 \n%load_ext rpy2.ipython\n%run pybase\n%run heavysnow \n\n\n\nData\n\nf=np.array([-1,-1,-1,1,-1,-1,-1,1,1,1,-1,1,1,1])*1.0\nn=len(f)\nV=list(range(n))\nW=np.zeros([n,n])\nfor i in range(n):\n    for j in range(n):\n        if abs(i-j)==1: W[i,j]=1\nW[0,0]=0\nW[n-1,n-1]=0\n\n\ngs=GraphSignal(V,W,f)\n\n\ngs.initdist=np.array([1/n]*n)\n\n\n\nHST\n\n%run heavysnow \nhst=HeavySnowTransform(gs)\nhst.snow(tau=1000000,b=0.001,maxflow=2)\n\nHST (tau= 1000000, b=0.001)\n1000000/1000000\nHST completed and all history is recorded.\n\n\n\nplt.imshow(hst.snowdistance)\n\n\n\n\n\n\n\n\n\nhst.snowdistance/(hst.b**2*hst.tau)\n\narray([[   0.     ,    6.62729,   21.09601,  513.21229,  144.99293,\n         174.78548,  229.86424, 1367.48288, 1469.01427, 1541.47081,\n        1104.37238, 1939.21254, 2003.70522, 1972.38438],\n       [   6.62729,    0.     ,    8.70526,  478.68804,  114.41082,\n         140.73199,  190.27027, 1290.38981, 1388.36882, 1458.73142,\n        1027.58343, 1847.46733, 1911.12211, 1884.55171],\n       [  21.09601,    8.70526,    0.     ,  450.58642,   88.31524,\n         111.50557,  156.10131, 1223.00711, 1319.36988, 1388.02978,\n         961.47749, 1769.22195, 1832.48321, 1808.77811],\n       [ 513.21229,  478.68804,  450.58642,    0.     ,  327.31126,\n         348.63769,  384.03813,  429.56457,  503.89864,  568.92602,\n         801.50731,  780.10205,  830.37839,  815.65883],\n       [ 144.99293,  114.41082,   88.31524,  327.31126,    0.     ,\n          11.23731,   35.08409,  789.55023,  865.05526,  922.90664,\n         549.19535, 1224.63325, 1280.31923, 1264.28261],\n       [ 174.78548,  140.73199,  111.50557,  348.63769,   11.23731,\n           0.     ,   15.40954,  751.0249 ,  822.78351,  876.66509,\n         497.98752, 1176.15764, 1231.98094, 1218.47054],\n       [ 229.86424,  190.27027,  156.10131,  384.03813,   35.08409,\n          15.40954,    0.     ,  687.59144,  753.09867,  802.81247,\n         418.45038, 1095.83864, 1150.6394 , 1140.63196],\n       [1367.48288, 1290.38981, 1223.00711,  429.56457,  789.55023,\n         751.0249 ,  687.59144,    0.     ,   10.94633,   30.68243,\n         331.93456,   90.56094,  114.65644,  120.8578 ],\n       [1469.01427, 1388.36882, 1319.36988,  503.89864,  865.05526,\n         822.78351,  753.09867,   10.94633,    0.     ,   12.82752,\n         318.12425,   64.99807,   86.80923,   94.62813],\n       [1541.47081, 1458.73142, 1388.02978,  568.92602,  922.90664,\n         876.66509,  802.81247,   30.68243,   12.82752,    0.     ,\n         298.63121,   46.70485,   65.23165,   72.66127],\n       [1104.37238, 1027.58343,  961.47749,  801.50731,  549.19535,\n         497.98752,  418.45038,  331.93456,  318.12425,  298.63121,\n           0.     ,  411.02768,  433.02044,  437.0482 ],\n       [1939.21254, 1847.46733, 1769.22195,  780.10205, 1224.63325,\n        1176.15764, 1095.83864,   90.56094,   64.99807,   46.70485,\n         411.02768,    0.     ,    9.11974,   18.80406],\n       [2003.70522, 1911.12211, 1832.48321,  830.37839, 1280.31923,\n        1231.98094, 1150.6394 ,  114.65644,   86.80923,   65.23165,\n         433.02044,    9.11974,    0.     ,    6.17182],\n       [1972.38438, 1884.55171, 1808.77811,  815.65883, 1264.28261,\n        1218.47054, 1140.63196,  120.8578 ,   94.62813,   72.66127,\n         437.0482 ,   18.80406,    6.17182,    0.     ]])\n\n\n\ntheta=10\nhst.snowweight=np.exp(-hst.snowdistance/(theta*hst.tau*hst.b**2))-np.eye(n,n)\nplt.imshow(hst.snowweight)\n\n\n\n\n\n\n\n\n\nnp.std(W), np.std(hst.snowweight)\n\n(0.3391993905835645, 0.40491892481254094)\n\n\n\n\n시각화를 위해서 R로 자료를 옮김\n\nmaxtau=hst.tau\nW_Graph=hst.graphweight\nW_Euclid=hst.euclidweight\nW_HST=hst.snowweight\nV=np.array(hst.V)\nf=hst.f\nn=hst.n\n%R -i maxtau,W_Graph,W_Euclid,W_HST,V,f,n\n\n\n\nR을 활용한 시각화 (1): 원래자료\n\n%%R -w 2000 -h 800 -r 100\nlibrary(tidyverse)\nlibrary(latex2exp)\nlibrary(gridExtra)\nsource('rbase.R')\nVtext=str_c('node ',V+1)\nfig0&lt;-ggplot(data=tibble(V=V,f=f,Vtext=Vtext),aes(x=V,y=f,label=Vtext))+\ngeom_col(aes(fill=(f&gt;0)),width=0.1)+geom_hline(aes(yintercept=0),col=\"gray60\",lty=2)+\ngeom_text(fontface = 4,size=8)+\nxlab(\"\")+ylab(\"\")+guides(fill=FALSE)+theme(plot.title=element_text(face=\"bold.italic\"))+theme_bw()+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 15, color = \"black\", face = \"bold.italic\"))+\nylim(-1.2,1.2)+\ntheme(plot.title=element_text(face=\"bold.italic\"))\n#ggsave(plot=p0,\"./fig/2021-0217_fig0.pdf\",width=20,height=6)\nfig0\n\n\n\n\n\n\n\n\n\n\nR을 활용한 시각화 (2): Weight matrix 와 Eigen plot\n- ggplot에서 geom_tile을 사용하기 위해서 매트릭스 형태인 W_Graph, W_Euclid, W_HST를 길게 펼친다. 결과를 각각 W_Graph_long, W_Euclid_long, W_HST_long에 저장한다.\n\n%%R\ngrid&lt;-expand.grid(x=1:n,y=1:n)\nW_Graph_long&lt;-as_tibble(cbind(grid,as.vector(W_Graph)));names(W_Graph_long)&lt;-c(\"x\",\"y\",\"W\")\nW_Euclid_long&lt;-as_tibble(cbind(grid,as.vector(W_Euclid)));names(W_Euclid_long)&lt;-c(\"x\",\"y\",\"W\")\nW_HST_long&lt;-as_tibble(cbind(grid,as.vector(W_HST)));names(W_HST_long)&lt;-c(\"x\",\"y\",\"W\")\n\n- 그래프퓨리에 변환: \\((\\bf{f},\\bf{W})\\)에 그래프 퓨리에 변환을 수행함.\n\n%%R\nsource('heavysnow.R')\ngfftrslt_Euclid&lt;-gfft(f,W_Euclid)\ngfftrslt_Graph&lt;-gfft(f,W_Graph)\ngfftrslt_HST&lt;-gfft(f,W_HST)\n\n- 그래프 퓨리에 변환의 결과 고유치, 고유벡터, \\(\\bf{\\bar{f}}\\)가 반환됨.\n\n%%R\nhead(gfftrslt_HST)\n\n$λ\n [1] 1.239762e+00 1.235845e+00 1.234708e+00 1.224906e+00 1.218730e+00\n [6] 1.218183e+00 1.217879e+00 1.216651e+00 1.127025e+00 1.064638e+00\n[11] 1.002672e+00 9.980700e-01 9.304995e-04 1.450065e-16\n\n$Ψ\n               [,1]          [,2]          [,3]          [,4]          [,5]\n [1,]  0.0001751968 -1.874198e-06  8.688271e-06 -0.0003894479  7.218527e-01\n [2,]  0.0001675820 -1.769072e-06  8.327460e-06 -0.0003577999 -6.886049e-01\n [3,]  0.0001705841 -1.806950e-06  8.622934e-06 -0.0003981254 -3.919519e-02\n [4,]  0.0033579460 -4.149941e-05  1.431600e-04 -0.0065447260  1.120350e-04\n [5,] -0.0003877013  5.201596e-06 -1.764374e-05  0.0011478880 -1.511037e-02\n [6,] -0.0003146498  3.621689e-06 -1.448185e-05  0.0006741380 -2.570620e-02\n [7,] -0.0002767749  1.996564e-06 -1.421575e-05  0.0002168011  4.823331e-02\n [8,] -0.7003908056 -3.035159e-04 -4.275780e-03  0.3526586564  2.074735e-05\n [9,]  0.7130429771  4.696132e-03 -2.668838e-03  0.3725322326  1.392201e-05\n[10,]  0.0193130597 -1.647804e-03 -5.409646e-03 -0.8541110478 -3.705826e-05\n[11,] -0.0026756321  2.034397e-04  2.152887e-04  0.0153985420 -2.972710e-05\n[12,] -0.0145963589 -1.206721e-01  8.109795e-01  0.0467146386  2.461515e-06\n[13,] -0.0167962080  7.585750e-01 -2.966192e-01  0.0470234716  2.785654e-06\n[14,] -0.0116371385 -6.402948e-01 -5.042564e-01  0.0516745150  2.789755e-06\n               [,6]          [,7]          [,8]         [,9]        [,10]\n [1,]  1.477770e-02 -3.710372e-01  1.296249e-02  0.406366874  0.012539630\n [2,]  9.836523e-02 -4.266795e-01 -8.148809e-03  0.397563086  0.012308231\n [3,] -8.954434e-02  8.150322e-01 -3.912226e-02  0.385474053  0.012031186\n [4,]  9.263468e-04  3.061411e-04 -2.502940e-03  0.177426484 -0.055612410\n [5,] -8.393012e-02  1.174890e-02  8.226179e-01 -0.383537331 -0.008327158\n [6,] -6.657007e-01 -1.029900e-01 -4.610312e-01 -0.406055668 -0.008831733\n [7,]  7.293044e-01  7.248038e-02 -3.301185e-01 -0.429530203 -0.009617061\n [8,]  1.986048e-04  2.980291e-05 -2.784778e-04 -0.005358784  0.453576824\n [9,]  1.378324e-04  1.534449e-05 -1.531722e-04 -0.006422529  0.414665547\n[10,] -3.273898e-04 -6.168711e-05  5.097510e-04 -0.006853290  0.300908148\n[11,] -3.717634e-04 -1.569977e-05  3.658232e-04  0.008361464 -0.382783300\n[12,]  1.966381e-05  5.408451e-06 -4.164378e-05  0.004813031 -0.349545727\n[13,]  2.201436e-05  6.311993e-06 -4.828417e-05  0.005052496 -0.360651427\n[14,]  2.172082e-05  6.394810e-06 -4.823945e-05  0.005032854 -0.359463572\n            [,11]       [,12]       [,13]      [,14]\n [1,]  0.07901983  0.06493090 -0.28202999 0.29254246\n [2,]  0.07779727  0.06393416 -0.28250301 0.29303537\n [3,]  0.07642389  0.06281714 -0.28287512 0.29342350\n [4,] -0.76670668 -0.61029518 -0.04582622 0.05446431\n [5,] -0.03238393 -0.02602054 -0.28352826 0.29428443\n [6,] -0.03330112 -0.02715152 -0.28286723 0.29360735\n [7,] -0.03555637 -0.02958278 -0.28167310 0.29238523\n [8,]  0.06384719 -0.12759690  0.28704413 0.27668335\n [9,]  0.06084135 -0.11297776  0.29189710 0.28125061\n[10,]  0.05175621 -0.08194683  0.29707696 0.28609016\n[11,]  0.59036840 -0.70364218  0.06943132 0.06851660\n[12,] -0.10117517  0.16314267  0.29385003 0.28275430\n[13,] -0.10360119  0.16692827  0.29305198 0.28198418\n[14,] -0.10315258  0.16627589  0.29306978 0.28200174\n\n$fbar\n [1] -4.565133e-03  1.026278e-04 -2.301774e-03 -6.344255e-03 -1.321925e-03\n [6] -1.901611e-03  1.768618e-03 -8.854919e-05  1.950480e-01  4.165576e-01\n[11] -1.620559e+00  1.582450e-01  3.336209e+00 -8.256629e-02\n\n\n\n- 시각화코드\n\n%%R -w 1000 -h 800 -r 100\nlibrary(gridExtra)\n\nfig1_1&lt;-ggplot()+geom_tile(data=W_Euclid_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"white\",high=\"black\")+\nlabs(fill=TeX('$W$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(a) Euclid\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_2&lt;-ggplot()+geom_tile(data=W_Graph_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"white\",high=\"black\")+\nlabs(fill=TeX('$\\\\hat{W}$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(b) Graph\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_3&lt;-ggplot()+geom_tile(data=W_HST_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"white\",high=\"black\")+\nlabs(fill=TeX('$\\\\hat{W}(\\\\tau)$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(c) HST\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_4&lt;-eigenplot(gfftrslt_Euclid)+ylim(0,2)+theme_light()\nfig1_5&lt;-eigenplot(gfftrslt_Graph)+ylim(0,2)+theme_light()\nfig1_6&lt;-eigenplot(gfftrslt_HST)+ylim(0,2)+theme_light()\nfig1=grid.arrange(fig1_1,fig1_2,fig1_3,fig1_4,fig1_5,fig1_6,ncol=3,nrow=2)\nfig1\nggsave(plot=fig1,\"temp.pdf\",width=15,height=10)\n\n\n\n\n\n\n\n\n\n%%R -w 200 -h 600 -r 120\nfig_= grid.arrange(fig1_4,fig1_5,fig1_6,nrow=3)\nggsave(plot=fig_,\"spectrum.pdf\",width=2,height=6)\n\n\n\n\n\n\n\n\n\n\nR을 활용한 시각화 (3): Decomposition\n- 디콤포지션을 수행하고 결과를 저장: \\((\\bf{f},\\bf{W})\\)에 decomposition을 수행하고 그 결과를 각각 decomprslt_Euclid, decomprslt_Graph, decomprslt_HST에 저장한다.\n\n%%R \ndecomprslt_Euclid&lt;-decompose(f,W_Euclid,V=1:n) # 0, 35000, 60000, 80000\ndecomprslt_Graph&lt;-decompose(f,W_Graph,V=1:n) # 0, 35000, 60000, 80000\ndecomprslt_HST&lt;-decompose(f,W_HST,V=1:n) # 0, 35000, 60000, 80000\n\n- 디콤포지션 결과는 아래와 같은 형태임\n\n%%R\nhead(decomprslt_Euclid)\n\n# A tibble: 6 × 5\n      V Vindex eigenvectorindex      fhat eigenvalue\n  &lt;int&gt;  &lt;int&gt;            &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1     1      1                1  1.45e-32   3.28e-18\n2     2      2                1  2.48e-17   3.28e-18\n3     3      3                1 -2.02e-16   3.28e-18\n4     4      4                1  1   e+ 0   3.28e-18\n5     5      5                1  8.73e-17   3.28e-18\n6     6      6                1 -6.32e-17   3.28e-18\n\n\n\n%%R \ndecomprslt_Euclid$method=\"Euclid\"\ndecomprslt_Graph$method=\"Graph\"\ndecomprslt_HST$method=\"HST\"\ndecomprslt&lt;-rbind(decomprslt_Euclid,decomprslt_Graph,decomprslt_HST)\n\n- 디콤포지션결과를 시각화한다. geom_col과 facet_grid를 이용.\n\n%%R -w 2000 -h 500 -r 100\nfig2&lt;-ggplot(data=decomprslt,aes(x=V,y=fhat))+\ngeom_col(aes(fill=fhat&gt;0),width=0.7)+facet_grid(method~eigenvectorindex)+geom_hline(aes(yintercept=0),col=\"gray60\",lty=2)+\nxlab(\"\")+ylab(\"\")+guides(fill=FALSE)+theme(plot.title=element_text(face=\"bold.italic\"))+theme_bw()+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 15, color = \"black\", face = \"bold.italic\"))+\nylim(-1.2,1.2)+\ntheme(plot.title=element_text(face=\"bold.italic\"))\nfig2\n#ggsave(plot=fig2,\"./fig/2021-0514_fig2.pdf\",width=20,height=6)\n\n\n\n\n\n\n\n\n\n\nAppendix\n\n_, (ax1,ax2) = plt.subplots(1,2)\nax1.imshow(hst.eucliddistance[:7,:7],origin='lower')\nax2.imshow(hst.snowdistance[:7,:7],origin='lower')\nplt.show()\n\n\n\n\n\n\n\n\n\nbrk=500\n_, (ax1,ax2,ax3) = plt.subplots(1,3) \nax1.imshow(l2distance(hst.snowygrounds[:,0:brk]),origin='lower')\nax2.imshow(l2distance(hst.snowygrounds[:,brk:]),origin='lower')\nax3.imshow(hst.snowdistance,origin='lower')\n#ax4.imshow(diffusion_distance)\nplt.show()\n\n\n\n\n\n\n\n\n\ny=hst.snowdistance[0]\nplt.plot(y,'o--')\nplt.plot([0,1,2,4,5,6,10],y[[0,1,2,4,5,6,10]],'o')\nplt.plot([3,7,8,9,11,12,13],y[[3,7,8,9,11,12,13]],'o')\n\n\n\n\n\n\n\n\n\np, (ax1,ax2,ax3) = plt.subplots(1,3) \nax1.imshow(hst.euclidweight,origin='lower')\nax2.imshow(hst.snowweight,origin='lower')\nax3.imshow(hst.graphweight,origin='lower')\n#ax4.imshow(diffusion_distance)\n#p.show()\np.savefig('temp.pdf', transparent=True)"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-08-02-HST example 1 (4).html",
    "href": "연구/교수님이랑/HST/2021-08-02-HST example 1 (4).html",
    "title": "(연구&교수님) HST example 1 (4)",
    "section": "",
    "text": "Import\n\nimport heavysnow as hs\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport rpy2 \n%load_ext rpy2.ipython\n%run pybase\n\n\n\nData\n\nf=np.array([-1,-1,-1,1,-1,-1,-1,1,1,1,-1,1,1,1])*1.0\nn=len(f)\nV=list(range(n))\nW=np.zeros([n,n])\nfor i in range(n):\n    for j in range(n):\n        if abs(i-j)==1: W[i,j]=1\nW[0,0]=1\nW[n-1,n-1]=1\n\n\ngs=hs.GraphSignal(V,W,f)\n\n\ngs.initdist=np.array([1/n]*n)\n\n\n\nHST\n\nhst=hs.HeavySnowTransform(gs)\nhst.snow(tau=80000,b=0.03)\n\nHST (tau= 80000, b=0.03)\n80000/80000\nHST completed and all history is recorded.\n\n\n\nplt.imshow(hst.snowweight)\n\n\n\n\n\n\n\n\n\n\n시각화를 위해서 R로 자료를 옮김\n\nmaxtau=hst.tau\nW_Graph=hst.graphweight\nW_Euclid=hst.euclidweight\nW_HST=hst.snowweight\nV=np.array(hst.V)\nf=hst.f\nn=hst.n\n%R -i maxtau,W_Graph,W_Euclid,W_HST,V,f,n\n\n\n\nR을 활용한 시각화 (1): 원래자료\n\n%%R -w 2000 -h 800 -r 100\nlibrary(tidyverse)\nlibrary(latex2exp)\nlibrary(gridExtra)\nsource('rbase.R')\nVtext=str_c('node ',V+1)\nfig0&lt;-ggplot(data=tibble(V=V,f=f,Vtext=Vtext),aes(x=V,y=f,label=Vtext))+\ngeom_col(aes(fill=(f&gt;0)),width=0.1)+geom_hline(aes(yintercept=0),col=\"gray60\",lty=2)+\ngeom_text(fontface = 4,size=8)+\nxlab(\"\")+ylab(\"\")+guides(fill=FALSE)+theme(plot.title=element_text(face=\"bold.italic\"))+theme_bw()+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 15, color = \"black\", face = \"bold.italic\"))+\nylim(-1.2,1.2)+\ntheme(plot.title=element_text(face=\"bold.italic\"))\n#ggsave(plot=p0,\"./fig/2021-0217_fig0.pdf\",width=20,height=6)\nfig0\n\nR[write to console]: ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\nR[write to console]: ✔ ggplot2 3.3.5     ✔ purrr   0.3.4\n✔ tibble  3.1.3     ✔ dplyr   1.0.7\n✔ tidyr   1.1.3     ✔ stringr 1.4.0\n✔ readr   2.0.1     ✔ forcats 0.5.1\n\nR[write to console]: ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nR[write to console]: \nAttaching package: ‘gridExtra’\n\n\nR[write to console]: The following object is masked from ‘package:dplyr’:\n\n    combine\n\n\nR[write to console]: \nAttaching package: ‘lubridate’\n\n\nR[write to console]: The following objects are masked from ‘package:base’:\n\n    date, intersect, setdiff, union\n\n\n\n\n\n\n\n\n\n\n\n\n\nR을 활용한 시각화 (2): Weight matrix 와 Eigen plot\n- ggplot에서 geom_tile을 사용하기 위해서 매트릭스 형태인 W_Graph, W_Euclid, W_HST를 길게 펼친다. 결과를 각각 W_Graph_long, W_Euclid_long, W_HST_long에 저장한다.\n\n%%R\ngrid&lt;-expand.grid(x=1:n,y=1:n)\nW_Graph_long&lt;-as_tibble(cbind(grid,as.vector(W_Graph)));names(W_Graph_long)&lt;-c(\"x\",\"y\",\"W\")\nW_Euclid_long&lt;-as_tibble(cbind(grid,as.vector(W_Euclid)));names(W_Euclid_long)&lt;-c(\"x\",\"y\",\"W\")\nW_HST_long&lt;-as_tibble(cbind(grid,as.vector(W_HST)));names(W_HST_long)&lt;-c(\"x\",\"y\",\"W\")\n\n- 그래프퓨리에 변환: \\((\\bf{f},\\bf{W})\\)에 그래프 퓨리에 변환을 수행함.\n\n%%R\nsource('heavysnow.R')\ngfftrslt_Euclid&lt;-gfft(f,W_Euclid)\ngfftrslt_Graph&lt;-gfft(f,W_Graph)\ngfftrslt_HST&lt;-gfft(f,W_HST)\n\nR[write to console]: \nAttaching package: ‘kohonen’\n\n\nR[write to console]: The following object is masked from ‘package:purrr’:\n\n    map\n\n\nR[write to console]: \nAttaching package: ‘igraph’\n\n\nR[write to console]: The following objects are masked from ‘package:lubridate’:\n\n    %--%, union\n\n\nR[write to console]: The following objects are masked from ‘package:dplyr’:\n\n    as_data_frame, groups, union\n\n\nR[write to console]: The following objects are masked from ‘package:purrr’:\n\n    compose, simplify\n\n\nR[write to console]: The following object is masked from ‘package:tidyr’:\n\n    crossing\n\n\nR[write to console]: The following object is masked from ‘package:tibble’:\n\n    as_data_frame\n\n\nR[write to console]: The following objects are masked from ‘package:stats’:\n\n    decompose, spectrum\n\n\nR[write to console]: The following object is masked from ‘package:base’:\n\n    union\n\n\n\n\n- 그래프 퓨리에 변환의 결과 고유치, 고유벡터, \\(\\bf{\\bar{f}}\\)가 반환됨.\n\n%%R\nhead(gfftrslt_HST)\n\n$λ\n [1] 1.000001e+00 1.787345e-06 1.470615e-07 1.416525e-07 1.302853e-07\n [6] 1.388941e-08 2.177604e-11 3.320085e-12 1.973246e-14 1.533766e-16\n[11] 1.384959e-18 5.606658e-26 3.974896e-26 1.761591e-30\n\n$Ψ\n               [,1]          [,2]          [,3]          [,4]          [,5]\n [1,] -1.403931e-22  7.070809e-01 -7.947551e-24  7.591779e-19  1.348505e-22\n [2,] -1.403863e-22 -7.071326e-01 -7.947164e-24  7.591420e-19  1.348439e-22\n [3,] -2.876394e-18  8.408882e-10 -1.628472e-19 -3.577911e-14  2.763119e-18\n [4,]  4.207339e-24  9.954128e-26 -6.214184e-16 -5.551115e-16 -2.371401e-17\n [5,]  2.829643e-05  2.304122e-22  4.996446e-18  1.773058e-01 -7.321149e-13\n [6,] -9.999996e-01 -4.428097e-23  9.268412e-22 -8.536656e-04  3.230721e-15\n [7,]  8.725068e-04 -3.411385e-24  9.002328e-19 -9.841554e-01  3.726534e-12\n [8,]  6.118374e-20  5.889401e-37  1.237469e-16  2.556936e-12  1.587786e-01\n [9,]  7.925032e-25 -5.915170e-39  5.273557e-17 -3.280217e-12 -9.333698e-01\n[10,]  1.012965e-28  3.646515e-40  9.187549e-17  1.024146e-12  3.218855e-01\n[11,]  1.322669e-32  2.619586e-41  3.848226e-23 -1.207074e-24 -4.415323e-13\n[12,] -4.630337e-50 -2.142860e-56 -2.883533e-09 -2.756118e-27 -9.418240e-16\n[13,] -5.770641e-61  8.981613e-64  7.071547e-01  5.168948e-35  2.680300e-23\n[14,] -1.079175e-67 -3.845164e-65 -7.070589e-01 -4.005637e-35 -2.247864e-23\n               [,6]          [,7]          [,8]          [,9]         [,10]\n [1,] -3.967316e-22 -7.071326e-01  3.178394e-20  1.447203e-16 -9.322824e-09\n [2,] -3.967123e-22 -7.070809e-01  3.178239e-20  1.447132e-16 -9.322370e-09\n [3,] -8.129125e-18  6.901722e-05  6.512603e-16  2.961542e-12 -1.910249e-04\n [4,]  1.250698e-16 -5.886527e-19  2.570340e-12  6.797431e-11 -1.262960e-07\n [5,]  2.426851e-12 -1.360822e-13 -2.037860e-14 -1.870672e-06  9.841558e-01\n [6,] -7.395544e-16 -2.524444e-17 -3.780105e-18 -3.469849e-10  1.825486e-04\n [7,] -9.262813e-13 -2.451991e-14 -3.671561e-15 -3.370191e-07  1.773057e-01\n [8,] -6.305704e-01  1.212638e-22 -4.995542e-13  7.597173e-01  1.444063e-06\n [9,]  1.549996e-01  5.181013e-23 -2.128634e-13  3.237221e-01  6.153267e-07\n[10,]  7.604973e-01  9.039134e-23 -3.708201e-13  5.639447e-01  1.071938e-06\n[11,] -9.787922e-12 -1.096101e-30  8.754796e-17 -5.109122e-06 -1.249408e-09\n[12,] -2.087413e-14 -2.337556e-33  1.277102e-04 -1.089566e-08 -2.664472e-12\n[13,] -9.436410e-21 -4.772343e-37 -7.070589e-01 -1.448832e-12 -1.473685e-14\n[14,]  1.033617e-20  5.206962e-37 -7.071547e-01 -1.448947e-12 -1.473665e-14\n              [,11]         [,12]         [,13]         [,14]\n [1,] -4.880373e-05  2.670627e-13  6.824687e-12  1.830580e-15\n [2,] -4.880135e-05  2.670496e-13  6.824354e-12  1.830490e-15\n [3,] -1.000000e+00  5.472177e-09  1.398394e-07  3.750901e-11\n [4,] -1.399223e-07 -3.909661e-02 -9.992354e-01  1.101266e-05\n [5,] -1.879982e-04 -4.881712e-09 -1.241728e-07 -1.218460e-09\n [6,] -3.487132e-08 -9.054965e-13 -2.303250e-11 -2.260091e-13\n [7,] -3.386980e-05 -8.794901e-10 -2.237099e-08 -2.195180e-10\n [8,] -2.736021e-10 -7.389240e-08  2.899881e-09 -3.880787e-06\n [9,] -1.165841e-10 -3.148626e-08  1.235667e-09 -1.653641e-06\n[10,] -2.030967e-10 -5.485120e-08  2.152616e-09 -2.880753e-06\n[11,] -3.881854e-11 -2.116816e-02  8.172180e-04 -9.997756e-01\n[12,] -8.278411e-14  9.990112e-01 -3.908807e-02 -2.118393e-02\n[13,] -4.630662e-16  9.021138e-05 -3.529681e-06 -1.912923e-06\n[14,] -4.630902e-16  9.021953e-05 -3.530000e-06 -1.913095e-06\n\n$fbar\n [1]  9.990988e-01  5.168789e-05  9.578186e-05  8.077033e-01 -4.527057e-01\n [6]  2.849265e-01  1.414145e+00 -1.414086e+00  1.647391e+00 -1.161450e+00\n[11]  1.000319e+00  9.812630e-01 -1.039148e+00  9.785904e-01\n\n\n\n- 시각화코드\n\n%%R -w 1000 -h 800 -r 100\nlibrary(gridExtra)\n\nfig1_1&lt;-ggplot()+geom_tile(data=W_Euclid_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"red\",high=\"blue\",mid=\"purple\",midpoint=0.25,breaks=c(0,0.5,0.99))+\nlabs(fill=TeX('$W$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(a) Euclid\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_2&lt;-ggplot()+geom_tile(data=W_Graph_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"red\",high=\"blue\",mid=\"purple\",midpoint=0.5,breaks=c(0,0.5,0.99))+\nlabs(fill=TeX('$\\\\hat{W}$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(b) Graph\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_3&lt;-ggplot()+geom_tile(data=W_HST_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"red\",high=\"blue\",mid=\"purple\",midpoint=0.5,breaks=c(0,0.5,0.99))+\nlabs(fill=TeX('$\\\\hat{W}(\\\\tau)$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(c) HST\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_4&lt;-eigenplot(gfftrslt_Euclid)+ylim(0,2)+theme_light()\nfig1_5&lt;-eigenplot(gfftrslt_Graph)+ylim(0,2)+theme_light()\nfig1_6&lt;-eigenplot(gfftrslt_HST)+ylim(0,2)+theme_light()\nfig1=grid.arrange(fig1_1,fig1_2,fig1_3,fig1_4,fig1_5,fig1_6,ncol=3,nrow=2)\nfig1\n#ggsave(plot=grid.arrange(p1_a,p1_b,p1_c,ncol=3),\"2021-07-22_fig1.png\",width=20,height=4)\n\nTableGrob (2 x 3) \"arrange\": 6 grobs\n  z     cells    name           grob\n1 1 (1-1,1-1) arrange gtable[layout]\n2 2 (1-1,2-2) arrange gtable[layout]\n3 3 (1-1,3-3) arrange gtable[layout]\n4 4 (2-2,1-1) arrange gtable[layout]\n5 5 (2-2,2-2) arrange gtable[layout]\n6 6 (2-2,3-3) arrange gtable[layout]\n\n\n\n\n\n\n\n\n\n\n\nR을 활용한 시각화 (3): Decomposition\n- 디콤포지션을 수행하고 결과를 저장: \\((\\bf{f},\\bf{W})\\)에 decomposition을 수행하고 그 결과를 각각 decomprslt_Euclid, decomprslt_Graph, decomprslt_HST에 저장한다.\n\n%%R \ndecomprslt_Euclid&lt;-decompose(f,W_Euclid,V=1:n) # 0, 35000, 60000, 80000\ndecomprslt_Graph&lt;-decompose(f,W_Graph,V=1:n) # 0, 35000, 60000, 80000\ndecomprslt_HST&lt;-decompose(f,W_HST,V=1:n) # 0, 35000, 60000, 80000\n\nNote: Using an external vector in selections is ambiguous.\nℹ Use `all_of(n)` instead of `n` to silence this message.\nℹ See &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;.\nThis message is displayed once per session.\n\n\n- 디콤포지션 결과는 아래와 같은 형태임\n\n%%R\nhead(decomprslt_Euclid)\n\n# A tibble: 6 × 5\n      V Vindex eigenvectorindex      fhat eigenvalue\n  &lt;int&gt;  &lt;int&gt;            &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1     1      1                1  1.45e-32   3.28e-18\n2     2      2                1  2.48e-17   3.28e-18\n3     3      3                1 -2.02e-16   3.28e-18\n4     4      4                1  1   e+ 0   3.28e-18\n5     5      5                1  8.73e-17   3.28e-18\n6     6      6                1 -6.32e-17   3.28e-18\n\n\n\n%%R \ndecomprslt_Euclid$method=\"Euclid\"\ndecomprslt_Graph$method=\"Graph\"\ndecomprslt_HST$method=\"HST\"\ndecomprslt&lt;-rbind(decomprslt_Euclid,decomprslt_Graph,decomprslt_HST)\n\n- 디콤포지션결과를 시각화한다. geom_col과 facet_grid를 이용.\n\n%%R -w 2000 -h 500 -r 100\nfig2&lt;-ggplot(data=decomprslt,aes(x=V,y=fhat))+\ngeom_col(aes(fill=fhat&gt;0),width=0.7)+facet_grid(method~eigenvectorindex)+geom_hline(aes(yintercept=0),col=\"gray60\",lty=2)+\nxlab(\"\")+ylab(\"\")+guides(fill=FALSE)+theme(plot.title=element_text(face=\"bold.italic\"))+theme_bw()+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 15, color = \"black\", face = \"bold.italic\"))+\nylim(-1.5,1.5)+\ntheme(plot.title=element_text(face=\"bold.italic\"))\nfig2\n#ggsave(plot=fig2,\"./fig/2021-0514_fig2.pdf\",width=20,height=6)"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-08-02-HST example 1 (1).html",
    "href": "연구/교수님이랑/HST/2021-08-02-HST example 1 (1).html",
    "title": "(연구&교수님) HST example 1 (1)",
    "section": "",
    "text": "Import\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport rpy2 \n%load_ext rpy2.ipython\n%run pybase\n%run heavysnow \n\n\n\nData\n\nf=np.array([-1,-1,-1,1,-1,-1,-1,1,1,1,-1,1,1,1])*1.0\nn=len(f)\nV=list(range(n))\nW=np.zeros([n,n])\nfor i in range(n):\n    for j in range(n):\n        if abs(i-j)==1: W[i,j]=1\nW[0,0]=0\nW[n-1,n-1]=0\n\n\ngs=GraphSignal(V,W,f)\n\n\ngs.initdist=np.array([1/n]*n)\n\n\n\nHST\n\n%run heavysnow \nhst=HeavySnowTransform(gs)\nhst.snow(tau=80000,b=0.015,maxflow=2)\n\nHST (tau= 80000, b=0.015)\n80000/80000\nHST completed and all history is recorded.\n\n\n\nplt.imshow(hst.snowdistance)\n\n\n\n\n\n\n\n\n\nhst.snowweight=np.exp(-hst.snowdistance/(hst.tau*hst.b**1.5))-np.eye(n,n)\nplt.imshow(hst.snowweight)\n\n\n\n\n\n\n\n\n\n\n시각화를 위해서 R로 자료를 옮김\n\nmaxtau=hst.tau\nW_Graph=hst.graphweight\nW_Euclid=hst.euclidweight\nW_HST=hst.snowweight\nV=np.array(hst.V)\nf=hst.f\nn=hst.n\n%R -i maxtau,W_Graph,W_Euclid,W_HST,V,f,n\n\n\n\nR을 활용한 시각화 (1): 원래자료\n\n%%R -w 2000 -h 800 -r 100\nlibrary(tidyverse)\nlibrary(latex2exp)\nlibrary(gridExtra)\nsource('rbase.R')\nVtext=str_c('node ',V+1)\nfig0&lt;-ggplot(data=tibble(V=V,f=f,Vtext=Vtext),aes(x=V,y=f,label=Vtext))+\ngeom_col(aes(fill=(f&gt;0)),width=0.1)+geom_hline(aes(yintercept=0),col=\"gray60\",lty=2)+\ngeom_text(fontface = 4,size=8)+\nxlab(\"\")+ylab(\"\")+guides(fill=FALSE)+theme(plot.title=element_text(face=\"bold.italic\"))+theme_bw()+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 15, color = \"black\", face = \"bold.italic\"))+\nylim(-1.2,1.2)+\ntheme(plot.title=element_text(face=\"bold.italic\"))\n#ggsave(plot=p0,\"./fig/2021-0217_fig0.pdf\",width=20,height=6)\nfig0\n\nR[write to console]: ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\nR[write to console]: ✔ ggplot2 3.3.5     ✔ purrr   0.3.4\n✔ tibble  3.1.3     ✔ dplyr   1.0.7\n✔ tidyr   1.1.3     ✔ stringr 1.4.0\n✔ readr   1.4.0     ✔ forcats 0.5.1\n\nR[write to console]: ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nR[write to console]: Error in library(gridExtra) : there is no package called ‘gridExtra’\n\n\n\n\nError in library(gridExtra) : there is no package called ‘gridExtra’\n\n\nRInterpreterError: Failed to parse and evaluate line 'library(tidyverse)\\nlibrary(latex2exp)\\nlibrary(gridExtra)\\nsource(\\'rbase.R\\')\\nVtext=str_c(\\'node \\',V+1)\\nfig0&lt;-ggplot(data=tibble(V=V,f=f,Vtext=Vtext),aes(x=V,y=f,label=Vtext))+\\ngeom_col(aes(fill=(f&gt;0)),width=0.1)+geom_hline(aes(yintercept=0),col=\"gray60\",lty=2)+\\ngeom_text(fontface = 4,size=8)+\\nxlab(\"\")+ylab(\"\")+guides(fill=FALSE)+theme(plot.title=element_text(face=\"bold.italic\"))+theme_bw()+\\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\\ntheme(strip.text.y = element_text(size = 15, color = \"black\", face = \"bold.italic\"))+\\nylim(-1.2,1.2)+\\ntheme(plot.title=element_text(face=\"bold.italic\"))\\n#ggsave(plot=p0,\"./fig/2021-0217_fig0.pdf\",width=20,height=6)\\nfig0\\n'.\nR error message: 'Error in library(gridExtra) : there is no package called ‘gridExtra’'\n\n\n\n\nR을 활용한 시각화 (2): Weight matrix 와 Eigen plot\n- ggplot에서 geom_tile을 사용하기 위해서 매트릭스 형태인 W_Graph, W_Euclid, W_HST를 길게 펼친다. 결과를 각각 W_Graph_long, W_Euclid_long, W_HST_long에 저장한다.\n\n%%R\ngrid&lt;-expand.grid(x=1:n,y=1:n)\nW_Graph_long&lt;-as_tibble(cbind(grid,as.vector(W_Graph)));names(W_Graph_long)&lt;-c(\"x\",\"y\",\"W\")\nW_Euclid_long&lt;-as_tibble(cbind(grid,as.vector(W_Euclid)));names(W_Euclid_long)&lt;-c(\"x\",\"y\",\"W\")\nW_HST_long&lt;-as_tibble(cbind(grid,as.vector(W_HST)));names(W_HST_long)&lt;-c(\"x\",\"y\",\"W\")\n\n- 그래프퓨리에 변환: \\((\\bf{f},\\bf{W})\\)에 그래프 퓨리에 변환을 수행함.\n\n%%R\nsource('heavysnow.R')\ngfftrslt_Euclid&lt;-gfft(f,W_Euclid)\ngfftrslt_Graph&lt;-gfft(f,W_Graph)\ngfftrslt_HST&lt;-gfft(f,W_HST)\n\n- 그래프 퓨리에 변환의 결과 고유치, 고유벡터, \\(\\bf{\\bar{f}}\\)가 반환됨.\n\n%%R\nhead(gfftrslt_HST)\n\n- 시각화코드\n\n%%R -w 1000 -h 800 -r 100\nlibrary(gridExtra)\n\nfig1_1&lt;-ggplot()+geom_tile(data=W_Euclid_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"red\",high=\"blue\",mid=\"purple\",midpoint=0.25,breaks=c(0,0.5,0.99))+\nlabs(fill=TeX('$W$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(a) Euclid\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_2&lt;-ggplot()+geom_tile(data=W_Graph_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"red\",high=\"blue\",mid=\"purple\",midpoint=0.5,breaks=c(0,0.5,0.99))+\nlabs(fill=TeX('$\\\\hat{W}$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(b) Graph\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_3&lt;-ggplot()+geom_tile(data=W_HST_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"red\",high=\"blue\",mid=\"purple\",midpoint=0.5,breaks=c(0,0.5,0.99))+\nlabs(fill=TeX('$\\\\hat{W}(\\\\tau)$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(c) HST\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_4&lt;-eigenplot(gfftrslt_Euclid)+ylim(0,2)+theme_light()\nfig1_5&lt;-eigenplot(gfftrslt_Graph)+ylim(0,2)+theme_light()\nfig1_6&lt;-eigenplot(gfftrslt_HST)+ylim(0,2)+theme_light()\nfig1=grid.arrange(fig1_1,fig1_2,fig1_3,fig1_4,fig1_5,fig1_6,ncol=3,nrow=2)\nfig1\n#ggsave(plot=grid.arrange(p1_a,p1_b,p1_c,ncol=3),\"2021-07-22_fig1.png\",width=20,height=4)\n\n\n\nR을 활용한 시각화 (3): Decomposition\n- 디콤포지션을 수행하고 결과를 저장: \\((\\bf{f},\\bf{W})\\)에 decomposition을 수행하고 그 결과를 각각 decomprslt_Euclid, decomprslt_Graph, decomprslt_HST에 저장한다.\n\n%%R \ndecomprslt_Euclid&lt;-decompose(f,W_Euclid,V=1:n) # 0, 35000, 60000, 80000\ndecomprslt_Graph&lt;-decompose(f,W_Graph,V=1:n) # 0, 35000, 60000, 80000\ndecomprslt_HST&lt;-decompose(f,W_HST,V=1:n) # 0, 35000, 60000, 80000\n\n- 디콤포지션 결과는 아래와 같은 형태임\n\n%%R\nhead(decomprslt_Euclid)\n\n\n%%R \ndecomprslt_Euclid$method=\"Euclid\"\ndecomprslt_Graph$method=\"Graph\"\ndecomprslt_HST$method=\"HST\"\ndecomprslt&lt;-rbind(decomprslt_Euclid,decomprslt_Graph,decomprslt_HST)\n\n- 디콤포지션결과를 시각화한다. geom_col과 facet_grid를 이용.\n\n%%R -w 2000 -h 500 -r 100\nfig2&lt;-ggplot(data=decomprslt,aes(x=V,y=fhat))+\ngeom_col(aes(fill=fhat&gt;0),width=0.7)+facet_grid(method~eigenvectorindex)+geom_hline(aes(yintercept=0),col=\"gray60\",lty=2)+\nxlab(\"\")+ylab(\"\")+guides(fill=FALSE)+theme(plot.title=element_text(face=\"bold.italic\"))+theme_bw()+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 15, color = \"black\", face = \"bold.italic\"))+\nylim(-1.5,1.5)+\ntheme(plot.title=element_text(face=\"bold.italic\"))\nfig2\n#ggsave(plot=fig2,\"./fig/2021-0514_fig2.pdf\",width=20,height=6)"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-10-29-HST example 3 파이썬으로 변경.html",
    "href": "연구/교수님이랑/HST/2021-10-29-HST example 3 파이썬으로 변경.html",
    "title": "(연구&교수님) HST example 3, 파이썬으로 변경",
    "section": "",
    "text": "import\n\n## 1. remove trash\n#!rm -rf ~/.local/share/Trash/files/*\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib\n#matplotlib.rc('image', cmap='Greys')\nimport rpy2 \nfrom adjustText import adjust_text\n%load_ext rpy2.ipython\n%run heavysnow \n\nThe rpy2.ipython extension is already loaded. To reload it, use:\n  %reload_ext rpy2.ipython\n\n\n\n\nload data\n\nn=23\nf=np.array(pd.read_csv(\"2021-08-15-MCU-ticket.csv\").Worldwide)/1000000\nV=np.array(pd.read_csv(\"2021-08-15-MCU-ticket.csv\").Film)\nW=np.array(pd.read_csv(\"2021-08-15-MCU-weights.csv\",index_col=0))-np.eye(n,n)\n\n\n\nscatter plot\n\ndf=pd.DataFrame({'V':V,'f':f,'in_degree':[sum(W[:,i]) for i in range(n)],'out_degree':[sum(W[i,:]) for i in range(n)]})\ndf.head()\n\n\n\n\n\n\n\n\nV\nf\nin_degree\nout_degree\n\n\n\n\n0\nIron Man\n585.174222\n2.515815\n4.000000\n\n\n1\nThe Incredible Hulk\n263.427551\n0.294608\n1.000000\n\n\n2\nIron Man 2\n623.933331\n3.107363\n4.153846\n\n\n3\nThor\n449.326618\n2.241890\n2.562500\n\n\n4\nCaptain America: The First Avenger\n370.569774\n0.948269\n1.750000\n\n\n\n\n\n\n\n\ndf['type']='SOLO/NOT-CORE'\n\n\ndf.loc[map(lambda x: (\"Iron Man\" in x) or (\"Thor\" in x) or (\"Captain America\" in x),df1.V),'type']='SOLO/CORE'\ndf.loc[map(lambda x: (\"Avengers\" in x) or (\"Civil War\" in x),df1.V),'type']='MULTI'\n\n\ndf\n\n\n\n\n\n\n\n\nV\nf\nin_degree\nout_degree\ntype\n\n\n\n\n0\nIron Man\n585.174222\n2.515815\n4.000000\nSOLO/CORE\n\n\n1\nThe Incredible Hulk\n263.427551\n0.294608\n1.000000\nSOLO/NOT-CORE\n\n\n2\nIron Man 2\n623.933331\n3.107363\n4.153846\nSOLO/CORE\n\n\n3\nThor\n449.326618\n2.241890\n2.562500\nSOLO/CORE\n\n\n4\nCaptain America: The First Avenger\n370.569774\n0.948269\n1.750000\nSOLO/CORE\n\n\n5\nThe Avengers\n1518.812988\n4.332114\n4.647059\nMULTI\n\n\n6\nIron Man 3\n1214.811252\n1.690351\n3.200000\nSOLO/CORE\n\n\n7\nThor: The Dark World\n644.571402\n2.147921\n2.411765\nSOLO/CORE\n\n\n8\nCaptain America: The Winter Soldier\n714.264267\n2.455757\n3.266667\nSOLO/CORE\n\n\n9\nGuardians of the Galaxy\n773.328629\n1.212075\n1.631579\nSOLO/NOT-CORE\n\n\n10\nAvengers: Age of Ultron\n1405.403694\n4.428065\n3.952381\nMULTI\n\n\n11\nAnt-man\n519.311965\n1.096071\n1.750000\nSOLO/NOT-CORE\n\n\n12\nCaptain America: Civil War\n1153.304495\n4.048106\n3.500000\nMULTI\n\n\n13\nDoctor Strange\n677.718395\n0.182711\n0.857143\nSOLO/NOT-CORE\n\n\n14\nGuardians of the Galaxy Vol 2\n863.756051\n0.898435\n1.190476\nSOLO/NOT-CORE\n\n\n15\nSpider-man: Homecoming\n880.166924\n2.416100\n1.913043\nSOLO/NOT-CORE\n\n\n16\nThor: Ragnarok\n853.977126\n1.682512\n2.285714\nSOLO/CORE\n\n\n17\nBlack Panther\n1346.913161\n0.582001\n1.142857\nSOLO/NOT-CORE\n\n\n18\nAvengers: Infinity War\n2048.359754\n7.545470\n3.589744\nMULTI\n\n\n19\nAnt-man and the Wasp\n622.674139\n0.875455\n1.000000\nSOLO/NOT-CORE\n\n\n20\nCaptain Marvel\n1128.274794\n0.926001\n1.333333\nSOLO/NOT-CORE\n\n\n21\nAvengers: Endgame\n2796.274401\n8.935337\n3.120000\nMULTI\n\n\n22\nSpider-man: Far From Home\n1131.026557\n1.633182\n1.937500\nSOLO/NOT-CORE\n\n\n\n\n\n\n\n\nfig = ggplot(df) \na1= aes(x='in_degree',y='out_degree',size='f',color='type')\na2= aes(x='in_degree',y='out_degree',label='V',color='type')\npoint1= geom_point(a1)\n\n\np1=fig+point1\\\n+xlab(\"In-degree\")+ylab(\"Out-degree\")\\\n+geom_text(a2)+theme_minimal()\np1=p1.draw()\np1.set_figheight(7)\np1.set_figwidth(10)\n\n\n\n\n\n\n\n\n\nadjust_text(p1.axes[0].texts,ax=p1.axes[0], arrowprops=dict(arrowstyle='-', color='gray'))\n\n500\n\n\n&lt;Figure size 432x288 with 0 Axes&gt;\n\n\n\np1\n\n\n\n\n\n\n\n\n\n\nHST\n\ngs=GraphSignal(V,W,f)\nhst=HeavysnowTransform(gs)\nhst.snow(tau=20000,b=1)\n\nHST (tau= 20000, b=1)\n20000/20000\nHST completed and all history is recorded.\n\n\n\nplt.plot(hst.snowygrounds[:,0])\nplt.plot(hst.snowygrounds[:,2000])\nplt.plot(hst.snowygrounds[:,20000])\nplt.plot(hst.snowygrounds[:,40000])\nplt.plot(hst.snowygrounds[:,60000])\nplt.plot(hst.snowygrounds[:,-1])\n\nIndexError: index 40000 is out of bounds for axis 1 with size 20001\n\n\n\n\n\n\n\n\n\n\n\nSpectral analysis\n\n%run heavysnow\ngs=GraphSignal(V,hst.snowweight,f)\nspa=SpectralAnalysis(gs)\nspa.graphFouriertransform()\nspa.decompose()\n\n\ndef choose_theta(maxtheta=100):\n    y=[]\n    x=np.arange(start=0.01,stop=maxtheta,step=0.1)\n    for i in range(len(x)):\n        hst.adjustingtheta(x[i]) \n        gs=GraphSignal(V,hst.snowweight,f)\n        spa=SpectralAnalysis(gs)\n        spa.graphFouriertransform()\n        spa.decompose()        \n        y.append(sum(abs(spa.lamb)&lt;0.001))\n    plt.plot(x,y)\nchoose_theta()   \n\n/home/cgb3/Dropbox/01_yechan/_notebooks/heavysnow.py:11: RuntimeWarning: invalid value encountered in true_divide\n\n\n\n\n\n\n\n\n\n\nabs(spa.fbar)\n\narray([ 113.82693976,   69.1874798 ,  111.44376896,  120.73111873,\n         27.31894564,   28.72744563,   18.9015293 ,  129.94958627,\n         23.58492009,  117.97292179,   44.70789371,  257.06854198,\n        389.82856746,  234.97154632,  296.21620356, 1134.27156442,\n          4.21826872, 1321.97934777,  212.13470331, 3727.64704919,\n        686.79172621, 1947.68808622, 2796.274401  ])\n\n\n\nhst.adjustingtheta(100)\ngs=GraphSignal(V,hst.snowweight,f)\nspa=SpectralAnalysis(gs)\nspa.graphFouriertransform()\nspa.decompose() \nplt.plot(spa.lamb,abs(spa.fbar),'.')\n\n\n\n\n\n\n\n\n\nabs(spa.fbar)\n\narray([ 113.82693976,   69.1874798 ,  111.44376896,  120.73111873,\n         27.31894564,   28.72744563,   18.9015293 ,  129.94958627,\n         23.58492009,  117.97292179,   44.70789371,  257.06854198,\n        389.82856746,  234.97154632,  296.21620356, 1134.27156442,\n          4.21826872, 1321.97934777,  212.13470331, 3727.64704919,\n        686.79172621, 1947.68808622, 2796.274401  ])\n\n\n\nfig, axs= plt.subplots(1,3) \naxs[0].imshow(hst.euclidweight)\naxs[1].imshow(hst.snowweight)\naxs[2].imshow(hst.graphweight)\nfig.set_figwidth(15)\nfig.set_figheight(10)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n_a = pd.DataFrame({'lambda_i':spa.lamb}).reset_index().rename(columns={'index':'comp'})\n_b = pd.DataFrame(spa.components).stack().reset_index().rename(columns={'level_0':'Vindex','level_1':'comp',0:'fbar'})\n_ = pd.merge(_a,_b)\n\n\ndf2 =_.assign(comp=list(map(lambda x: spa.n-x, _.comp))).merge(pd.DataFrame({'V':df.V,'Vindex':range(spa.n),'fill':df.type}))\n\n\ndf2\n\n\n\n\n\n\n\n\ncomp\nlambda_i\nVindex\nfbar\nV\nfill\n\n\n\n\n0\n23\n1.648869e+00\n0\n-1.670024e-02\nIron Man\nSOLO/CORE\n\n\n1\n22\n1.502045e+00\n0\n-1.013031e-14\nIron Man\nSOLO/CORE\n\n\n2\n21\n1.422011e+00\n0\n8.004475e-02\nIron Man\nSOLO/CORE\n\n\n3\n20\n1.408156e+00\n0\n7.656253e-03\nIron Man\nSOLO/CORE\n\n\n4\n19\n1.394609e+00\n0\n-1.093432e-05\nIron Man\nSOLO/CORE\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n524\n5\n1.182634e-03\n22\n0.000000e+00\nSpider-man: Far From Home\nSOLO/NOT-CORE\n\n\n525\n4\n1.351494e-05\n22\n0.000000e+00\nSpider-man: Far From Home\nSOLO/NOT-CORE\n\n\n526\n3\n5.897675e-17\n22\n0.000000e+00\nSpider-man: Far From Home\nSOLO/NOT-CORE\n\n\n527\n2\n2.975736e-17\n22\n1.131027e+03\nSpider-man: Far From Home\nSOLO/NOT-CORE\n\n\n528\n1\n0.000000e+00\n22\n0.000000e+00\nSpider-man: Far From Home\nSOLO/NOT-CORE\n\n\n\n\n529 rows × 6 columns\n\n\n\n\nggplot(df2)+facet_wrap('comp')+geom_col(aes(x='Vindex',y='fbar',fill='fill'))\n\n\n\n\n\n\n\n\n\nplt.plot(df2.query(\" V=='Avengers: Infinity War' \")['fbar'],'.')\ndf2.query(\" V=='Avengers: Infinity War' \")['fbar'].sum()\n\n2048.359754000001\n\n\n\n\n\n\n\n\n\n\nf\n\narray([ 585.174222,  263.427551,  623.933331,  449.326618,  370.569774,\n       1518.812988, 1214.811252,  644.571402,  714.264267,  773.328629,\n       1405.403694,  519.311965, 1153.304495,  677.718395,  863.756051,\n        880.166924,  853.977126, 1346.913161, 2048.359754,  622.674139,\n       1128.274794, 2796.274401, 1131.026557])\n\n\n\nfig=ggplot(df2)\nfacet=facet_wrap('comp',ncol=1)\na1=aes(x='Vindex',y='fbar',fill='fill')\na2=aes(x='Vindex',y='fbar',label='V')\ncol=geom_col(a1,alpha=0.5)\nhline=geom_hline(yintercept=0,linetype='dashed',color='gray',size=0.3)\n\np2=fig+facet\\\n+geom_col(a1)\\\n+geom_hline(yintercept=0,linetype='dashed',color='gray')\\\n+theme(figure_size=(20, 100))\\\n+geom_text(a2)\np2\n\n\n\n\n\n\n\n\n\n\n유클리드와 그래프도메인의 정보를 플랏.\n\n%R -i f\n\n\nWW =hst.snowweight\n\n\n%R -i WW\n\n\n%%R \ndegree&lt;-function(W){\n    diag(apply(W,1,sum))\n}\ndegree_rootinv&lt;-function(W){\n    d&lt;-apply(W,1,sum)\n    drootinv&lt;-d\n    drootinv[d&gt;0.01]&lt;-sqrt(1/d[d&gt;0.01])\n    diag(drootinv)\n}\n\n\n%%R \ngfft&lt;-function(f,W){\n    n&lt;-length(f)\n    D&lt;-degree(W)\n    D_rootinv&lt;-degree_rootinv(W)\n    L&lt;-D-W\n    L_tilde&lt;-D_rootinv%*%L%*%D_rootinv\n    svdrslt&lt;-svd(L_tilde)\n    λ&lt;-svdrslt$d\n    Λ&lt;-diag(λ)\n    U&lt;-svdrslt$u; \n    V&lt;-svdrslt$v; \n    Ψ&lt;-U\n    ## reconstruction: L_tilde &lt;- U%*%Lamb*t(V) or L_tilde &lt;- Psi%*%Lamb*t(Psi)\n    fbar&lt;-as.vector(t(Ψ)%*%f) ## fhat is Fourier Transform of f. \n    list(λ=λ,Ψ=Ψ,fbar=fbar)\n}\n\n\n%%R \nPsi=gfft(f,WW)$Ψ\nlamb=gfft(f,WW)$λ\nfbar=gfft(f,WW)$fbar\n\n\n%R -o Psi \n%R -o lamb \n%R -o fbar\n\n\n%%R \nA=rbind(c(1,2,4,5),c(2,3,1,0),c(5,4,0,2),c(2,0,0,1))\nsvd(L_tilde)\n\n$d\n [1]  2.000000e+00  2.000000e+00  2.220446e-16  1.251279e-71  2.072649e-87\n [6] 3.094230e-204 3.094230e-204  0.000000e+00  0.000000e+00  0.000000e+00\n[11]  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00\n[16]  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00\n[21]  0.000000e+00  0.000000e+00  0.000000e+00\n\n$u\n            [,1]           [,2]       [,3]       [,4]       [,5]           [,6]\n [1,]  0.0000000   0.000000e+00  0.0000000  0.0000000  0.0000000   0.000000e+00\n [2,]  0.0000000   0.000000e+00  0.0000000  0.0000000  0.0000000   0.000000e+00\n [3,]  0.0000000  -7.071068e-01  0.0000000  0.0000000  0.0000000 -1.995229e-204\n [4,]  0.0000000   0.000000e+00  0.0000000  0.0000000  0.0000000   0.000000e+00\n [5,]  0.0000000   0.000000e+00  0.0000000  0.0000000  0.0000000   0.000000e+00\n [6,]  0.0000000   0.000000e+00  0.0000000  0.0000000  0.0000000   0.000000e+00\n [7,]  0.0000000   0.000000e+00  0.0000000  0.0000000  0.0000000   0.000000e+00\n [8,]  0.0000000  1.542089e-204  0.0000000  0.0000000  0.0000000  -1.000000e+00\n [9,]  0.0000000   0.000000e+00  0.0000000  0.0000000  0.0000000   0.000000e+00\n[10,]  0.0000000   0.000000e+00  0.0000000  0.0000000  0.0000000   0.000000e+00\n[11,]  0.0000000   0.000000e+00  0.0000000  0.0000000  0.0000000   0.000000e+00\n[12,]  0.0000000   0.000000e+00  0.0000000  0.0000000  0.0000000   0.000000e+00\n[13,]  0.0000000   0.000000e+00  0.0000000  0.0000000  0.0000000   0.000000e+00\n[14,]  0.0000000   0.000000e+00  0.0000000  0.0000000  0.0000000   0.000000e+00\n[15,]  0.0000000   0.000000e+00  0.0000000  0.7071068 -0.7071068   0.000000e+00\n[16,]  0.0000000   0.000000e+00  0.0000000  0.0000000  0.0000000   0.000000e+00\n[17,]  0.0000000   0.000000e+00  0.0000000 -0.7071068 -0.7071068   0.000000e+00\n[18,]  0.0000000   0.000000e+00  0.0000000  0.0000000  0.0000000   0.000000e+00\n[19,]  0.0000000   0.000000e+00  0.0000000  0.0000000  0.0000000   0.000000e+00\n[20,]  0.0000000   7.071068e-01  0.0000000  0.0000000  0.0000000  1.856148e-205\n[21,] -0.7071068   0.000000e+00 -0.7071068  0.0000000  0.0000000   0.000000e+00\n[22,]  0.0000000   0.000000e+00  0.0000000  0.0000000  0.0000000   0.000000e+00\n[23,]  0.7071068   0.000000e+00 -0.7071068  0.0000000  0.0000000   0.000000e+00\n                [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] [,15]\n [1,]   0.000000e+00    0    0     0     0     0     0     0     0\n [2,]   0.000000e+00    0    0     0     0     0     0     0     0\n [3,]   7.071068e-01    0    0     0     0     0     0     0     0\n [4,]   0.000000e+00    0    0     0     0     0     0     0     0\n [5,]   0.000000e+00    0    0     0     0     0     1     0     0\n [6,]   0.000000e+00    0    0     0     0     0     0     0     0\n [7,]   0.000000e+00    0    0     0     0     0     0     0     0\n [8,] -1.279590e-204    0    0     0     0     0     0     0     0\n [9,]   0.000000e+00    0    0     0     0     0     0     0     0\n[10,]   0.000000e+00    0    0     0     0     0     0     0     0\n[11,]   0.000000e+00    1    0     0     0     0     0     0     0\n[12,]   0.000000e+00    0    1     0     0     0     0     0     0\n[13,]   0.000000e+00    0    0     0     0     0     0     0     0\n[14,]   0.000000e+00    0    0     0     0     0     0    -1     0\n[15,]   0.000000e+00    0    0     0     0     0     0     0     0\n[16,]   0.000000e+00    0    0    -1     0     0     0     0     0\n[17,]   0.000000e+00    0    0     0     0     0     0     0     0\n[18,]   0.000000e+00    0    0     0     1     0     0     0     0\n[19,]   0.000000e+00    0    0     0     0     1     0     0     0\n[20,]   7.071068e-01    0    0     0     0     0     0     0     0\n[21,]   0.000000e+00    0    0     0     0     0     0     0     0\n[22,]   0.000000e+00    0    0     0     0     0     0     0     1\n[23,]   0.000000e+00    0    0     0     0     0     0     0     0\n              [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23]\n [1,]  0.000000e+00     0     0     0     0     0     0     1\n [2,]  0.000000e+00     0     0     0     0     0     1     0\n [3,]  0.000000e+00     0     0     0     0     0     0     0\n [4,]  0.000000e+00     0     0    -1     0     0     0     0\n [5,]  0.000000e+00     0     0     0     0     0     0     0\n [6,]  0.000000e+00     0     0     0     0     1     0     0\n [7,]  0.000000e+00     0     0     0     1     0     0     0\n [8,]  0.000000e+00     0     0     0     0     0     0     0\n [9,]  0.000000e+00     0     1     0     0     0     0     0\n[10,]  0.000000e+00     1     0     0     0     0     0     0\n[11,]  0.000000e+00     0     0     0     0     0     0     0\n[12,]  0.000000e+00     0     0     0     0     0     0     0\n[13,]  1.000000e+00     0     0     0     0     0     0     0\n[14,]  0.000000e+00     0     0     0     0     0     0     0\n[15,]  0.000000e+00     0     0     0     0     0     0     0\n[16,]  0.000000e+00     0     0     0     0     0     0     0\n[17,]  0.000000e+00     0     0     0     0     0     0     0\n[18,]  0.000000e+00     0     0     0     0     0     0     0\n[19,]  0.000000e+00     0     0     0     0     0     0     0\n[20,]  0.000000e+00     0     0     0     0     0     0     0\n[21,] -1.295618e-33     0     0     0     0     0     0     0\n[22,]  0.000000e+00     0     0     0     0     0     0     0\n[23,]  0.000000e+00     0     0     0     0     0     0     0\n\n$v\n                [,1]           [,2]           [,3]          [,4]          [,5]\n [1,]   0.000000e+00   0.000000e+00   0.000000e+00  0.000000e+00  0.000000e+00\n [2,]   0.000000e+00   0.000000e+00   0.000000e+00  0.000000e+00  0.000000e+00\n [3,]   0.000000e+00  -7.071068e-01   0.000000e+00  0.000000e+00  0.000000e+00\n [4,]   0.000000e+00   0.000000e+00   0.000000e+00  0.000000e+00  0.000000e+00\n [5,]   0.000000e+00   0.000000e+00   0.000000e+00  0.000000e+00  0.000000e+00\n [6,]   0.000000e+00   0.000000e+00   0.000000e+00  0.000000e+00  0.000000e+00\n [7,]   0.000000e+00   0.000000e+00   0.000000e+00  0.000000e+00  0.000000e+00\n [8,]   0.000000e+00  1.542089e-204   0.000000e+00  0.000000e+00  0.000000e+00\n [9,]   0.000000e+00   0.000000e+00   0.000000e+00  0.000000e+00  0.000000e+00\n[10,]   0.000000e+00   0.000000e+00   0.000000e+00  0.000000e+00  0.000000e+00\n[11,]   0.000000e+00   0.000000e+00   0.000000e+00  0.000000e+00  0.000000e+00\n[12,]   0.000000e+00   0.000000e+00   0.000000e+00  0.000000e+00  0.000000e+00\n[13,] -1.175703e-267   0.000000e+00  1.058979e-251  0.000000e+00  0.000000e+00\n[14,]   0.000000e+00   0.000000e+00  -1.000000e+00  1.570092e-16  2.453269e-18\n[15,]   0.000000e+00   0.000000e+00   0.000000e+00  7.071068e-01  2.080627e-02\n[16,]   0.000000e+00   0.000000e+00   0.000000e+00  1.110223e-16  9.995670e-01\n[17,]   0.000000e+00   0.000000e+00   0.000000e+00 -7.071068e-01  2.080627e-02\n[18,]   0.000000e+00   0.000000e+00   0.000000e+00  0.000000e+00  0.000000e+00\n[19,]   0.000000e+00   0.000000e+00   0.000000e+00  0.000000e+00  0.000000e+00\n[20,]   0.000000e+00   7.071068e-01   0.000000e+00  0.000000e+00  0.000000e+00\n[21,]  -7.071068e-01   0.000000e+00  -1.110223e-16  2.465190e-32  3.851860e-34\n[22,]   0.000000e+00   0.000000e+00   0.000000e+00  0.000000e+00  0.000000e+00\n[23,]   7.071068e-01   0.000000e+00   1.110223e-16 -2.465190e-32 -3.851860e-34\n               [,6]           [,7] [,8] [,9]         [,10] [,11] [,12]\n [1,]  0.000000e+00   0.000000e+00    0    0  0.000000e+00     0     0\n [2,]  0.000000e+00   0.000000e+00    0    0  0.000000e+00     0     0\n [3,]  7.071068e-01   0.000000e+00    0    0  0.000000e+00     0     0\n [4,]  0.000000e+00  2.180843e-204    0    0  0.000000e+00     0     0\n [5,]  0.000000e+00   0.000000e+00    0    0  0.000000e+00     0     0\n [6,]  0.000000e+00   0.000000e+00    0    0  0.000000e+00     0     0\n [7,]  0.000000e+00   0.000000e+00    0    0  0.000000e+00     0     0\n [8,] 1.542089e-204  -1.000000e+00    0    0  0.000000e+00     0     0\n [9,]  0.000000e+00   0.000000e+00    0    0  0.000000e+00     0     0\n[10,]  0.000000e+00   0.000000e+00    0    0  0.000000e+00     0     0\n[11,]  0.000000e+00   0.000000e+00    1    0  0.000000e+00     0     0\n[12,]  0.000000e+00   0.000000e+00    0    1  0.000000e+00     0     0\n[13,]  0.000000e+00   0.000000e+00    0    0  1.000000e+00     0     0\n[14,]  0.000000e+00   0.000000e+00    0    0 1.058979e-251     0     0\n[15,]  0.000000e+00   0.000000e+00    0    0  0.000000e+00     0     0\n[16,]  0.000000e+00   0.000000e+00    0    0  0.000000e+00     0     0\n[17,]  0.000000e+00   0.000000e+00    0    0  0.000000e+00     0     0\n[18,]  0.000000e+00   0.000000e+00    0    0  0.000000e+00     1     0\n[19,]  0.000000e+00   0.000000e+00    0    0  0.000000e+00     0     1\n[20,]  7.071068e-01  2.180843e-204    0    0  0.000000e+00     0     0\n[21,]  0.000000e+00   0.000000e+00    0    0  0.000000e+00     0     0\n[22,]  0.000000e+00   0.000000e+00    0    0  0.000000e+00     0     0\n[23,]  0.000000e+00   0.000000e+00    0    0  0.000000e+00     0     0\n               [,13]       [,14] [,15]       [,16] [,17] [,18] [,19] [,20]\n [1,]   0.000000e+00  0.00000000     0  0.00000000     0     0     0     0\n [2,]   0.000000e+00  0.00000000     0  0.00000000     0     0     0     0\n [3,]   0.000000e+00  0.00000000     0  0.00000000     0     0     0     0\n [4,]  -1.000000e+00  0.00000000     0  0.00000000     0     0     0     0\n [5,]   0.000000e+00  0.00000000     0  0.00000000     0     0     1     0\n [6,]   0.000000e+00  0.00000000     0  0.00000000     0     0     0     0\n [7,]   0.000000e+00  0.00000000     0  0.00000000     0     0     0     1\n [8,] -2.180843e-204  0.00000000     0  0.00000000     0     0     0     0\n [9,]   0.000000e+00  0.00000000     0  0.00000000     0     1     0     0\n[10,]   0.000000e+00  0.00000000     0  0.00000000     1     0     0     0\n[11,]   0.000000e+00  0.00000000     0  0.00000000     0     0     0     0\n[12,]   0.000000e+00  0.00000000     0  0.00000000     0     0     0     0\n[13,]   0.000000e+00  0.00000000     0  0.00000000     0     0     0     0\n[14,]   0.000000e+00  0.00000000     0  0.00000000     0     0     0     0\n[15,]   0.000000e+00  0.49978350     0 -0.49978350     0     0     0     0\n[16,]   0.000000e+00 -0.02080627     0  0.02080627     0     0     0     0\n[17,]   0.000000e+00  0.49978350     0 -0.49978350     0     0     0     0\n[18,]   0.000000e+00  0.00000000     0  0.00000000     0     0     0     0\n[19,]   0.000000e+00  0.00000000     0  0.00000000     0     0     0     0\n[20,]   0.000000e+00  0.00000000     0  0.00000000     0     0     0     0\n[21,]   0.000000e+00  0.50000000     0  0.50000000     0     0     0     0\n[22,]   0.000000e+00  0.00000000     1  0.00000000     0     0     0     0\n[23,]   0.000000e+00  0.50000000     0  0.50000000     0     0     0     0\n      [,21] [,22] [,23]\n [1,]     0     0     1\n [2,]     0     1     0\n [3,]     0     0     0\n [4,]     0     0     0\n [5,]     0     0     0\n [6,]     1     0     0\n [7,]     0     0     0\n [8,]     0     0     0\n [9,]     0     0     0\n[10,]     0     0     0\n[11,]     0     0     0\n[12,]     0     0     0\n[13,]     0     0     0\n[14,]     0     0     0\n[15,]     0     0     0\n[16,]     0     0     0\n[17,]     0     0     0\n[18,]     0     0     0\n[19,]     0     0     0\n[20,]     0     0     0\n[21,]     0     0     0\n[22,]     0     0     0\n[23,]     0     0     0\n\n\n\n\nnp.linalg.svd(spa.Lz)\n\n(array([[ 8.31802845e-07, -2.28244345e-02,  1.69005964e-05,\n          8.32458517e-05,  1.37445367e-03, -1.69822716e-03,\n         -2.72169523e-04,  1.62367170e-01,  1.00120612e-01,\n          7.87048705e-01,  2.28051493e-03,  1.30702273e-01,\n         -2.37071773e-01, -1.52905997e-02,  2.00695093e-01,\n          2.67355662e-01, -2.13953115e-01,  1.09902642e-01,\n          7.86967503e-02, -1.48612089e-01, -2.68747745e-01,\n          1.30686848e-15,  0.00000000e+00],\n        [-1.73745237e-07,  5.82817056e-01,  3.19679606e-06,\n          1.95527208e-05, -4.01026817e-04,  1.79423330e-03,\n          1.42218015e-03, -2.93595666e-01, -1.03797754e-02,\n          1.14069591e-01,  6.91273124e-04,  4.16978017e-02,\n         -8.86891483e-02, -1.23071410e-02,  2.91466972e-01,\n         -4.03091203e-01,  4.10097210e-01,  3.04233036e-01,\n          1.72107925e-01, -5.85142438e-02, -1.00131938e-01,\n          4.86771502e-16,  0.00000000e+00],\n        [ 1.79945470e-06, -8.86372067e-03, -1.04110175e-05,\n         -9.71301027e-06,  4.57105960e-03, -4.80419733e-03,\n         -1.70253832e-03,  6.84489722e-02, -8.94572257e-02,\n         -3.62195685e-01,  7.07057922e-01, -8.91235662e-02,\n         -3.08771296e-01, -1.43439358e-02,  2.87180479e-01,\n          1.38574486e-03, -2.50779597e-01,  5.25321979e-02,\n          4.62662964e-02, -1.53603086e-01, -2.80575388e-01,\n          1.27474638e-15,  0.00000000e+00],\n        [-3.81405817e-07,  3.49123335e-01, -1.13849656e-05,\n         -5.20669020e-05,  1.71456172e-03, -4.55458198e-03,\n         -3.23802030e-03,  6.03887632e-01,  1.59324493e-02,\n         -1.71482299e-01, -1.01439208e-03, -6.13090187e-02,\n          1.29497547e-01,  1.64717834e-02, -3.63078784e-01,\n          3.19851736e-01,  2.19096359e-01,  3.13539902e-01,\n          1.85056706e-01, -1.08809944e-01, -1.90814734e-01,\n          9.28237485e-16,  0.00000000e+00],\n        [ 3.16749182e-07, -7.33268982e-01, -5.84182485e-07,\n         -5.10615468e-06,  1.76538169e-05, -3.21602859e-04,\n         -2.73625670e-04,  5.32095578e-02,  8.79091764e-04,\n         -4.98735345e-03, -2.44886069e-05, -1.33381519e-03,\n          2.20628230e-03, -9.51433687e-04,  4.34514775e-02,\n         -1.84099352e-01,  4.42865286e-01,  3.83729129e-01,\n          2.19747367e-01, -8.96443849e-02, -1.54818075e-01,\n          7.52880680e-16,  0.00000000e+00],\n        [-4.21211716e-01, -1.26228933e-06,  9.91140473e-03,\n          1.05442602e-01, -2.34738842e-02,  8.53928708e-02,\n         -4.37304704e-01, -1.81877637e-03, -1.21592942e-02,\n          3.22860569e-03,  1.99130400e-04,  6.87072180e-03,\n         -8.67943385e-03,  5.85421891e-01,  2.28593792e-02,\n          3.80026942e-03,  1.21361156e-02, -2.35507433e-01,\n          4.01787503e-01,  2.04572687e-01, -9.92561433e-02,\n          5.47220932e-16,  0.00000000e+00],\n        [ 7.57297687e-02, -6.30483358e-06,  3.91285206e-02,\n          3.71727089e-01, -4.54039898e-02,  1.26342172e-01,\n         -6.01054964e-01, -1.99193673e-03, -3.77249821e-04,\n         -4.01709394e-04, -4.51319737e-05, -1.59359360e-03,\n          2.37308481e-03, -5.22068979e-01, -2.88333379e-02,\n         -8.70800118e-03, -1.75269179e-02,  9.61943777e-02,\n         -1.21708705e-01,  3.73352537e-01, -1.94988884e-01,\n          1.03622738e-15,  0.00000000e+00],\n        [ 1.86543546e-06, -2.97029443e-03, -3.36972961e-05,\n         -1.05359128e-04,  4.99362785e-03, -5.24357048e-03,\n         -2.35731474e-03,  2.37200800e-02, -1.09617362e-01,\n         -6.16365153e-02,  1.42842702e-02,  5.07740516e-01,\n          7.11653463e-01, -4.13443733e-03,  1.88246122e-01,\n         -1.34691861e-01, -2.46561507e-01,  2.10092754e-02,\n          2.76205858e-02, -1.53692883e-01, -2.82641870e-01,\n          1.37503249e-15,  0.00000000e+00],\n        [-7.99573985e-06,  3.95206738e-03, -6.27063562e-05,\n         -3.92509820e-04, -1.69919218e-02,  1.62054211e-02,\n          2.80023428e-03, -4.07149823e-02,  6.87137136e-01,\n         -6.93247574e-02,  7.38886061e-03,  2.21976985e-01,\n         -1.87390215e-01,  2.61529015e-02, -4.24713135e-01,\n         -3.69548565e-01, -1.14035532e-01, -9.97472687e-02,\n         -4.81725917e-02, -1.41761537e-01, -2.70847893e-01,\n          1.31690350e-15,  0.00000000e+00],\n        [-3.95062745e-05,  1.57431046e-03,  4.06604890e-04,\n          1.18991491e-03, -7.33907458e-02,  7.64563613e-02,\n          3.33175204e-02, -5.19933079e-03, -6.78035427e-01,\n          1.21947194e-01,  6.51141842e-03,  2.21973929e-01,\n         -2.57726712e-01,  5.74820600e-03, -4.45391431e-01,\n         -2.23195140e-01,  9.46570807e-02, -2.15389710e-01,\n         -1.24586624e-01, -1.23608317e-01, -2.50818380e-01,\n          1.21581416e-15,  0.00000000e+00],\n        [ 7.42676668e-01,  1.32904594e-06, -3.99249712e-03,\n         -3.94942827e-02,  7.34555531e-03, -2.26382886e-02,\n          1.10541819e-01,  3.97233327e-04,  8.59303569e-04,\n         -1.51619560e-04, -6.17706951e-06, -2.07405990e-04,\n          2.05099427e-04,  4.74556551e-02,  3.47728873e-03,\n          1.70086239e-03,  1.25454062e-02, -2.83772670e-01,\n          4.90026906e-01,  2.99206276e-01, -1.46514769e-01,\n          6.96183304e-16,  0.00000000e+00],\n        [-3.90910918e-07, -6.36400071e-03,  2.21728059e-05,\n          7.82229365e-05, -4.58350808e-03,  7.96250033e-03,\n          4.65490914e-03, -7.12305097e-01, -1.02963001e-02,\n         -9.01948826e-02, -2.89885212e-04, -2.39584007e-02,\n          5.89179260e-02,  9.93604657e-03, -2.82526103e-01,\n          5.16201870e-01, -3.87611918e-02,  2.09850059e-01,\n          1.31822329e-01, -1.30288266e-01, -2.32190851e-01,\n          1.12860186e-15,  0.00000000e+00],\n        [ 4.19197158e-03, -3.33385384e-06, -3.37382216e-02,\n         -8.28576687e-01,  5.81916530e-03,  3.00909739e-02,\n         -1.88089877e-01, -1.03679492e-03, -6.50140854e-03,\n          1.56416197e-03,  8.88984740e-05,  3.05321800e-03,\n         -3.71410692e-03,  6.77143011e-02, -2.98911556e-03,\n         -4.54139776e-03, -1.88890206e-02,  1.62808110e-01,\n         -2.36446569e-01,  3.83251555e-01, -2.04088197e-01,\n          1.02375742e-15,  0.00000000e+00],\n        [-5.66982260e-08,  2.55064959e-03, -7.19961507e-05,\n         -3.00326201e-04,  6.07234653e-04, -1.09077308e-03,\n         -2.15658870e-03, -2.46346567e-02, -5.50520388e-02,\n          1.96041569e-01, -2.69369204e-02, -7.77356097e-01,\n          3.24311614e-01,  1.64295269e-02, -1.13776766e-01,\n         -3.00731043e-01, -2.04937318e-01, -3.32171483e-02,\n         -5.70435499e-03, -1.50080534e-01, -2.80031330e-01,\n          1.36278202e-15,  0.00000000e+00],\n        [ 4.10395438e-05, -3.13366217e-04,  8.14273566e-04,\n          5.56447636e-03,  6.41222150e-01,  5.01569971e-01,\n          5.62343554e-02,  4.95667053e-03,  8.51669174e-02,\n         -2.04955771e-02, -1.19727187e-03, -4.10396061e-02,\n          4.97920470e-02, -1.12808282e-02,  1.39500146e-01,\n          1.47501547e-01,  3.11105818e-01, -3.04008474e-01,\n         -1.92176972e-01, -9.10637927e-02, -2.15471294e-01,\n          1.05080883e-15,  0.00000000e+00],\n        [ 1.48848758e-04, -2.35982660e-04, -3.53800726e-03,\n         -1.71372928e-02, -7.45851291e-01,  2.44486580e-01,\n          8.56940821e-02,  1.15410572e-02,  1.31798247e-01,\n         -3.31660885e-02, -1.86999343e-03, -6.43221718e-02,\n          7.83897657e-02, -2.74666493e-03,  1.98432101e-01,\n          1.79123088e-01,  3.17444893e-01, -2.97926254e-01,\n         -1.92852034e-01, -8.18949588e-02, -2.06142479e-01,\n          9.93177050e-16,  0.00000000e+00],\n        [ 8.78543271e-07, -3.17838052e-04,  1.34421400e-03,\n          6.78594911e-03,  1.51549473e-01, -8.02101418e-01,\n         -1.75991858e-01, -8.06160106e-03,  4.14051119e-02,\n         -8.94283673e-03, -5.89880091e-04, -2.01057558e-02,\n          2.42119590e-02, -1.44689643e-02,  8.93288614e-02,\n          1.20168864e-01,  3.01542324e-01, -3.03845431e-01,\n         -1.89928235e-01, -9.58247486e-02, -2.20590883e-01,\n          1.08307003e-15,  0.00000000e+00],\n        [-5.14913484e-01,  4.18430716e-07, -9.80986052e-03,\n         -1.03562437e-01,  2.24827063e-02, -8.16855839e-02,\n          4.18037887e-01,  1.73339634e-03,  1.11731626e-02,\n         -2.93783168e-03, -1.79887167e-04, -6.20431547e-03,\n          7.81293050e-03, -4.94481358e-01, -1.81997957e-02,\n         -1.90892495e-03,  5.98037592e-03, -2.06293518e-01,\n          3.65843309e-01,  3.11017153e-01, -1.54468446e-01,\n          6.89446812e-16,  0.00000000e+00],\n        [-3.30872245e-24, -6.46234854e-27, -6.93889390e-18,\n          3.46944695e-18, -3.46944695e-18, -2.77555756e-17,\n          2.22044605e-16,  1.08420217e-19, -4.33680869e-19,\n          2.16840434e-19, -2.49800181e-16,  0.00000000e+00,\n         -8.67361738e-19,  2.71050543e-20,  2.11758237e-22,\n         -1.55096365e-25, -1.03397577e-25, -9.92616735e-24,\n          1.65436123e-23,  1.82641479e-21, -4.82947016e-15,\n         -1.00000000e+00,  0.00000000e+00],\n        [ 1.79531969e-06, -8.94842690e-03, -1.01546268e-05,\n         -8.73262658e-06,  4.55614976e-03, -4.79156777e-03,\n         -1.69335914e-03,  6.90829904e-02, -8.89583848e-02,\n         -3.67777353e-01, -7.06420773e-01, -4.41061120e-02,\n         -3.12741481e-01, -1.44351074e-02,  2.87782945e-01,\n          3.18915913e-03, -2.50720746e-01,  5.29210854e-02,\n          4.64923431e-02, -1.53587496e-01, -2.80525323e-01,\n          1.45326093e-15,  0.00000000e+00],\n        [-8.33021631e-03,  1.05962533e-05,  7.09113594e-01,\n          2.40362541e-01,  1.65950319e-02, -6.45471772e-02,\n          3.19056399e-01,  1.13629083e-03,  1.20076058e-04,\n          2.58146832e-04,  2.73459895e-05,  9.63515224e-04,\n         -1.41365588e-03,  2.63265400e-01,  1.27213549e-02,\n          1.05603468e-03, -1.39706382e-02,  1.64799812e-01,\n         -2.50268914e-01,  3.66433378e-01, -1.98337145e-01,\n          9.19573780e-16,  0.00000000e+00],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00, -1.00000000e+00],\n        [-7.36022066e-03,  8.23867965e-06, -7.03038426e-01,\n          3.06153537e-01,  1.79901928e-02, -5.91845158e-02,\n          2.84078264e-01,  9.35442758e-04, -8.43705836e-04,\n          4.66038804e-04,  3.80317664e-05,  1.32834008e-03,\n         -1.83555043e-03,  2.48090528e-01,  1.10378059e-02,\n          3.25080258e-04, -1.47079819e-02,  1.65391227e-01,\n         -2.49763201e-01,  3.68918163e-01, -1.99236686e-01,\n          9.21646644e-16,  0.00000000e+00]]),\n array([1.62354816e+00, 1.54316369e+00, 1.35756541e+00, 1.34448641e+00,\n        1.31529137e+00, 1.29394024e+00, 1.28834537e+00, 1.27251369e+00,\n        1.20017996e+00, 1.18789691e+00, 1.17953136e+00, 1.17909170e+00,\n        1.17562417e+00, 1.11826799e+00, 1.07719638e+00, 8.87648300e-01,\n        4.23129021e-01, 2.66322700e-01, 2.52463591e-01, 1.37935777e-02,\n        2.83343727e-09, 1.11370076e-17, 0.00000000e+00]),\n array([[ 8.31802845e-07, -1.73745237e-07,  1.79945470e-06,\n         -3.81405817e-07,  3.16749182e-07, -4.21211716e-01,\n          7.57297687e-02,  1.86543546e-06, -7.99573985e-06,\n         -3.95062745e-05,  7.42676668e-01, -3.90910918e-07,\n          4.19197158e-03, -5.66982261e-08,  4.10395438e-05,\n          1.48848758e-04,  8.78543271e-07, -5.14913484e-01,\n          2.11758237e-22,  1.79531969e-06, -8.33021631e-03,\n          0.00000000e+00, -7.36022066e-03],\n        [-2.28244345e-02,  5.82817056e-01, -8.86372067e-03,\n          3.49123335e-01, -7.33268982e-01, -1.26228933e-06,\n         -6.30483358e-06, -2.97029443e-03,  3.95206738e-03,\n          1.57431046e-03,  1.32904594e-06, -6.36400071e-03,\n         -3.33385384e-06,  2.55064959e-03, -3.13366217e-04,\n         -2.35982660e-04, -3.17838052e-04,  4.18430716e-07,\n          0.00000000e+00, -8.94842690e-03,  1.05962533e-05,\n          0.00000000e+00,  8.23867965e-06],\n        [ 1.69005964e-05,  3.19679606e-06, -1.04110175e-05,\n         -1.13849656e-05, -5.84182485e-07,  9.91140473e-03,\n          3.91285206e-02, -3.36972961e-05, -6.27063562e-05,\n          4.06604890e-04, -3.99249712e-03,  2.21728059e-05,\n         -3.37382216e-02, -7.19961507e-05,  8.14273566e-04,\n         -3.53800726e-03,  1.34421400e-03, -9.80986052e-03,\n         -1.11022302e-16, -1.01546268e-05,  7.09113594e-01,\n          0.00000000e+00, -7.03038426e-01],\n        [ 8.32458517e-05,  1.95527208e-05, -9.71301027e-06,\n         -5.20669020e-05, -5.10615468e-06,  1.05442602e-01,\n          3.71727089e-01, -1.05359128e-04, -3.92509820e-04,\n          1.18991491e-03, -3.94942827e-02,  7.82229365e-05,\n         -8.28576687e-01, -3.00326201e-04,  5.56447636e-03,\n         -1.71372928e-02,  6.78594911e-03, -1.03562437e-01,\n          5.55111512e-17, -8.73262658e-06,  2.40362541e-01,\n          0.00000000e+00,  3.06153537e-01],\n        [ 1.37445367e-03, -4.01026817e-04,  4.57105960e-03,\n          1.71456172e-03,  1.76538169e-05, -2.34738842e-02,\n         -4.54039898e-02,  4.99362785e-03, -1.69919218e-02,\n         -7.33907458e-02,  7.34555531e-03, -4.58350808e-03,\n          5.81916530e-03,  6.07234653e-04,  6.41222150e-01,\n         -7.45851291e-01,  1.51549473e-01,  2.24827063e-02,\n          0.00000000e+00,  4.55614976e-03,  1.65950319e-02,\n          0.00000000e+00,  1.79901928e-02],\n        [-1.69822716e-03,  1.79423330e-03, -4.80419733e-03,\n         -4.55458198e-03, -3.21602859e-04,  8.53928708e-02,\n          1.26342172e-01, -5.24357048e-03,  1.62054211e-02,\n          7.64563613e-02, -2.26382886e-02,  7.96250033e-03,\n          3.00909739e-02, -1.09077308e-03,  5.01569971e-01,\n          2.44486580e-01, -8.02101418e-01, -8.16855839e-02,\n         -2.77555756e-17, -4.79156777e-03, -6.45471772e-02,\n          0.00000000e+00, -5.91845158e-02],\n        [-2.72169523e-04,  1.42218015e-03, -1.70253832e-03,\n         -3.23802030e-03, -2.73625670e-04, -4.37304704e-01,\n         -6.01054964e-01, -2.35731474e-03,  2.80023428e-03,\n          3.33175204e-02,  1.10541819e-01,  4.65490914e-03,\n         -1.88089877e-01, -2.15658870e-03,  5.62343554e-02,\n          8.56940821e-02, -1.75991858e-01,  4.18037887e-01,\n          2.08166817e-17, -1.69335914e-03,  3.19056399e-01,\n          0.00000000e+00,  2.84078264e-01],\n        [ 1.62367170e-01, -2.93595666e-01,  6.84489722e-02,\n          6.03887632e-01,  5.32095578e-02, -1.81877637e-03,\n         -1.99193673e-03,  2.37200800e-02, -4.07149823e-02,\n         -5.19933079e-03,  3.97233327e-04, -7.12305097e-01,\n         -1.03679492e-03, -2.46346567e-02,  4.95667053e-03,\n          1.15410572e-02, -8.06160106e-03,  1.73339634e-03,\n          0.00000000e+00,  6.90829904e-02,  1.13629083e-03,\n          0.00000000e+00,  9.35442758e-04],\n        [ 1.00120612e-01, -1.03797754e-02, -8.94572257e-02,\n          1.59324493e-02,  8.79091764e-04, -1.21592942e-02,\n         -3.77249821e-04, -1.09617362e-01,  6.87137136e-01,\n         -6.78035427e-01,  8.59303569e-04, -1.02963001e-02,\n         -6.50140854e-03, -5.50520388e-02,  8.51669174e-02,\n          1.31798247e-01,  4.14051119e-02,  1.11731626e-02,\n          0.00000000e+00, -8.89583848e-02,  1.20076058e-04,\n          0.00000000e+00, -8.43705836e-04],\n        [ 7.87048705e-01,  1.14069591e-01, -3.62195685e-01,\n         -1.71482299e-01, -4.98735345e-03,  3.22860569e-03,\n         -4.01709394e-04, -6.16365153e-02, -6.93247574e-02,\n          1.21947194e-01, -1.51619560e-04, -9.01948826e-02,\n          1.56416197e-03,  1.96041569e-01, -2.04955771e-02,\n         -3.31660885e-02, -8.94283673e-03, -2.93783168e-03,\n          0.00000000e+00, -3.67777353e-01,  2.58146832e-04,\n          0.00000000e+00,  4.66038804e-04],\n        [ 2.28051493e-03,  6.91273124e-04,  7.07057922e-01,\n         -1.01439208e-03, -2.44886069e-05,  1.99130400e-04,\n         -4.51319737e-05,  1.42842702e-02,  7.38886061e-03,\n          6.51141842e-03, -6.17706950e-06, -2.89885212e-04,\n          8.88984740e-05, -2.69369204e-02, -1.19727187e-03,\n         -1.86999343e-03, -5.89880091e-04, -1.79887167e-04,\n          5.20417043e-18, -7.06420773e-01,  2.73459895e-05,\n          0.00000000e+00,  3.80317664e-05],\n        [ 1.30702273e-01,  4.16978017e-02, -8.91235662e-02,\n         -6.13090187e-02, -1.33381519e-03,  6.87072180e-03,\n         -1.59359360e-03,  5.07740516e-01,  2.21976985e-01,\n          2.21973929e-01, -2.07405990e-04, -2.39584007e-02,\n          3.05321800e-03, -7.77356097e-01, -4.10396061e-02,\n         -6.43221718e-02, -2.01057558e-02, -6.20431547e-03,\n          5.55111512e-17, -4.41061120e-02,  9.63515224e-04,\n          0.00000000e+00,  1.32834008e-03],\n        [-2.37071773e-01, -8.86891483e-02, -3.08771296e-01,\n          1.29497547e-01,  2.20628230e-03, -8.67943385e-03,\n          2.37308481e-03,  7.11653463e-01, -1.87390215e-01,\n         -2.57726712e-01,  2.05099427e-04,  5.89179260e-02,\n         -3.71410692e-03,  3.24311614e-01,  4.97920470e-02,\n          7.83897657e-02,  2.42119590e-02,  7.81293050e-03,\n          0.00000000e+00, -3.12741481e-01, -1.41365588e-03,\n          0.00000000e+00, -1.83555043e-03],\n        [-1.52905997e-02, -1.23071410e-02, -1.43439358e-02,\n          1.64717834e-02, -9.51433687e-04,  5.85421891e-01,\n         -5.22068979e-01, -4.13443733e-03,  2.61529015e-02,\n          5.74820600e-03,  4.74556551e-02,  9.93604657e-03,\n          6.77143011e-02,  1.64295269e-02, -1.12808282e-02,\n         -2.74666493e-03, -1.44689643e-02, -4.94481358e-01,\n          0.00000000e+00, -1.44351074e-02,  2.63265400e-01,\n          0.00000000e+00,  2.48090528e-01],\n        [ 2.00695093e-01,  2.91466972e-01,  2.87180479e-01,\n         -3.63078784e-01,  4.34514775e-02,  2.28593792e-02,\n         -2.88333379e-02,  1.88246122e-01, -4.24713135e-01,\n         -4.45391431e-01,  3.47728873e-03, -2.82526103e-01,\n         -2.98911556e-03, -1.13776766e-01,  1.39500146e-01,\n          1.98432101e-01,  8.93288614e-02, -1.81997957e-02,\n          0.00000000e+00,  2.87782945e-01,  1.27213549e-02,\n          0.00000000e+00,  1.10378059e-02],\n        [ 2.67355662e-01, -4.03091203e-01,  1.38574486e-03,\n          3.19851736e-01, -1.84099352e-01,  3.80026942e-03,\n         -8.70800118e-03, -1.34691861e-01, -3.69548565e-01,\n         -2.23195140e-01,  1.70086239e-03,  5.16201870e-01,\n         -4.54139776e-03, -3.00731043e-01,  1.47501547e-01,\n          1.79123088e-01,  1.20168864e-01, -1.90892495e-03,\n          0.00000000e+00,  3.18915913e-03,  1.05603468e-03,\n          0.00000000e+00,  3.25080258e-04],\n        [-2.13953115e-01,  4.10097210e-01, -2.50779597e-01,\n          2.19096359e-01,  4.42865286e-01,  1.21361156e-02,\n         -1.75269179e-02, -2.46561507e-01, -1.14035532e-01,\n          9.46570807e-02,  1.25454062e-02, -3.87611918e-02,\n         -1.88890206e-02, -2.04937318e-01,  3.11105818e-01,\n          3.17444893e-01,  3.01542324e-01,  5.98037592e-03,\n          0.00000000e+00, -2.50720746e-01, -1.39706382e-02,\n          0.00000000e+00, -1.47079819e-02],\n        [ 1.09902642e-01,  3.04233036e-01,  5.25321979e-02,\n          3.13539902e-01,  3.83729129e-01, -2.35507433e-01,\n          9.61943777e-02,  2.10092754e-02, -9.97472687e-02,\n         -2.15389710e-01, -2.83772670e-01,  2.09850059e-01,\n          1.62808110e-01, -3.32171483e-02, -3.04008474e-01,\n         -2.97926254e-01, -3.03845431e-01, -2.06293518e-01,\n          4.23516474e-22,  5.29210854e-02,  1.64799812e-01,\n          0.00000000e+00,  1.65391227e-01],\n        [ 7.86967503e-02,  1.72107925e-01,  4.62662964e-02,\n          1.85056706e-01,  2.19747367e-01,  4.01787503e-01,\n         -1.21708705e-01,  2.76205858e-02, -4.81725917e-02,\n         -1.24586624e-01,  4.90026906e-01,  1.31822329e-01,\n         -2.36446569e-01, -5.70435499e-03, -1.92176972e-01,\n         -1.92852034e-01, -1.89928235e-01,  3.65843309e-01,\n          4.23516474e-22,  4.64923431e-02, -2.50268914e-01,\n          0.00000000e+00, -2.49763201e-01],\n        [-1.48612089e-01, -5.85142438e-02, -1.53603086e-01,\n         -1.08809944e-01, -8.96443849e-02,  2.04572687e-01,\n          3.73352537e-01, -1.53692883e-01, -1.41761537e-01,\n         -1.23608317e-01,  2.99206276e-01, -1.30288266e-01,\n          3.83251555e-01, -1.50080534e-01, -9.10637927e-02,\n         -8.18949588e-02, -9.58247486e-02,  3.11017153e-01,\n          0.00000000e+00, -1.53587496e-01,  3.66433378e-01,\n          0.00000000e+00,  3.68918163e-01],\n        [-2.68747745e-01, -1.00131938e-01, -2.80575388e-01,\n         -1.90814734e-01, -1.54818075e-01, -9.92561433e-02,\n         -1.94988884e-01, -2.82641870e-01, -2.70847893e-01,\n         -2.50818380e-01, -1.46514769e-01, -2.32190851e-01,\n         -2.04088197e-01, -2.80031330e-01, -2.15471294e-01,\n         -2.06142479e-01, -2.20590883e-01, -1.54468446e-01,\n         -8.78843834e-10, -2.80525323e-01, -1.98337145e-01,\n          0.00000000e+00, -1.99236686e-01],\n        [ 2.36187298e-10,  8.80003360e-11,  2.46581927e-10,\n          1.67696352e-10,  1.36060911e-10,  8.72306466e-11,\n          1.71364793e-10,  2.48398124e-10,  2.38033022e-10,\n          2.20430187e-10,  1.28763601e-10,  2.04059498e-10,\n          1.79361579e-10,  2.46103751e-10,  1.89365580e-10,\n          1.81167053e-10,  1.93864968e-10,  1.35753644e-10,\n         -1.00000000e+00,  2.46537947e-10,  1.74307318e-10,\n          0.00000000e+00,  1.75098054e-10],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         -1.00000000e+00,  0.00000000e+00]]))\n\n\n\n%run heavysnow.py\nspa=SpectralAnalysis(gs)\nspa.graphFouriertransform()\nspa.decompose()\n\n\nplt.imshow(spa.Lz)\n\n\n\n\n\n\n\n\n\nspa.Lz[13:18,13:18]\n\narray([[ 1.00000000e+00, -3.47748512e-02, -2.56935107e-02,\n        -4.14298210e-02, -6.56720534e-12],\n       [-3.47748512e-02,  1.00000000e+00, -3.13567731e-01,\n        -2.95687253e-01, -1.13797574e-06],\n       [-2.56935107e-02, -3.13567731e-01,  1.00000000e+00,\n        -2.99256990e-01, -2.77663248e-06],\n       [-4.14298210e-02, -2.95687253e-01, -2.99256990e-01,\n         1.00000000e+00, -6.51246540e-07],\n       [-6.56720534e-12, -1.13797574e-06, -2.77663248e-06,\n        -6.51246540e-07,  1.00000000e+00]])\n\n\n\n%%R \n    D&lt;-degree(WW)\n    D_rootinv&lt;-degree_rootinv(WW)\n    L&lt;-D-WW\n    L_tilde&lt;-D_rootinv%*%L%*%D_rootinv\n\n\n%R -o L_tilde\n\n\nplt.imshow(spa.Lz)\n\n\n\n\n\n\n\n\n\nplt.imshow(L_tilde)\n\n\n\n\n\n\n\n\n\nspa.Psi[0]\n\narray([ 8.31802845e-07, -2.28244345e-02,  1.69005964e-05,  8.32458517e-05,\n        1.37445367e-03, -1.69822716e-03, -2.72169523e-04,  1.62367170e-01,\n        1.00120612e-01,  7.87048705e-01,  2.28051493e-03,  1.30702273e-01,\n       -2.37071773e-01, -1.52905997e-02,  2.00695093e-01,  2.67355662e-01,\n       -2.13953115e-01,  1.09902642e-01,  7.86967503e-02, -1.48612089e-01,\n       -2.68747745e-01,  1.30686848e-15,  0.00000000e+00])\n\n\n\nPsi[0]\n\narray([ 8.31802846e-07, -2.28244345e-02,  1.69005964e-05,  8.32458517e-05,\n        1.37445367e-03, -1.69822716e-03, -2.72169523e-04,  1.62367170e-01,\n        1.00120612e-01,  7.87048705e-01,  2.28051493e-03, -1.30702273e-01,\n       -2.37071773e-01, -1.52905997e-02,  2.00695093e-01,  2.67355662e-01,\n       -2.13953115e-01,  1.09902642e-01,  7.86967503e-02, -1.48612089e-01,\n       -2.68747745e-01,  4.53298893e-07,  1.40733495e-38])\n\n\n\nspa.fbar\n\narray([-2.10281887e+02,  1.40244756e+01,  8.71311468e+00,  7.45361934e+01,\n       -3.80931713e+01,  6.17719604e+01, -2.14128291e+02, -3.55025393e+00,\n        1.92122028e+01, -3.86380121e+00,  4.42134781e-01, -8.70162667e+00,\n        1.07088816e+01,  3.00488134e+02,  3.01659077e+01,  4.85119271e+01,\n        3.80885030e+02, -7.85570930e+02,  5.73774201e+02,  1.80256280e+03,\n       -3.59847855e+03, -2.04835975e+03, -2.79627440e+03])\n\n\n\nplt.imshow(spa.Psi)\n\n\n\n\n\n\n\n\n\nU, lamb, Vt =np.linalg.svd(spa.Lz)\n\n\nplt.imshow(Vt)\n\n\n\n\n\n\n\n\n\nplt.imshow(U @ np.diag(lamb) @ Vt)\n\n\n\n\n\n\n\n\n\nplt.imshow(spa.Lz)\n\n\n\n\n\n\n\n\n\nfbar\n\narray([-2.10281887e+02,  1.40244756e+01,  8.71311468e+00,  7.45361934e+01,\n       -3.80931713e+01,  6.17719604e+01, -2.14128291e+02, -3.55025393e+00,\n        1.92122028e+01, -3.86380121e+00,  4.42134781e-01,  8.70162667e+00,\n        1.07088816e+01,  3.00488134e+02,  3.01659077e+01,  4.85119271e+01,\n        3.80885030e+02, -7.85570930e+02,  5.73774201e+02,  1.80256280e+03,\n       -3.59847510e+03,  2.04836582e+03, -2.79627440e+03])\n\n\n\nplt.imshow(Psi @np.diag(lamb) @ Psi.T)\n\n\n\n\n\n\n\n\n\nPsi\n\narray([[ 8.31802846e-07, -2.28244345e-02,  1.69005964e-05,\n         8.32458517e-05,  1.37445367e-03, -1.69822716e-03,\n        -2.72169523e-04,  1.62367170e-01,  1.00120612e-01,\n         7.87048705e-01,  2.28051493e-03, -1.30702273e-01,\n        -2.37071773e-01, -1.52905997e-02,  2.00695093e-01,\n         2.67355662e-01, -2.13953115e-01,  1.09902642e-01,\n         7.86967503e-02, -1.48612089e-01, -2.68747745e-01,\n         4.53298893e-07,  1.40733495e-38],\n       [-1.73745234e-07,  5.82817056e-01,  3.19679606e-06,\n         1.95527208e-05, -4.01026817e-04,  1.79423330e-03,\n         1.42218015e-03, -2.93595666e-01, -1.03797754e-02,\n         1.14069591e-01,  6.91273124e-04, -4.16978017e-02,\n        -8.86891483e-02, -1.23071410e-02,  2.91466972e-01,\n        -4.03091203e-01,  4.10097210e-01,  3.04233036e-01,\n         1.72107925e-01, -5.85142438e-02, -1.00131938e-01,\n         1.68893309e-07,  5.24354816e-39],\n       [ 1.79945470e-06, -8.86372067e-03, -1.04110175e-05,\n        -9.71301027e-06,  4.57105960e-03, -4.80419733e-03,\n        -1.70253832e-03,  6.84489722e-02, -8.94572257e-02,\n        -3.62195685e-01,  7.07057922e-01,  8.91235662e-02,\n        -3.08771296e-01, -1.43439358e-02,  2.87180479e-01,\n         1.38574486e-03, -2.50779597e-01,  5.25321979e-02,\n         4.62662964e-02, -1.53603086e-01, -2.80575388e-01,\n         4.73248670e-07,  1.46927205e-38],\n       [-3.81405816e-07,  3.49123335e-01, -1.13849656e-05,\n        -5.20669020e-05,  1.71456172e-03, -4.55458198e-03,\n        -3.23802030e-03,  6.03887632e-01,  1.59324493e-02,\n        -1.71482299e-01, -1.01439208e-03,  6.13090187e-02,\n         1.29497547e-01,  1.64717834e-02, -3.63078784e-01,\n         3.19851736e-01,  2.19096359e-01,  3.13539902e-01,\n         1.85056706e-01, -1.08809944e-01, -1.90814734e-01,\n         3.21848681e-07,  9.99227897e-39],\n       [ 3.16749178e-07, -7.33268982e-01, -5.84182485e-07,\n        -5.10615468e-06,  1.76538169e-05, -3.21602859e-04,\n        -2.73625670e-04,  5.32095578e-02,  8.79091764e-04,\n        -4.98735345e-03, -2.44886069e-05,  1.33381519e-03,\n         2.20628230e-03, -9.51433687e-04,  4.34514775e-02,\n        -1.84099352e-01,  4.42865286e-01,  3.83729129e-01,\n         2.19747367e-01, -8.96443849e-02, -1.54818075e-01,\n         2.61132838e-07,  8.10726382e-39],\n       [-4.21211716e-01, -1.26228933e-06,  9.91140473e-03,\n         1.05442602e-01, -2.34738842e-02,  8.53928708e-02,\n        -4.37304704e-01, -1.81877637e-03, -1.21592942e-02,\n         3.22860569e-03,  1.99130400e-04, -6.87072180e-03,\n        -8.67943385e-03,  5.85421891e-01,  2.28593792e-02,\n         3.80026942e-03,  1.21361156e-02, -2.35507433e-01,\n         4.01787503e-01,  2.04572687e-01, -9.92561433e-02,\n         1.67416356e-07,  5.19769120e-39],\n       [ 7.57297687e-02, -6.30483358e-06,  3.91285206e-02,\n         3.71727089e-01, -4.54039898e-02,  1.26342172e-01,\n        -6.01054964e-01, -1.99193673e-03, -3.77249821e-04,\n        -4.01709394e-04, -4.51319737e-05,  1.59359360e-03,\n         2.37308481e-03, -5.22068979e-01, -2.88333379e-02,\n        -8.70800118e-03, -1.75269179e-02,  9.61943777e-02,\n        -1.21708705e-01,  3.73352537e-01, -1.94988884e-01,\n         3.28889581e-07,  1.02108736e-38],\n       [ 1.86543546e-06, -2.97029443e-03, -3.36972961e-05,\n        -1.05359128e-04,  4.99362785e-03, -5.24357048e-03,\n        -2.35731474e-03,  2.37200800e-02, -1.09617362e-01,\n        -6.16365153e-02,  1.42842702e-02, -5.07740516e-01,\n         7.11653463e-01, -4.13443733e-03,  1.88246122e-01,\n        -1.34691861e-01, -2.46561507e-01,  2.10092754e-02,\n         2.76205858e-02, -1.53692883e-01, -2.82641870e-01,\n         4.76734222e-07,  1.48009348e-38],\n       [-7.99573985e-06,  3.95206738e-03, -6.27063562e-05,\n        -3.92509820e-04, -1.69919218e-02,  1.62054211e-02,\n         2.80023428e-03, -4.07149823e-02,  6.87137136e-01,\n        -6.93247574e-02,  7.38886061e-03, -2.21976985e-01,\n        -1.87390215e-01,  2.61529015e-02, -4.24713135e-01,\n        -3.69548565e-01, -1.14035532e-01, -9.97472687e-02,\n        -4.81725917e-02, -1.41761537e-01, -2.70847893e-01,\n         4.56841235e-07,  1.41833269e-38],\n       [-3.95062745e-05,  1.57431046e-03,  4.06604890e-04,\n         1.18991491e-03, -7.33907458e-02,  7.64563613e-02,\n         3.33175204e-02, -5.19933079e-03, -6.78035427e-01,\n         1.21947194e-01,  6.51141842e-03, -2.21973929e-01,\n        -2.57726712e-01,  5.74820600e-03, -4.45391431e-01,\n        -2.23195140e-01,  9.46570807e-02, -2.15389710e-01,\n        -1.24586624e-01, -1.23608317e-01, -2.50818380e-01,\n         4.23057305e-07,  1.31344537e-38],\n       [ 7.42676668e-01,  1.32904593e-06, -3.99249712e-03,\n        -3.94942827e-02,  7.34555531e-03, -2.26382886e-02,\n         1.10541819e-01,  3.97233327e-04,  8.59303569e-04,\n        -1.51619560e-04, -6.17706950e-06,  2.07405990e-04,\n         2.05099427e-04,  4.74556551e-02,  3.47728873e-03,\n         1.70086239e-03,  1.25454062e-02, -2.83772670e-01,\n         4.90026906e-01,  2.99206276e-01, -1.46514769e-01,\n         2.47127902e-07,  7.67245728e-39],\n       [-3.90910918e-07, -6.36400071e-03,  2.21728059e-05,\n         7.82229365e-05, -4.58350808e-03,  7.96250033e-03,\n         4.65490914e-03, -7.12305097e-01, -1.02963001e-02,\n        -9.01948826e-02, -2.89885212e-04,  2.39584007e-02,\n         5.89179260e-02,  9.93604657e-03, -2.82526103e-01,\n         5.16201870e-01, -3.87611918e-02,  2.09850059e-01,\n         1.31822329e-01, -1.30288266e-01, -2.32190851e-01,\n         3.91638098e-07,  1.21589969e-38],\n       [ 4.19197158e-03, -3.33385384e-06, -3.37382216e-02,\n        -8.28576687e-01,  5.81916530e-03,  3.00909739e-02,\n        -1.88089877e-01, -1.03679492e-03, -6.50140854e-03,\n         1.56416197e-03,  8.88984740e-05, -3.05321800e-03,\n        -3.71410692e-03,  6.77143011e-02, -2.98911556e-03,\n        -4.54139776e-03, -1.88890206e-02,  1.62808110e-01,\n        -2.36446569e-01,  3.83251555e-01, -2.04088197e-01,\n         3.44237465e-07,  1.06873721e-38],\n       [-5.66982257e-08,  2.55064959e-03, -7.19961507e-05,\n        -3.00326201e-04,  6.07234653e-04, -1.09077308e-03,\n        -2.15658870e-03, -2.46346567e-02, -5.50520388e-02,\n         1.96041569e-01, -2.69369204e-02,  7.77356097e-01,\n         3.24311614e-01,  1.64295269e-02, -1.13776766e-01,\n        -3.00731043e-01, -2.04937318e-01, -3.32171483e-02,\n        -5.70435499e-03, -1.50080534e-01, -2.80031330e-01,\n         4.72331005e-07,  1.46642303e-38],\n       [ 4.10395438e-05, -3.13366217e-04,  8.14273566e-04,\n         5.56447636e-03,  6.41222150e-01,  5.01569971e-01,\n         5.62343554e-02,  4.95667053e-03,  8.51669174e-02,\n        -2.04955771e-02, -1.19727187e-03,  4.10396061e-02,\n         4.97920470e-02, -1.12808282e-02,  1.39500146e-01,\n         1.47501547e-01,  3.11105818e-01, -3.04008474e-01,\n        -1.92176972e-01, -9.10637927e-02, -2.15471294e-01,\n         3.63437110e-07,  1.12834546e-38],\n       [ 1.48848758e-04, -2.35982660e-04, -3.53800726e-03,\n        -1.71372928e-02, -7.45851291e-01,  2.44486580e-01,\n         8.56940821e-02,  1.15410572e-02,  1.31798247e-01,\n        -3.31660885e-02, -1.86999343e-03,  6.43221718e-02,\n         7.83897657e-02, -2.74666493e-03,  1.98432101e-01,\n         1.79123088e-01,  3.17444893e-01, -2.97926254e-01,\n        -1.92852034e-01, -8.18949588e-02, -2.06142479e-01,\n         3.47702130e-07,  1.07949384e-38],\n       [ 8.78543271e-07, -3.17838052e-04,  1.34421400e-03,\n         6.78594911e-03,  1.51549473e-01, -8.02101418e-01,\n        -1.75991858e-01, -8.06160106e-03,  4.14051119e-02,\n        -8.94283673e-03, -5.89880091e-04,  2.01057558e-02,\n         2.42119590e-02, -1.44689643e-02,  8.93288614e-02,\n         1.20168864e-01,  3.01542324e-01, -3.03845431e-01,\n        -1.89928235e-01, -9.58247486e-02, -2.20590883e-01,\n         3.72072360e-07,  1.15515490e-38],\n       [-5.14913484e-01,  4.18430718e-07, -9.80986052e-03,\n        -1.03562437e-01,  2.24827063e-02, -8.16855839e-02,\n         4.18037887e-01,  1.73339634e-03,  1.11731626e-02,\n        -2.93783168e-03, -1.79887167e-04,  6.20431547e-03,\n         7.81293050e-03, -4.94481358e-01, -1.81997957e-02,\n        -1.90892495e-03,  5.98037592e-03, -2.06293518e-01,\n         3.65843309e-01,  3.11017153e-01, -1.54468446e-01,\n         2.60543425e-07,  8.08896293e-39],\n       [ 1.24737016e-14,  3.93407465e-20, -3.45930152e-16,\n        -3.77912922e-15,  8.60963323e-16, -3.15374791e-15,\n         1.62369084e-14,  6.86568858e-17,  4.88028646e-16,\n        -1.30919084e-16, -7.70880621e-17,  2.77661485e-16,\n         3.55900371e-16, -2.51906933e-14, -1.02117568e-15,\n        -2.06045401e-16, -1.38074571e-15,  4.25733421e-14,\n        -7.66199636e-14, -7.14108351e-13,  1.68670810e-06,\n         1.00000000e+00,  5.55916566e-39],\n       [ 1.79531969e-06, -8.94842690e-03, -1.01546268e-05,\n        -8.73262658e-06,  4.55614976e-03, -4.79156777e-03,\n        -1.69335914e-03,  6.90829904e-02, -8.89583848e-02,\n        -3.67777353e-01, -7.06420773e-01,  4.41061120e-02,\n        -3.12741481e-01, -1.44351074e-02,  2.87782945e-01,\n         3.18915913e-03, -2.50720746e-01,  5.29210854e-02,\n         4.64923431e-02, -1.53587496e-01, -2.80525323e-01,\n         4.73164226e-07,  1.46900989e-38],\n       [-8.33021631e-03,  1.05962533e-05,  7.09113594e-01,\n         2.40362541e-01,  1.65950319e-02, -6.45471772e-02,\n         3.19056399e-01,  1.13629083e-03,  1.20076058e-04,\n         2.58146832e-04,  2.73459895e-05, -9.63515224e-04,\n        -1.41365588e-03,  2.63265400e-01,  1.27213549e-02,\n         1.05603468e-03, -1.39706382e-02,  1.64799812e-01,\n        -2.50268914e-01,  3.66433378e-01, -1.98337145e-01,\n         3.34537107e-07,  1.03862099e-38],\n       [-2.91684989e-48, -9.67870296e-54,  7.66429393e-50,\n         1.08195293e-48, -2.53869829e-49,  8.96655349e-49,\n        -4.58225740e-48, -2.04520610e-50, -1.56019945e-49,\n         4.54073575e-50, -5.67284365e-47, -1.13905076e-48,\n        -7.09980313e-50,  8.55192528e-48,  3.59904771e-49,\n         8.81265710e-50,  1.23887175e-48, -6.06897321e-47,\n         1.15220264e-46,  1.96550022e-44, -5.23663927e-38,\n         5.55925399e-39, -1.00000000e+00],\n       [-7.36022066e-03,  8.23867965e-06, -7.03038426e-01,\n         3.06153537e-01,  1.79901928e-02, -5.91845158e-02,\n         2.84078264e-01,  9.35442758e-04, -8.43705836e-04,\n         4.66038804e-04,  3.80317664e-05, -1.32834008e-03,\n        -1.83555043e-03,  2.48090528e-01,  1.10378059e-02,\n         3.25080258e-04, -1.47079819e-02,  1.65391227e-01,\n        -2.49763201e-01,  3.68918163e-01, -1.99236686e-01,\n         3.36054372e-07,  1.04333156e-38]])\n\n\n\nplt.imshow(Psi)\n\n\n\n\n\n\n\n\n\nplt.imshow(spa.Psi)\n\n\n\n\n\n\n\n\n\n%%R -r 150 -w 2000 -h 660\nsource('heavysnow.R')\ndat_&lt;-tibble(V)\ndat_$f&lt;-as.vector(f)\ndat_$divlink&lt;-0\ndat_$conlink&lt;-0\ndat_$link&lt;-0\ndat&lt;-dat_\nfor(i in 1:23){\n    dat$divlink[i]&lt;-sum(W[i,])\n    dat$conlink[i]&lt;-sum(W[,i])\n    dat$link[i]&lt;-sum(W[i,])+sum(W[i,])\n}\np1_&lt;-ggplot(dat)+geom_point(aes(x=f,y=divlink),size=3)+theme_light()+\n        geom_text_repel(aes(x=f,y=divlink,label=V),col=\"gray40\")+\n        ylab(\"Out-degree\")+xlab(\"Box office record\")+\n        geom_hline(aes(yintercept=2),col=2,lty=2,lwd=0.5)+\n        geom_vline(aes(xintercept=1000),col=2,lty=2,lwd=0.5)+\n        ggtitle(\"(a)\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(2)))+\n        theme(axis.title.x=element_text(face=4,size=rel(1)))+\n        theme(axis.title.y=element_text(face=4,size=rel(1)))\np2_&lt;-ggplot(dat)+geom_point(aes(x=f,y=conlink),size=3)+theme_light()+\n        geom_text_repel(aes(x=f,y=conlink,label=V),col=\"gray40\")+\n        ylab(\"In-degree\")+xlab(\"Box office record\")+\n        geom_hline(aes(yintercept=3.75),col=2,lty=2,lwd=0.5)+\n        geom_vline(aes(xintercept=1000),col=2,lty=2,lwd=0.5)+\n        ggtitle(\"(b)\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(2)))+\n        theme(axis.title.x=element_text(face=4,size=rel(1)))+\n        theme(axis.title.y=element_text(face=4,size=rel(1)))\n# p3_&lt;-ggplot(dat)+geom_point(aes(x=f,y=link),size=3)+theme_light()+\n#         geom_text_repel(aes(x=f,y=link,label=V),col=\"gray40\")+\n#         ylab(\"Graph\")+xlab(\"Box office record\")+\n#         geom_hline(aes(yintercept=6.25),col=2,lty=2,lwd=0.5)+\n#         geom_vline(aes(xintercept=1000),col=2,lty=2,lwd=0.5)+\n#         ggtitle(\"(c)\")\np1&lt;-grid.arrange(p1_,p2_,ncol=2)\n#ggsave(plot=p1,\"./fig/p1.pdf\",width=9,height=4.5)\n\nR[write to console]: Error in library(kohonen) : there is no package called ‘kohonen’\n\n\n\n\nError in library(kohonen) : there is no package called ‘kohonen’\n\n\nRInterpreterError: Failed to parse and evaluate line 'source(\\'heavysnow.R\\')\\ndat_&lt;-tibble(V)\\ndat_$f&lt;-as.vector(f)\\ndat_$divlink&lt;-0\\ndat_$conlink&lt;-0\\ndat_$link&lt;-0\\ndat&lt;-dat_\\nfor(i in 1:23){\\n    dat$divlink[i]&lt;-sum(W[i,])\\n    dat$conlink[i]&lt;-sum(W[,i])\\n    dat$link[i]&lt;-sum(W[i,])+sum(W[i,])\\n}\\np1_&lt;-ggplot(dat)+geom_point(aes(x=f,y=divlink),size=3)+theme_light()+\\n        geom_text_repel(aes(x=f,y=divlink,label=V),col=\"gray40\")+\\n        ylab(\"Out-degree\")+xlab(\"Box office record\")+\\n        geom_hline(aes(yintercept=2),col=2,lty=2,lwd=0.5)+\\n        geom_vline(aes(xintercept=1000),col=2,lty=2,lwd=0.5)+\\n        ggtitle(\"(a)\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(2)))+\\n        theme(axis.title.x=element_text(face=4,size=rel(1)))+\\n        theme(axis.title.y=element_text(face=4,size=rel(1)))\\np2_&lt;-ggplot(dat)+geom_point(aes(x=f,y=conlink),size=3)+theme_light()+\\n        geom_text_repel(aes(x=f,y=conlink,label=V),col=\"gray40\")+\\n        ylab(\"In-degree\")+xlab(\"Box office record\")+\\n        geom_hline(aes(yintercept=3.75),col=2,lty=2,lwd=0.5)+\\n        geom_vline(aes(xintercept=1000),col=2,lty=2,lwd=0.5)+\\n        ggtitle(\"(b)\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(2)))+\\n        theme(axis.title.x=element_text(face=4,size=rel(1)))+\\n        theme(axis.title.y=element_text(face=4,size=rel(1)))\\n# p3_&lt;-ggplot(dat)+geom_point(aes(x=f,y=link),size=3)+theme_light()+\\n#         geom_text_repel(aes(x=f,y=link,label=V),col=\"gray40\")+\\n#         ylab(\"Graph\")+xlab(\"Box office record\")+\\n#         geom_hline(aes(yintercept=6.25),col=2,lty=2,lwd=0.5)+\\n#         geom_vline(aes(xintercept=1000),col=2,lty=2,lwd=0.5)+\\n#         ggtitle(\"(c)\")\\np1&lt;-grid.arrange(p1_,p2_,ncol=2)\\n#ggsave(plot=p1,\"./fig/p1.pdf\",width=9,height=4.5)\\n'.\nR error message: 'Error in library(kohonen) : there is no package called ‘kohonen’'\n\n\n\n\ngfft 수행하고 결과를 저장함.\n\n%%R \ng1&lt;-gfft(f,WEuclid)\ng2&lt;-gfft(f,Wgraph)\ng3&lt;-gfft(f,Whst)\n\n\n\n아이겐플랏\n\n%%R -r 150 -w 1000 -h 400\nlibrary(gridExtra)\ne1&lt;-eigenplot(g1)+ggtitle(\"(a) Euclid weights\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(1)))\ne2&lt;-eigenplot(g2)+ggtitle(\"(b) Graph weights\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(1)))\ne3&lt;-eigenplot(g3)+ggtitle(\"(c) HST weights\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(1)))\ns1&lt;-specplot(g1)\ns2&lt;-specplot(g2)\ns3&lt;-specplot(g3)\np2&lt;-grid.arrange(e1,e2,e3,s1,s2,s3,nrow=2)\n#ggsave(plot=p2,\"./fig/p2.pdf\",width=6,height=3)\n\n\n\n분해\n\n%%R -r 300 -w 2500 -h 1500\nd1&lt;-decompose(f,WEuclid,V=V) # 0, 35000, 60000, 80000\nd2&lt;-decompose(f,Wgraph,V=V) # 0, 35000, 60000, 80000\nd3&lt;-decompose(f,Whst,V=V) # 0, 35000, 60000, 80000\n\nd1$case&lt;-\"Euclid\"\nd2$case&lt;-\"Graph\"\nd3$case&lt;-\"HST\"\ndecomprslt&lt;-rbind(d1,d2,d3)\n\n\n%%R -r 150 -w 2000 -h 4200\n\ndecomp_dat&lt;- decomprslt %&gt;% \n                group_by(case,eigenvectorindex) %&gt;% \n                mutate(textsize= 10*(abs(fhat)&gt;50))\n        \np3&lt;-ggplot(data=filter(decomp_dat,eigenvectorindex %in% 1:23))+\n    geom_col(aes(x=Vindex,y=fhat,fill=fhat&gt;0),width=0.7)+\n    geom_text_repel(aes(x=Vindex,y=fhat,label=V,size=textsize),col=1,fontface=4,alpha=0.8,segment.size=0.2,segment.color=\"gray60\",min.segment.length=5,hjust=0.1)+\n    scale_radius(range = c(0,1.8))+\n    guides(size=FALSE)+\n    facet_grid(eigenvectorindex~case)+\n    geom_hline(aes(yintercept=0),col=\"gray60\",lty=2)+\n    xlab(\"\")+ylab(\"\")+guides(fill=FALSE)+\n    theme(axis.text.x=element_text(angle=85,hjust=1,vjust=1,face=4,size=rel(0.7),colour=\"gray60\"))+\n    theme_light()+\n    theme(strip.text.x = element_text(size = 10, color = \"black\", face = \"bold.italic\"))+\n    theme(strip.text.y = element_text(size = 10, color = \"black\", face = \"bold.italic\"))+\n    theme(plot.title=element_text(face=\"bold.italic\",size=rel(1.5)))\nshow(p3)\n\n# decomp_dat&lt;- decomprslt %&gt;% \n#                 group_by(case,eigenvectorindex) %&gt;% \n#                 mutate(textsize=(fhat&gt;mean(fhat)) *(fhat&gt;240) * ((case==\"Euclid\")*1.7+\n#                                                                  (case!=\"Euclid\")*(eigenvectorindex!=1)*1.7+\n#                                                                  (case!=\"Euclid\")*(eigenvectorindex==1)*1))\n\n\n# p3&lt;-ggplot(data=filter(decomp_dat,eigenvectorindex %in% 1:7))+\n#     geom_col(aes(x=Vindex,y=fhat,fill=fhat&gt;0),width=0.7)+\n#     geom_text_repel(aes(x=Vindex,y=fhat,label=V,size=textsize),col=1,fontface=4,alpha=0.8,segment.size=0.2,segment.color=\"gray60\",min.segment.length=5,hjust=0.1)+\n#     scale_radius(range = c(0,1.8))+\n#     guides(size=FALSE)+\n#     facet_grid(eigenvectorindex~case)+\n#     geom_hline(aes(yintercept=0),col=\"gray60\",lty=2)+\n#     xlab(\"\")+ylab(\"\")+guides(fill=FALSE)+\n#     theme(axis.text.x=element_text(angle=85,hjust=1,vjust=1,face=4,size=rel(0.7),colour=\"gray60\"))+\n#     theme_light()+\n#     theme(strip.text.x = element_text(size = 10, color = \"black\", face = \"bold.italic\"))+\n#     theme(strip.text.y = element_text(size = 10, color = \"black\", face = \"bold.italic\"))+\n#     theme(plot.title=element_text(face=\"bold.italic\",size=rel(1.5)))\n# show(p3)\n#ggsave(plot=p3,\"./fig/p3.pdf\",width=6,height=6)\n\n\n%%R\ndat3_Euclid &lt;- decomp_dat %&gt;% filter(case==\"Euclid\",eigenvectorindex==1) %&gt;% select(V,case,eigenvectorindex,textsize,fhat)\ndat3_Euclid &lt;- left_join(dat,dat3_Euclid,by=\"V\")\n\nfor(j in 2:23){\n        decomp_filtered_dat_&lt;- decomp_dat %&gt;% filter(case==\"Euclid\",eigenvectorindex==j) %&gt;% select(V,case,eigenvectorindex,textsize,fhat)\n        decomp_filtered_dat_&lt;- left_join(dat,decomp_filtered_dat_,by=\"V\")\n        dat3_Euclid&lt;-rbind(dat3_Euclid,decomp_filtered_dat_)\n}\n\ndat3_Graph &lt;- decomp_dat %&gt;% filter(case==\"Graph\",eigenvectorindex==1) %&gt;% select(V,case,eigenvectorindex,textsize,fhat)\ndat3_Graph &lt;- left_join(dat,dat3_Graph,by=\"V\")\n\nfor(j in 2:23){\n        decomp_filtered_dat_&lt;- decomp_dat %&gt;% filter(case==\"Graph\",eigenvectorindex==j) %&gt;% select(V,case,eigenvectorindex,textsize,fhat)\n        decomp_filtered_dat_&lt;- left_join(dat,decomp_filtered_dat_,by=\"V\")\n        dat3_Graph&lt;-rbind(dat3_Graph,decomp_filtered_dat_)\n}\n\ndat3_HST &lt;- decomp_dat %&gt;% filter(case==\"HST\",eigenvectorindex==1) %&gt;% select(V,case,eigenvectorindex,textsize,fhat)\ndat3_HST &lt;- left_join(dat,dat3_HST,by=\"V\")\n\nfor(j in 2:23){\n        decomp_filtered_dat_&lt;- decomp_dat %&gt;% filter(case==\"HST\",eigenvectorindex==j) %&gt;% select(V,case,eigenvectorindex,textsize,fhat)\n        decomp_filtered_dat_&lt;- left_join(dat,decomp_filtered_dat_,by=\"V\")\n        dat3_HST&lt;-rbind(dat3_HST,decomp_filtered_dat_)\n}\ndat3&lt;-rbind(dat3_Euclid,dat3_Graph,dat3_HST)\n\n\n%%R -r 300 -w 2000 -h 3000\nhull_cyl &lt;- dat3 %&gt;%\n            group_by(case,eigenvectorindex) %&gt;% \n            filter(textsize&gt;0) %&gt;% \n            slice(chull(f, divlink))\np4&lt;-ggplot(dat3%&gt;% filter(eigenvectorindex&lt;8))+geom_point(aes(x=f,y=divlink,col=textsize&gt;0,size=fhat*(fhat&gt;0)),alpha=0.8)+\n        geom_shape(data=hull_cyl%&gt;% filter(eigenvectorindex&lt;8) ,aes(x=f,y=divlink),alpha=0.05,col=\"gray30\",radius=0.05,expand=0.05)+\n        facet_grid(eigenvectorindex~case)+\n        scale_size_continuous(range=c(2,2.5))+\n        scale_color_manual(values=c(\"gray80\", \"gray20\"))+\n        ylim(0,8)+xlim(0,3000)+\n        guides(alpha=F)+\n        guides(col=F)+\n        guides(size=F)+\n        ylab(\"\")+xlab(\"\")+\n        geom_hline(aes(yintercept=2),col=\"gray30\",lty=2,lwd=0.2)+\n        geom_vline(aes(xintercept=1000),col=\"gray30\",lty=2,lwd=0.2)+\n        theme_light()+\n        theme(strip.text.x = element_text(size = 10, color = \"black\", face = \"bold.italic\"))+\n        theme(strip.text.y = element_text(size = 10, color = \"black\", face = \"bold.italic\"))+\n        theme(plot.title=element_text(face=\"bold.italic\",size=rel(1.5)))\nshow(p4)\n#ggsave(plot=p4,\"./fig/p4.pdf\",width=7,height=7)\n\n\n%%R -r 300 -w 2000 -h 3000\nhull_cyl &lt;- dat3 %&gt;%\n            group_by(case,eigenvectorindex) %&gt;% \n            filter(textsize&gt;0) %&gt;% \n            slice(chull(f, conlink))\np5&lt;-ggplot(dat3%&gt;% filter(eigenvectorindex&lt;8))+geom_point(aes(x=f,y=conlink,col=textsize&gt;0,size=fhat*(fhat&gt;0)),alpha=0.8)+\n        geom_shape(data=hull_cyl%&gt;% filter(eigenvectorindex&lt;8) ,aes(x=f,y=conlink),alpha=0.05,col=\"gray30\",radius=0.05,expand=0.05)+\n        facet_grid(eigenvectorindex~case)+\n        scale_size_continuous(range=c(2,2.5))+\n        scale_color_manual(values=c(\"gray80\", \"gray20\"))+        \n        ylim(0,10)+xlim(0,3000)+\n        guides(col=F)+\n        guides(alpha=F)+\n        guides(size=F)+       \n        ylab(\"\")+xlab(\"\")+\n        geom_hline(aes(yintercept=3.75),col=\"gray30\",lty=2,lwd=0.2)+\n        geom_vline(aes(xintercept=1000),col=\"gray30\",lty=2,lwd=0.2)+\n        theme_light()+\n        theme(strip.text.x = element_text(size = 10, color = \"black\", face = \"bold.italic\"))+\n        theme(strip.text.y = element_text(size = 10, color = \"black\", face = \"bold.italic\"))+\n        theme(plot.title=element_text(face=\"bold.italic\",size=rel(1.5)))\nshow(p5)\n#ggsave(plot=p5,\"./fig/p5.pdf\",width=7,height=7)        \n\n\n%%R -r 300 -w 2000 -h 1500\np_&lt;-grid.arrange(p4,p5,ncol=2)\n#ggsave(plot=p6,\"./fig/p6.pdf\",width=10,height=12)\n\n\n%%R -r 200 -w 2000 -h 3000\np6&lt;-grid.arrange(p1,p_,nrow=2,heights=c(3,5))"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-08-14-HST example 1, Appendix 추가 (2) 이거로하자..html",
    "href": "연구/교수님이랑/HST/2021-08-14-HST example 1, Appendix 추가 (2) 이거로하자..html",
    "title": "(연구&교수님) HST example 1, Appendix 추가 (2)",
    "section": "",
    "text": "Import\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib\nmatplotlib.rc('image', cmap='Greys')\nimport rpy2 \n%load_ext rpy2.ipython\n%run pybase\n%run heavysnow \n\n\n\nData\n\nf=np.array([-1,-1,-1,1,-1,-1,-1,1,1,1,-1,1,1,1])*1.0\nn=len(f)\nV=list(range(n))\nW=np.zeros([n,n])\nfor i in range(n):\n    for j in range(n):\n        if abs(i-j)==1: W[i,j]=1\nW[0,0]=0\nW[n-1,n-1]=0\n\n\ngs=GraphSignal(V,W,f)\n\n\ngs.initdist=np.array([1/n]*n)\n\n\n\nHST\n\n%run heavysnow \nhst=HeavySnowTransform(gs)\nhst.snow(tau=100000,b=0.01,maxflow=3)\n\nHST (tau= 100000, b=0.01)\n100000/100000\nHST completed and all history is recorded.\n\n\n\nplt.imshow(hst.snowdistance)\n\n\n\n\n\n\n\n\n\ntheta=100\nhst.snowweight=np.exp(-hst.snowdistance/(theta*hst.tau*hst.b**2))-np.eye(n,n)\nplt.imshow(hst.snowweight)\n\n\n\n\n\n\n\n\n- \\(\\theta=10, \\theta=100\\) 에서의 결과가 우수하다.\n\n\n시각화를 위해서 R로 자료를 옮김\n\nmaxtau=hst.tau\nW_Graph=hst.graphweight\nW_Euclid=hst.euclidweight\nW_HST=hst.snowweight\nV=np.array(hst.V)\nf=hst.f\nn=hst.n\n%R -i maxtau,W_Graph,W_Euclid,W_HST,V,f,n\n\n\n\nR을 활용한 시각화 (1): 원래자료\n\n%%R -w 2000 -h 800 -r 100\nlibrary(tidyverse)\nlibrary(latex2exp)\nlibrary(gridExtra)\nsource('rbase.R')\nVtext=str_c('node ',V+1)\nfig0&lt;-ggplot(data=tibble(V=V,f=f,Vtext=Vtext),aes(x=V,y=f,label=Vtext))+\ngeom_col(aes(fill=(f&gt;0)),width=0.1)+geom_hline(aes(yintercept=0),col=\"gray60\",lty=2)+\ngeom_text(fontface = 4,size=8)+\nxlab(\"\")+ylab(\"\")+guides(fill=FALSE)+theme(plot.title=element_text(face=\"bold.italic\"))+theme_bw()+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 15, color = \"black\", face = \"bold.italic\"))+\nylim(-1.2,1.2)+\ntheme(plot.title=element_text(face=\"bold.italic\"))\n#ggsave(plot=p0,\"./fig/2021-0217_fig0.pdf\",width=20,height=6)\nfig0\n\n\n\n\n\n\n\n\n\n\nR을 활용한 시각화 (2): Weight matrix 와 Eigen plot\n- ggplot에서 geom_tile을 사용하기 위해서 매트릭스 형태인 W_Graph, W_Euclid, W_HST를 길게 펼친다. 결과를 각각 W_Graph_long, W_Euclid_long, W_HST_long에 저장한다.\n\n%%R\ngrid&lt;-expand.grid(x=1:n,y=1:n)\nW_Graph_long&lt;-as_tibble(cbind(grid,as.vector(W_Graph)));names(W_Graph_long)&lt;-c(\"x\",\"y\",\"W\")\nW_Euclid_long&lt;-as_tibble(cbind(grid,as.vector(W_Euclid)));names(W_Euclid_long)&lt;-c(\"x\",\"y\",\"W\")\nW_HST_long&lt;-as_tibble(cbind(grid,as.vector(W_HST)));names(W_HST_long)&lt;-c(\"x\",\"y\",\"W\")\n\n- 그래프퓨리에 변환: \\((\\bf{f},\\bf{W})\\)에 그래프 퓨리에 변환을 수행함.\n\n%%R\nsource('heavysnow.R')\ngfftrslt_Euclid&lt;-gfft(f,W_Euclid)\ngfftrslt_Graph&lt;-gfft(f,W_Graph)\ngfftrslt_HST&lt;-gfft(f,W_HST)\n\n- 그래프 퓨리에 변환의 결과 고유치, 고유벡터, \\(\\bf{\\bar{f}}\\)가 반환됨.\n\n%%R\nhead(gfftrslt_HST)\n\n$λ\n [1] 1.281581e+00 1.280062e+00 1.277538e+00 1.276594e+00 1.246469e+00\n [6] 1.246289e+00 1.226622e+00 1.223498e+00 1.040855e+00 1.012083e+00\n[11] 9.567342e-01 9.183002e-01 1.337453e-02 1.628144e-17\n\n$Ψ\n               [,1]         [,2]         [,3]          [,4]        [,5]\n [1,] -1.101322e-02  0.623405435 -0.091622721  0.0017456559  0.24806543\n [2,]  1.205878e-02 -0.755269196  0.101832475 -0.0018036764  0.09749994\n [3,] -2.573593e-03  0.151302392  0.013830158 -0.0006387095 -0.55300723\n [4,] -3.533479e-02  0.001934776 -0.002380270  0.0010829689 -0.01418293\n [5,]  5.657077e-03  0.020641957  0.146149059 -0.0047285571  0.42944573\n [6,] -4.457739e-05 -0.100557489 -0.758698999  0.0208523679 -0.06840576\n [7,] -1.383726e-05  0.084966266  0.618622425 -0.0161356769 -0.14706653\n [8,]  6.379135e-01  0.009833070 -0.003446524 -0.0341177590  0.07952772\n [9,] -7.573498e-01 -0.012587447  0.004061202  0.0444005100  0.04376935\n[10,]  1.154586e-01  0.003127545  0.005845689 -0.0075676043 -0.30295320\n[11,] -4.609255e-04 -0.003317048 -0.024308993 -0.0035332301  0.02583902\n[12,]  4.730960e-02  0.001047695  0.004598465  0.2254533731  0.48704881\n[13,] -3.047283e-02 -0.001452908 -0.021027461 -0.7829094180 -0.05509983\n[14,]  3.789495e-02  0.001287373  0.015629783  0.5764486262 -0.26695761\n              [,6]        [,7]         [,8]        [,9]        [,10]\n [1,] -0.212232549  0.09881472 -0.329397556 -0.13067797  0.063725698\n [2,] -0.084101745  0.05674655 -0.190831764 -0.12127549  0.054889359\n [3,]  0.470671293 -0.13442332  0.421298057 -0.05974113  0.024188103\n [4,]  0.002765557  0.06280393 -0.009895878 -0.63041398 -0.633874206\n [5,] -0.348970037 -0.17458199  0.630033245  0.10992323 -0.052910827\n [6,]  0.048584324  0.05625359 -0.188006658  0.17769490 -0.028871736\n [7,]  0.119347649  0.10986267 -0.407133854  0.16776649  0.002820665\n [8,]  0.089444425 -0.38001485 -0.116950543  0.23074930  0.003055157\n [9,]  0.043414503 -0.20792297 -0.058773593  0.23821823  0.036484538\n[10,] -0.345030868  0.70637068  0.211023700  0.13128564  0.066544116\n[11,]  0.010336186 -0.05708445  0.031196235 -0.56567341  0.747888280\n[12,]  0.589920338  0.30490632  0.076863167 -0.06735025 -0.057838094\n[13,] -0.068030869 -0.15894641 -0.047726561 -0.13334698 -0.093017561\n[14,] -0.326018829 -0.33345933 -0.092856858 -0.16089617 -0.098997802\n             [,11]       [,12]       [,13]      [,14]\n [1,] -0.408422219 -0.18530534 -0.28175180 0.27628218\n [2,] -0.382397860 -0.17397805 -0.29307694 0.28761516\n [3,] -0.241322800 -0.11713506 -0.30076063 0.29568698\n [4,] -0.009187363  0.43375706 -0.01686117 0.08220472\n [5,]  0.217900271  0.07652214 -0.29810032 0.29572434\n [6,]  0.385963701  0.13946811 -0.28977255 0.28893239\n [7,]  0.437641440  0.16717721 -0.27181805 0.27314760\n [8,] -0.253652135  0.40038366  0.26429363 0.26763390\n [9,] -0.216705167  0.31947800  0.28793316 0.28944113\n[10,] -0.105041138  0.14508110  0.29867982 0.29882229\n[11,]  0.171365092  0.26759456  0.06408804 0.09987810\n[12,]  0.122167373 -0.25125645  0.29861358 0.29615188\n[13,]  0.182730793 -0.34935928  0.29175718 0.28892148\n[14,]  0.201613365 -0.37424884  0.27730440 0.27451198\n\n$fbar\n [1]  0.011809548 -0.017982211 -0.002522520  0.027032523 -0.061218282\n [6] -0.017170862  0.038149625 -0.005474273  0.030229173 -1.589373396\n[11] -0.258801898  0.149491686  3.372912843 -0.019579358\n\n\n\n- 시각화코드\n\n%%R -w 1000 -h 800 -r 100\nlibrary(gridExtra)\n\nfig1_1&lt;-ggplot()+geom_tile(data=W_Euclid_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"white\",high=\"black\")+\nlabs(fill=TeX('$W$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(a) Euclid\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_2&lt;-ggplot()+geom_tile(data=W_Graph_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"white\",high=\"black\")+\nlabs(fill=TeX('$\\\\hat{W}$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(b) Graph\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_3&lt;-ggplot()+geom_tile(data=W_HST_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"white\",high=\"black\")+\nlabs(fill=TeX('$\\\\hat{W}(\\\\tau)$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(c) HST\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_4&lt;-eigenplot(gfftrslt_Euclid)+ylim(0,2)+theme_light()\nfig1_5&lt;-eigenplot(gfftrslt_Graph)+ylim(0,2)+theme_light()\nfig1_6&lt;-eigenplot(gfftrslt_HST)+ylim(0,2)+theme_light()\nfig1=grid.arrange(fig1_1,fig1_2,fig1_3,fig1_4,fig1_5,fig1_6,ncol=3,nrow=2)\nfig1\nggsave(plot=fig1,\"2021-08-14-EX1(0).pdf\",width=15,height=10)\n\n\n\n\n\n\n\n\n\n%%R -w 200 -h 600 -r 120\nfig_= grid.arrange(fig1_4,fig1_5,fig1_6,nrow=3)\nggsave(plot=fig_,\"2021-08-14-EX1(1).pdf\",width=2,height=6)\n\n\n\n\n\n\n\n\n\n\nR을 활용한 시각화 (3): Decomposition\n- 디콤포지션을 수행하고 결과를 저장: \\((\\bf{f},\\bf{W})\\)에 decomposition을 수행하고 그 결과를 각각 decomprslt_Euclid, decomprslt_Graph, decomprslt_HST에 저장한다.\n\n%%R \ndecomprslt_Euclid&lt;-decompose(f,W_Euclid,V=1:n) # 0, 35000, 60000, 80000\ndecomprslt_Graph&lt;-decompose(f,W_Graph,V=1:n) # 0, 35000, 60000, 80000\ndecomprslt_HST&lt;-decompose(f,W_HST,V=1:n) # 0, 35000, 60000, 80000\n\n- 디콤포지션 결과는 아래와 같은 형태임\n\n%%R\nhead(decomprslt_Euclid)\n\n# A tibble: 6 × 5\n      V Vindex eigenvectorindex      fhat eigenvalue\n  &lt;int&gt;  &lt;int&gt;            &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1     1      1                1  1.45e-32   3.28e-18\n2     2      2                1  2.48e-17   3.28e-18\n3     3      3                1 -2.02e-16   3.28e-18\n4     4      4                1  1   e+ 0   3.28e-18\n5     5      5                1  8.73e-17   3.28e-18\n6     6      6                1 -6.32e-17   3.28e-18\n\n\n\n%%R \ndecomprslt_Euclid$method=\"Euclid\"\ndecomprslt_Graph$method=\"Graph\"\ndecomprslt_HST$method=\"HST\"\ndecomprslt&lt;-rbind(decomprslt_Euclid,decomprslt_Graph,decomprslt_HST)\n\n- 디콤포지션결과를 시각화한다. geom_col과 facet_grid를 이용.\n\n%%R -w 2000 -h 500 -r 100\nfig2&lt;-ggplot(data=decomprslt,aes(x=V,y=fhat))+\ngeom_col(aes(fill=fhat&gt;0),width=0.7)+facet_grid(method~eigenvectorindex)+geom_hline(aes(yintercept=0),col=\"gray60\",lty=2)+\nxlab(\"\")+ylab(\"\")+guides(fill=FALSE)+theme(plot.title=element_text(face=\"bold.italic\"))+theme_bw()+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 15, color = \"black\", face = \"bold.italic\"))+\nylim(-1.2,1.2)+\ntheme(plot.title=element_text(face=\"bold.italic\"))\nfig2\nggsave(plot=fig2,\"2021-08-14-EX1(2).pdf\",width=20,height=6)\n\n\n\nAppendix\n\n_, (ax1,ax2) = plt.subplots(1,2)\nax1.imshow(hst.eucliddistance[:7,:7],origin='lower')\nax2.imshow(hst.snowdistance[:7,:7],origin='lower')\nplt.show()\n\n\n\n\n\n\n\n\n\nbrk=10000\np, (ax1,ax2,ax3) = plt.subplots(1,3) \nax1.imshow(l2distance(hst.snowygrounds[:,0:brk]),origin='lower')\nax2.imshow(l2distance(hst.snowygrounds[:,brk:]),origin='lower')\nax3.imshow(hst.snowdistance,origin='lower')\n#ax4.imshow(diffusion_distance)\n#plt.show()\np.savefig('temp.pdf',transparent=True)\n\n\n\n\n\n\n\n\n\ny=hst.snowdistance[0]\nplt.plot(y,'o--')\nplt.plot([0,1,2,4,5,6,10],y[[0,1,2,4,5,6,10]],'o')\nplt.plot([3,7,8,9,11,12,13],y[[3,7,8,9,11,12,13]],'o')\n\n\n\n\n\n\n\n\n\np, (ax1,ax2,ax3) = plt.subplots(1,3) \nax1.imshow(hst.euclidweight,origin='lower')\nax2.imshow(hst.snowweight,origin='lower')\nax3.imshow(hst.graphweight,origin='lower')\n#ax4.imshow(diffusion_distance)\n#p.show()\np.savefig('temp.pdf', transparent=True)"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-08-03-HST example 2 (6).html",
    "href": "연구/교수님이랑/HST/2021-08-03-HST example 2 (6).html",
    "title": "(연구&교수님) HST example 2 (6)",
    "section": "",
    "text": "import heavysnow as hs \nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt \nfrom sklearn.decomposition import PCA \nimport rpy2 \n%load_ext rpy2.ipython\n%run pybase\n\n\n### Example 2\nnp.random.seed(777)\nimport math\npi=math.pi\nn=59\nang=np.linspace(-pi,pi-2*pi/n,n)\nV=np.arange(n)+1\nr=1\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=vx*0\n\nf2=vx*0\nf2[vy&lt;0]=3+np.random.normal(size=sum(vy&lt;0),scale=0.1)\nf2[vy&gt;0]= -3+np.random.normal(size=sum(vy&gt;0),scale=0.1)\n\n\n# Edg setting\nΣ=l2distance(np.matrix([vx,vy]).T)\nθ=0.05\nW=np.exp(-Σ**2/(2*θ**2))\nE=W&gt;0\nplt.plot(W[0,:].T)\n# color\nimport matplotlib.cm as cm\ncol=list(np.array(cm.rainbow((ang+pi)/2/pi)))\n\n\n\n\n\n\n\n\n\n%R -i ang,vx,vy,n\n\n\n%%R\nlibrary(latex2exp)\nlibrary(gridExtra)\nlibrary(tidyverse)\n\nR[write to console]: ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\nR[write to console]: ✔ ggplot2 3.3.5     ✔ purrr   0.3.4\n✔ tibble  3.1.2     ✔ dplyr   1.0.7\n✔ tidyr   1.1.3     ✔ stringr 1.4.0\n✔ readr   1.4.0     ✔ forcats 0.5.1\n\nR[write to console]: ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::combine() masks gridExtra::combine()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n\n\n\n\n%%R -w 450 -h 300 -r 100\nex2df&lt;-data.frame(cbind(ang,vx,vy))\nnames(ex2df)&lt;-c(\"ang\",\"vx\",\"vy\")\nex2plt &lt;- ggplot(data=ex2df,aes(x=vx,y=vy))+\n            geom_point(col=\"gray60\",cex=1.5,alpha=0.7)+\n            geom_point(data=ex2df[1:n,],aes(x=vx,y=vy,col=ang),cex=1.5,alpha=0.7)+\n            xlab(\"\")+ylab(\"\")+scale_colour_gradientn(colours=rainbow(7))+labs(col=TeX(\"$\\\\phi$\"))+theme_classic()+\n            theme(legend.key.width = unit(2,\"mm\"))\nshow(ex2plt)\n\n\n\n\n\n\n\n\n\ngs1=hs.GraphSignal(V,W,f1)\ngs2=hs.GraphSignal(V,W,f2)\n\n\nplt.imshow(W)\n\n\n\n\n\n\n\n\n\nDiffusion distance\n\nP=W/W.round(3).sum(axis=0)[0]\nprint(P)\nplt.imshow(P)\n\n[[2.20167327e-01 2.14586355e-01 1.46335569e-01 ... 2.83862880e-02\n  1.46335569e-01 2.14586355e-01]\n [2.14586355e-01 2.20167327e-01 2.14586355e-01 ... 3.69898283e-04\n  2.83862880e-02 1.46335569e-01]\n [1.46335569e-01 2.14586355e-01 2.20167327e-01 ... 4.82347874e-08\n  3.69898283e-04 2.83862880e-02]\n ...\n [2.83862880e-02 3.69898283e-04 4.82347874e-08 ... 2.20167327e-01\n  2.14586355e-01 1.46335569e-01]\n [1.46335569e-01 2.83862880e-02 3.69898283e-04 ... 2.14586355e-01\n  2.20167327e-01 2.14586355e-01]\n [2.14586355e-01 1.46335569e-01 2.83862880e-02 ... 1.46335569e-01\n  2.14586355e-01 2.20167327e-01]]\n\n\n\n\n\n\n\n\n\n\nplt.imshow(P@P@P@P)\n\n\n\n\n\n\n\n\n\nP4=P@P@P@P\ndiffusion_distance=l2distance(P4)\nplt.imshow(diffusion_distance)\n\n\n\n\n\n\n\n\n\n\nSnow distance\n\nhs1=hs.HeavySnowTransform(gs1)\nhs2=hs.HeavySnowTransform(gs2)\n\n\nhs1.snow(tau=70000,b=0.1)\nhs2.snow(tau=70000,b=0.1)\n\nHST (tau= 70000, b=0.1)\n70000/70000\nHST completed and all history is recorded.\nHST (tau= 70000, b=0.1)\n70000/70000\nHST completed and all history is recorded.\n\n\n\nfrom sklearn.decomposition import PCA \np1=PCA(n_components=3)\np2=PCA(n_components=3)\np3=PCA(n_components=3)\np4=PCA(n_components=3)\np5=PCA(n_components=3)\np6=PCA(n_components=3)\n\n\np1.fit(hs1.eucliddistance)\np2.fit(diffusion_distance)\np3.fit(hs1.snowdistance)\np4.fit(hs2.eucliddistance)\np5.fit(diffusion_distance)\np6.fit(hs2.snowdistance)\n\nr1=p1.transform(hs1.eucliddistance)\nr2=p2.transform(diffusion_distance)\nr3=p3.transform(hs1.snowdistance)\nr4=p4.transform(hs2.eucliddistance)\nr5=p5.transform(diffusion_distance)\nr6=p6.transform(hs2.snowdistance)\n\n/home/cgb4/anaconda3/envs/py38r40/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:470: RuntimeWarning: invalid value encountered in true_divide\n  explained_variance_ratio_ = explained_variance_ / total_var\n\n\n\n# 1. \np=plt.figure(figsize=(12,4), dpi=70)  # Make figure object \n\n# 2. \nax1=p.add_subplot(2,4,1, projection='3d')\nax2=p.add_subplot(2,4,2, projection='3d')\nax3=p.add_subplot(2,4,3, projection='3d')\nax4=p.add_subplot(2,4,4, projection='3d')\nax5=p.add_subplot(2,4,5, projection='3d')\nax6=p.add_subplot(2,4,6, projection='3d')\nax7=p.add_subplot(2,4,7, projection='3d')\nax8=p.add_subplot(2,4,8, projection='3d')\n\n# 3. \nax1.grid(False)\nax1.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax1.scatter3D(vx, vy, f1, c=col,alpha=1)\nax1.set_xlim(-1,1)\nax1.set_ylim(-1,1)\nax1.set_zlim(-5,5)\n\nax2.grid(False)\nax2.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax2.scatter3D(r1[:,0],r1[:,1],r1[:,2],s=20,c=col,alpha=1)\n\nax3.grid(False)\nax3.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax3.scatter3D(r2[:,0],r2[:,1],r2[:,2],s=20,c=col,alpha=1)\n\nax4.grid(False)\nax4.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax4.scatter3D(r3[:,0],r3[:,1],r3[:,2],s=20,c=col,alpha=1)\n\n\nax5.grid(False)\nax5.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\ntop = -f2\nbottom = np.zeros_like(top)\nwidth=depth=0.05\nax5.bar3d(vx, vy, bottom, width, depth, top, shade=False,color=col)\nax5.set_xlim(-1,1)\nax5.set_ylim(-1,1)\nax5.set_zlim(-5,5)\n\nax6.grid(False)\nax6.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax6.scatter3D(r4[:,0],r4[:,1],r4[:,2],s=20,c=col,alpha=1)\n\nax7.grid(False)\nax7.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax7.scatter3D(r5[:,0],r5[:,1],r5[:,2],s=20,c=col,alpha=1)\n\nax8.grid(False)\nax8.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax8.scatter3D(r6[:,0],r6[:,1],r6[:,2],s=20,c=col,alpha=1)\np.tight_layout(h_pad=2.6) #rect : tuple (left, bottom, right, top), optional"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-08-02-HST example 1 (3).html",
    "href": "연구/교수님이랑/HST/2021-08-02-HST example 1 (3).html",
    "title": "(연구&교수님) HST example 1 (3)",
    "section": "",
    "text": "Import\n\nimport heavysnow as hs\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport rpy2 \n%load_ext rpy2.ipython\n%run pybase\n\n\n\nData\n\nf=np.array([-1,-1,-1,1,-1,-1,-1,1,1,1,-1,1,1,1])*1.0\nn=len(f)\nV=list(range(n))\nW=np.zeros([n,n])\nfor i in range(n):\n    for j in range(n):\n        if abs(i-j)==1: W[i,j]=1\nW[0,0]=1\nW[n-1,n-1]=1\n\n\ngs=hs.GraphSignal(V,W,f)\n\n\ngs.initdist=np.array([1/n]*n)\n\n\n\nHST\n\nhst=hs.HeavySnowTransform(gs)\nhst.snow(tau=80000,b=0.03)\n\nHST (tau= 80000, b=0.03)\n80000/80000\nHST completed and all history is recorded.\n\n\n\nplt.imshow(hst.snowweight)\n\n\n\n\n\n\n\n\n\n\n시각화를 위해서 R로 자료를 옮김\n\nmaxtau=hst.tau\nW_Graph=hst.graphweight\nW_Euclid=hst.euclidweight\nW_HST=hst.snowweight\nV=np.array(hst.V)\nf=hst.f\nn=hst.n\n%R -i maxtau,W_Graph,W_Euclid,W_HST,V,f,n\n\n\n\nR을 활용한 시각화 (1): 원래자료\n\n%%R -w 2000 -h 800 -r 100\nlibrary(tidyverse)\nlibrary(latex2exp)\nlibrary(gridExtra)\nsource('rbase.R')\nVtext=str_c('node ',V+1)\nfig0&lt;-ggplot(data=tibble(V=V,f=f,Vtext=Vtext),aes(x=V,y=f,label=Vtext))+\ngeom_col(aes(fill=(f&gt;0)),width=0.1)+geom_hline(aes(yintercept=0),col=\"gray60\",lty=2)+\ngeom_text(fontface = 4,size=8)+\nxlab(\"\")+ylab(\"\")+guides(fill=FALSE)+theme(plot.title=element_text(face=\"bold.italic\"))+theme_bw()+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 15, color = \"black\", face = \"bold.italic\"))+\nylim(-1.2,1.2)+\ntheme(plot.title=element_text(face=\"bold.italic\"))\n#ggsave(plot=p0,\"./fig/2021-0217_fig0.pdf\",width=20,height=6)\nfig0\n\nR[write to console]: ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\nR[write to console]: ✔ ggplot2 3.3.5     ✔ purrr   0.3.4\n✔ tibble  3.1.3     ✔ dplyr   1.0.7\n✔ tidyr   1.1.3     ✔ stringr 1.4.0\n✔ readr   2.0.1     ✔ forcats 0.5.1\n\nR[write to console]: ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nR[write to console]: \nAttaching package: ‘gridExtra’\n\n\nR[write to console]: The following object is masked from ‘package:dplyr’:\n\n    combine\n\n\nR[write to console]: \nAttaching package: ‘lubridate’\n\n\nR[write to console]: The following objects are masked from ‘package:base’:\n\n    date, intersect, setdiff, union\n\n\n\n\n\n\n\n\n\n\n\n\n\nR을 활용한 시각화 (2): Weight matrix 와 Eigen plot\n- ggplot에서 geom_tile을 사용하기 위해서 매트릭스 형태인 W_Graph, W_Euclid, W_HST를 길게 펼친다. 결과를 각각 W_Graph_long, W_Euclid_long, W_HST_long에 저장한다.\n\n%%R\ngrid&lt;-expand.grid(x=1:n,y=1:n)\nW_Graph_long&lt;-as_tibble(cbind(grid,as.vector(W_Graph)));names(W_Graph_long)&lt;-c(\"x\",\"y\",\"W\")\nW_Euclid_long&lt;-as_tibble(cbind(grid,as.vector(W_Euclid)));names(W_Euclid_long)&lt;-c(\"x\",\"y\",\"W\")\nW_HST_long&lt;-as_tibble(cbind(grid,as.vector(W_HST)));names(W_HST_long)&lt;-c(\"x\",\"y\",\"W\")\n\n- 그래프퓨리에 변환: \\((\\bf{f},\\bf{W})\\)에 그래프 퓨리에 변환을 수행함.\n\n%%R\nsource('heavysnow.R')\ngfftrslt_Euclid&lt;-gfft(f,W_Euclid)\ngfftrslt_Graph&lt;-gfft(f,W_Graph)\ngfftrslt_HST&lt;-gfft(f,W_HST)\n\nR[write to console]: \nAttaching package: ‘kohonen’\n\n\nR[write to console]: The following object is masked from ‘package:purrr’:\n\n    map\n\n\nR[write to console]: \nAttaching package: ‘igraph’\n\n\nR[write to console]: The following objects are masked from ‘package:lubridate’:\n\n    %--%, union\n\n\nR[write to console]: The following objects are masked from ‘package:dplyr’:\n\n    as_data_frame, groups, union\n\n\nR[write to console]: The following objects are masked from ‘package:purrr’:\n\n    compose, simplify\n\n\nR[write to console]: The following object is masked from ‘package:tidyr’:\n\n    crossing\n\n\nR[write to console]: The following object is masked from ‘package:tibble’:\n\n    as_data_frame\n\n\nR[write to console]: The following objects are masked from ‘package:stats’:\n\n    decompose, spectrum\n\n\nR[write to console]: The following object is masked from ‘package:base’:\n\n    union\n\n\n\n\n- 그래프 퓨리에 변환의 결과 고유치, 고유벡터, \\(\\bf{\\bar{f}}\\)가 반환됨.\n\n%%R\nhead(gfftrslt_HST)\n\n$λ\n [1] 1.193925e-06 2.092204e-07 9.580557e-08 5.455557e-08 1.064895e-08\n [6] 6.060082e-09 4.294887e-10 1.064746e-14 3.364764e-16 3.235964e-18\n[11] 6.618887e-21 2.770527e-24 8.040989e-30 5.752486e-36\n\n$Ψ\n               [,1]          [,2]          [,3]          [,4]          [,5]\n [1,] -7.063428e-01 -6.053749e-22  1.869147e-19  7.626175e-22  2.679111e-19\n [2,]  7.078700e-01 -6.045045e-22  1.868795e-19  7.615210e-22  2.616164e-19\n [3,] -7.335644e-07 -4.204124e-19  3.330671e-16  5.296120e-19 -5.467861e-15\n [4,]  1.065757e-27  1.220969e-16  1.464965e-17 -1.784350e-16  7.351012e-17\n [5,]  5.023002e-23 -3.388788e-17 -2.408081e-01 -3.058298e-14  7.110555e-01\n [6,] -9.820624e-25 -1.709990e-17  9.427587e-01  6.163647e-14  9.585785e-03\n [7,]  1.727671e-26 -3.450357e-17 -2.306893e-01  1.219716e-13 -7.030706e-01\n [8,] -3.292670e-40 -1.634073e-18  7.331731e-14 -2.440900e-01  2.886819e-12\n [9,]  3.043749e-42 -3.277651e-19 -1.999038e-14  9.427074e-01  5.432442e-13\n[10,]  7.337701e-45  3.951862e-19  2.612372e-15 -2.274266e-01 -1.316616e-12\n[11,] -1.024163e-47  1.477549e-22  5.040934e-26  3.891927e-13  1.299756e-23\n[12,] -2.504526e-62  1.470243e-17 -1.925844e-34  2.944241e-20  8.732261e-31\n[13,] -1.184385e-66 -7.071068e-01  3.074302e-40 -1.069214e-24 -1.049724e-31\n[14,]  1.136956e-67  7.071068e-01 -3.074303e-40  1.069214e-24  1.049724e-31\n               [,6]          [,7]          [,8]          [,9]         [,10]\n [1,] -3.688129e-22 -7.078685e-01  8.811501e-16 -9.614111e-14  2.315469e-08\n [2,] -3.682826e-22 -7.063413e-01  8.798831e-16 -9.600288e-14  2.312140e-08\n [3,] -2.561281e-19  2.034936e-03  6.119287e-13 -6.676675e-11  1.608015e-05\n [4,]  2.062995e-17 -1.204826e-19 -2.948330e-11  1.638106e-08 -2.088525e-06\n [5,]  3.545791e-12 -1.596836e-16 -7.499280e-07 -5.446001e-09 -6.606146e-01\n [6,]  7.982009e-13 -8.504093e-17 -3.784040e-07 -2.747985e-09 -3.333379e-01\n [7,] -6.567954e-13 -1.790135e-16 -7.636026e-07 -5.545319e-09 -6.726620e-01\n [8,] -7.135637e-01  4.469097e-27  6.566939e-01  4.348222e-13 -7.454780e-07\n [9,] -1.578573e-02  2.506379e-27  3.332471e-01  2.206557e-13 -3.783008e-07\n[10,]  7.004125e-01  5.495560e-27  6.765349e-01  4.479597e-13 -7.679983e-07\n[11,] -1.079305e-11 -1.185759e-36 -5.933708e-06  1.886461e-14  2.216327e-08\n[12,] -8.163006e-19 -9.037231e-44 -4.487655e-13 -9.142051e-09  1.751612e-15\n[13,]  1.023878e-18  5.625541e-40 -4.747859e-13  7.071068e-01 -5.829251e-09\n[14,] -1.023878e-18 -5.625541e-40 -4.748538e-13  7.071068e-01 -5.829251e-09\n              [,11]         [,12]         [,13]        [,14]\n [1,]  1.439952e-03 -6.653658e-09 -2.766438e-13 1.119196e-15\n [2,]  1.437882e-03 -6.644092e-09 -2.762461e-13 1.117587e-15\n [3,]  9.999979e-01 -4.620740e-06 -1.921198e-10 7.772436e-13\n [4,] -4.620716e-06 -1.000000e+00 -3.264321e-06 1.311061e-08\n [5,]  1.062281e-05  1.379661e-06 -1.463231e-08 5.922670e-11\n [6,]  5.360137e-06  6.961598e-07 -7.383283e-09 2.988506e-11\n [7,]  1.081653e-05  1.404821e-06 -1.489916e-08 6.030680e-11\n [8,]  1.158480e-11 -5.084759e-12 -3.896591e-06 1.577206e-08\n [9,]  5.878831e-12 -2.580111e-12 -1.977374e-06 8.003731e-09\n[10,]  1.193477e-11 -5.238249e-12 -4.014335e-06 1.624865e-08\n[11,] -1.773944e-10  3.264348e-06 -9.999918e-01 4.047547e-03\n[12,] -9.525445e-17 -1.019884e-10  4.047547e-03 9.999918e-01\n[13,]  4.735857e-11  1.158317e-08  2.621626e-11 6.464353e-09\n[14,]  4.735857e-11  1.158317e-08  2.621626e-11 6.464353e-09\n\n$fbar\n [1] -1.526477e-03 -6.823100e-09 -4.712613e-01  4.711907e-01 -1.757068e-02\n [6] -2.893692e-02  1.412175e+00  1.666484e+00  1.414214e+00  1.666594e+00\n[11] -1.002907e+00 -1.000002e+00  1.004026e+00  9.959443e-01\n\n\n\n- 시각화코드\n\n%%R -w 1000 -h 800 -r 100\nlibrary(gridExtra)\n\nfig1_1&lt;-ggplot()+geom_tile(data=W_Euclid_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"red\",high=\"blue\",mid=\"purple\",midpoint=0.25,breaks=c(0,0.5,0.99))+\nlabs(fill=TeX('$W$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(a) Euclid\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_2&lt;-ggplot()+geom_tile(data=W_Graph_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"red\",high=\"blue\",mid=\"purple\",midpoint=0.5,breaks=c(0,0.5,0.99))+\nlabs(fill=TeX('$\\\\hat{W}$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(b) Graph\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_3&lt;-ggplot()+geom_tile(data=W_HST_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"red\",high=\"blue\",mid=\"purple\",midpoint=0.5,breaks=c(0,0.5,0.99))+\nlabs(fill=TeX('$\\\\hat{W}(\\\\tau)$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(c) HST\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_4&lt;-eigenplot(gfftrslt_Euclid)+ylim(0,2)+theme_light()\nfig1_5&lt;-eigenplot(gfftrslt_Graph)+ylim(0,2)+theme_light()\nfig1_6&lt;-eigenplot(gfftrslt_HST)+ylim(0,2)+theme_light()\nfig1=grid.arrange(fig1_1,fig1_2,fig1_3,fig1_4,fig1_5,fig1_6,ncol=3,nrow=2)\nfig1\n#ggsave(plot=grid.arrange(p1_a,p1_b,p1_c,ncol=3),\"2021-07-22_fig1.png\",width=20,height=4)\n\nTableGrob (2 x 3) \"arrange\": 6 grobs\n  z     cells    name           grob\n1 1 (1-1,1-1) arrange gtable[layout]\n2 2 (1-1,2-2) arrange gtable[layout]\n3 3 (1-1,3-3) arrange gtable[layout]\n4 4 (2-2,1-1) arrange gtable[layout]\n5 5 (2-2,2-2) arrange gtable[layout]\n6 6 (2-2,3-3) arrange gtable[layout]\n\n\n\n\n\n\n\n\n\n\n\nR을 활용한 시각화 (3): Decomposition\n- 디콤포지션을 수행하고 결과를 저장: \\((\\bf{f},\\bf{W})\\)에 decomposition을 수행하고 그 결과를 각각 decomprslt_Euclid, decomprslt_Graph, decomprslt_HST에 저장한다.\n\n%%R \ndecomprslt_Euclid&lt;-decompose(f,W_Euclid,V=1:n) # 0, 35000, 60000, 80000\ndecomprslt_Graph&lt;-decompose(f,W_Graph,V=1:n) # 0, 35000, 60000, 80000\ndecomprslt_HST&lt;-decompose(f,W_HST,V=1:n) # 0, 35000, 60000, 80000\n\nNote: Using an external vector in selections is ambiguous.\nℹ Use `all_of(n)` instead of `n` to silence this message.\nℹ See &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;.\nThis message is displayed once per session.\n\n\n- 디콤포지션 결과는 아래와 같은 형태임\n\n%%R\nhead(decomprslt_Euclid)\n\n# A tibble: 6 × 5\n      V Vindex eigenvectorindex      fhat eigenvalue\n  &lt;int&gt;  &lt;int&gt;            &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1     1      1                1  1.45e-32   3.28e-18\n2     2      2                1  2.48e-17   3.28e-18\n3     3      3                1 -2.02e-16   3.28e-18\n4     4      4                1  1   e+ 0   3.28e-18\n5     5      5                1  8.73e-17   3.28e-18\n6     6      6                1 -6.32e-17   3.28e-18\n\n\n\n%%R \ndecomprslt_Euclid$method=\"Euclid\"\ndecomprslt_Graph$method=\"Graph\"\ndecomprslt_HST$method=\"HST\"\ndecomprslt&lt;-rbind(decomprslt_Euclid,decomprslt_Graph,decomprslt_HST)\n\n- 디콤포지션결과를 시각화한다. geom_col과 facet_grid를 이용.\n\n%%R -w 2000 -h 500 -r 100\nfig2&lt;-ggplot(data=decomprslt,aes(x=V,y=fhat))+\ngeom_col(aes(fill=fhat&gt;0),width=0.7)+facet_grid(method~eigenvectorindex)+geom_hline(aes(yintercept=0),col=\"gray60\",lty=2)+\nxlab(\"\")+ylab(\"\")+guides(fill=FALSE)+theme(plot.title=element_text(face=\"bold.italic\"))+theme_bw()+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 15, color = \"black\", face = \"bold.italic\"))+\nylim(-1.5,1.5)+\ntheme(plot.title=element_text(face=\"bold.italic\"))\nfig2\n#ggsave(plot=fig2,\"./fig/2021-0514_fig2.pdf\",width=20,height=6)"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-08-03-HST example 2 (5).html",
    "href": "연구/교수님이랑/HST/2021-08-03-HST example 2 (5).html",
    "title": "(연구&교수님) HST example 2 (5)",
    "section": "",
    "text": "import heavysnow as hs \nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt \nfrom sklearn.decomposition import PCA \nimport rpy2 \n%load_ext rpy2.ipython\n%run pybase\n\n\n### Example 2\nnp.random.seed(777)\nimport math\npi=math.pi\nn=59\nang=np.linspace(-pi,pi-2*pi/n,n)\nV=np.arange(n)+1\nr=1\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=vx*0\n\nf2=vx*0\nf2[vy&lt;0]=3+np.random.normal(size=sum(vy&lt;0),scale=0.1)\nf2[vy&gt;0]= -3+np.random.normal(size=sum(vy&gt;0),scale=0.1)\n\n\n# Edg setting\nΣ=l2distance(np.matrix([vx,vy]).T)\nθ=0.05\nW=np.exp(-Σ**2/(2*θ**2))\nE=W&gt;0\nplt.plot(W[0,:].T)\n# color\nimport matplotlib.cm as cm\ncol=list(np.array(cm.rainbow((ang+pi)/2/pi)))\n\n\n\n\n\n\n\n\n\n%R -i ang,vx,vy,n\n\n\n%%R\nlibrary(latex2exp)\nlibrary(gridExtra)\nlibrary(tidyverse)\n\nR[write to console]: ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\nR[write to console]: ✔ ggplot2 3.3.5     ✔ purrr   0.3.4\n✔ tibble  3.1.2     ✔ dplyr   1.0.7\n✔ tidyr   1.1.3     ✔ stringr 1.4.0\n✔ readr   1.4.0     ✔ forcats 0.5.1\n\nR[write to console]: ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::combine() masks gridExtra::combine()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n\n\n\n\n%%R -w 450 -h 300 -r 100\nex2df&lt;-data.frame(cbind(ang,vx,vy))\nnames(ex2df)&lt;-c(\"ang\",\"vx\",\"vy\")\nex2plt &lt;- ggplot(data=ex2df,aes(x=vx,y=vy))+\n            geom_point(col=\"gray60\",cex=1.5,alpha=0.7)+\n            geom_point(data=ex2df[1:n,],aes(x=vx,y=vy,col=ang),cex=1.5,alpha=0.7)+\n            xlab(\"\")+ylab(\"\")+scale_colour_gradientn(colours=rainbow(7))+labs(col=TeX(\"$\\\\phi$\"))+theme_classic()+\n            theme(legend.key.width = unit(2,\"mm\"))\nshow(ex2plt)\n\n\n\n\n\n\n\n\n\ngs1=hs.GraphSignal(V,W,f1)\ngs2=hs.GraphSignal(V,W,f2)\n\n\nplt.imshow(W)\n\n\n\n\n\n\n\n\n\nDiffusion distance\n\nP=W/W.round(3).sum(axis=0)[0]\nprint(P)\nplt.imshow(P)\n\n[[2.20167327e-01 2.14586355e-01 1.46335569e-01 ... 2.83862880e-02\n  1.46335569e-01 2.14586355e-01]\n [2.14586355e-01 2.20167327e-01 2.14586355e-01 ... 3.69898283e-04\n  2.83862880e-02 1.46335569e-01]\n [1.46335569e-01 2.14586355e-01 2.20167327e-01 ... 4.82347874e-08\n  3.69898283e-04 2.83862880e-02]\n ...\n [2.83862880e-02 3.69898283e-04 4.82347874e-08 ... 2.20167327e-01\n  2.14586355e-01 1.46335569e-01]\n [1.46335569e-01 2.83862880e-02 3.69898283e-04 ... 2.14586355e-01\n  2.20167327e-01 2.14586355e-01]\n [2.14586355e-01 1.46335569e-01 2.83862880e-02 ... 1.46335569e-01\n  2.14586355e-01 2.20167327e-01]]\n\n\n\n\n\n\n\n\n\n\nplt.imshow(P@P@P@P)\n\n\n\n\n\n\n\n\n\nP4=P@P@P@P\ndiffusion_distance=l2distance(P4)\nplt.imshow(diffusion_distance)\n\n\n\n\n\n\n\n\n\n\nSnow distance\n\nhs1=hs.HeavySnowTransform(gs1)\nhs2=hs.HeavySnowTransform(gs2)\n\n\nhs1.snow(tau=60000,b=0.1)\nhs2.snow(tau=60000,b=0.1)\n\nHST (tau= 60000, b=0.1)\n60000/60000\nHST completed and all history is recorded.\nHST (tau= 60000, b=0.1)\n60000/60000\nHST completed and all history is recorded.\n\n\n\nfrom sklearn.decomposition import PCA \np1=PCA(n_components=3)\np2=PCA(n_components=3)\np3=PCA(n_components=3)\np4=PCA(n_components=3)\np5=PCA(n_components=3)\np6=PCA(n_components=3)\n\n\np1.fit(hs1.eucliddistance)\np2.fit(diffusion_distance)\np3.fit(hs1.snowdistance)\np4.fit(hs2.eucliddistance)\np5.fit(diffusion_distance)\np6.fit(hs2.snowdistance)\n\nr1=p1.transform(hs1.eucliddistance)\nr2=p2.transform(diffusion_distance)\nr3=p3.transform(hs1.snowdistance)\nr4=p4.transform(hs2.eucliddistance)\nr5=p5.transform(diffusion_distance)\nr6=p6.transform(hs2.snowdistance)\n\n/home/cgb4/anaconda3/envs/py38r40/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:470: RuntimeWarning: invalid value encountered in true_divide\n  explained_variance_ratio_ = explained_variance_ / total_var\n\n\n\n# 1. \np=plt.figure(figsize=(12,4), dpi=70)  # Make figure object \n\n# 2. \nax1=p.add_subplot(2,4,1, projection='3d')\nax2=p.add_subplot(2,4,2, projection='3d')\nax3=p.add_subplot(2,4,3, projection='3d')\nax4=p.add_subplot(2,4,4, projection='3d')\nax5=p.add_subplot(2,4,5, projection='3d')\nax6=p.add_subplot(2,4,6, projection='3d')\nax7=p.add_subplot(2,4,7, projection='3d')\nax8=p.add_subplot(2,4,8, projection='3d')\n\n# 3. \nax1.grid(False)\nax1.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax1.scatter3D(vx, vy, f1, c=col,alpha=1)\nax1.set_xlim(-1,1)\nax1.set_ylim(-1,1)\nax1.set_zlim(-5,5)\n\nax2.grid(False)\nax2.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax2.scatter3D(r1[:,0],r1[:,1],r1[:,2],s=20,c=col,alpha=1)\n\nax3.grid(False)\nax3.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax3.scatter3D(r2[:,0],r2[:,1],r2[:,2],s=20,c=col,alpha=1)\n\nax4.grid(False)\nax4.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax4.scatter3D(r3[:,0],r3[:,1],r3[:,2],s=20,c=col,alpha=1)\n\n\nax5.grid(False)\nax5.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\ntop = -f2\nbottom = np.zeros_like(top)\nwidth=depth=0.05\nax5.bar3d(vx, vy, bottom, width, depth, top, shade=False,color=col)\nax5.set_xlim(-1,1)\nax5.set_ylim(-1,1)\nax5.set_zlim(-5,5)\n\nax6.grid(False)\nax6.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax6.scatter3D(r4[:,0],r4[:,1],r4[:,2],s=20,c=col,alpha=1)\n\nax7.grid(False)\nax7.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax7.scatter3D(r5[:,0],r5[:,1],r5[:,2],s=20,c=col,alpha=1)\n\nax8.grid(False)\nax8.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax8.scatter3D(r6[:,0],r6[:,1],r6[:,2],s=20,c=col,alpha=1)\np.tight_layout(h_pad=2.6) #rect : tuple (left, bottom, right, top), optional"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-08-09-HST example 2 (2).html",
    "href": "연구/교수님이랑/HST/2021-08-09-HST example 2 (2).html",
    "title": "(연구&교수님) HST example 2 (2)",
    "section": "",
    "text": "import heavysnow as hs \nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt \nfrom sklearn.decomposition import PCA \nimport rpy2 \n%load_ext rpy2.ipython\n%run pybase\n\n\n### Example 2\nnp.random.seed(777)\nimport math\npi=math.pi\nn=60\nang=np.linspace(-pi,pi-2*pi/n,n)\nV=np.arange(n)+1\nr=1\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=vx*0\n\nf2=vx*0\nf2[vy&lt;0]=3+np.random.normal(size=sum(vy&lt;0),scale=0.1)\nf2[vy&gt;=0]= -3+np.random.normal(size=sum(vy&gt;=0),scale=0.1)\n\n\n# Edg setting\nΣ=l2distance(np.matrix([vx,vy]).T)\nθ=0.05\nW=np.exp(-Σ**2/(2*θ**2))-np.eye(n,n)\nE=W&gt;0\nplt.plot(W[0,:].T)\n# color\nimport matplotlib.cm as cm\ncol=list(np.array(cm.rainbow((ang+pi)/2/pi)))\n\n\n\n\n\n\n\n\n\ngs1=hs.GraphSignal(V,W,f1)\ngs2=hs.GraphSignal(V,W,f2)\n\n\nDiffusion distance\n\nP=W/W.round(3).sum(axis=0)[0]\nprint(P)\nplt.imshow(P)\n\n[[0.00000000e+00 2.69988437e-01 1.88738971e-01 ... 4.06913345e-02\n  1.88738971e-01 2.69988437e-01]\n [2.69988437e-01 0.00000000e+00 2.69988437e-01 ... 6.99686096e-04\n  4.06913345e-02 1.88738971e-01]\n [1.88738971e-01 2.69988437e-01 0.00000000e+00 ... 1.60540051e-07\n  6.99686096e-04 4.06913345e-02]\n ...\n [4.06913345e-02 6.99686096e-04 1.60540051e-07 ... 0.00000000e+00\n  2.69988437e-01 1.88738971e-01]\n [1.88738971e-01 4.06913345e-02 6.99686096e-04 ... 2.69988437e-01\n  0.00000000e+00 2.69988437e-01]\n [2.69988437e-01 1.88738971e-01 4.06913345e-02 ... 1.88738971e-01\n  2.69988437e-01 0.00000000e+00]]\n\n\n\n\n\n\n\n\n\n\nplt.imshow(P@P@P@P)\n\n\n\n\n\n\n\n\n\nP4=P@P@P@P\ndiffusion_distance=l2distance(P4)\nplt.imshow(diffusion_distance)\n\n\n\n\n\n\n\n\n\n\nSnow distance\n\nhs1=hs.HeavySnowTransform(gs1)\nhs2=hs.HeavySnowTransform(gs2)\n\n\nhs1.snow(tau=100000,b=0.05)\nhs2.snow(tau=100000,b=0.05)\n\nHST (tau= 100000, b=0.05)\n100000/100000\nHST completed and all history is recorded.\nHST (tau= 100000, b=0.05)\n100000/100000\nHST completed and all history is recorded.\n\n\n\nfrom sklearn.decomposition import PCA \np1=PCA(n_components=3)\np2=PCA(n_components=3)\np3=PCA(n_components=3)\np4=PCA(n_components=3)\np5=PCA(n_components=3)\np6=PCA(n_components=3)\n\n\np1.fit(hs1.eucliddistance)\np2.fit(diffusion_distance)\np3.fit(hs1.snowdistance)\np4.fit(hs2.eucliddistance)\np5.fit(diffusion_distance)\np6.fit(hs2.snowdistance)\n\nr1=p1.transform(hs1.eucliddistance)\nr2=p2.transform(diffusion_distance)\nr3=p3.transform(hs1.snowdistance)\nr4=p4.transform(hs2.eucliddistance)\nr5=p5.transform(diffusion_distance)\nr6=p6.transform(hs2.snowdistance)\n\n/home/cgb4/anaconda3/envs/py38r40/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:470: RuntimeWarning: invalid value encountered in true_divide\n  explained_variance_ratio_ = explained_variance_ / total_var\n\n\n\n# 1. \np=plt.figure(figsize=(12,4), dpi=70)  # Make figure object \n\n# 2. \nax1=p.add_subplot(2,4,1, projection='3d')\nax2=p.add_subplot(2,4,2, projection='3d')\nax3=p.add_subplot(2,4,3, projection='3d')\nax4=p.add_subplot(2,4,4, projection='3d')\nax5=p.add_subplot(2,4,5, projection='3d')\nax6=p.add_subplot(2,4,6, projection='3d')\nax7=p.add_subplot(2,4,7, projection='3d')\nax8=p.add_subplot(2,4,8, projection='3d')\n\n# 3. \nax1.grid(False)\nax1.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax1.scatter3D(vx, vy, f1, c=col,alpha=1)\nax1.set_xlim(-1,1)\nax1.set_ylim(-1,1)\nax1.set_zlim(-5,5)\n\nax2.grid(False)\nax2.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax2.scatter3D(r1[:,0],r1[:,1],r1[:,2],s=20,c=col,alpha=1)\n\nax3.grid(False)\nax3.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax3.scatter3D(r2[:,0],r2[:,1],r2[:,2],s=20,c=col,alpha=1)\n\nax4.grid(False)\nax4.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax4.scatter3D(r3[:,0],r3[:,1],r3[:,2],s=20,c=col,alpha=1)\n\n\nax5.grid(False)\nax5.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\ntop = -f2\nbottom = np.zeros_like(top)\nwidth=depth=0.05\nax5.bar3d(vx, vy, bottom, width, depth, top, shade=False,color=col)\nax5.set_xlim(-1,1)\nax5.set_ylim(-1,1)\nax5.set_zlim(-5,5)\n\nax6.grid(False)\nax6.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax6.scatter3D(r4[:,0],r4[:,1],r4[:,2],s=20,c=col,alpha=1)\n\nax7.grid(False)\nax7.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax7.scatter3D(r5[:,0],r5[:,1],r5[:,2],s=20,c=col,alpha=1)\n\nax8.grid(False)\nax8.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax8.scatter3D(r6[:,0],r6[:,1],r6[:,2],s=20,c=col,alpha=1)\np.tight_layout(h_pad=2.6) #rect : tuple (left, bottom, right, top), optional"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-08-09-HST example 2 (6).html",
    "href": "연구/교수님이랑/HST/2021-08-09-HST example 2 (6).html",
    "title": "(연구&교수님) HST example 2 (6)",
    "section": "",
    "text": "import heavysnow as hs \nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt \nfrom sklearn.decomposition import PCA \nimport rpy2 \n%load_ext rpy2.ipython\n%run pybase\n\n\n### Example 2\nnp.random.seed(777)\nimport math\npi=math.pi\nn=60\nang=np.linspace(-pi,pi-2*pi/n,n)\nV=np.arange(n)+1\nr=1\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=vx*0\n\nf2=vx*0\nf2[vy&lt;0]=3+np.random.normal(size=sum(vy&lt;0),scale=0.1)\nf2[vy&gt;=0]= -3+np.random.normal(size=sum(vy&gt;=0),scale=0.1)\n\n\n# Edg setting\nΣ=l2distance(np.matrix([vx,vy]).T)\nθ=0.25\nW=np.exp(-Σ**2/(2*θ**2))-np.eye(n,n)\nE=W&gt;0\nplt.plot(W[0,:].T)\n# color\nimport matplotlib.cm as cm\ncol=list(np.array(cm.rainbow((ang+pi)/2/pi)))\n\n\n\n\n\n\n\n\n\ngs1=hs.GraphSignal(V,W,f1)\ngs2=hs.GraphSignal(V,W,f2)\n\n\nDiffusion distance\n\nP=W/W.round(3).sum(axis=0)[0]\nprint(P)\nplt.imshow(P)\n\n[[0.         0.10569617 0.10419332 ... 0.09799084 0.10419332 0.10569617]\n [0.10569617 0.         0.10569617 ... 0.08329167 0.09799084 0.10419332]\n [0.10419332 0.10569617 0.         ... 0.05957016 0.08329167 0.09799084]\n ...\n [0.09799084 0.08329167 0.05957016 ... 0.         0.10569617 0.10419332]\n [0.10419332 0.09799084 0.08329167 ... 0.10569617 0.         0.10569617]\n [0.10569617 0.10419332 0.09799084 ... 0.10419332 0.10569617 0.        ]]\n\n\n\n\n\n\n\n\n\n\nplt.imshow(P@P@P@P)\n\n\n\n\n\n\n\n\n\nP4=P@P@P@P\ndiffusion_distance=l2distance(P4)\nplt.imshow(diffusion_distance)\n\n\n\n\n\n\n\n\n\n\nSnow distance\n\nhs1=hs.HeavySnowTransform(gs1)\nhs2=hs.HeavySnowTransform(gs2)\n\n\nhs1.snow(tau=100000,b=0.05)\nhs2.snow(tau=100000,b=0.05)\n\nHST (tau= 100000, b=0.05)\n100000/100000\nHST completed and all history is recorded.\nHST (tau= 100000, b=0.05)\n100000/100000\nHST completed and all history is recorded.\n\n\n\nfrom sklearn.decomposition import PCA \np1=PCA(n_components=3)\np2=PCA(n_components=3)\np3=PCA(n_components=3)\np4=PCA(n_components=3)\np5=PCA(n_components=3)\np6=PCA(n_components=3)\n\n\np1.fit(hs1.eucliddistance)\np2.fit(diffusion_distance)\np3.fit(hs1.snowdistance)\np4.fit(hs2.eucliddistance)\np5.fit(diffusion_distance)\np6.fit(hs2.snowdistance)\n\nr1=p1.transform(hs1.eucliddistance)\nr2=p2.transform(diffusion_distance)\nr3=p3.transform(hs1.snowdistance)\nr4=p4.transform(hs2.eucliddistance)\nr5=p5.transform(diffusion_distance)\nr6=p6.transform(hs2.snowdistance)\n\n/home/cgb4/anaconda3/envs/py38r40/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:470: RuntimeWarning: invalid value encountered in true_divide\n  explained_variance_ratio_ = explained_variance_ / total_var\n\n\n\n# 1. \np=plt.figure(figsize=(12,4), dpi=70)  # Make figure object \n\n# 2. \nax1=p.add_subplot(2,4,1, projection='3d')\nax2=p.add_subplot(2,4,2, projection='3d')\nax3=p.add_subplot(2,4,3, projection='3d')\nax4=p.add_subplot(2,4,4, projection='3d')\nax5=p.add_subplot(2,4,5, projection='3d')\nax6=p.add_subplot(2,4,6, projection='3d')\nax7=p.add_subplot(2,4,7, projection='3d')\nax8=p.add_subplot(2,4,8, projection='3d')\n\n# 3. \nax1.grid(False)\nax1.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax1.scatter3D(vx, vy, f1, c=col,alpha=1)\nax1.set_xlim(-1,1)\nax1.set_ylim(-1,1)\nax1.set_zlim(-5,5)\n\nax2.grid(False)\nax2.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax2.scatter3D(r1[:,0],r1[:,1],r1[:,2],s=20,c=col,alpha=1)\n\nax3.grid(False)\nax3.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax3.scatter3D(r2[:,0],r2[:,1],r2[:,2],s=20,c=col,alpha=1)\n\nax4.grid(False)\nax4.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax4.scatter3D(r3[:,0],r3[:,1],r3[:,2],s=20,c=col,alpha=1)\n\n\nax5.grid(False)\nax5.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\ntop = -f2\nbottom = np.zeros_like(top)\nwidth=depth=0.05\nax5.bar3d(vx, vy, bottom, width, depth, top, shade=False,color=col)\nax5.set_xlim(-1,1)\nax5.set_ylim(-1,1)\nax5.set_zlim(-5,5)\n\nax6.grid(False)\nax6.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax6.scatter3D(r4[:,0],r4[:,1],r4[:,2],s=20,c=col,alpha=1)\n\nax7.grid(False)\nax7.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax7.scatter3D(r5[:,0],r5[:,1],r5[:,2],s=20,c=col,alpha=1)\n\nax8.grid(False)\nax8.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax8.scatter3D(r6[:,0],r6[:,1],r6[:,2],s=20,c=col,alpha=1)\np.tight_layout(h_pad=2.6) #rect : tuple (left, bottom, right, top), optional"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-08-15-HST example 3.html",
    "href": "연구/교수님이랑/HST/2021-08-15-HST example 3.html",
    "title": "(연구&교수님) HST example 3",
    "section": "",
    "text": "import\n\n## 1. remove trash\n!rm -rf ~/.local/share/Trash/files/*\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib\nmatplotlib.rc('image', cmap='Greys')\nimport rpy2 \n%load_ext rpy2.ipython\n%run pybase\n%run heavysnow \nplt.style.use('ggplot')\n\nThe rpy2.ipython extension is already loaded. To reload it, use:\n  %reload_ext rpy2.ipython\n\n\n\n\nload data\n\nn=23\nf=np.array(pd.read_csv(\"2021-08-15-MCU-ticket.csv\").Worldwide)/1000000\nV=np.array(pd.read_csv(\"2021-08-15-MCU-ticket.csv\").Film)\nW=np.array(pd.read_csv(\"2021-08-15-MCU-weights.csv\",index_col=0))-np.eye(n,n)\n\n\n\nHST\n\ngs=GraphSignal(V,W,f)\nhst=HeavysnowTransform(gs)\nhst.snow(tau=40000,b=1)\n\nHST (tau= 40000, b=1)\n40000/40000\nHST completed and all history is recorded.\n\n\n\nhst.adjustingtheta(140)\n\n\nplt.imshow(hst.snowweight)\n\n\n\n\n\n\n\n\n\n\nR 환경으로..\n\nimport rpy2 \n%load_ext rpy2.ipython\n\nThe rpy2.ipython extension is already loaded. To reload it, use:\n  %reload_ext rpy2.ipython\n\n\n\nn=hst.n \nV=hst.V\nf=hst.f \nWEuclid= hst.euclidweight\nWgraph= (hst.graphweight+hst.graphweight.T)/2\nWhst= hst.snowweight\nW= hst.graphweight\n\n\n%R -i n\n%R -i V\n%R -i f\n%R -i WEuclid\n%R -i Wgraph\n%R -i Whst\n%R -i W\n\n\n\n유클리드와 그래프도메인의 정보를 플랏.\n\n%%R -r 150 -w 2000 -h 660\nsource('heavysnow.R')\ndat_&lt;-tibble(V)\ndat_$f&lt;-as.vector(f)\ndat_$divlink&lt;-0\ndat_$conlink&lt;-0\ndat_$link&lt;-0\ndat&lt;-dat_\nfor(i in 1:23){\n    dat$divlink[i]&lt;-sum(W[i,])\n    dat$conlink[i]&lt;-sum(W[,i])\n    dat$link[i]&lt;-sum(W[i,])+sum(W[i,])\n}\np1_&lt;-ggplot(dat)+geom_point(aes(x=f,y=divlink),size=3)+theme_light()+\n        geom_text_repel(aes(x=f,y=divlink,label=V),col=\"gray40\")+\n        ylab(\"Out-degree\")+xlab(\"Box office record\")+\n        geom_hline(aes(yintercept=2),col=2,lty=2,lwd=0.5)+\n        geom_vline(aes(xintercept=1000),col=2,lty=2,lwd=0.5)+\n        ggtitle(\"(a)\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(2)))+\n        theme(axis.title.x=element_text(face=4,size=rel(1)))+\n        theme(axis.title.y=element_text(face=4,size=rel(1)))\np2_&lt;-ggplot(dat)+geom_point(aes(x=f,y=conlink),size=3)+theme_light()+\n        geom_text_repel(aes(x=f,y=conlink,label=V),col=\"gray40\")+\n        ylab(\"In-degree\")+xlab(\"Box office record\")+\n        geom_hline(aes(yintercept=3.75),col=2,lty=2,lwd=0.5)+\n        geom_vline(aes(xintercept=1000),col=2,lty=2,lwd=0.5)+\n        ggtitle(\"(b)\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(2)))+\n        theme(axis.title.x=element_text(face=4,size=rel(1)))+\n        theme(axis.title.y=element_text(face=4,size=rel(1)))\n# p3_&lt;-ggplot(dat)+geom_point(aes(x=f,y=link),size=3)+theme_light()+\n#         geom_text_repel(aes(x=f,y=link,label=V),col=\"gray40\")+\n#         ylab(\"Graph\")+xlab(\"Box office record\")+\n#         geom_hline(aes(yintercept=6.25),col=2,lty=2,lwd=0.5)+\n#         geom_vline(aes(xintercept=1000),col=2,lty=2,lwd=0.5)+\n#         ggtitle(\"(c)\")\np1&lt;-grid.arrange(p1_,p2_,ncol=2)\n#ggsave(plot=p1,\"./fig/p1.pdf\",width=9,height=4.5)\n\n\n\n\n\n\n\n\n\n\ngfft 수행하고 결과를 저장함.\n\n%%R \ng1&lt;-gfft(f,WEuclid)\ng2&lt;-gfft(f,Wgraph)\ng3&lt;-gfft(f,Whst)\n\n\n\n아이겐플랏\n\n%%R -r 150 -w 1000 -h 400\nlibrary(gridExtra)\ne1&lt;-eigenplot(g1)+ggtitle(\"(a) Euclid weights\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(1)))\ne2&lt;-eigenplot(g2)+ggtitle(\"(b) Graph weights\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(1)))\ne3&lt;-eigenplot(g3)+ggtitle(\"(c) HST weights\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(1)))\ns1&lt;-specplot(g1)\ns2&lt;-specplot(g2)\ns3&lt;-specplot(g3)\np2&lt;-grid.arrange(e1,e2,e3,s1,s2,s3,nrow=2)\n#ggsave(plot=p2,\"./fig/p2.pdf\",width=6,height=3)\n\n\n\n\n\n\n\n\n\n\n분해\n\n%%R -r 300 -w 2500 -h 1500\nd1&lt;-decompose(f,WEuclid,V=V) # 0, 35000, 60000, 80000\nd2&lt;-decompose(f,Wgraph,V=V) # 0, 35000, 60000, 80000\nd3&lt;-decompose(f,Whst,V=V) # 0, 35000, 60000, 80000\n\nd1$case&lt;-\"Euclid\"\nd2$case&lt;-\"Graph\"\nd3$case&lt;-\"HST\"\ndecomprslt&lt;-rbind(d1,d2,d3)\n\n\n%%R -r 150 -w 2000 -h 4200\n\ndecomp_dat&lt;- decomprslt %&gt;% \n                group_by(case,eigenvectorindex) %&gt;% \n                mutate(textsize= 10*(abs(fhat)&gt;50))\n        \np3&lt;-ggplot(data=filter(decomp_dat,eigenvectorindex %in% 1:23))+\n    geom_col(aes(x=Vindex,y=fhat,fill=fhat&gt;0),width=0.7)+\n    geom_text_repel(aes(x=Vindex,y=fhat,label=V,size=textsize),col=1,fontface=4,alpha=0.8,segment.size=0.2,segment.color=\"gray60\",min.segment.length=5,hjust=0.1)+\n    scale_radius(range = c(0,1.8))+\n    guides(size=FALSE)+\n    facet_grid(eigenvectorindex~case)+\n    geom_hline(aes(yintercept=0),col=\"gray60\",lty=2)+\n    xlab(\"\")+ylab(\"\")+guides(fill=FALSE)+\n    theme(axis.text.x=element_text(angle=85,hjust=1,vjust=1,face=4,size=rel(0.7),colour=\"gray60\"))+\n    theme_light()+\n    theme(strip.text.x = element_text(size = 10, color = \"black\", face = \"bold.italic\"))+\n    theme(strip.text.y = element_text(size = 10, color = \"black\", face = \"bold.italic\"))+\n    theme(plot.title=element_text(face=\"bold.italic\",size=rel(1.5)))\nshow(p3)\n\n# decomp_dat&lt;- decomprslt %&gt;% \n#                 group_by(case,eigenvectorindex) %&gt;% \n#                 mutate(textsize=(fhat&gt;mean(fhat)) *(fhat&gt;240) * ((case==\"Euclid\")*1.7+\n#                                                                  (case!=\"Euclid\")*(eigenvectorindex!=1)*1.7+\n#                                                                  (case!=\"Euclid\")*(eigenvectorindex==1)*1))\n\n\n# p3&lt;-ggplot(data=filter(decomp_dat,eigenvectorindex %in% 1:7))+\n#     geom_col(aes(x=Vindex,y=fhat,fill=fhat&gt;0),width=0.7)+\n#     geom_text_repel(aes(x=Vindex,y=fhat,label=V,size=textsize),col=1,fontface=4,alpha=0.8,segment.size=0.2,segment.color=\"gray60\",min.segment.length=5,hjust=0.1)+\n#     scale_radius(range = c(0,1.8))+\n#     guides(size=FALSE)+\n#     facet_grid(eigenvectorindex~case)+\n#     geom_hline(aes(yintercept=0),col=\"gray60\",lty=2)+\n#     xlab(\"\")+ylab(\"\")+guides(fill=FALSE)+\n#     theme(axis.text.x=element_text(angle=85,hjust=1,vjust=1,face=4,size=rel(0.7),colour=\"gray60\"))+\n#     theme_light()+\n#     theme(strip.text.x = element_text(size = 10, color = \"black\", face = \"bold.italic\"))+\n#     theme(strip.text.y = element_text(size = 10, color = \"black\", face = \"bold.italic\"))+\n#     theme(plot.title=element_text(face=\"bold.italic\",size=rel(1.5)))\n# show(p3)\n#ggsave(plot=p3,\"./fig/p3.pdf\",width=6,height=6)\n\n\n\n\n\n\n\n\n\n%%R\ndat3_Euclid &lt;- decomp_dat %&gt;% filter(case==\"Euclid\",eigenvectorindex==1) %&gt;% select(V,case,eigenvectorindex,textsize,fhat)\ndat3_Euclid &lt;- left_join(dat,dat3_Euclid,by=\"V\")\n\nfor(j in 2:23){\n        decomp_filtered_dat_&lt;- decomp_dat %&gt;% filter(case==\"Euclid\",eigenvectorindex==j) %&gt;% select(V,case,eigenvectorindex,textsize,fhat)\n        decomp_filtered_dat_&lt;- left_join(dat,decomp_filtered_dat_,by=\"V\")\n        dat3_Euclid&lt;-rbind(dat3_Euclid,decomp_filtered_dat_)\n}\n\ndat3_Graph &lt;- decomp_dat %&gt;% filter(case==\"Graph\",eigenvectorindex==1) %&gt;% select(V,case,eigenvectorindex,textsize,fhat)\ndat3_Graph &lt;- left_join(dat,dat3_Graph,by=\"V\")\n\nfor(j in 2:23){\n        decomp_filtered_dat_&lt;- decomp_dat %&gt;% filter(case==\"Graph\",eigenvectorindex==j) %&gt;% select(V,case,eigenvectorindex,textsize,fhat)\n        decomp_filtered_dat_&lt;- left_join(dat,decomp_filtered_dat_,by=\"V\")\n        dat3_Graph&lt;-rbind(dat3_Graph,decomp_filtered_dat_)\n}\n\ndat3_HST &lt;- decomp_dat %&gt;% filter(case==\"HST\",eigenvectorindex==1) %&gt;% select(V,case,eigenvectorindex,textsize,fhat)\ndat3_HST &lt;- left_join(dat,dat3_HST,by=\"V\")\n\nfor(j in 2:23){\n        decomp_filtered_dat_&lt;- decomp_dat %&gt;% filter(case==\"HST\",eigenvectorindex==j) %&gt;% select(V,case,eigenvectorindex,textsize,fhat)\n        decomp_filtered_dat_&lt;- left_join(dat,decomp_filtered_dat_,by=\"V\")\n        dat3_HST&lt;-rbind(dat3_HST,decomp_filtered_dat_)\n}\ndat3&lt;-rbind(dat3_Euclid,dat3_Graph,dat3_HST)\n\n\n%%R -r 300 -w 2000 -h 3000\nhull_cyl &lt;- dat3 %&gt;%\n            group_by(case,eigenvectorindex) %&gt;% \n            filter(textsize&gt;0) %&gt;% \n            slice(chull(f, divlink))\np4&lt;-ggplot(dat3%&gt;% filter(eigenvectorindex&lt;8))+geom_point(aes(x=f,y=divlink,col=textsize&gt;0,size=fhat*(fhat&gt;0)),alpha=0.8)+\n        geom_shape(data=hull_cyl%&gt;% filter(eigenvectorindex&lt;8) ,aes(x=f,y=divlink),alpha=0.05,col=\"gray30\",radius=0.05,expand=0.05)+\n        facet_grid(eigenvectorindex~case)+\n        scale_size_continuous(range=c(2,2.5))+\n        scale_color_manual(values=c(\"gray80\", \"gray20\"))+\n        ylim(0,8)+xlim(0,3000)+\n        guides(alpha=F)+\n        guides(col=F)+\n        guides(size=F)+\n        ylab(\"\")+xlab(\"\")+\n        geom_hline(aes(yintercept=2),col=\"gray30\",lty=2,lwd=0.2)+\n        geom_vline(aes(xintercept=1000),col=\"gray30\",lty=2,lwd=0.2)+\n        theme_light()+\n        theme(strip.text.x = element_text(size = 10, color = \"black\", face = \"bold.italic\"))+\n        theme(strip.text.y = element_text(size = 10, color = \"black\", face = \"bold.italic\"))+\n        theme(plot.title=element_text(face=\"bold.italic\",size=rel(1.5)))\nshow(p4)\n#ggsave(plot=p4,\"./fig/p4.pdf\",width=7,height=7)\n\n\n\n\n\n\n\n\n\n%%R -r 300 -w 2000 -h 3000\nhull_cyl &lt;- dat3 %&gt;%\n            group_by(case,eigenvectorindex) %&gt;% \n            filter(textsize&gt;0) %&gt;% \n            slice(chull(f, conlink))\np5&lt;-ggplot(dat3%&gt;% filter(eigenvectorindex&lt;8))+geom_point(aes(x=f,y=conlink,col=textsize&gt;0,size=fhat*(fhat&gt;0)),alpha=0.8)+\n        geom_shape(data=hull_cyl%&gt;% filter(eigenvectorindex&lt;8) ,aes(x=f,y=conlink),alpha=0.05,col=\"gray30\",radius=0.05,expand=0.05)+\n        facet_grid(eigenvectorindex~case)+\n        scale_size_continuous(range=c(2,2.5))+\n        scale_color_manual(values=c(\"gray80\", \"gray20\"))+        \n        ylim(0,10)+xlim(0,3000)+\n        guides(col=F)+\n        guides(alpha=F)+\n        guides(size=F)+       \n        ylab(\"\")+xlab(\"\")+\n        geom_hline(aes(yintercept=3.75),col=\"gray30\",lty=2,lwd=0.2)+\n        geom_vline(aes(xintercept=1000),col=\"gray30\",lty=2,lwd=0.2)+\n        theme_light()+\n        theme(strip.text.x = element_text(size = 10, color = \"black\", face = \"bold.italic\"))+\n        theme(strip.text.y = element_text(size = 10, color = \"black\", face = \"bold.italic\"))+\n        theme(plot.title=element_text(face=\"bold.italic\",size=rel(1.5)))\nshow(p5)\n#ggsave(plot=p5,\"./fig/p5.pdf\",width=7,height=7)        \n\n\n\n\n\n\n\n\n\n%%R -r 300 -w 2000 -h 1500\np_&lt;-grid.arrange(p4,p5,ncol=2)\n#ggsave(plot=p6,\"./fig/p6.pdf\",width=10,height=12)\n\n\n\n\n\n\n\n\n\n%%R -r 200 -w 2000 -h 3000\np6&lt;-grid.arrange(p1,p_,nrow=2,heights=c(3,5))\n\n\n\n\n\n\n\n\n\n%run heavysnow \ngs=GraphSignal(V,hst.snowweight,f)\nspa=SpectralAnalysis(gs)\n\n\nspa.n\n\n23\n\n\n\nspa.graphFouriertransform()\nspa.decompose()\n\n\nspa.V\n\narray(['Iron Man', 'The Incredible Hulk', 'Iron Man 2', 'Thor',\n       'Captain America: The First Avenger', 'The Avengers', 'Iron Man 3',\n       'Thor: The Dark World', 'Captain America: The Winter Soldier',\n       'Guardians of the Galaxy', 'Avengers: Age of Ultron', 'Ant-man',\n       'Captain America: Civil War', 'Doctor Strange',\n       'Guardians of the Galaxy Vol 2', 'Spider-man: Homecoming',\n       'Thor: Ragnarok', 'Black Panther', 'Avengers: Infinity War',\n       'Ant-man and the Wasp', 'Captain Marvel', 'Avengers: Endgame',\n       'Spider-man: Far From Home'], dtype=object)\n\n\n\ndf=pd.DataFrame(spa.components)\ndf\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n...\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n\n\n0\n6.247290e-15\n1.707095e+03\n-9.827837e-14\n-8.486396e-14\n2.899762e-14\n6.041645e-15\n-1.187456e-14\n-3.502007e-13\n-1.193541e-13\n3.794379e-13\n...\n-1.121921e+03\n-3.548465e-14\n-1.892759e-14\n4.544603e-13\n-1.900950e-14\n8.032471e-14\n-8.990956e-10\n-1.633610e-13\n-7.430218e-14\n-6.028971e-15\n\n\n1\n2.712215e-16\n1.058137e-08\n-5.007274e-14\n3.386473e-17\n1.420744e-11\n-1.437544e-15\n-1.321678e-14\n4.039994e-15\n-2.833873e-14\n-1.633926e-10\n...\n-6.954407e-09\n-4.113024e-11\n4.516539e-14\n5.644640e-16\n-3.435360e-04\n9.652342e-16\n1.450493e+02\n6.727200e-10\n4.158595e-16\n-1.646478e-14\n\n\n2\n5.567872e-01\n-3.517889e-13\n4.205928e+00\n3.135672e-01\n1.237232e-13\n1.002442e+01\n1.419019e+00\n-6.420902e-01\n-2.586033e+00\n-3.800564e-15\n...\n4.504242e-14\n3.881354e-15\n-7.222631e+00\n-1.270091e-01\n-3.911058e-13\n1.458953e+03\n-6.970078e-17\n-4.258602e-14\n-7.984930e+02\n-1.051491e+00\n\n\n3\n-1.059263e-14\n-4.888031e-13\n-2.398614e-13\n-5.563074e-14\n4.899172e-01\n5.509354e-14\n3.093273e-14\n-5.194113e-13\n-5.543531e-14\n5.360109e+02\n...\n2.551620e-13\n-1.247248e+02\n-2.667641e-14\n1.290511e-13\n-1.099014e-04\n-4.141358e-14\n-1.039357e-10\n3.755068e+01\n-1.017089e-14\n5.754851e-14\n\n\n4\n-1.338283e-14\n3.813154e-13\n5.864303e-14\n6.890875e-14\n1.634047e+02\n-5.976314e-14\n-2.108992e-14\n2.695599e-13\n7.059745e-14\n-3.468382e+02\n...\n-4.555950e-13\n-6.202443e+01\n3.944487e-13\n-2.381748e-13\n-2.477574e-03\n-3.908796e-14\n-2.329564e-09\n6.160302e+02\n-3.849599e-14\n-2.522857e-14\n\n\n5\n6.268624e-01\n5.025556e-14\n3.621003e+00\n3.780309e+02\n-3.789023e-13\n-9.031218e-02\n-6.086432e-01\n1.451182e+03\n-8.818405e-01\n2.446920e-13\n...\n-4.128901e-13\n-1.945880e-14\n1.479923e+00\n-3.154052e+02\n2.823262e-20\n2.283802e-02\n-1.940234e-16\n-4.831462e-14\n-4.437603e-02\n6.842734e-01\n\n\n6\n3.634492e+00\n0.000000e+00\n2.251986e+01\n3.648403e+02\n1.237232e-13\n-5.152353e-01\n-5.098148e+00\n-4.000544e+02\n-8.218727e+00\n-8.219362e-14\n...\n3.071239e-13\n4.246548e-15\n1.439908e+01\n1.215892e+03\n-2.276049e-20\n1.454592e-01\n1.091523e-16\n2.670230e-14\n-3.092549e-01\n4.780988e+00\n\n\n7\n-1.469804e+00\n2.680297e-13\n-1.084964e+01\n-2.645684e-01\n6.263487e-13\n1.490922e+02\n1.817207e+00\n1.485871e+00\n5.348931e+00\n-2.997392e-13\n...\n2.165643e-13\n2.126956e-14\n1.003275e+01\n1.777094e+00\n9.978330e-19\n-1.753933e+00\n2.539023e-15\n1.997032e-13\n6.687601e+00\n-7.156614e-01\n\n\n8\n-8.116393e+00\n1.675185e-13\n-6.823096e+01\n-2.585005e+00\n-1.546540e-13\n8.415274e+01\n6.742951e+00\n1.147843e+01\n3.914723e+01\n-5.540890e-14\n...\n-1.694475e-13\n6.807886e-16\n7.498935e+01\n1.348579e+01\n-3.385392e-18\n-6.612900e+00\n-3.888607e-15\n1.516414e-13\n2.824586e+01\n-6.751284e-01\n\n\n9\n-1.457985e+02\n1.340148e-13\n9.688547e+02\n-1.627500e-01\n3.093080e-14\n7.405009e-01\n-1.841870e+00\n2.753373e+00\n-5.049281e+01\n2.737548e-14\n...\n-8.177666e-14\n-7.010920e-15\n-8.832644e+00\n4.080923e+00\n5.407829e-20\n-7.998628e-02\n3.110801e-15\n-6.383287e-14\n3.682641e-01\n1.447229e+00\n\n\n10\n6.907220e+01\n2.680297e-13\n6.433580e+02\n-6.595574e-01\n4.021004e-13\n-4.700005e-01\n4.265512e+00\n-3.580883e+00\n6.750131e+02\n-3.291044e-14\n...\n-2.470088e-13\n-1.671705e-14\n3.531860e+01\n-7.096645e+00\n-6.576134e-19\n3.818266e-02\n5.714582e-15\n-1.327708e-13\n-2.015752e-01\n-6.434574e+00\n\n\n11\n1.463660e+01\n1.340148e-13\n1.103874e+02\n-3.273026e+00\n4.059667e-13\n5.031685e+00\n1.379003e+02\n4.407592e+00\n-5.729486e+01\n-1.630527e-13\n...\n-1.519603e-13\n2.150495e-14\n2.642115e+02\n-1.013413e+00\n2.467838e-18\n-1.329087e+00\n1.306457e-14\n-3.994124e-14\n5.810507e+00\n1.103411e+02\n\n\n12\n2.042957e+01\n6.700742e-14\n1.604964e+02\n1.760594e+00\n-6.031506e-13\n-4.010409e+00\n2.059552e+01\n-4.051919e+00\n-1.275852e+02\n6.623007e-14\n...\n1.551758e-13\n-1.177289e-14\n1.186266e+03\n-3.177545e+00\n2.097188e-18\n1.912961e-01\n-7.902333e-15\n-9.644055e-14\n-1.219998e+00\n-7.250937e+01\n\n\n13\n6.668434e+01\n1.340148e-13\n4.618421e+02\n-1.859682e+01\n-6.186160e-13\n-2.507029e+01\n-1.107716e+02\n6.813721e+00\n-2.345541e+02\n1.556516e-14\n...\n1.339132e-13\n4.870343e-15\n2.608371e+02\n-5.710231e+01\n-2.579978e-18\n3.369735e+00\n1.420847e-17\n1.264037e-13\n-2.913932e+01\n8.693155e+01\n\n\n14\n3.422525e-14\n-8.940864e-14\n1.037470e-13\n-3.364652e-14\n1.082258e+03\n-4.474060e-14\n-1.322970e-13\n5.440031e-13\n-4.988318e-13\n-3.546742e+01\n...\n2.216706e-13\n-9.831858e+00\n6.181378e-13\n-1.170664e-13\n1.322688e-02\n-5.095742e-13\n1.623088e-08\n-1.732161e+02\n1.503337e-13\n-2.027809e-14\n\n\n15\n-6.106282e-15\n-4.014393e-13\n-3.966886e-14\n1.328179e-14\n-1.604103e-02\n1.036244e-14\n-6.330841e-15\n-4.115207e-14\n2.341767e-14\n-8.891039e-04\n...\n-3.211852e-13\n-1.551127e-04\n4.475967e-14\n-3.631372e-14\n8.801798e+02\n6.468891e-13\n1.106361e-03\n3.872341e-03\n-3.664909e-13\n5.779847e-15\n\n\n16\n-6.667865e+01\n2.680297e-13\n-4.738936e+02\n-1.007199e+02\n1.237232e-13\n-9.769302e+01\n-6.283744e+00\n2.978993e+02\n2.671375e+02\n-6.366001e-15\n...\n1.847935e-13\n-1.586313e-15\n2.938494e+02\n2.466987e+02\n-2.673912e-19\n-5.211991e+01\n5.876455e-21\n-1.717282e-14\n-1.079660e+02\n2.525438e+01\n\n\n17\n-8.130269e+00\n1.340148e-13\n-6.563066e+01\n-3.230602e+02\n-1.546540e-13\n5.434013e+01\n-2.813232e+01\n9.334007e+02\n4.237280e+01\n3.274076e-15\n...\n-6.704179e-14\n8.977368e-16\n1.263153e+02\n7.489960e+02\n3.979446e-20\n1.464130e+02\n-2.815570e-21\n9.029172e-15\n1.173458e+02\n1.800376e+01\n\n\n18\n-1.187357e+01\n1.340148e-13\n-8.462116e+01\n5.170168e+01\n8.179912e-63\n-1.000490e+01\n-7.699697e+00\n-1.503880e+02\n4.833255e+01\n1.592742e-14\n...\n2.236371e-14\n2.012683e-15\n7.302472e+01\n-1.224382e+02\n-2.141600e-18\n1.430858e+03\n-1.839765e-20\n1.335035e-14\n7.841594e+02\n8.491160e+00\n\n\n19\n5.695819e-04\n1.092131e-02\n4.100482e-03\n-1.356002e-03\n1.068875e+02\n-5.208507e-04\n5.581691e-04\n3.978264e-03\n-2.372015e-03\n2.308013e+02\n...\n7.177600e-03\n5.073098e+01\n-4.074587e-03\n3.292610e-03\n-4.969979e-03\n2.041970e-03\n1.247561e+02\n2.112912e+02\n8.552650e-04\n-5.052201e-04\n\n\n20\n5.899266e+01\n1.674174e+02\n4.246946e+02\n-1.404436e+02\n-4.895903e+01\n-5.394548e+01\n5.781061e+01\n4.120362e+02\n-2.456740e+02\n-1.057168e+02\n...\n1.100285e+02\n-2.323695e+01\n-4.220126e+02\n3.410218e+02\n-1.115816e-03\n2.114906e+02\n2.010064e+01\n-9.678036e+01\n8.858139e+01\n-5.232658e+01\n\n\n21\n8.370471e+00\n1.155986e+03\n6.025994e+01\n-1.992755e+01\n1.303271e+02\n-7.654326e+00\n8.202750e+00\n5.846383e+01\n-3.485870e+01\n2.814142e+02\n...\n7.597260e+02\n6.185588e+01\n-5.987939e+01\n4.838760e+01\n2.970488e-03\n3.000842e+01\n-5.351234e+01\n2.576257e+02\n1.256882e+01\n-7.424621e+00\n\n\n22\n-1.570579e+01\n1.244926e+03\n-1.130677e+02\n3.739071e+01\n-1.144332e+02\n1.436206e+01\n-1.539109e+01\n-1.096976e+02\n6.540651e+01\n-2.470946e+02\n...\n8.181785e+02\n-5.431231e+01\n1.123536e+02\n-9.079122e+01\n-2.608172e-03\n-5.630576e+01\n4.698508e+01\n-2.262072e+02\n-2.358328e+01\n1.393106e+01\n\n\n\n\n23 rows × 23 columns\n\n\n\n\ndf=df.stack().reset_index().rename(columns={'level_0':'vertex','level_1':'comp',0:'fhat'})\n\n\ndf \n\n\n\n\n\n\n\n\nvertex\ncomp\nfhat\n\n\n\n\n0\n0\n0\n6.247290e-15\n\n\n1\n0\n1\n1.707095e+03\n\n\n2\n0\n2\n-9.827837e-14\n\n\n3\n0\n3\n-8.486396e-14\n\n\n4\n0\n4\n2.899762e-14\n\n\n...\n...\n...\n...\n\n\n524\n22\n18\n-5.630576e+01\n\n\n525\n22\n19\n4.698508e+01\n\n\n526\n22\n20\n-2.262072e+02\n\n\n527\n22\n21\n-2.358328e+01\n\n\n528\n22\n22\n1.393106e+01\n\n\n\n\n529 rows × 3 columns\n\n\n\n\ndf['fill']= df.fhat &gt;0 \n\n\ndf\n\n\n\n\n\n\n\n\nvertex\ncomp\nfhat\nfill\n\n\n\n\n0\n0\n0\n6.247290e-15\nTrue\n\n\n1\n0\n1\n1.707095e+03\nTrue\n\n\n2\n0\n2\n-9.827837e-14\nFalse\n\n\n3\n0\n3\n-8.486396e-14\nFalse\n\n\n4\n0\n4\n2.899762e-14\nTrue\n\n\n...\n...\n...\n...\n...\n\n\n524\n22\n18\n-5.630576e+01\nFalse\n\n\n525\n22\n19\n4.698508e+01\nTrue\n\n\n526\n22\n20\n-2.262072e+02\nFalse\n\n\n527\n22\n21\n-2.358328e+01\nFalse\n\n\n528\n22\n22\n1.393106e+01\nTrue\n\n\n\n\n529 rows × 4 columns\n\n\n\n\nn=23\nfig=ggplot(df)\nfacet=facet_wrap('comp',ncol=1)\naes1=aes(x='vertex',y='fhat',fill='fill')\naes3=aes(x='vertex',y='fhat',label=spa.V)\ngeom1=geom_col(aes1,alpha=0.8)\ngeom2=geom_hline(yintercept = 0,linetype='dashed',color='gray',size=0.3)\n#geom3=geom_text_repel(aes(x=Vindex,y=fhat,label=V)\n\n\nfig+facet+geom1+geom2+xlab(\"\")+ylab(\"\")+theme(figure_size=(3, 3*n))+theme(legend_position=\"none\")"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-08-03-HST example 2 (1).html",
    "href": "연구/교수님이랑/HST/2021-08-03-HST example 2 (1).html",
    "title": "(연구&교수님) HST example 2 (1)",
    "section": "",
    "text": "import heavysnow as hs \nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt \nfrom sklearn.decomposition import PCA \nimport rpy2 \n%load_ext rpy2.ipython\n%run pybase\n\n\n### Example 2\nnp.random.seed(777)\nimport math\npi=math.pi\nn=59\nang=np.linspace(-pi,pi-2*pi/n,n)\nV=np.arange(n)+1\nr=1\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=vx*0\n\nf2=vx*0\nf2[vy&lt;0]=3+np.random.normal(size=sum(vy&lt;0),scale=0.1)\nf2[vy&gt;0]= -3+np.random.normal(size=sum(vy&gt;0),scale=0.1)\n\n\n# Edg setting\nΣ=l2distance(np.matrix([vx,vy]).T)\nθ=0.05\nW=np.exp(-Σ**2/(2*θ**2))\nE=W&gt;0\nplt.plot(W[0,:].T)\n# color\nimport matplotlib.cm as cm\ncol=list(np.array(cm.rainbow((ang+pi)/2/pi)))\n\n\n\n\n\n\n\n\n\n%R -i ang,vx,vy,n\n\n\n%%R\nlibrary(latex2exp)\nlibrary(gridExtra)\nlibrary(tidyverse)\n\nR[write to console]: ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\nR[write to console]: ✔ ggplot2 3.3.5     ✔ purrr   0.3.4\n✔ tibble  3.1.2     ✔ dplyr   1.0.7\n✔ tidyr   1.1.3     ✔ stringr 1.4.0\n✔ readr   1.4.0     ✔ forcats 0.5.1\n\nR[write to console]: ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::combine() masks gridExtra::combine()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n\n\n\n\n%%R -w 450 -h 300 -r 100\nex2df&lt;-data.frame(cbind(ang,vx,vy))\nnames(ex2df)&lt;-c(\"ang\",\"vx\",\"vy\")\nex2plt &lt;- ggplot(data=ex2df,aes(x=vx,y=vy))+\n            geom_point(col=\"gray60\",cex=1.5,alpha=0.7)+\n            geom_point(data=ex2df[1:n,],aes(x=vx,y=vy,col=ang),cex=1.5,alpha=0.7)+\n            xlab(\"\")+ylab(\"\")+scale_colour_gradientn(colours=rainbow(7))+labs(col=TeX(\"$\\\\phi$\"))+theme_classic()+\n            theme(legend.key.width = unit(2,\"mm\"))\nshow(ex2plt)\n\n\n\n\n\n\n\n\n\ngs1=hs.GraphSignal(V,W,f1)\ngs2=hs.GraphSignal(V,W,f2)\n\n\nplt.imshow(W)\n\n\n\n\n\n\n\n\n\nDiffusion distance\n\nP=W/W.round(3).sum(axis=0)[0]\nprint(P)\nplt.imshow(P)\n\n[[2.20167327e-01 2.14586355e-01 1.46335569e-01 ... 2.83862880e-02\n  1.46335569e-01 2.14586355e-01]\n [2.14586355e-01 2.20167327e-01 2.14586355e-01 ... 3.69898283e-04\n  2.83862880e-02 1.46335569e-01]\n [1.46335569e-01 2.14586355e-01 2.20167327e-01 ... 4.82347874e-08\n  3.69898283e-04 2.83862880e-02]\n ...\n [2.83862880e-02 3.69898283e-04 4.82347874e-08 ... 2.20167327e-01\n  2.14586355e-01 1.46335569e-01]\n [1.46335569e-01 2.83862880e-02 3.69898283e-04 ... 2.14586355e-01\n  2.20167327e-01 2.14586355e-01]\n [2.14586355e-01 1.46335569e-01 2.83862880e-02 ... 1.46335569e-01\n  2.14586355e-01 2.20167327e-01]]\n\n\n\n\n\n\n\n\n\n\nplt.imshow(P@P@P@P)\n\n\n\n\n\n\n\n\n\nP4=P@P@P@P\ndiffusion_distance=l2distance(P4)\nplt.imshow(diffusion_distance)\n\n\n\n\n\n\n\n\n\n\nSnow distance\n\nhs1=hs.HeavySnowTransform(gs1)\nhs2=hs.HeavySnowTransform(gs2)\n\n\nhs1.snow(tau=20000,b=0.1)\nhs2.snow(tau=20000,b=0.1)\n\nHST (tau= 20000, b=0.1)\n20000/20000\nHST completed and all history is recorded.\nHST (tau= 20000, b=0.1)\n20000/20000\nHST completed and all history is recorded.\n\n\n\nfrom sklearn.decomposition import PCA \np1=PCA(n_components=3)\np2=PCA(n_components=3)\np3=PCA(n_components=3)\np4=PCA(n_components=3)\np5=PCA(n_components=3)\np6=PCA(n_components=3)\n\n\np1.fit(hs1.eucliddistance)\np2.fit(diffusion_distance)\np3.fit(hs1.snowdistance)\np4.fit(hs2.eucliddistance)\np5.fit(diffusion_distance)\np6.fit(hs2.snowdistance)\n\nr1=p1.transform(hs1.eucliddistance)\nr2=p2.transform(diffusion_distance)\nr3=p3.transform(hs1.snowdistance)\nr4=p4.transform(hs2.eucliddistance)\nr5=p5.transform(diffusion_distance)\nr6=p6.transform(hs2.snowdistance)\n\n/home/cgb4/anaconda3/envs/py38r40/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:470: RuntimeWarning: invalid value encountered in true_divide\n  explained_variance_ratio_ = explained_variance_ / total_var\n\n\n\n# 1. \np=plt.figure(figsize=(12,4), dpi=70)  # Make figure object \n\n# 2. \nax1=p.add_subplot(2,4,1, projection='3d')\nax2=p.add_subplot(2,4,2, projection='3d')\nax3=p.add_subplot(2,4,3, projection='3d')\nax4=p.add_subplot(2,4,4, projection='3d')\nax5=p.add_subplot(2,4,5, projection='3d')\nax6=p.add_subplot(2,4,6, projection='3d')\nax7=p.add_subplot(2,4,7, projection='3d')\nax8=p.add_subplot(2,4,8, projection='3d')\n\n# 3. \nax1.grid(False)\nax1.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax1.scatter3D(vx, vy, f1, c=col,alpha=1)\nax1.set_xlim(-1,1)\nax1.set_ylim(-1,1)\nax1.set_zlim(-5,5)\n\nax2.grid(False)\nax2.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax2.scatter3D(r1[:,0],r1[:,1],r1[:,2],s=20,c=col,alpha=1)\n\nax3.grid(False)\nax3.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax3.scatter3D(r2[:,0],r2[:,1],r2[:,2],s=20,c=col,alpha=1)\n\nax4.grid(False)\nax4.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax4.scatter3D(r3[:,0],r3[:,1],r3[:,2],s=20,c=col,alpha=1)\n\n\nax5.grid(False)\nax5.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\ntop = -f2\nbottom = np.zeros_like(top)\nwidth=depth=0.05\nax5.bar3d(vx, vy, bottom, width, depth, top, shade=False,color=col)\nax5.set_xlim(-1,1)\nax5.set_ylim(-1,1)\nax5.set_zlim(-5,5)\n\nax6.grid(False)\nax6.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax6.scatter3D(r4[:,0],r4[:,1],r4[:,2],s=20,c=col,alpha=1)\n\nax7.grid(False)\nax7.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax7.scatter3D(r5[:,0],r5[:,1],r5[:,2],s=20,c=col,alpha=1)\n\nax8.grid(False)\nax8.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax8.scatter3D(r6[:,0],r6[:,1],r6[:,2],s=20,c=col,alpha=1)\np.tight_layout(h_pad=2.6) #rect : tuple (left, bottom, right, top), optional"
  },
  {
    "objectID": "연구/교수님이랑/HST/2023-07-12-그래프신호만들고시각화하기.html",
    "href": "연구/교수님이랑/HST/2023-07-12-그래프신호만들고시각화하기.html",
    "title": "(연구&교수님) 그래프신호만들고시각화하기",
    "section": "",
    "text": "import numpy as np\nimport torch\nimport torch_geometric\nimport graft\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n1. Undirected / Unweighted\n\nimport pandas as pd\n\n# Ex – default\n\nlinks = torch.tensor([[0, 1, 2, 3, 4, 3],\n                      [1, 0, 3, 2, 3, 4]], dtype=torch.long)\ng = torch_geometric.data.Data(\n    edge_index = links\n)\n\n\ngraft.graph.plot_undirected_unweighted(g)\n\n\n\n\n\n\n\n\n# Ex – node_names\n\ngraft.graph.plot_undirected_unweighted(\n    g, \n    node_names = ['a','b','c','d','e'], \n)\n\n\n\n\n\n\n\n\n# Ex – node_color (continuous)\n\nlinks = torch.tensor([[0, 1, 2, 3, 4, 3],\n                      [1, 0, 3, 2, 3, 4]], dtype=torch.long)\ng = torch_geometric.data.Data(\n    edge_index = links, \n    y = np.random.randn(5)\n)\n\n\ngraft.graph.plot_undirected_unweighted(\n    g,\n    node_color=g.y\n)\n\n\n\n\n\n\n\n\n# Ex – node_color (discrete)\n\nlinks = torch.tensor([[0, 1, 2, 3, 4, 3],\n                      [1, 0, 3, 2, 3, 4]], dtype=torch.long)\ng = torch_geometric.data.Data(\n    edge_index = links, \n    y = torch.tensor([0,1,0,0,1])\n)\n\n\ngraft.graph.plot_undirected_unweighted(\n    g,\n    node_color=g.y\n)\n\n\n\n\n\n\n\n\n# Ex – node_color (discrete) / node_size\n\nlinks = torch.tensor([[0, 1, 2, 3, 4, 3],\n                      [1, 0, 3, 2, 3, 4]], dtype=torch.long)\ng = torch_geometric.data.Data(\n    edge_index = links, \n    y = torch.tensor([0,1,0,0,1]),\n    x = torch.tensor([10,100,15,20,150])\n)\n\n\ngraft.graph.plot_undirected_unweighted(\n    g,\n    node_color=g.y,\n    node_size=g.x\n)\n\n\n\n\n\n\n\n\n# Ex – draw options\n\nlinks = torch.tensor([[0, 1, 2, 3, 4, 3],\n                      [1, 0, 3, 2, 3, 4]], dtype=torch.long)\ng = torch_geometric.data.Data(\n    edge_index = links\n)\n\n\ngraft.graph.plot_undirected_unweighted(\n    g,\n)\n\n\n\n\n\n\n\n\n\ndr_opts = {\n    'vertex_size':30\n}\ngraft.graph.plot_undirected_unweighted(\n    g,\n    draw_options= dr_opts\n)\n\n\n\n\n\n\n\n\n\ndr_opts = {\n    'edge_marker_size': 200, \n    'output_size': (300,300)\n}\ngraft.graph.plot_undirected_unweighted(\n    g,\n    draw_options= dr_opts\n)\n\n\n\n\n\n\n\n\n\n\n2. Undirected / Weighted\n# Ex1 – 무방향 그래프, 가중치 값이 존재\n\nlinks = torch.tensor([[0, 1, 2, 3, 4, 3],\n                      [1, 0, 3, 2, 3, 4]], dtype=torch.long)\nweights = torch.tensor([5, 5, 1.5, 1.5, 0.19, 0.19], dtype=torch.float)\n\ng = torch_geometric.data.Data(\n    edge_index=links,\n    edge_attr=weights,\n)\n\n\ngraft.graph.plot_undirected_weighted(\n    g,\n)\n\n\n\n\n\n\n\n\n# Ex1 – 무방향 그래프, 가중치 값이 존재\n\nlinks = torch.tensor([[0, 1, 2, 3, 4, 3],\n                      [1, 0, 3, 2, 3, 4]], dtype=torch.long)\nweights = torch.tensor([5, 5, 1.5, 1.5, 0.19, 0.19], dtype=torch.float)\n\ng = torch_geometric.data.Data(\n    edge_index=links,\n    edge_attr=weights,\n)\n\n\ngraft.graph.plot_undirected_weighted(\n    g,\n    edge_weight_text=False\n)\n\n\n\n\n\n\n\n\n# Ex1 – 무방향 그래프, 가중치 값이 존재\n\nlinks = torch.tensor([[0, 1, 2, 3, 4, 3],\n                      [1, 0, 3, 2, 3, 4]], dtype=torch.long)\nweights = torch.tensor([5, 5, 1.5, 1.5, 0.19, 0.19], dtype=torch.float)\n\ng = torch_geometric.data.Data(\n    edge_index=links,\n    edge_attr=weights,\n)\n\n\ngraft.graph.plot_undirected_weighted(\n    g,\n    edge_weight_text=False,\n    edge_weight_width=False\n)\n\n\n\n\n\n\n\n\n# Ex1 – 무방향 그래프, 가중치 값이 존재\n\nlinks = torch.tensor([[0, 1, 2, 3, 4, 3],\n                      [1, 0, 3, 2, 3, 4]], dtype=torch.long)\nweights = torch.tensor([5, 5, 1.5, 1.5, 0.19, 0.19], dtype=torch.float)\n\ng = torch_geometric.data.Data(\n    edge_index=links,\n    edge_attr=weights,\n)\n\n\ngraft.graph.plot_undirected_weighted(\n    g,\n    edge_weight_text=True,\n    edge_weight_width=True,\n    edge_weight_text_format='.1f',\n)\n\n\n\n\n\n\n\n\n\ngraft.graph.plot_undirected_weighted(\n    g,\n    edge_weight_text=True,\n    edge_weight_width=True,\n    edge_weight_text_format='.1f',\n    edge_weight_width_scale=5.0,\n)\n\n\n\n\n\n\n\n\n# Ex2 – 무방향 그래프, 가중치 값이 존재\n\nlinks = torch.tensor([[0, 1, 2, 3, 4, 3],\n                      [1, 0, 3, 2, 3, 4]], dtype=torch.long)\nweights = torch.tensor([5, 5, 1.5, 1.5, 0.19, 0.19], dtype=torch.float)\n\ngraph = torch_geometric.data.Data(\n    edge_index=links,\n    edge_attr=weights,\n    y = torch.tensor([1,1,0,0,0])\n)\n\n\ngraft.graph.plot_undirected_weighted(graph,node_color=graph.y)\n\n\n\n\n\n\n\n\n\n\n3.\n# Ex2 – 방향 그래프\n\nlinks = torch.tensor([[0, 1, 2, 3, 4, 5],\n                      [1, 2, 3, 4, 5, 0]], dtype=torch.long)\ngraph = torch_geometric.data.Data(edge_index = links, num_nodes=6)\n\n\nhst.plot_directed_unweighted_without_y(graph)\n\n\n\n\n\n\n\n\n\n# 사용 예시\nhst.plot_directed_unweighted_without_y(\n    graph, \n    node_names = ['A', 'B', 'C', 'D', 'E', 'F'], \n)\n\n\n\n\n\n\n\n\n\n# 사용 예시\nly_opts = {\"K\": 0.1, \"max_iter\": 1000}\ndr_opts = {\n    \"vertex_size\": 20, \n    \"vertex_fill_color\": \"white\", \n    \"edge_pen_width\": 1.2, \n    \"output_size\": (100,100)\n}\nhst.plot_directed_unweighted_without_y(\n    graph, \n    node_names = ['A', 'B', 'C', 'D', 'E', 'F'], \n    layout_options = ly_opts,\n    draw_options = dr_opts    \n)\n\n\n\n\n\n\n\n\n\n# 사용 예시\nly_opts = {\"K\": 0.1, \"max_iter\": 1000}\ndr_opts = {\n    \"vertex_size\": 20, \n    \"vertex_fill_color\": \"white\", \n    \"edge_pen_width\": 1.2, \n    \"output_size\": (100,100),\n    \"output\": \"output.pdf\"\n}\nhst.plot_directed_unweighted_without_y(\n    graph, \n    node_names = ['A', 'B', 'C', 'D', 'E', 'F'], \n    layout_options = ly_opts,\n    draw_options = dr_opts\n)\n\n# Ex4 – 방향 그래프, 가중치 값이 존재\n\nlinks = torch.tensor([[0, 2, 3, 4, 3],\n                      [1, 3, 2, 3, 4]], dtype=torch.long)\nweights = torch.tensor([5, 1.5, 1.5, 0.19, 0.19], dtype=torch.float)\n\ngraph = torch_geometric.data.Data(\n    edge_index=links,\n    edge_attr=weights,\n    num_nodes =5 \n)\n\n\nhst.plot_directed_weighted_without_y(graph,edge_weight_text=False,edge_weight_width=False)\n\n\n\n\n\n\n\n\n\ndr_opts = {\n    'edge_marker_size': 10, \n    'vertex_size':15\n}\nhst.plot_directed_weighted_without_y(\n    graph,\n    draw_options= dr_opts\n    )"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-08-09-HST example 2 이거로하자.html",
    "href": "연구/교수님이랑/HST/2021-08-09-HST example 2 이거로하자.html",
    "title": "(연구&교수님) HST example 2 이거로하자",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib\nmatplotlib.rc('image', cmap='Greys')\nimport rpy2 \n%load_ext rpy2.ipython\n%run pybase\n%run heavysnow \n\n\n### Example 2\nnp.random.seed(777)\nimport math\npi=math.pi\nn=60\nang=np.linspace(-pi,pi-2*pi/n,n)\nV=np.arange(n)+1\nr=1\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=vx*0\n\nf2=vx*0\nf2[vy&lt;0]=3+np.random.normal(size=sum(vy&lt;0),scale=0.1)\nf2[vy&gt;=0]= -3+np.random.normal(size=sum(vy&gt;=0),scale=0.1)\n\n\n# Edg setting\nΣ=l2distance(np.matrix([vx,vy]).T)\nθ=0.35\nW=np.exp(-Σ**2/(2*θ**2))-np.eye(n,n)\nE=W&gt;0\nplt.plot(W[0,:].T)\n# color\nimport matplotlib.cm as cm\ncol=list(np.array(cm.rainbow((ang+pi)/2/pi)))\n\n\n\n\n\n\n\n\n\ngs1=GraphSignal(V,W,f1)\ngs2=GraphSignal(V,W,f2)\n\n\nDiffusion distance\n\nP=W/W.round(3).sum(axis=0)[0]\nprint(P)\nplt.imshow(P)\n\n[[0.         0.08727822 0.08664285 ... 0.08397182 0.08664285 0.08727822]\n [0.08727822 0.         0.08727822 ... 0.07728965 0.08397182 0.08664285]\n [0.08664285 0.08727822 0.         ... 0.06514026 0.07728965 0.08397182]\n ...\n [0.08397182 0.07728965 0.06514026 ... 0.         0.08727822 0.08664285]\n [0.08664285 0.08397182 0.07728965 ... 0.08727822 0.         0.08727822]\n [0.08727822 0.08664285 0.08397182 ... 0.08664285 0.08727822 0.        ]]\n\n\n\n\n\n\n\n\n\n\nplt.imshow(P@P@P@P)\n\n\n\n\n\n\n\n\n\nP4=P@P@P@P\ndiffusion_distance=l2distance(P4)\nplt.imshow(diffusion_distance)\n\n\n\n\n\n\n\n\n\n\nSnow distance\n\nhs1=HeavySnowTransform(gs1)\nhs2=HeavySnowTransform(gs2)\n\n\nhs1.snow(tau=100000,b=0.05)\nhs2.snow(tau=100000,b=0.05)\n\nHST (tau= 100000, b=0.05)\n100000/100000\nHST completed and all history is recorded.\nHST (tau= 100000, b=0.05)\n100000/100000\nHST completed and all history is recorded.\n\n\n\nfrom sklearn.decomposition import PCA \np1=PCA(n_components=3)\np2=PCA(n_components=3)\np3=PCA(n_components=3)\np4=PCA(n_components=3)\np5=PCA(n_components=3)\np6=PCA(n_components=3)\n\n\np1.fit(hs1.eucliddistance)\np2.fit(diffusion_distance)\np3.fit(hs1.snowdistance)\np4.fit(hs2.eucliddistance)\np5.fit(diffusion_distance)\np6.fit(hs2.snowdistance)\n\nr1=p1.transform(hs1.eucliddistance)\nr2=p2.transform(diffusion_distance)\nr3=p3.transform(hs1.snowdistance)\nr4=p4.transform(hs2.eucliddistance)\nr5=p5.transform(diffusion_distance)\nr6=p6.transform(hs2.snowdistance)\n\n/home/cgb3/anaconda3/envs/py38r40/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:470: RuntimeWarning: invalid value encountered in true_divide\n  explained_variance_ratio_ = explained_variance_ / total_var\n\n\n\n# 1. \np=plt.figure(figsize=(12,4), dpi=100)  # Make figure object \n\n# 2. \nax1=p.add_subplot(2,4,1, projection='3d')\nax2=p.add_subplot(2,4,2, projection='3d')\nax3=p.add_subplot(2,4,3, projection='3d')\nax4=p.add_subplot(2,4,4, projection='3d')\nax5=p.add_subplot(2,4,5, projection='3d')\nax6=p.add_subplot(2,4,6, projection='3d')\nax7=p.add_subplot(2,4,7, projection='3d')\nax8=p.add_subplot(2,4,8, projection='3d')\n\n# 3. \nax1.grid(False)\nax1.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax1.scatter3D(vx, vy, f1, c=col,alpha=1)\nax1.set_xlim(-1,1)\nax1.set_ylim(-1,1)\nax1.set_zlim(-5,5)\n\nax2.grid(False)\nax2.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax2.scatter3D(r1[:,0],r1[:,1],r1[:,2],s=20,c=col,alpha=1)\n\nax3.grid(False)\nax3.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax3.scatter3D(r2[:,0],r2[:,1],r2[:,2],s=20,c=col,alpha=1)\n\nax4.grid(False)\nax4.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax4.scatter3D(r3[:,0],r3[:,1],r3[:,2],s=20,c=col,alpha=1)\n\n\nax5.grid(False)\nax5.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\ntop = -f2\nbottom = np.zeros_like(top)\nwidth=depth=0.05\nax5.bar3d(vx, vy, bottom, width, depth, top, shade=False,color=col)\nax5.set_xlim(-1,1)\nax5.set_ylim(-1,1)\nax5.set_zlim(-5,5)\n\nax6.grid(False)\nax6.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax6.scatter3D(r4[:,0],r4[:,1],r4[:,2],s=20,c=col,alpha=1)\n\nax7.grid(False)\nax7.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax7.scatter3D(r5[:,0],r5[:,1],r5[:,2],s=20,c=col,alpha=1)\n\nax8.grid(False)\nax8.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax8.scatter3D(r6[:,0],r6[:,1],r6[:,2],s=20,c=col,alpha=1)\n#p.tight_layout(h_pad=2.6) #rect : tuple (left, bottom, right, top), optional\np.savefig('temp.pdf',transparent=True)\n\n\n\n\n\n\n\n\n\nbrk=15000\np, ((ax1,ax2,ax3,ax4),(ax5,ax6,ax7,ax8)) = plt.subplots(2,4) \nax1.imshow(hs1.eucliddistance,origin='lower')\nax2.imshow(diffusion_distance,origin='lower')\nax3.imshow(l2distance(hs1.snowygrounds[:,0:brk]),origin='lower')\nax4.imshow(l2distance(hs1.snowygrounds[:,brk:]),origin='lower')\nax5.imshow(hs2.eucliddistance,origin='lower')\nax6.imshow(diffusion_distance,origin='lower')\nax7.imshow(l2distance(hs2.snowygrounds[:,0:brk]),origin='lower')\nax8.imshow(l2distance(hs2.snowygrounds[:,brk:]),origin='lower')\np.tight_layout() #rect : tuple (left, bottom, right, top), optional\np.savefig(\"temp.pdf\",tranparent=True)\n\n/tmp/ipykernel_25956/1733975175.py:12: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"tranparent\" which is no longer supported as of 3.3 and will become an error two minor releases later\n  p.savefig(\"temp.pdf\",tranparent=True)\n\n\n\n\n\n\n\n\n\n\nhs1_eucliddistance=hs1.eucliddistance\ndiffusion_distance=diffusion_distance\nhs1_sigma1=l2distance(hs1.snowygrounds[:,:brk])\nhs1_sigma2=l2distance(hs1.snowygrounds[:,brk:])\nhs2_eucliddistance=hs2.eucliddistance\ndiffusion_distance=diffusion_distance\nhs2_sigma1=l2distance(hs2.snowygrounds[:,:brk])\nhs2_sigma2=l2distance(hs2.snowygrounds[:,brk:])\n\n\n%R -i hs1_eucliddistance,diffusion_distance,hs1_sigma1,hs1_sigma2,hs2_eucliddistance,hs2_sigma1,hs2_sigma2\n\n\n%%R\nlibrary(tidyverse)\nlibrary(gridExtra)\nlibrary(latex2exp)\nn=60\ngrid&lt;-expand.grid(x=1:n,y=1:n)\nW_Graph_long_caseA&lt;-as_tibble(cbind(grid,as.vector(diffusion_distance)));names(W_Graph_long_caseA)&lt;-c(\"x\",\"y\",\"W\")\nW_Euclid_long_caseA&lt;-as_tibble(cbind(grid,as.vector(hs1_eucliddistance)));names(W_Euclid_long_caseA)&lt;-c(\"x\",\"y\",\"W\")\nW_HST1_long_caseA&lt;-as_tibble(cbind(grid,as.vector(hs1_sigma1)));names(W_HST1_long_caseA)&lt;-c(\"x\",\"y\",\"W\")\nW_HST2_long_caseA&lt;-as_tibble(cbind(grid,as.vector(hs1_sigma2)));names(W_HST2_long_caseA)&lt;-c(\"x\",\"y\",\"W\")\n\nW_Graph_long_caseB&lt;-as_tibble(cbind(grid,as.vector(diffusion_distance)));names(W_Graph_long_caseB)&lt;-c(\"x\",\"y\",\"W\")\nW_Euclid_long_caseB&lt;-as_tibble(cbind(grid,as.vector(hs2_eucliddistance)));names(W_Euclid_long_caseB)&lt;-c(\"x\",\"y\",\"W\")\nW_HST1_long_caseB&lt;-as_tibble(cbind(grid,as.vector(hs2_sigma1)));names(W_HST1_long_caseB)&lt;-c(\"x\",\"y\",\"W\")\nW_HST2_long_caseB&lt;-as_tibble(cbind(grid,as.vector(hs2_sigma2)));names(W_HST2_long_caseB)&lt;-c(\"x\",\"y\",\"W\")\n\n\n%%R -w 2000 -h 1000 -r 250\nfig1&lt;-ggplot()+geom_tile(data=W_Euclid_long_caseA,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"white\",high=\"black\")+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())\n\nfig2&lt;-ggplot()+geom_tile(data=W_Graph_long_caseA,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"white\",high=\"black\")+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())\n\nfig3&lt;-ggplot()+geom_tile(data=W_HST1_long_caseA,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"white\",high=\"black\")+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())\n\nfig4&lt;-ggplot()+geom_tile(data=W_HST2_long_caseA,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"white\",high=\"black\")+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())\n\nfig5&lt;-ggplot()+geom_tile(data=W_Euclid_long_caseB,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"white\",high=\"black\")+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())\n\nfig6&lt;-ggplot()+geom_tile(data=W_Graph_long_caseB,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"white\",high=\"black\")+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())\n\n\nfig7&lt;-ggplot()+geom_tile(data=W_HST1_long_caseB,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"white\",high=\"black\")+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())\n\nfig8&lt;-ggplot()+geom_tile(data=W_HST2_long_caseB,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"white\",high=\"black\")+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())\n\n\n# fig1_4&lt;-eigenplot(gfftrslt_Euclid)+ylim(0,2)+theme_light()\n# fig1_5&lt;-eigenplot(gfftrslt_Graph)+ylim(0,2)+theme_light()\n# fig1_6&lt;-eigenplot(gfftrslt_HST)+ylim(0,2)+theme_light()\nfig=grid.arrange(fig1,fig2,fig3,fig4,fig5,fig6,fig7,fig8,ncol=4,nrow=2)\nfig\nggsave(plot=fig,\"temp.pdf\",width=10,height=5)"
  },
  {
    "objectID": "연구/지윤이랑/SOLAR/2023-08-14-(연구&지윤) 태양광자료분석 -- GConvLSTM +++++++ 이거!!! ++++++++++++.html",
    "href": "연구/지윤이랑/SOLAR/2023-08-14-(연구&지윤) 태양광자료분석 -- GConvLSTM +++++++ 이거!!! ++++++++++++.html",
    "title": "(연구&지윤) 태양광자료분석 – GConvLSTM +++++++ 이거!!! ++++++++++++",
    "section": "",
    "text": "변경사항: RGCN_Learner 수정 – 일부기능추가\n\n\n포인트: 배치학습을 적용하여 update가 빨리이루어지도록 코드수정\n\n\n\n\n# modules \nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch\nimport eptstgcn\nimport eptstgcn.planner\nimport torch_geometric_temporal\nfrom torch_geometric_temporal.signal.static_graph_temporal_signal import StaticGraphTemporalSignal\nimport mplcyberpunk\n\n# torch\nimport torch\nimport torch.nn.functional as F\n#import torch_geometric_temporal\nfrom torch_geometric_temporal.nn.recurrent import GConvLSTM\n# from torch_geometric_temporal.nn.recurrent import GCLSTM\n# from torch_geometric_temporal.nn.recurrent import LRGCN\n# from torch_geometric_temporal.nn.recurrent import TGCN\n# from torch_geometric_temporal.nn.recurrent import DCRNN\n\n# read data\ndef makedict(FX,W=None,node_ids=None):\n    T,N = np.array(FX).shape\n    if W==None:\n        W = pd.DataFrame(FX).corr().to_numpy().reshape(-1).tolist() # corr 로 weights\n    if node_ids==None:\n        node_ids = ['node'+str(n) for n in range(N)]\n    _dict={\n        'edges':[[i,j] for i in range(N) for j in range(N)], \n        'node_ids': node_ids,\n        'weights':W,\n        'FX':FX\n    }\n    return _dict\n\nclass Loader(object):\n    def __init__(self, data_dict):\n        self._dataset = data_dict\n    \n    def _get_edges(self):\n        self._edges = np.array(self._dataset[\"edges\"]).T\n\n    def _get_edge_weights(self):\n        # self._edge_weights = np.array(self._dataset[\"weights\"]).T\n        edge_weights = np.array(self._dataset[\"weights\"]).T\n        #scaled_edge_weights = minmaxscaler(edge_weights)\n        self._edge_weights = edge_weights\n\n    def _get_targets_and_features(self):\n        stacked_target = np.stack(self._dataset[\"FX\"])\n        self.features = np.stack([\n            stacked_target[i : i + self.lags, :].T\n            for i in range(stacked_target.shape[0] - self.lags)\n        ])\n        self.targets = np.stack([\n            stacked_target[i + self.lags, :].T\n            for i in range(stacked_target.shape[0] - self.lags)\n        ])\n\n\n    def get_dataset(self, lags: int = 4) -&gt; StaticGraphTemporalSignal:\n        self.lags = lags\n        self._get_edges()\n        self._get_edge_weights()\n        self._get_targets_and_features()\n        dataset = StaticGraphTemporalSignal(\n            self._edges, self._edge_weights, self.features, self.targets\n        )\n        dataset.node_ids = self._dataset['node_ids']\n        return dataset\n    \nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvLSTM(in_channels = node_features, out_channels = filters, K = 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight, h, c):\n        h_0, c_0 = self.recurrent(x, edge_index, edge_weight, h, c)\n        h = F.relu(h_0)\n        h = self.linear(h)\n        return h, h_0, c_0\n    \n    \n# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\ndevice = torch.device('cpu')\n\nclass RGCN_Learner:\n    def __init__(self):\n        self.method = 'RecurrentGCN'\n        self.figs = []\n        self.epochs = 0\n        self.losses = []\n        self._node_idx = 0\n    def load(self,y): \n        if (self.lags is None) or (self.train_ratio is None):\n            self.lags = 4\n            self.train_ratio = 0.8 \n        self.t,self.n = y.shape\n        dct = makedict(FX=y.tolist())\n        self.loader = Loader(dct)\n        self.dataset = self.loader.get_dataset(lags=self.lags)\n        self.X = torch.tensor(self.dataset.features).float()\n        self.y = torch.tensor(self.dataset.targets).float()\n        self.train_dataset, self.test_dataset = eptstgcn.utils.temporal_signal_split(self.dataset, train_ratio = self.train_ratio)\n        self.len_test = self.test_dataset.snapshot_count\n        self.len_tr = self.train_dataset.snapshot_count\n        #self.dataset_name = str(self.train_dataset) if dataset_name is None else dataset_name\n    def get_batches(self, batch_size=256):\n        num_batches =  self.len_tr // batch_size + (1 if self.len_tr % batch_size != 0 else 0)\n        self.batches = []\n        for i in range(num_batches):\n            start_idx = i * batch_size\n            end_idx = start_idx + batch_size\n            self.batches.append(self.train_dataset[start_idx:end_idx])\n    \n    def learn(self,epoch=1):\n        self.model.train()\n        for e in range(epoch):\n            losses_batch = []\n            for b,batch in enumerate(self.batches):\n                loss = 0\n                self.h, self.c = None, None\n                for t, snapshot in enumerate(batch):\n                    snapshot = snapshot.to(device)\n                    yt_hat, self.h, self.c = self.model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, self.h, self.c)\n                    loss = loss + torch.mean((yt_hat.reshape(-1)-snapshot.y.reshape(-1))**2)\n                    print(f'\\rbatch={b}\\t t={t+1}\\t loss={loss/(t+1)}\\t', end='', flush=True)\n                loss = loss / (t+1)\n                loss.backward()\n                self.optimizer.step()\n                self.optimizer.zero_grad()\n                losses_batch.append(loss.item())\n            self.epochs = self.epochs + 1\n            print(f'\\repoch={self.epochs}\\t loss={np.mean(losses_batch)}\\n', end='', flush=True)\n        self.losses.append(np.mean(losses_batch))\n        self._savefigs() \n    def _savefigs(self): \n        self.__call__()\n        self._node_idx\n        with plt.style.context('default'): \n            plt.ioff()\n            plt.rcParams['figure.figsize'] = [20, 3]  # [가로 크기, 세로 크기]\n            fig,ax = plt.subplots()\n            ax.plot(self.y[:,self._node_idx],label='real',lw=0.5)\n            ax.plot(self.yhat[:,self._node_idx],'--',label='predited',alpha=0.5)\n            ax.set_title(f'Epoch={self.epochs}, node_idx={self._node_idx}',size=15)\n            ax.legend()\n            #mplcyberpunk.add_glow_effects()  \n        self.figs.append(fig)\n        plt.close()\n    def __call__(self,dataset=None):\n        if dataset == None: \n            dataset = self.dataset\n        self.yhat = torch.stack([self.model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, self.h, self.c)[0] for snapshot in dataset]).detach().squeeze().float()\n        return {'X':self.X, 'y':self.y, 'yhat':self.yhat} \n\n# learn \n# def rgcn(FX,train_ratio,lags,filters,epoch):\n#     dct = makedict(FX=FX.tolist())\n#     loader = Loader(dct)\n#     dataset = loader.get_dataset(lags=lags)\n#     dataset_tr, dataset_test = eptstgcn.utils.temporal_signal_split(dataset, train_ratio = train_ratio)\n#     lrnr = RGCN_Learner(dataset_tr, dataset_name = 'org & arbitrary')\n#     lrnr.learn(filters=filters, epoch=epoch)\n#     yhat = np.array(lrnr(dataset)['yhat'])\n#     yhat = np.concatenate([np.array([list(yhat[0])]*lags),yhat],axis=0)\n#     return yhat\n\n\n\n\n\n# read dataframe \ndf = pd.read_csv('data_eng_230710.csv')\n# make y, y_upper, y_period, time, regions \ny = df.loc[:,'Bukchoncheon':'Gyeongju-si'].to_numpy()\nyU = df.loc[:,'Bukchoncheon_Upper':'Gyeongju-si_Upper'].to_numpy()\nyP = np.divide(y, yU+1e-10)\n\n\n\n\n- 예시1: y를 학습\n학습~\n\n# step1: create lrnr object\nlrnr = RGCN_Learner()\n# step2: load data \nlrnr.lags = 4 \nlrnr.train_ratio = 0.8\nlrnr.load(y) \n# step3: construct networks \nlrnr.nof_filters = 16\nlrnr.model = RecurrentGCN(node_features=lrnr.lags, filters=lrnr.nof_filters).to(device)\nlrnr.optimizer = torch.optim.Adam(lrnr.model.parameters(),lr=10/1000)\n# step4: learn \nlrnr.get_batches(batch_size=24)\nfor e in range(5):    \n    lrnr.learn()\n\nepoch=1  loss=0.348616252371738191366577        \nepoch=2  loss=0.096857151493083602352905            \nepoch=3  loss=0.085899897092996645071335            \nepoch=4  loss=0.082436966038374011698761            \nepoch=5  loss=0.080951251696015514699783            \n\n\n\nlrnr.y.shape\n\ntorch.Size([2564, 44])\n\n\n\nlrnr.get_batches(batch_size=24)\n\n\nlrnr.batches[-1]\n\n&lt;torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal at 0x7fa2cfbc7cd0&gt;\n\n\n\nplt.plot(y[:100,0])\n\n에폭별 적합결과(\\(\\hat{y}\\)) 시각화\n\nlrnr.figs[0]\n\n\n\n\n\n\n\n\n\nlrnr.figs[1]\n\n\n\n\n\n\n\n\n\nlrnr.figs[-1]\n\n\n\n\n\n\n\n\n- 예시2: yU 학습\n\n# step1: create lrnr object\nlrnr = RGCN_Learner()\n# step2: load data \nlrnr.lags = 4 \nlrnr.train_ratio = 0.8\nlrnr.load(yU) \n# step3: construct networks \nlrnr.nof_filters = 16\nlrnr.model = RecurrentGCN(node_features=lrnr.lags, filters=lrnr.nof_filters).to(device)\nlrnr.optimizer = torch.optim.Adam(lrnr.model.parameters(),lr=10/1000)\n# step4: learn \nlrnr.get_batches(batch_size=24)\nfor e in range(5):    \n    lrnr.learn()\n\nepoch=1  loss=1.98579962707536175294647     \nepoch=2  loss=0.202098417204133351100159        \nepoch=3  loss=0.052548440736393594218872        \nepoch=4  loss=0.0272646296531135271772957   \nepoch=5  loss=0.0191931016526596582006645   \n\n\n\nlrnr.figs[-1]\n\n\n\n\n\n\n\n\n5번정도 더 돌려보자\n\nfor e in range(5):    \n    lrnr.learn()\n\nepoch=6  loss=0.0169690931215882312923717       \nepoch=7  loss=0.0141667058247379891905975       \nepoch=8  loss=0.0124263072353896015870743       \nepoch=9  loss=0.0103476242200189951082373       \nepoch=10     loss=0.009508996026937005688799        \n\n\n\nlrnr.figs[-1]\n\n\n\n\n\n\n\n\n- 예시3: yP 학습\n\n# step1: create lrnr object\nlrnr = RGCN_Learner()\n# step2: load data \nlrnr.lags = 4 \nlrnr.train_ratio = 0.8\nlrnr.load(yP) \n# step3: construct networks \nlrnr.nof_filters = 16\nlrnr.model = RecurrentGCN(node_features=lrnr.lags, filters=lrnr.nof_filters).to(device)\nlrnr.optimizer = torch.optim.Adam(lrnr.model.parameters(),lr=10/1000)\n# step4: learn \nlrnr.get_batches(batch_size=24)\nfor e in range(5):    \n    lrnr.learn()\n\nepoch=1  loss=0.030719049366970748393135            \nepoch=2  loss=0.0119630681123411254793358       \nepoch=3  loss=0.0109235838672882638420868       \nepoch=4  loss=0.0107088599754714682600975       \nepoch=5  loss=0.0105961727974719788335514       \n\n\n\nlrnr.figs[-1]"
  },
  {
    "objectID": "연구/지윤이랑/SOLAR/2023-08-14-(연구&지윤) 태양광자료분석 -- GConvLSTM +++++++ 이거!!! ++++++++++++.html#import",
    "href": "연구/지윤이랑/SOLAR/2023-08-14-(연구&지윤) 태양광자료분석 -- GConvLSTM +++++++ 이거!!! ++++++++++++.html#import",
    "title": "(연구&지윤) 태양광자료분석 – GConvLSTM +++++++ 이거!!! ++++++++++++",
    "section": "",
    "text": "# modules \nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch\nimport eptstgcn\nimport eptstgcn.planner\nimport torch_geometric_temporal\nfrom torch_geometric_temporal.signal.static_graph_temporal_signal import StaticGraphTemporalSignal\nimport mplcyberpunk\n\n# torch\nimport torch\nimport torch.nn.functional as F\n#import torch_geometric_temporal\nfrom torch_geometric_temporal.nn.recurrent import GConvLSTM\n# from torch_geometric_temporal.nn.recurrent import GCLSTM\n# from torch_geometric_temporal.nn.recurrent import LRGCN\n# from torch_geometric_temporal.nn.recurrent import TGCN\n# from torch_geometric_temporal.nn.recurrent import DCRNN\n\n# read data\ndef makedict(FX,W=None,node_ids=None):\n    T,N = np.array(FX).shape\n    if W==None:\n        W = pd.DataFrame(FX).corr().to_numpy().reshape(-1).tolist() # corr 로 weights\n    if node_ids==None:\n        node_ids = ['node'+str(n) for n in range(N)]\n    _dict={\n        'edges':[[i,j] for i in range(N) for j in range(N)], \n        'node_ids': node_ids,\n        'weights':W,\n        'FX':FX\n    }\n    return _dict\n\nclass Loader(object):\n    def __init__(self, data_dict):\n        self._dataset = data_dict\n    \n    def _get_edges(self):\n        self._edges = np.array(self._dataset[\"edges\"]).T\n\n    def _get_edge_weights(self):\n        # self._edge_weights = np.array(self._dataset[\"weights\"]).T\n        edge_weights = np.array(self._dataset[\"weights\"]).T\n        #scaled_edge_weights = minmaxscaler(edge_weights)\n        self._edge_weights = edge_weights\n\n    def _get_targets_and_features(self):\n        stacked_target = np.stack(self._dataset[\"FX\"])\n        self.features = np.stack([\n            stacked_target[i : i + self.lags, :].T\n            for i in range(stacked_target.shape[0] - self.lags)\n        ])\n        self.targets = np.stack([\n            stacked_target[i + self.lags, :].T\n            for i in range(stacked_target.shape[0] - self.lags)\n        ])\n\n\n    def get_dataset(self, lags: int = 4) -&gt; StaticGraphTemporalSignal:\n        self.lags = lags\n        self._get_edges()\n        self._get_edge_weights()\n        self._get_targets_and_features()\n        dataset = StaticGraphTemporalSignal(\n            self._edges, self._edge_weights, self.features, self.targets\n        )\n        dataset.node_ids = self._dataset['node_ids']\n        return dataset\n    \nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvLSTM(in_channels = node_features, out_channels = filters, K = 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight, h, c):\n        h_0, c_0 = self.recurrent(x, edge_index, edge_weight, h, c)\n        h = F.relu(h_0)\n        h = self.linear(h)\n        return h, h_0, c_0\n    \n    \n# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\ndevice = torch.device('cpu')\n\nclass RGCN_Learner:\n    def __init__(self):\n        self.method = 'RecurrentGCN'\n        self.figs = []\n        self.epochs = 0\n        self.losses = []\n        self._node_idx = 0\n    def load(self,y): \n        if (self.lags is None) or (self.train_ratio is None):\n            self.lags = 4\n            self.train_ratio = 0.8 \n        self.t,self.n = y.shape\n        dct = makedict(FX=y.tolist())\n        self.loader = Loader(dct)\n        self.dataset = self.loader.get_dataset(lags=self.lags)\n        self.X = torch.tensor(self.dataset.features).float()\n        self.y = torch.tensor(self.dataset.targets).float()\n        self.train_dataset, self.test_dataset = eptstgcn.utils.temporal_signal_split(self.dataset, train_ratio = self.train_ratio)\n        self.len_test = self.test_dataset.snapshot_count\n        self.len_tr = self.train_dataset.snapshot_count\n        #self.dataset_name = str(self.train_dataset) if dataset_name is None else dataset_name\n    def get_batches(self, batch_size=256):\n        num_batches =  self.len_tr // batch_size + (1 if self.len_tr % batch_size != 0 else 0)\n        self.batches = []\n        for i in range(num_batches):\n            start_idx = i * batch_size\n            end_idx = start_idx + batch_size\n            self.batches.append(self.train_dataset[start_idx:end_idx])\n    \n    def learn(self,epoch=1):\n        self.model.train()\n        for e in range(epoch):\n            losses_batch = []\n            for b,batch in enumerate(self.batches):\n                loss = 0\n                self.h, self.c = None, None\n                for t, snapshot in enumerate(batch):\n                    snapshot = snapshot.to(device)\n                    yt_hat, self.h, self.c = self.model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, self.h, self.c)\n                    loss = loss + torch.mean((yt_hat.reshape(-1)-snapshot.y.reshape(-1))**2)\n                    print(f'\\rbatch={b}\\t t={t+1}\\t loss={loss/(t+1)}\\t', end='', flush=True)\n                loss = loss / (t+1)\n                loss.backward()\n                self.optimizer.step()\n                self.optimizer.zero_grad()\n                losses_batch.append(loss.item())\n            self.epochs = self.epochs + 1\n            print(f'\\repoch={self.epochs}\\t loss={np.mean(losses_batch)}\\n', end='', flush=True)\n        self.losses.append(np.mean(losses_batch))\n        self._savefigs() \n    def _savefigs(self): \n        self.__call__()\n        self._node_idx\n        with plt.style.context('default'): \n            plt.ioff()\n            plt.rcParams['figure.figsize'] = [20, 3]  # [가로 크기, 세로 크기]\n            fig,ax = plt.subplots()\n            ax.plot(self.y[:,self._node_idx],label='real',lw=0.5)\n            ax.plot(self.yhat[:,self._node_idx],'--',label='predited',alpha=0.5)\n            ax.set_title(f'Epoch={self.epochs}, node_idx={self._node_idx}',size=15)\n            ax.legend()\n            #mplcyberpunk.add_glow_effects()  \n        self.figs.append(fig)\n        plt.close()\n    def __call__(self,dataset=None):\n        if dataset == None: \n            dataset = self.dataset\n        self.yhat = torch.stack([self.model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, self.h, self.c)[0] for snapshot in dataset]).detach().squeeze().float()\n        return {'X':self.X, 'y':self.y, 'yhat':self.yhat} \n\n# learn \n# def rgcn(FX,train_ratio,lags,filters,epoch):\n#     dct = makedict(FX=FX.tolist())\n#     loader = Loader(dct)\n#     dataset = loader.get_dataset(lags=lags)\n#     dataset_tr, dataset_test = eptstgcn.utils.temporal_signal_split(dataset, train_ratio = train_ratio)\n#     lrnr = RGCN_Learner(dataset_tr, dataset_name = 'org & arbitrary')\n#     lrnr.learn(filters=filters, epoch=epoch)\n#     yhat = np.array(lrnr(dataset)['yhat'])\n#     yhat = np.concatenate([np.array([list(yhat[0])]*lags),yhat],axis=0)\n#     return yhat"
  },
  {
    "objectID": "연구/지윤이랑/SOLAR/2023-08-14-(연구&지윤) 태양광자료분석 -- GConvLSTM +++++++ 이거!!! ++++++++++++.html#load-data",
    "href": "연구/지윤이랑/SOLAR/2023-08-14-(연구&지윤) 태양광자료분석 -- GConvLSTM +++++++ 이거!!! ++++++++++++.html#load-data",
    "title": "(연구&지윤) 태양광자료분석 – GConvLSTM +++++++ 이거!!! ++++++++++++",
    "section": "",
    "text": "# read dataframe \ndf = pd.read_csv('data_eng_230710.csv')\n# make y, y_upper, y_period, time, regions \ny = df.loc[:,'Bukchoncheon':'Gyeongju-si'].to_numpy()\nyU = df.loc[:,'Bukchoncheon_Upper':'Gyeongju-si_Upper'].to_numpy()\nyP = np.divide(y, yU+1e-10)"
  },
  {
    "objectID": "연구/지윤이랑/SOLAR/2023-08-14-(연구&지윤) 태양광자료분석 -- GConvLSTM +++++++ 이거!!! ++++++++++++.html#sample_codes",
    "href": "연구/지윤이랑/SOLAR/2023-08-14-(연구&지윤) 태양광자료분석 -- GConvLSTM +++++++ 이거!!! ++++++++++++.html#sample_codes",
    "title": "(연구&지윤) 태양광자료분석 – GConvLSTM +++++++ 이거!!! ++++++++++++",
    "section": "",
    "text": "- 예시1: y를 학습\n학습~\n\n# step1: create lrnr object\nlrnr = RGCN_Learner()\n# step2: load data \nlrnr.lags = 4 \nlrnr.train_ratio = 0.8\nlrnr.load(y) \n# step3: construct networks \nlrnr.nof_filters = 16\nlrnr.model = RecurrentGCN(node_features=lrnr.lags, filters=lrnr.nof_filters).to(device)\nlrnr.optimizer = torch.optim.Adam(lrnr.model.parameters(),lr=10/1000)\n# step4: learn \nlrnr.get_batches(batch_size=24)\nfor e in range(5):    \n    lrnr.learn()\n\nepoch=1  loss=0.348616252371738191366577        \nepoch=2  loss=0.096857151493083602352905            \nepoch=3  loss=0.085899897092996645071335            \nepoch=4  loss=0.082436966038374011698761            \nepoch=5  loss=0.080951251696015514699783            \n\n\n\nlrnr.y.shape\n\ntorch.Size([2564, 44])\n\n\n\nlrnr.get_batches(batch_size=24)\n\n\nlrnr.batches[-1]\n\n&lt;torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal at 0x7fa2cfbc7cd0&gt;\n\n\n\nplt.plot(y[:100,0])\n\n에폭별 적합결과(\\(\\hat{y}\\)) 시각화\n\nlrnr.figs[0]\n\n\n\n\n\n\n\n\n\nlrnr.figs[1]\n\n\n\n\n\n\n\n\n\nlrnr.figs[-1]\n\n\n\n\n\n\n\n\n- 예시2: yU 학습\n\n# step1: create lrnr object\nlrnr = RGCN_Learner()\n# step2: load data \nlrnr.lags = 4 \nlrnr.train_ratio = 0.8\nlrnr.load(yU) \n# step3: construct networks \nlrnr.nof_filters = 16\nlrnr.model = RecurrentGCN(node_features=lrnr.lags, filters=lrnr.nof_filters).to(device)\nlrnr.optimizer = torch.optim.Adam(lrnr.model.parameters(),lr=10/1000)\n# step4: learn \nlrnr.get_batches(batch_size=24)\nfor e in range(5):    \n    lrnr.learn()\n\nepoch=1  loss=1.98579962707536175294647     \nepoch=2  loss=0.202098417204133351100159        \nepoch=3  loss=0.052548440736393594218872        \nepoch=4  loss=0.0272646296531135271772957   \nepoch=5  loss=0.0191931016526596582006645   \n\n\n\nlrnr.figs[-1]\n\n\n\n\n\n\n\n\n5번정도 더 돌려보자\n\nfor e in range(5):    \n    lrnr.learn()\n\nepoch=6  loss=0.0169690931215882312923717       \nepoch=7  loss=0.0141667058247379891905975       \nepoch=8  loss=0.0124263072353896015870743       \nepoch=9  loss=0.0103476242200189951082373       \nepoch=10     loss=0.009508996026937005688799        \n\n\n\nlrnr.figs[-1]\n\n\n\n\n\n\n\n\n- 예시3: yP 학습\n\n# step1: create lrnr object\nlrnr = RGCN_Learner()\n# step2: load data \nlrnr.lags = 4 \nlrnr.train_ratio = 0.8\nlrnr.load(yP) \n# step3: construct networks \nlrnr.nof_filters = 16\nlrnr.model = RecurrentGCN(node_features=lrnr.lags, filters=lrnr.nof_filters).to(device)\nlrnr.optimizer = torch.optim.Adam(lrnr.model.parameters(),lr=10/1000)\n# step4: learn \nlrnr.get_batches(batch_size=24)\nfor e in range(5):    \n    lrnr.learn()\n\nepoch=1  loss=0.030719049366970748393135            \nepoch=2  loss=0.0119630681123411254793358       \nepoch=3  loss=0.0109235838672882638420868       \nepoch=4  loss=0.0107088599754714682600975       \nepoch=5  loss=0.0105961727974719788335514       \n\n\n\nlrnr.figs[-1]"
  },
  {
    "objectID": "연구/지윤이랑/SOLAR/2023-07-17-(연구&지윤) 태양광자료분석 -- EPT + RGCN.html",
    "href": "연구/지윤이랑/SOLAR/2023-07-17-(연구&지윤) 태양광자료분석 -- EPT + RGCN.html",
    "title": "(연구&지윤) 태양광자료분석 – EPT + RGCN",
    "section": "",
    "text": "Import\n- source\n\nhttps://github.com/miruetoto/yechan3/blob/main/posts/3_Researches/PINKOCTO/SOLAR/0720.py\n\n- download source\n\n# https://github.com/miruetoto/yechan3/blob/main/posts/3_Researches/PINKOCTO/SOLAR/0720.py\n\n- run\n\n%run 0720.py\n\n\n\nLoad data\n\n# read dataframe \ndf = pd.read_csv('https://media.githubusercontent.com/media/miruetoto/yechan3/main/posts/3_Researches/PINKOCTO/SOLAR/data_eng_230710.csv')\n\n# make y, y_upper, y_period, time, regions \ny = df.loc[:,'Bukchoncheon':'Gyeongju-si'].to_numpy()\nyU = df.loc[:,'Bukchoncheon_Upper':'Gyeongju-si_Upper'].to_numpy()\nyP = np.divide(y, yU+1e-10)\nt = df.loc[:,'date']\nregions = list(df.loc[:,'Bukchoncheon':'Gyeongju-si'].columns)\n\n# plot rawdata \nstart = 50 \nend = 50+24*3\ncity = 19 # 광주 \nwith plt.style.context('cyberpunk'):\n    plt.rcParams['figure.figsize'] = [20, 3]  # [가로 크기, 세로 크기]\n    plt.plot(t[start:end],y[start:end,city],'o',label='y')\n    plt.plot(t[start:end],yU[start:end,city],'--',label='yU')\n    plt.plot(t[start:end],yP[start:end,city],'o',label='y/yU')\n    tick_interval = 4\n    plt.xticks(range(1, len(t) + 1, tick_interval),rotation=25)        \n    plt.legend()\n    plt.title(\"The solar radiation data in {} from {} to {} \".format(regions[city],t.to_list()[0][:10],t.to_list()[-1][:10]))\n    mplcyberpunk.add_glow_effects()    \n\n\n\n\n\n\n\n\n\n\nLearn\n- y \\(\\to\\) yhat\n\n# hyper params\nLAGS = 4\nFILTERS = 8\nEPOCH = 5\n\n# global params\nTRAIN_RATIO = 0.8\nT,N = len(t),len(regions) \nLEN_TEST = int(np.floor(T*(1-TRAIN_RATIO)))\nLEN_TR = T - LEN_TEST\n\n# 방법1\nmodel = RecurrentGCN(node_features=LAGS, filters=FILTERS)\nyhat = rgcn(y, model = model, train_ratio = TRAIN_RATIO, lags=LAGS, epoch=EPOCH)\nyhat[yhat &lt; 0]= 0 \n\n# 방법2 \nmodel = RecurrentGCN(node_features=LAGS, filters=FILTERS)\nyUhat = rgcn(yU, model = model, train_ratio = TRAIN_RATIO, lags=LAGS, epoch=EPOCH)\n\nmodel = RecurrentGCN(node_features=LAGS, filters=FILTERS)\nyPhat = rgcn(yP, model = model, train_ratio = TRAIN_RATIO, lags=LAGS, epoch=EPOCH)\nyPhat[yPhat &lt; 0] =0 \n\n\nclassic = ((y - yhat)[LEN_TR:, :] ** 2)\nproposed = ((y - yUhat*yPhat)[LEN_TR:, :] ** 2)\n\n# print mse\nprint(\"\"\"\ntotal_mse(classic): {:.4f}\ntotal_mse(proposed): {:.4f}\n\"\"\".format(classic.mean(), proposed.mean()))\n\n5/5\ntotal_mse(classic): 0.0573\ntotal_mse(proposed): 0.0476\n\n\n\n\n# plot \nstart = LEN_TR \nend = LEN_TR + LEN_TEST \ncity = 20\ntick_interval = 24 \n\nclassic = (y - yhat)[start:end, :] ** 2\nproposed = (y - yUhat*yPhat)[start:end, :] ** 2\n\nprint(\"\"\"\ntotal_mse(classic): {:.4f}\ntotal_mse(proposed): {:.4f}\n\"\"\".format(classic.mean(), proposed.mean()))\n\nwith plt.style.context('cyberpunk'): \n    plt.rcParams['figure.figsize'] = [20, 4]  # [가로 크기, 세로 크기]\n    plt.plot(t[start:end],y[start:end,city],'-',label='real')\n    plt.plot(t[start:end],yhat[start:end,city],'--',label='predited(classic)')\n    plt.plot(t[start:end],(yUhat*yPhat)[start:end,city],'--',label='predited(proposed)')\n    plt.xticks(range(1, len(t[start:end]) + 1, tick_interval),rotation=25,ha='right')\n    plt.title(\"The predicted results in {} from {} to {} \".format(regions[city],t[start:end].to_list()[0][:10],t[start:end].to_list()[-1][:10]))    \n    plt.legend()\n    mplcyberpunk.add_glow_effects()\n\n\ntotal_mse(classic): 0.0573\ntotal_mse(proposed): 0.0476\n\n\n\n\n\n\n\n\n\n\n\n\nAnalyze\n- y vs yhat\n\nwith plt.style.context('seaborn-bright'): \n    plt.rcParams['figure.figsize'] = [20, 3]  # [가로 크기, 세로 크기]\n    plt.plot(y[50:150,0],'o-',label='real')\n    plt.plot(yhat[50:150,0],'o--',label='predited')\n    plt.legend()\n    mplcyberpunk.add_glow_effects()    \n\n\n\n\n\n\n\n\n- yU vs yUhat\n\nwith plt.style.context('seaborn-bright'): \n    plt.rcParams['figure.figsize'] = [20, 3]  # [가로 크기, 세로 크기]\n    plt.plot(yU[:,25],label='real')\n    plt.plot(yUhat[:,25],label='predited')\n    plt.legend()\n    mplcyberpunk.add_glow_effects()    \n\n\n\n\n\n\n\n\n- yP vs yPhat\n\nwith plt.style.context('seaborn-bright'): \n    plt.rcParams['figure.figsize'] = [20, 3]  # [가로 크기, 세로 크기]\n    plt.plot(yP[50:150,city],'o-',label='real')\n    plt.plot(yPhat[50:150,city],'o--',label='predited')\n    plt.legend()\n    mplcyberpunk.add_glow_effects()    \n\n\n\n\n\n\n\n\n- y vs (yUhat*yPhat)\n\nwith plt.style.context('seaborn-bright'): \n    plt.rcParams['figure.figsize'] = [20, 3]  # [가로 크기, 세로 크기]\n    plt.plot(y[50:150,0],'o-',label='real')\n    plt.plot((yUhat*yPhat)[50:150,0],'o--',label='predited')\n    plt.legend()\n    mplcyberpunk.add_glow_effects()    \n\n\n\n\n\n\n\n\n- 지역별분석\n\nwith plt.style.context('cyberpunk'):\n    plt.rcParams['figure.figsize'] = [20, 3]  # [가로 크기, 세로 크기]\n    plt.plot(regions,classic.mean(axis=0)-proposed.mean(axis=0),'--o');\n    plt.xticks(regions, rotation=55, ha='right');    \n    mplcyberpunk.add_glow_effects()"
  },
  {
    "objectID": "연구/서연이랑/ITSTGCN/2023-09-14-논문리비전.html",
    "href": "연구/서연이랑/ITSTGCN/2023-09-14-논문리비전.html",
    "title": "(연구&서연) IT-STGCN – 논문리비전",
    "section": "",
    "text": "1. intro\n\n\n\nimage.png\n\n\n- 초록색은 나쁘지 않음. 하지만 아래의 내용을 보완하는게 좋음.\n\n분야의 예시로 신경과학, 환경데이터, 교통자료가 있는데 우리가 실제로 분석한 자료들이 사용된 논문을 찾아보며 예시를 들것 (Chickenpox, …) 사용하지 않더라도 예시를 들것.\n이러한 자료를 분석하는것이 왜 어려운지 설명할 것. 즉 단순히 시계열로 해석하거나 공간자료로 해석하면 어떠한 문제가 있는지 간단히 서술할 것. (1~2문장) 레퍼런스 찾을것. (torch_geometric_temporal 의 도입부분 활용)\n\n- 붉은부분\n\n의도는 좋으나 sparse data 는 올바르지 않은 표현임. missing, irregulary observed data 등으로 설명할 것.\n이러한 자료가 왜 발생하는지 설명할 것. (이부분은 레퍼런스 필요) 이러한 자료를 처리하는 것이 어려운 이유를 설명할 것.1\n우리의 아이디어는 “호모지니우스하지 않은 그래프 -&gt; 호모지니우스화 시킴” 인데 이러한 방식은 이상한방식이 아님. Yu et al. (2017) and Guo et al. (2019) Bai et al. (2020), Li et al. (2019), Zhao et al. (2019) 이 우리와 비슷한 연구를 했음.\n\n1 보통 결측없이 모두 관측한상태에서는 모형이 잘 동작함, 대부분의 spatio temporal data는 각각의 스냅샷마다 동일한 그래프구조를 가진다는 가정을 사용함. 스냅샷마다 그래프구조가 다른 경우를 가정하는 모형도 있음. 그러한 모형의 예시는 A,B,C,…. 등이 있음. 하지만 이러한 연구는 애초에 데이터가 스냅샷마다 non-호모지니우스하게 생겼으면 효율적일 수 있으나, 실제true model은 스냅샷마다 그래프구조가 동일하다고 여겨지지만 결측치로 인하여 스냅샷마다 호모지니우스가 깨지는 경우는 효율적이지 않을 수 있음. 우리는 이 부분에 초점을 맞추었음. 우리의 아이디어는 호모지니우스 하지 않은 그래프를 A,B,C, 등을 이용하여 그대로 처리하는것 보다 missing을 처리하여 호모지니우스하게 강제로 만들고 그 자료를 분석하자는 아이디어임.- 아래식은 틀렸음. 이건 회귀모형이 아님.. GNAR의 notation을 사용하여 모형을 다시표현해볼것..\n\n\n\nimage.png\n\n\n\n이부분이 아주 클리어 해야함\n사용하는 대부분의 Notations들이 정리되어야함.\nintro에 쓰는 것이 부담스러우면 제외해도 무방\n뒤에 self consistence estimator에 사용할 Notation을 함께 고려\n\n- 빨간부분 삭제후 다시 작성 (혹은 공부할 것)\n\n\n\nimage.png\n\n\n- 초록색부분은 나쁘지 않음\n\n\n\nimage.png\n\n\n\n\n2. Related works\n- 2.1과 2.2를 왜 리뷰하는지 설명이 필요함\n- 2.1에서 왜 Convolution Operator에 집중하는지 설명이 필요\n- 2.2에서 왜 Dynamic graphs에 집중하는지 설명이 필요\n- 전체적으로 이름은 related works인데 뭐가 related 되어있길래 이런것들을 소개하는지 클리어하지 않음. (솔직히 저도 저 방법들이 우리랑 뭔 관련있는지 잘모르겠어요)\n\n\n3. Backgrounds\n- 좋아요\n- 자잘한건 제가 수정하면 될 듯합니다.\n\n\n4.\n- 내용을 좀 더 팬시하게 쓸 필요가 있어보임\n- 아래부분을 정리하여 알고리즘화 해야함.\n\n\n\nimage.png\n\n\n\n\n5. Experiments\n- 아직 덜 읽어봄\n- 데이터 설명은 Appendix에, 실험결과와 Fig는 본문에 있는게 좋음"
  },
  {
    "objectID": "연구/서연이랑/ITSTGCN/2023-03-18-SimualtionPlanner-Tutorial.html",
    "href": "연구/서연이랑/ITSTGCN/2023-03-18-SimualtionPlanner-Tutorial.html",
    "title": "(연구&서연) IT-STGCN – SimualtionPlanner-Tutorial",
    "section": "",
    "text": "import itstgcn\nimport torch\nimport itstgcn.planner"
  },
  {
    "objectID": "연구/서연이랑/ITSTGCN/2023-03-18-SimualtionPlanner-Tutorial.html#plnr_stgcn_rand",
    "href": "연구/서연이랑/ITSTGCN/2023-03-18-SimualtionPlanner-Tutorial.html#plnr_stgcn_rand",
    "title": "(연구&서연) IT-STGCN – SimualtionPlanner-Tutorial",
    "section": "PLNR_STGCN_RAND",
    "text": "PLNR_STGCN_RAND\n\nplans_stgcn_rand = {\n    'max_iteration': 2, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mrate': [0.0, 0.2],\n    'lags': [2, 4], \n    'nof_filters': [4, 8], \n    'inter_method': ['nearest'],\n    'epoch': [3]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_RAND(plans_stgcn_rand,loader,dataset_name='five_nodes')\n\n\nplnr.simulate()\n\n1/2 is done\n2/2 is done\nAll results are stored in ./simulation_results/2023-03-18_11-56-03.csv"
  },
  {
    "objectID": "연구/서연이랑/ITSTGCN/2023-03-18-SimualtionPlanner-Tutorial.html#plnr_stgcn_manual",
    "href": "연구/서연이랑/ITSTGCN/2023-03-18-SimualtionPlanner-Tutorial.html#plnr_stgcn_manual",
    "title": "(연구&서연) IT-STGCN – SimualtionPlanner-Tutorial",
    "section": "PLNR_STGCN_MANUAL",
    "text": "PLNR_STGCN_MANUAL\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\nloader = itstgcn.DatasetLoader(data_dict)\n\n\nmindex= [list(range(10,100)),[],list(range(50,80)),[],[]]\nplans_stgcn_block = {\n    'max_iteration': 3, \n    'method': ['STGCN', 'IT-STGCN'], \n    'mindex': [mindex],\n    'lags': [2, 4], \n    'nof_filters': [8,16], \n    'inter_method': ['nearest','linear'],\n    'epoch': [1]\n}\n\n\nplnr = itstgcn.planner.PLNR_STGCN_MANUAL(plans_stgcn_block,loader,dataset_name='five_nodes')\n\n\nplnr.simulate(mindex=mindex,mtype='block')\n\n1/3 is done\n2/3 is done\n3/3 is done\nAll results are stored in ./simulation_results/2023-03-18_11-56-55.csv"
  },
  {
    "objectID": "연구/서연이랑/ITSTGCN/2023-03-18-SimualtionPlanner-Tutorial.html#plnr_gnar_rand",
    "href": "연구/서연이랑/ITSTGCN/2023-03-18-SimualtionPlanner-Tutorial.html#plnr_gnar_rand",
    "title": "(연구&서연) IT-STGCN – SimualtionPlanner-Tutorial",
    "section": "PLNR_GNAR_RAND",
    "text": "PLNR_GNAR_RAND\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\nloader = itstgcn.DatasetLoader(data_dict)\n\n\nplans_gnar_rand = {\n    'max_iteration': 3, \n#    'method': ['GNAR'], \n    'mrate': [0.0, 0.2, 0.4],\n    'lags': [2, 4], \n#    'nof_filters': [8,16], \n    'inter_method': ['nearest','linear'],\n#    'epoch': [1]\n}\n\n\nplnr = itstgcn.planner.PLNR_GNAR_RAND(plans_gnar_rand,loader,dataset_name='five_nodes')\nplnr.simulate()\n\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n1/3 is done\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n2/3 is done\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n3/3 is done\nAll results are stored in ./simulation_results/2023-03-18_11-56-56.csv"
  },
  {
    "objectID": "연구/서연이랑/ITSTGCN/2023-03-18-SimualtionPlanner-Tutorial.html#plnr_gnar_block",
    "href": "연구/서연이랑/ITSTGCN/2023-03-18-SimualtionPlanner-Tutorial.html#plnr_gnar_block",
    "title": "(연구&서연) IT-STGCN – SimualtionPlanner-Tutorial",
    "section": "PLNR_GNAR_BLOCK",
    "text": "PLNR_GNAR_BLOCK\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\nloader = itstgcn.DatasetLoader(data_dict)\n\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\nplans_gnar_block = {\n    'max_iteration': 3, \n    'method': ['GNAR'], \n    'mindex': [mindex],\n    'lags': [2, 4], \n    'inter_method': ['nearest','linear'],\n}\n\n\nplnr = itstgcn.planner.PLNR_GNAR_MANUAL(plans_gnar_block,loader,dataset_name='five_nodes')\nplnr.simulate(mindex,mtype='block')\n\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n1/3 is done\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n2/3 is done\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n3/3 is done\nAll results are stored in ./simulation_results/2023-03-18_11-56-57.csv"
  },
  {
    "objectID": "연구/서연이랑/ITSTGCN/2024-01-24-ToyExam.html",
    "href": "연구/서연이랑/ITSTGCN/2024-01-24-ToyExam.html",
    "title": "(연구&서연) IT-STGCN – ToyExam",
    "section": "",
    "text": "Import\n\nimport pandas as pd\nimport numpy as np\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport pickle\n\nimport plotly.io as pio\n\n\npd.options.plotting.backend = \"plotly\"\npio.templates.default = \"plotly_white\"\n\n\n\nLoad Data\n\nwith open(\"60persent_random_epoch100.pkl\",'rb') as f: \n    fig1,fig2 = pickle.load(f)\nfig1['frames'] = list(fig1['frames'])[::10]\nfig2['frames'] = list(fig2['frames'])[::10]\nfig1.update_layout(template=\"plotly_white\")\nfig2.update_layout(template=\"plotly_white\")\nfig1.update_layout(width=650, height=450)\nfig2.update_layout(width=650, height=450)\nmindex = np.array(pd.read_csv('epoch100_mindex.csv').iloc[:,-1].tolist())\nscatter_opacity = np.array([1.0]*10000)\nscatter_opacity[mindex] = 0.1\nfig1.data[-1]['marker'] = {'color': 'black', 'opacity': scatter_opacity, 'size': 1}\nfig2.data[-1]['marker'] = {'color': 'black', 'opacity': scatter_opacity, 'size': 1}\n\nFileNotFoundError: [Errno 2] No such file or directory: 'epoch100_mindex.csv'\n\n\n\nfig2"
  },
  {
    "objectID": "연구/서연이랑/ITSTGCN/2022-12-30-Toy Example.html",
    "href": "연구/서연이랑/ITSTGCN/2022-12-30-Toy Example.html",
    "title": "(연구&서연) IT-STGCN – Toy Example",
    "section": "",
    "text": "import networkx as nx\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport torch"
  },
  {
    "objectID": "연구/서연이랑/ITSTGCN/2022-12-30-Toy Example.html#data",
    "href": "연구/서연이랑/ITSTGCN/2022-12-30-Toy Example.html#data",
    "title": "(연구&서연) IT-STGCN – Toy Example",
    "section": "data",
    "text": "data\n\nfrom torch_geometric_temporal.dataset import WikiMathsDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = WikiMathsDatasetLoader()\n\ndataset = loader.get_dataset(lags=14)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)"
  },
  {
    "objectID": "연구/서연이랑/ITSTGCN/2022-12-30-Toy Example.html#recurrentgcn",
    "href": "연구/서연이랑/ITSTGCN/2022-12-30-Toy Example.html#recurrentgcn",
    "title": "(연구&서연) IT-STGCN – Toy Example",
    "section": "RecurrentGCN",
    "text": "RecurrentGCN\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h"
  },
  {
    "objectID": "연구/서연이랑/ITSTGCN/2022-12-30-Toy Example.html#learn",
    "href": "연구/서연이랑/ITSTGCN/2022-12-30-Toy Example.html#learn",
    "title": "(연구&서연) IT-STGCN – Toy Example",
    "section": "Learn",
    "text": "Learn\n\n# from tqdm import tqdm\n\n# model = RecurrentGCN(node_features=14, filters=32)\n\n# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\n# model.train()\n\n# for epoch in tqdm(range(50)):\n#     for time, snapshot in enumerate(train_dataset):\n#         y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n#         cost = torch.mean((y_hat-snapshot.y)**2)\n#         cost.backward()\n#         optimizer.step()\n#         optimizer.zero_grad()\n\n\nmodel = RecurrentGCN(node_features=14, filters=32)\nmodel.train()\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(14, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(14, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(14, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)\n\n\n\nfor s in train_dataset:\n    print((s.y-model(s.x,s.edge_index,s.edge_attr)).shape)\n\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])\ntorch.Size([1068, 1068])"
  },
  {
    "objectID": "연구/서연이랑/ITSTGCN/2022-12-30-Toy Example.html#예제의-차원-조사",
    "href": "연구/서연이랑/ITSTGCN/2022-12-30-Toy Example.html#예제의-차원-조사",
    "title": "(연구&서연) IT-STGCN – Toy Example",
    "section": "예제의 차원 조사",
    "text": "예제의 차원 조사\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([1068, 14])\n\n\n\n1068: number of nodes // 1068개의 노드가 있음\n14: number of features // 하나의 노드에 맵핑된 차원의수\n\n\n_edge_index.shape\n\ntorch.Size([2, 27079])\n\n\n\n_edge_attr.shape\n\ntorch.Size([27079])\n\n\n\n_y.shape\n\ntorch.Size([1068])\n\n\n\n1068: number of nodes\n\n\n_x.shape\n\ntorch.Size([1068, 14])"
  },
  {
    "objectID": "연구/서연이랑/ITSTGCN/2023-02-14-Tables.html",
    "href": "연구/서연이랑/ITSTGCN/2023-02-14-Tables.html",
    "title": "(연구&서연) IT-STGCN – Tables",
    "section": "",
    "text": "import pandas as pd\n\n- Dataset 5nodes\n\ncol = ['Dataset','iteration', 'method', 'missingrate', 'missingtype', 'lag', 'number_of_filters', 'interpolation','MSE_train', 'MSE_test',]\n\n\ndf = pd.DataFrame(columns=col)\ndf\n\n\n\n\n\n\n\n\nDataset\niteration\nmethod\nmissingrate\nmissingtype\nlag\nnumber_of_filters\ninterpolation\nMSE_train\nMSE_test\n\n\n\n\n\n\n\n\n\n- 실험마다 아래와 같은식으로 추가\n\ndf_row = pd.DataFrame(columns=col)\ndf_row['Dataset'] = 'fivenodes', # ...\ndf_row['iteration'] = 1, # 1,2,3,...,10 \ndf_row['method'] = 'stgcn', # 'stgcn','estgcn','gnar' \ndf_row['missingrate'] = 0.0, # 0.0, 0.2, 0.4, 0.6, 0.8 \ndf_row['missingtype'] = None,  # None, 'randomly' and 'block' \ndf_row['lag'] = 1, # 1,2,3,4 ... \ndf_row['number_of_filters'] = 16, # 16,24,32, ... \ndf_row['interpolation'] = None, # None, 'mean', 'linear'\ndf_row['MSE_train'] = 0.96 \ndf_row['MSE_test'] = 0.55\n\n\ndf = pd.concat([df,df_row])\ndf\n\n\n\n\n\n\n\n\nDataset\niteration\nmethod\nmissingrate\nmissingtype\nlag\nnumber_of_filters\ninterpolation\nMSE_train\nMSE_test\n\n\n\n\n0\nfivenodes\n1\nstgcn\n0.0\nNone\n1\n16\nNone\n0.96\n0.55\n\n\n\n\n\n\n\n\ndf_row = pd.DataFrame(columns=col)\ndf_row['Dataset'] = 'fivenodes', # ...\ndf_row['iteration'] = 1, # 1,2,3,...,10 \ndf_row['method'] = 'stgcn', # 'stgcn','estgcn','gnar' \ndf_row['missingrate'] = 0.2, # 0.0, 0.2, 0.4, 0.6, 0.8 \ndf_row['missingtype'] = 'randomly',  # None, 'randomly' and 'block' \ndf_row['lag'] = 1, # 1,2,3,4 ... \ndf_row['number_of_filters'] = 16, # 16,24,32, ... \ndf_row['interpolation'] = 'mean', # None, 'mean', 'linear'\ndf_row['MSE_train'] = 1.23\ndf_row['MSE_test'] = 0.88\n\n\ndf = pd.concat([df,df_row])\ndf\n\n\n\n\n\n\n\n\nDataset\niteration\nmethod\nmissingrate\nmissingtype\nlag\nnumber_of_filters\ninterpolation\nMSE_train\nMSE_test\n\n\n\n\n0\nfivenodes\n1\nstgcn\n0.0\nNone\n1\n16\nNone\n0.96\n0.55\n\n\n0\nfivenodes\n1\nstgcn\n0.2\nrandomly\n1\n16\nmean\n1.23\n0.88"
  },
  {
    "objectID": "연구/서연이랑/GODE/Ex2_Distance히스토그램시각화.html",
    "href": "연구/서연이랑/GODE/Ex2_Distance히스토그램시각화.html",
    "title": "(연구&서연) GODE – Ex2 Distance Histogram 시각화",
    "section": "",
    "text": "ref: https://seoyeonc.github.io/GODE_blog/posts/Result/3_table/2024-06-22-final_GODE_code_JKSS_review.html\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport pandas as pd\nimport random\nimport pickle\n\nimport warnings\nwarnings.simplefilter(\"ignore\", np.ComplexWarning)\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)\nfrom haversine import haversine\nfrom IPython.display import HTML\nimport plotly.graph_objects as go\nimport copy \n\nimport tqdm\nfrom rpy2.robjects.packages import importr\nfrom rpy2.robjects.vectors import FloatVector \n\nfrom pygsp import graphs, filters, plotting, utils\n\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, roc_curve, auc\n\n\nfrom pyod.models.lof import LOF\nfrom pyod.models.knn import KNN\nfrom pyod.models.cblof import CBLOF\nfrom pyod.models.ocsvm import OCSVM\nfrom pyod.models.mcd import MCD\nfrom pyod.models.feature_bagging import FeatureBagging\nfrom pyod.models.abod import ABOD\nfrom pyod.models.iforest import IForest\nfrom pyod.models.hbos import HBOS\nfrom pyod.models.sos import SOS\nfrom pyod.models.so_gaal import SO_GAAL\nfrom pyod.models.mo_gaal import MO_GAAL\nfrom pyod.models.lscp import LSCP\n\n\nplt.rcParams['text.usetex'] = True\n\n\nclass Conf_matrx:\n    def __init__(self,original,compare):\n        self.original = original\n        self.compare = compare\n    def conf(self,name):\n        self.name = name\n        self.conf_matrix = confusion_matrix(self.original, self.compare)\n        \n        # fig, ax = plt.subplots(figsize=(5, 5))\n        # ax.matshow(self.conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n        # for i in range(self.conf_matrix.shape[0]):\n        #     for j in range(self.conf_matrix.shape[1]):\n        #         ax.text(x=j, y=i,s=self.conf_matrix[i, j], va='center', ha='center', size='xx-large')\n        # plt.xlabel('Predictions', fontsize=18)\n        # plt.ylabel('Actuals', fontsize=18)\n        # plt.title('Confusion Matrix of ' + str(name), fontsize=18)\n        # plt.show()\n        \n        self.acc = accuracy_score(self.original, self.compare)\n        self.pre = precision_score(self.original, self.compare)\n        self.rec = recall_score(self.original, self.compare)\n        self.f1 = f1_score(self.original, self.compare)\n        \n        # print('Accuracy: %.3f' % self.acc)\n        # print('Precision: %.3f' % self.pre)\n        # print('Recall: %.3f' % self.rec)\n        # print('F1 Score: %.3f' % self.f1)\n\n\nclass Orbit:\n    def __init__(self,df):\n        self.df = df \n        self.f = df.f.to_numpy()\n        self.x = df.x.to_numpy()\n        self.y = df.y.to_numpy()\n        self.n = len(self.f)\n        self.theta= None\n    def get_distance(self):\n        self.D = np.zeros([self.n,self.n])\n        locations = np.stack([self.x, self.y],axis=1)\n        for i in tqdm.tqdm(range(self.n)):\n            for j in range(i,self.n):\n                self.D[i,j]=np.linalg.norm(locations[i]-locations[j])\n        self.D = self.D + self.D.T\n    def get_weightmatrix(self,theta=1,beta=0.5,kappa=4000):\n        self.theta = theta\n        dist = np.where(self.D &lt; kappa,self.D,0)\n        self.W = np.exp(-(dist/self.theta)**2)\n    def _eigen(self):\n        d= self.W.sum(axis=1)\n        D= np.diag(d)\n        self.L = np.diag(1/np.sqrt(d)) @ (D-self.W) @ np.diag(1/np.sqrt(d))\n        self.lamb, self.Psi = np.linalg.eigh(self.L)\n        self.Lamb = np.diag(self.lamb)       \n    def fit(self,sd=5): # fit with ebayesthresh\n        self._eigen()\n        self.fbar = self.Psi.T @ self.f # fbar := graph fourier transform of f\n        self.power = self.fbar**2 \n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        self.power_threshed=np.array(ebayesthresh(FloatVector(self.power),sd=sd))\n        self.fbar_threshed = np.where(self.power_threshed&gt;0,self.fbar,0)\n        self.fhat = self.Psi@self.fbar_threshed\n        self.df = self.df.assign(fHat = self.fhat)\n        self.df = self.df.assign(Residual = self.df.f- self.df.fHat)\n\n\nclass fortable:\n    def __init__(self, df, clf, tab, outlier_true, conf_name = \"Method\"):\n        self.df = df\n        self.clf = clf\n        self.conf_name = conf_name\n        self.tabb = tab\n        self.outlier_true = outlier_true\n        \n    def _forfit(self):\n        if 'fnoise' in self.df.columns:\n            self.clf.fit(self.df[['x', 'y','fnoise']])\n        elif 'f' in self.df.columns:\n            self.clf.fit(self.df[['x', 'y', 'f']])\n        if 'f' not in self.df.columns:\n            self.clf.fit(self.df[['x', 'y']])\n\n    def _forlabels(self):\n        self.labels = list(self.clf.labels_)\n\n    def _forpredict(self):\n        self.predict = self.clf.fit_predict(self.df)\n        \n    def comparison(self, compare_outlier = None, conf_outlier = None, gode = False):\n        if gode == False:\n            self._forfit()\n            self._forlabels()\n            if 'fnoise' in self.df.columns:\n                compare_outlier = self.clf.decision_function(np.array(self.df[['x', 'y','fnoise']]))\n            else:\n                compare_outlier = self.clf.decision_function(self.df)\n            if self.conf_name == \"LOF\":\n                self._forpredict()\n                conf_outlier = self.predict\n            elif self.conf_name != \"LOF\":\n                conf_outlier = self.labels\n        elif gode == True:\n            compare_outlier = compare_outlier\n            conf_outlier = conf_outlier\n\n        fpr, tpr, thresh = roc_curve(self.outlier_true, compare_outlier)       \n        \n        _conf = Conf_matrx(self.outlier_true, conf_outlier)\n        _conf.conf(self.conf_name)\n        \n        _table = pd.concat([self.tabb,\n                   pd.DataFrame({\"Accuracy\":[_conf.acc],\"Precision\":[_conf.pre],\"Recall\":[_conf.rec],\"F1\":[_conf.f1],\"AUC\":[auc(fpr, tpr)],\"N\":n, \"Contamination\": eta_sparsity,\"kappa\":kappa},index = [_conf.name])])\n        \n        return _table\n\n\nOrbit\n\nn = 1000\neta_sparsity = 0.05\nrandom_seed=77\nnp.random.seed(777)\nepsilon = np.around(np.random.normal(size=n),15)\nsignal = np.random.choice(np.concatenate((np.random.uniform(-4, -1, round(n * eta_sparsity / 2)).round(15), np.random.uniform(1, 4, round(n * eta_sparsity / 2)).round(15), np.repeat(0, n - round(n * eta_sparsity)))), n)\neta = signal + epsilon\npi=np.pi\nang=np.linspace(-pi,pi-2*pi/n,n)\nr=5+np.cos(np.linspace(0,12*pi,n))\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=10*np.sin(np.linspace(0,6*pi,n))\nf = f1 + eta\ndata = pd.DataFrame({'x' : vx, 'y' : vy, 'f' : f})\noutlier_true_orbit = signal.copy()\noutlier_true_orbit = list(map(lambda x: 1 if x!=0 else 0,outlier_true_orbit))\n\n\n\nGODE\n\norbit = Orbit(data)\norbit.get_distance()\ndists = np.array([orbit.D[i,j] for i in range(len(orbit.f)) for j in range(i+1,len(orbit.f))])\n\n100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:01&lt;00:00, 545.62it/s]\n\n\n\n#np.save('~/Dropbox/03_Yechan3/연구/서연이랑/GODE/dists.npy', dists)\nnp.save('./Dropbox/03_Yechan3/연구/서연이랑/GODE/dists.npy', dists)\ndists = np.load('./Dropbox/03_Yechan3/연구/서연이랑/GODE/dists.npy')\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n# Calculate the quantiles (25%, 50%, 75%, 100%)\nquantiles = np.percentile(dists, [25, 50, 75, 100])\n\n# Calculate the optimal number of bins using the Freedman-Diaconis rule\nq75, q25 = np.percentile(dists, [75, 25])\niqr = q75 - q25\nbin_width = 2 * iqr * len(dists) ** (-1/3)\nbins = int((dists.max() - dists.min()) / bin_width)\n\n# Set up the figure\nplt.figure(figsize=(12, 7))\n\n# Plot the histogram with the calculated bin size and gray bins\nsns.histplot(dists, bins=bins, kde=False, stat=\"density\", color='gray', edgecolor='white', alpha=0.6)\n\n# Overlay the KDE plot with a black line\nkde = sns.kdeplot(dists, color='black', linewidth=2)\n\n# Get the density values from the KDE plot for each quantile\ndensity_values = kde.get_lines()[0].get_data()\n\n# Add vertical lines at each quantile with black color and adjust the height\nfor i, q in enumerate(quantiles):\n    # Find the closest x value in the KDE data and corresponding y value (density)\n    idx = np.argmin(np.abs(density_values[0] - q))\n    plt.axvline(q, color='black', linestyle='--', linewidth=1, ymax=density_values[1][idx] / plt.ylim()[1])\n    # Annotate the quantile with detailed text on the x-axis\n    plt.text(q, density_values[1][idx] * 1.1, f'{25 * (i + 1)}\\% quantile: {q:.2f}', color='red', fontsize=12, ha='center')\n\n# Add titles and labels\nplt.title('Distribution of Distance', fontsize=18, fontweight='bold')\nplt.xlabel('Distance', fontsize=14)\nplt.ylabel('Density', fontsize=14)\nplt.grid(True)\n\n# Show the plot\nplt.show()\n\n# Print the quantile values (for reference)\nfor i, q in enumerate(quantiles):\n    print(f'{25 * (i + 1)}% quantile: {q:.2f}')\n\n\n\n\n\n\n\n\n25% quantile: 3.82\n50% quantile: 7.03\n75% quantile: 9.15\n100% quantile: 12.00"
  },
  {
    "objectID": "연구/서연이랑/GODE/다양한셋팅에서 예제1,2,3 AUC 결과 시각화.html",
    "href": "연구/서연이랑/GODE/다양한셋팅에서 예제1,2,3 AUC 결과 시각화.html",
    "title": "(연구&서연) GODE – Ex2 Kappa에 따른 성능 시각화",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.rcParams['text.usetex'] = True\n\n\ndf_bunny = pd.read_csv(\"~/Dropbox/03_Yechan3/연구/서연이랑/GODE/Bunny_Dataset.csv\").rename({'Unnamed: 0':'Method'},axis=1)\ndf_linear = pd.read_csv(\"~/Dropbox/03_Yechan3/연구/서연이랑/GODE/Linear_Dataset.csv\").rename({'Unnamed: 0':'Method'},axis=1)\ndf_orbit = pd.read_csv(\"~/Dropbox/03_Yechan3/연구/서연이랑/GODE/Orbit_Dataset.csv\").rename({'Unnamed: 0':'Method'},axis=1)\n\n\nBunny\n\n# Save the plots as a PDF\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create the 1x3 bar plots as requested, focusing on AUC with GODE highlighted and labeled in thicker bold red\nfig, axs = plt.subplots(1, 3, figsize=(24*(2/3), 8*(2/3)))\n\n# Filter data based on Contamination values and sort by AUC\ncontaminations = [0.01, 0.05, 0.10]\nhighlight_method = 'GODE'\n\nfor i, contamination in enumerate(contaminations):\n    df_subset = df_bunny[df_bunny['Contamination'] == contamination].sort_values(by='AUC', ascending=False)\n    \n    # Highlight GODE with a different color\n    colors = ['blue' if method == highlight_method else 'purple' for method in df_subset['Method']]\n    \n    # Plot only AUC with dodge and numbers on top\n    sns.barplot(x='Method', y='AUC', data=df_subset, ax=axs[i], palette=colors)\n    \n    # Add text labels for AUC values\n    for j in range(len(df_subset)):\n        axs[i].text(j, df_subset['AUC'].values[j] + 0.02, round(df_subset['AUC'].values[j], 3), ha='center')\n    \n    # Customize the x-tick labels, making GODE bold and red\n    xtick_labels = []\n    for method in df_subset['Method']:\n        if method == highlight_method:\n            xtick_labels.append(f\"GODE\")\n        else:\n            xtick_labels.append(method)\n    axs[i].set_xticklabels(xtick_labels, rotation=45, ha='right', fontsize=12)\n    \n    for label in axs[i].get_xticklabels():\n        if label.get_text() == \"GODE\":\n            label.set_color(\"red\")\n            label.set_fontweight(\"extra bold\")  # Set to extra bold to increase thickness\n            label.set_fontsize(14)  # Increase font size for more emphasis\n    \n    axs[i].set_title(f'AUC for Contamination {contamination}')\n    axs[i].set_ylabel('AUC Value')\n    axs[i].set_ylim(0, 1.1)\n\nplt.tight_layout()\n\n# Save the figure as a PDF\npdf_filename = \"./Dropbox/03_Yechan3/연구/서연이랑/GODE/Bunny_Dataset.pdf\"\nplt.savefig(pdf_filename, format='pdf')\nplt.show()\n\n/tmp/ipykernel_497972/2230919312.py:19: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x='Method', y='AUC', data=df_subset, ax=axs[i], palette=colors)\n/tmp/ipykernel_497972/2230919312.py:32: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n  axs[i].set_xticklabels(xtick_labels, rotation=45, ha='right', fontsize=12)\n/tmp/ipykernel_497972/2230919312.py:19: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x='Method', y='AUC', data=df_subset, ax=axs[i], palette=colors)\n/tmp/ipykernel_497972/2230919312.py:32: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n  axs[i].set_xticklabels(xtick_labels, rotation=45, ha='right', fontsize=12)\n/tmp/ipykernel_497972/2230919312.py:19: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x='Method', y='AUC', data=df_subset, ax=axs[i], palette=colors)\n/tmp/ipykernel_497972/2230919312.py:32: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n  axs[i].set_xticklabels(xtick_labels, rotation=45, ha='right', fontsize=12)\n\n\n\n\n\n\n\n\n\n\n\nLinear\n\n# Adjust the grid size accordingly (3 rows for the 3 sample sizes, 3 columns for the contamination levels)\nfig, axs = plt.subplots(3, 3, figsize=(24*(2/3), 24*(2/3)))\n\nhighlight_method = 'GODE'\n\n# Define the specific plots where GODE should be placed first\nplots_to_reorder = [(0, 1), (1, 0), (1, 1), (2, 1)]  # (row, col) format for 2, 4, 5, 8\n\n# Loop over each combination of filtered sample size and contamination to create subplots\nfor i, n in enumerate(filtered_ns):\n    for j, contamination in enumerate(filtered_contaminations):\n        # Filter the data by N and Contamination\n        df_subset = df_linear[(df_linear['N'] == n) & (df_linear['Contamination'] == contamination)]\n        \n        # Sort by AUC first, then by method name, ensuring GODE is first if needed\n        df_subset = df_subset.sort_values(by=['AUC', 'Method'], ascending=[False, True])\n        \n        # Check if the current plot needs GODE to be placed first\n        if (i, j) in plots_to_reorder:\n            df_subset = pd.concat([df_subset[df_subset['Method'] == highlight_method], df_subset[df_subset['Method'] != highlight_method]])\n        \n        # Determine the correct subplot\n        ax = axs[i, j]\n        \n        # Set up colors, where only GODE gets the blue highlight, and make its label bold red\n        colors = ['blue' if method == highlight_method else 'purple' for method in df_subset['Method']]\n        \n        # Plot AUC with labels, and assign color based on method\n        sns.barplot(x='Method', y='AUC', data=df_subset, ax=ax, dodge=False, palette=colors)\n        \n        # Add text labels for AUC values\n        for k in range(len(df_subset)):\n            ax.text(k, df_subset['AUC'].values[k] + 0.02, round(df_subset['AUC'].values[k], 3), ha='center')\n        \n        # Customize the x-tick labels, making GODE bold and red\n        xtick_labels = []\n        for method in df_subset['Method']:\n            if method == highlight_method:\n                xtick_labels.append(f\"GODE\")\n            else:\n                xtick_labels.append(method)\n        ax.set_xticks(range(len(xtick_labels)))\n        ax.set_xticklabels(xtick_labels, rotation=45, ha='right', fontsize=12)\n        \n        for label in ax.get_xticklabels():\n            if label.get_text() == \"GODE\":\n                label.set_color(\"red\")\n                label.set_fontweight(\"extra bold\")\n                label.set_fontsize(14)\n        \n        ax.set_title(f'AUC for N={int(n)}, Contamination={contamination}')\n        ax.set_ylabel('AUC Value')\n        ax.set_ylim(0, 1.1)\n\nplt.tight_layout()\n\n# Save the figure as a PDF\npdf_filename = \"./Dropbox/03_Yechan3/연구/서연이랑/GODE/Linear_Dataset.pdf\"\nplt.savefig(pdf_filename, format='pdf')\n\n# Return the filename for reference\npdf_filename\n\n/tmp/ipykernel_497972/286785422.py:29: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x='Method', y='AUC', data=df_subset, ax=ax, dodge=False, palette=colors)\n/tmp/ipykernel_497972/286785422.py:29: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x='Method', y='AUC', data=df_subset, ax=ax, dodge=False, palette=colors)\n/tmp/ipykernel_497972/286785422.py:29: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x='Method', y='AUC', data=df_subset, ax=ax, dodge=False, palette=colors)\n/tmp/ipykernel_497972/286785422.py:29: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x='Method', y='AUC', data=df_subset, ax=ax, dodge=False, palette=colors)\n/tmp/ipykernel_497972/286785422.py:29: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x='Method', y='AUC', data=df_subset, ax=ax, dodge=False, palette=colors)\n/tmp/ipykernel_497972/286785422.py:29: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x='Method', y='AUC', data=df_subset, ax=ax, dodge=False, palette=colors)\n/tmp/ipykernel_497972/286785422.py:29: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x='Method', y='AUC', data=df_subset, ax=ax, dodge=False, palette=colors)\n/tmp/ipykernel_497972/286785422.py:29: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x='Method', y='AUC', data=df_subset, ax=ax, dodge=False, palette=colors)\n/tmp/ipykernel_497972/286785422.py:29: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x='Method', y='AUC', data=df_subset, ax=ax, dodge=False, palette=colors)\n\n\n'./Dropbox/03_Yechan3/연구/서연이랑/GODE/Linear_Dataset.pdf'\n\n\n\n\n\n\n\n\n\n\n\nOrbit\n\nfiltered_contaminations\n\n[0.05, 0.1, 0.2]\n\n\n\n# Adjust the grid size accordingly (3 rows for the 3 sample sizes, 3 columns for the contamination levels)\nfig, axs = plt.subplots(3, 3, figsize=(24*(2/3), 24*(2/3)))\n\nhighlight_method = 'GODE'\n\n# Define the specific plots where GODE should be placed first\nplots_to_reorder = [(0, 1), (1, 0), (1, 1), (2, 1)]  # (row, col) format for 2, 4, 5, 8\n\ncontaminations = [0.01, 0.05, 0.10]\n\n# Loop over each combination of filtered sample size and contamination to create subplots\nfor i, n in enumerate(filtered_ns):\n    for j, contamination in enumerate(contaminations):\n        # Filter the data by N and Contamination\n        df_subset = df_orbit[(df_orbit['N'] == n) & (df_orbit['Contamination'] == contamination)]\n        \n        # Sort by AUC first, then by method name, ensuring GODE is first if needed\n        df_subset = df_subset.sort_values(by=['AUC', 'Method'], ascending=[False, True])\n        \n        # Check if the current plot needs GODE to be placed first\n        if (i, j) in plots_to_reorder:\n            df_subset = pd.concat([df_subset[df_subset['Method'] == highlight_method], df_subset[df_subset['Method'] != highlight_method]])\n        \n        # Determine the correct subplot\n        ax = axs[i, j]\n        \n        # Set up colors, where only GODE gets the blue highlight, and make its label bold red\n        colors = ['blue' if method == highlight_method else 'purple' for method in df_subset['Method']]\n        \n        # Plot AUC with labels, and assign color based on method\n        sns.barplot(x='Method', y='AUC', data=df_subset, ax=ax, dodge=False, palette=colors)\n        \n        # Add text labels for AUC values\n        for k in range(len(df_subset)):\n            ax.text(k, df_subset['AUC'].values[k] + 0.02, round(df_subset['AUC'].values[k], 3), ha='center')\n        \n        # Customize the x-tick labels, making GODE bold and red\n        xtick_labels = []\n        for method in df_subset['Method']:\n            if method == highlight_method:\n                xtick_labels.append(f\"GODE\")\n            else:\n                xtick_labels.append(method)\n        ax.set_xticks(range(len(xtick_labels)))\n        ax.set_xticklabels(xtick_labels, rotation=45, ha='right', fontsize=12)\n        \n        for label in ax.get_xticklabels():\n            if label.get_text() == \"GODE\":\n                label.set_color(\"red\")\n                label.set_fontweight(\"extra bold\")\n                label.set_fontsize(14)\n        \n        ax.set_title(f'AUC for N={int(n)}, Contamination={contamination}')\n        ax.set_ylabel('AUC Value')\n        ax.set_ylim(0, 1.1)\n\nplt.tight_layout()\n\n# Save the figure as a PDF\npdf_filename = \"./Dropbox/03_Yechan3/연구/서연이랑/GODE/Orbit_Dataset.pdf\"\nplt.savefig(pdf_filename, format='pdf')\n\n# Return the filename for reference\npdf_filename\n\n/tmp/ipykernel_497972/3937110979.py:31: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x='Method', y='AUC', data=df_subset, ax=ax, dodge=False, palette=colors)\n/tmp/ipykernel_497972/3937110979.py:31: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x='Method', y='AUC', data=df_subset, ax=ax, dodge=False, palette=colors)\n/tmp/ipykernel_497972/3937110979.py:31: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x='Method', y='AUC', data=df_subset, ax=ax, dodge=False, palette=colors)\n/tmp/ipykernel_497972/3937110979.py:31: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x='Method', y='AUC', data=df_subset, ax=ax, dodge=False, palette=colors)\n/tmp/ipykernel_497972/3937110979.py:31: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x='Method', y='AUC', data=df_subset, ax=ax, dodge=False, palette=colors)\n/tmp/ipykernel_497972/3937110979.py:31: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x='Method', y='AUC', data=df_subset, ax=ax, dodge=False, palette=colors)\n/tmp/ipykernel_497972/3937110979.py:31: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x='Method', y='AUC', data=df_subset, ax=ax, dodge=False, palette=colors)\n/tmp/ipykernel_497972/3937110979.py:31: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x='Method', y='AUC', data=df_subset, ax=ax, dodge=False, palette=colors)\n/tmp/ipykernel_497972/3937110979.py:31: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x='Method', y='AUC', data=df_subset, ax=ax, dodge=False, palette=colors)"
  },
  {
    "objectID": "연구/서연이랑/GODE/EX2_DistKappa.html",
    "href": "연구/서연이랑/GODE/EX2_DistKappa.html",
    "title": "(연구&서연) GODE – Ex2 Distance의분포/Kappa에따른AUC 시각화",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nimport os\nplt.rcParams['text.usetex'] = True\n\n\nfile_path = os.path.expanduser(\"~/Dropbox/03_Yechan3/연구/서연이랑/GODE/dists.npy\")\ndists = np.load(file_path)\ndf = pd.read_csv(\"~/Dropbox/03_Yechan3/연구/서연이랑/GODE/ex2_kappa_results.csv\")\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n# Assuming 'dists' contains the distribution data used in the first plot\n# Assuming 'df' contains the dataframe used in the second plot\n# Assuming 'metrics' is a list containing 'AUC'\n\n# Calculate the optimal Kappa values for each metric\noptimal_kappas = {}\nfor metric in metrics:\n    near_2_range = df[(df['Kappa'] &gt;= 0) & (df['Kappa'] &lt;= 2)]\n    mean_values = near_2_range.groupby('Kappa')[metric].mean()\n    optimal_kappa = mean_values.idxmax()\n    optimal_kappas[metric] = optimal_kappa\n\n# Calculate the quantiles (25%, 50%, 75%, 100%) for the first plot\nquantiles = np.percentile(dists, [25, 50, 75, 100])\n\n# Calculate the optimal number of bins using the Freedman-Diaconis rule for the first plot\nq75, q25 = np.percentile(dists, [75, 25])\niqr = q75 - q25\nbin_width = 2 * iqr * len(dists) ** (-1/3)\nbins = int((dists.max() - dists.min()) / bin_width)\n\n# Set up the figure with two subplots side by side\nfig, axs = plt.subplots(1, 2, figsize=(14*(2/3), 6*(2/3)))\n\n# ---- First subplot: Distribution of Distance ----\n# Plot the histogram with the calculated bin size and gray bins\nsns.histplot(dists, bins=bins, kde=False, stat=\"density\", color='gray', edgecolor='white', alpha=0.6, ax=axs[0])\n\n# Overlay the KDE plot with a black line\nkde = sns.kdeplot(dists, color='black', linewidth=2, ax=axs[0])\n\n# Get the density values from the KDE plot for each quantile\ndensity_values = kde.get_lines()[0].get_data()\n\n# Add vertical lines at each quantile with black color and adjust the height\nfor i, q in enumerate(quantiles):\n    idx = np.argmin(np.abs(density_values[0] - q))\n    axs[0].axvline(q, color='black', linestyle='--', linewidth=1, ymax=density_values[1][idx] / axs[0].get_ylim()[1])\n    axs[0].text(q, density_values[1][idx] * 1.1, f'{25 * (i + 1)}\\% quantile: {q:.2f}', color='red', fontsize=12, ha='center')\n\n# Add titles and labels\naxs[0].set_title('Distribution of Distance', fontsize=16, fontweight='bold')\naxs[0].set_xlabel('Distance', fontsize=14)\naxs[0].set_ylabel('Density', fontsize=14)\naxs[0].grid(True)\n\n# ---- Second subplot: Kappa vs. AUC ----\nmetric = 'AUC'  # Focus on AUC\nmeans = df.groupby('Kappa')[metric].mean().to_numpy()\nstd_devs = df.groupby('Kappa')[metric].std().fillna(0).to_numpy()\nkappa_values = df.groupby('Kappa')[metric].mean().index.to_numpy()\n\naxs[1].plot(kappa_values, means, label='Area Under Curve (AUC)', linestyle='-', linewidth=2, color='blue')\naxs[1].fill_between(kappa_values, means - std_devs, means + std_devs, alpha=0.2, color='blue')\n\n# Set y-axis limit to [0, 1]\naxs[1].set_ylim(0, 1)\n\n# Add red dotted line at the optimal Kappa\noptimal_kappa = optimal_kappas[metric]\naxs[1].axvline(x=optimal_kappa, color='red', linestyle='--', linewidth=2)\n\n# Annotate the optimal Kappa value, making the text more prominent\naxs[1].text(optimal_kappa - 0.2, 0.65, f'$\\kappa$ = {optimal_kappa:.2f}', \n            fontsize=14, color='black', fontweight='bold', bbox=dict(facecolor='white', alpha=1.0))\n\naxs[1].set_title('Kappa vs. Area Under Curve (AUC)', fontsize=16, fontweight='bold')\naxs[1].set_xlabel('Kappa', fontsize=14)\naxs[1].set_ylabel('AUC', fontsize=14)\naxs[1].grid(True)\n\n# Adjust layout for better spacing\nplt.tight_layout()\n\n# Save the figure as a PDF\nplt.savefig('./Dropbox/03_Yechan3/연구/서연이랑/GODE/Ex2_Kappa.pdf', format='pdf')\n\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "연구/재인이랑/2023-12-13-(연구&재인) MBTI -- 추가자료분석(429).html",
    "href": "연구/재인이랑/2023-12-13-(연구&재인) MBTI -- 추가자료분석(429).html",
    "title": "(연구&재인) MBTI – 추가자료분석 (429)",
    "section": "",
    "text": "1. Imports\n\nimport pandas as pd\nimport sklearn.model_selection\nimport sklearn.metrics\nfrom autogluon.multimodal import MultiModalPredictor\nfrom autogluon.tabular import TabularPredictor\n\n/root/anaconda3/envs/ag/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n\n\n\n2. Data\n\ndf = pd.read_csv('mbti_1.csv')\ndf_train, df_test = sklearn.model_selection.train_test_split(df,test_size=0.5,random_state=42)\n\n\nlabels = list(set(df_train.type))\n\n\ndf_additinal = pd.read_csv('MBTI.csv')\ndf_additinal2= df_additinal.copy()[429:]\n\n\ndf_additinal2['type'].value_counts()\n\ntype\nESTJ    372\nESFJ    194\nENFJ    164\nESFP     91\nESTP     57\nISFJ     32\nENFP      3\nName: count, dtype: int64\n\n\n\nfor i,post in enumerate(df_additinal['posts']):\n    for label in labels:\n        if label in post: \n            df_additinal['posts'][i] = post.replace(label,'')\n\n\ndf_train2 = pd.concat([df_train,df_additinal],axis=0).reset_index(drop=True)\n\n\ndf_train2\n\n\n\n\n\n\n\n\ntype\nposts\n\n\n\n\n0\nINFP\nI feel trapped by what people around me think of me. On one hand the way I react and live is based off my interactions with people. And know that I have people who know me or at least feel they...|||I never get it when people tell me they would have needed to be on acid to enjoy some sort of psychedelic concert. If an experience is intense enough to give the appearance of being on drugs why...|||55317 This is me...very tired, in my favorite sweater. I have such a love for good sweaters.|||Thank you all for the responses and the honesty in them. The advice you've given is quite sound. ...\n\n\n1\nENTP\n'http://www.youtube.com/watch?v=xQ04WbgI9rg&ob=av2e http://www.youtube.com/watch?v=gGdGFtwCNBE&ob=av3e http://www.youtube.com/watch?v=gH2efAcmBQM&ob=av3e ...|||What we did is inform each other what our love languages were, and both of our primaries are physical touch. So hugs, cuddling, hand holding, all that cute-sy crap that couples do... we're big on...|||I am currently dating an INTJ. Objectively, she is the most compatible woman for me from all of my relationships heretofore. This was an observation by both of us (eventually) and all of our...|||Quite, actually. It keeps us ali...\n\n\n2\nINFP\n'No, no, and no. In my opinion. I believe the adage you have to hit your kids sometimes is really just totally wrong. There are plenty of ways to discipline children that do not involve physical...|||It does kinda sound like she's using you to an extent. Don't do anything for her that you don't want to do. That's not what friendship is about. Sounds like she tries to guilt you into doing stuff...|||Hey, I never said I was making an attempt to be wholly logical in my response. :P As for your comparison, it actually is kind of like that. I'll consider the emotional reactions to all of my pos...\n\n\n3\nINFP\n'Hey! It seems like you have a great foundation and the fact that you have passion for you what you do is HUGE! Passion will take you farther then any skill set will and you can always learn skills...|||I would say there has been 3 time frames in my life that I was pretty depressed. They are never for a long time but they were pretty low points. They could be fluctuating but I always come out of it...|||I have not been on perc in forever and my heart melted when I saw all the responses I got. I appreciate you taking the time to write back. I'm doing much better. Much love and Thanks.|||It'...\n\n\n4\nENTP\n'Hahahaha, you guys are hilarious. I suppose I should do that, I don't quite understand myself all too well anywho. As to the, 'Making stuff up as you go that happens to be correct/make sense, I...|||After taking about a dozen personality tests over the course of about two months I came to the conclusion of being an INTP, although unwillingly. A few things stood out to me that I didn't agree...|||Nothing too fancy My dream goal is pretty simple (not necessarily to achieve). I want a family, and a good earning to live comfortably. I'd like money to not be an issue, so I can treat my family....\n\n\n...\n...\n...\n\n\n5674\nESFP\nToday, I dove into the realm of art. A canvas, a palette of colors, and a surge of creativity - it was time to unleash the artist within.\\nMy morning began with a visit to a local art studio. Surrounded by fellow artists, the space buzzed with creative energy. I picked up a brush and let my imagination flow onto the canvas.\\nAs the day unfolded, I found a peaceful corner in a park to continue my artistic journey. Nature itself became my muse.\\nLunch was a quaint affair in a charming café. A warm cup of tea and a slice of homemade pie - a treat for the taste buds.\\nThe afternoon was dedicat...\n\n\n5675\nESFP\nIn the heart of nature, I found my sanctuary today. The sun-dappled forest, the chirping birds, and the rustling leaves - a world apart from the concrete jungle.\\nMy morning commenced with a hike along a forest trail. The fresh scent of pine, the soft earth beneath my feet, and the symphony of nature - it's the ultimate therapy.\\nAs the day unfolded, I discovered a serene clearing by a crystal-clear stream. I couldn't resist taking a dip in the cool water and laying on the mossy banks, staring up at the canopy of green.\\nLunch was a simple affair, a picnic of sandwiches and fresh fruit. So...\n\n\n5676\nENFP\nAs the sun sets and the evening casts its warm glow, I find solace in the simplicity of home. There's something magical about cozying up with a good book or a movie, surrounded by the familiar comforts of my space.\\nTonight, I've chosen a classic novel to accompany me on my literary journey. The characters, the plot, and the scent of the pages make it feel like I'm visiting an old friend.\\nA warm cup of herbal tea in my favorite mug completes the scene. The gentle steam, the earthy aroma, and the first sip – it's like a soothing embrace for the soul.\\nAs I lose myself in the story, I can't...\n\n\n5677\nENFP\nToday, I embarked on a book lover's dream adventure, exploring quaint and hidden bookstores in the heart of the city. Each store held its own charm, secrets waiting to be uncovered in the pages of books.\\nThe first stop was a tiny, independent bookstore tucked away in an alley. The musty scent of old books and the creaking wooden floors gave it an irresistible vintage charm.\\nI spent hours browsing through shelves, discovering rare editions and forgotten gems. There's an excitement in the hunt for the perfect book that only fellow bookworms understand.\\nEach bookstore had its own theme – f...\n\n\n5678\nENFP\nToday was a day of pure artistic indulgence. From the canvas to the camera lens, I explored the world through the eyes of an artist, capturing moments and emotions in various forms.\\nThe morning began with a blank canvas and a palette of colors. With each stroke of the brush, I lost myself in the world of abstraction, a language where emotions spoke louder than words.\\nThe afternoon took me to the heart of the city, where I explored street photography. Every corner had a story to tell, and every face had a unique expression. I was a silent observer of life's drama.\\nAs the day drew to a cl...\n\n\n\n\n5679 rows × 2 columns\n\n\n\n\n\n3. Tabular\n\npredictor = TabularPredictor(label='type', eval_metric='acc')\npredictor.fit(df_train2)\n#predictor = TabularPredictor.load(\"AutogluonModels/ag-20231214_002525\")\npredictor.leaderboard()\n\nNo path specified. Models will be saved in: \"AutogluonModels/ag-20231214_011537\"\nNo presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n    Recommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n    presets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n    presets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n    presets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n    presets='medium_quality' : Fast training time, ideal for initial prototyping.\nBeginning AutoGluon training ...\nAutoGluon will save models to \"AutogluonModels/ag-20231214_011537\"\n=================== System Info ===================\nAutoGluon Version:  1.0.0\nPython Version:     3.10.13\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #140-Ubuntu SMP Thu Aug 4 02:23:37 UTC 2022\nCPU Count:          128\nMemory Avail:       374.52 GB / 503.74 GB (74.3%)\nDisk Space Avail:   976.53 GB / 1757.88 GB (55.6%)\n===================================================\nTrain Data Rows:    5679\nTrain Data Columns: 1\nLabel Column:       type\nAutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n    First 10 (of 22) unique label values:  ['INFP', 'ENTP', 'ENFP', 'INTP', 'INTJ', 'ENFJ', 'INFJ', 'ISFP', 'ISTJ', 'ISTP']\n    If 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\nProblem Type:       multiclass\nPreprocessing data ...\nWarning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 16 out of 22 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\nFraction of data from classes with at least 10 examples that will be kept for training models: 0.9984152139461173\nTrain Data Class Count: 16\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n    Available Memory:                    383556.94 MB\n    Train Data (Original)  Memory Usage: 45.00 MB (0.0% of available memory)\n    Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n    Stage 1 Generators:\n        Fitting AsTypeFeatureGenerator...\n    Stage 2 Generators:\n        Fitting FillNaFeatureGenerator...\n    Stage 3 Generators:\n        Fitting CategoryFeatureGenerator...\n            Fitting CategoryMemoryMinimizeFeatureGenerator...\n        Fitting TextSpecialFeatureGenerator...\n            Fitting BinnedFeatureGenerator...\n            Fitting DropDuplicatesFeatureGenerator...\n        Fitting TextNgramFeatureGenerator...\n            Fitting CountVectorizer for text features: ['posts']\n            CountVectorizer fit with vocabulary size = 10000\n    Stage 4 Generators:\n        Fitting DropUniqueFeatureGenerator...\n    Stage 5 Generators:\n        Fitting DropDuplicatesFeatureGenerator...\n    Types of features in original data (raw dtype, special dtypes):\n        ('object', ['text']) : 1 | ['posts']\n    Types of features in processed data (raw dtype, special dtypes):\n        ('category', ['text_as_category'])  :    1 | ['posts']\n        ('int', ['binned', 'text_special']) :   38 | ['posts.char_count', 'posts.word_count', 'posts.capital_ratio', 'posts.lower_ratio', 'posts.digit_ratio', ...]\n        ('int', ['text_ngram'])             : 9970 | ['__nlp__.00', '__nlp__.000', '__nlp__.10', '__nlp__.10 years', '__nlp__.100', ...]\n    114.2s = Fit runtime\n    1 features in original data used to generate 10009 features in processed data.\n    Train Data (Processed) Memory Usage: 108.04 MB (0.0% of available memory)\nData preprocessing and feature engineering runtime = 116.66s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n    To change this, specify the eval_metric parameter of Predictor()\nAutomatically generating train/validation split with holdout_frac=0.1, Train Rows: 5103, Val Rows: 567\nUser-specified model hyperparameters to be fit:\n{\n    'NN_TORCH': {},\n    'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n    'CAT': {},\n    'XGB': {},\n    'FASTAI': {},\n    'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n    'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n    'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n}\nFitting 13 L1 models ...\nFitting model: KNeighborsUnif ...\n    0.2945   = Validation score   (accuracy)\n    6.51s    = Training   runtime\n    1.36s    = Validation runtime\nFitting model: KNeighborsDist ...\n    0.3298   = Validation score   (accuracy)\n    6.33s    = Training   runtime\n    1.4s     = Validation runtime\nFitting model: NeuralNetFastAI ...\n    0.2892   = Validation score   (accuracy)\n    8.62s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: LightGBMXT ...\n    0.7125   = Validation score   (accuracy)\n    169.24s  = Training   runtime\n    0.1s     = Validation runtime\nFitting model: LightGBM ...\n    0.7037   = Validation score   (accuracy)\n    143.3s   = Training   runtime\n    0.09s    = Validation runtime\nFitting model: RandomForestGini ...\n    0.5873   = Validation score   (accuracy)\n    12.44s   = Training   runtime\n    0.45s    = Validation runtime\nFitting model: RandomForestEntr ...\n    0.5714   = Validation score   (accuracy)\n    18.51s   = Training   runtime\n    0.13s    = Validation runtime\nFitting model: CatBoost ...\n    Many features detected (10009), dynamically setting 'colsample_bylevel' to 0.09991008092716555 to speed up training (Default = 1).\n    To disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n    0.7019   = Validation score   (accuracy)\n    57.55s   = Training   runtime\n    1.0s     = Validation runtime\nFitting model: ExtraTreesGini ...\n    0.515    = Validation score   (accuracy)\n    12.18s   = Training   runtime\n    0.12s    = Validation runtime\nFitting model: ExtraTreesEntr ...\n    0.4515   = Validation score   (accuracy)\n    12.01s   = Training   runtime\n    0.11s    = Validation runtime\nFitting model: XGBoost ...\n    0.7143   = Validation score   (accuracy)\n    56.77s   = Training   runtime\n    0.07s    = Validation runtime\nFitting model: NeuralNetTorch ...\n    0.3016   = Validation score   (accuracy)\n    11.84s   = Training   runtime\n    0.02s    = Validation runtime\nFitting model: LightGBMLarge ...\n    0.7055   = Validation score   (accuracy)\n    273.52s  = Training   runtime\n    0.08s    = Validation runtime\nFitting model: WeightedEnsemble_L2 ...\n    Ensemble Weights: {'CatBoost': 0.571, 'LightGBMXT': 0.143, 'XGBoost': 0.143, 'NeuralNetTorch': 0.143}\n    0.7337   = Validation score   (accuracy)\n    0.62s    = Training   runtime\n    0.0s     = Validation runtime\nAutoGluon training complete, total runtime = 925.58s ... Best model: \"WeightedEnsemble_L2\"\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231214_011537\")\n\n\n\n\n\n\n\n\n\nmodel\nscore_val\neval_metric\npred_time_val\nfit_time\npred_time_val_marginal\nfit_time_marginal\nstack_level\ncan_infer\nfit_order\n\n\n\n\n0\nWeightedEnsemble_L2\n0.733686\naccuracy\n1.190554\n296.010678\n0.000615\n0.620404\n2\nTrue\n14\n\n\n1\nXGBoost\n0.714286\naccuracy\n0.070626\n56.765352\n0.070626\n56.765352\n1\nTrue\n11\n\n\n2\nLightGBMXT\n0.712522\naccuracy\n0.102126\n169.236619\n0.102126\n169.236619\n1\nTrue\n4\n\n\n3\nLightGBMLarge\n0.705467\naccuracy\n0.077333\n273.520550\n0.077333\n273.520550\n1\nTrue\n13\n\n\n4\nLightGBM\n0.703704\naccuracy\n0.090923\n143.299396\n0.090923\n143.299396\n1\nTrue\n5\n\n\n5\nCatBoost\n0.701940\naccuracy\n1.001522\n57.553270\n1.001522\n57.553270\n1\nTrue\n8\n\n\n6\nRandomForestGini\n0.587302\naccuracy\n0.453024\n12.436017\n0.453024\n12.436017\n1\nTrue\n6\n\n\n7\nRandomForestEntr\n0.571429\naccuracy\n0.127032\n18.513521\n0.127032\n18.513521\n1\nTrue\n7\n\n\n8\nExtraTreesGini\n0.514991\naccuracy\n0.118020\n12.177610\n0.118020\n12.177610\n1\nTrue\n9\n\n\n9\nExtraTreesEntr\n0.451499\naccuracy\n0.105017\n12.011709\n0.105017\n12.011709\n1\nTrue\n10\n\n\n10\nKNeighborsDist\n0.329806\naccuracy\n1.404224\n6.326862\n1.404224\n6.326862\n1\nTrue\n2\n\n\n11\nNeuralNetTorch\n0.301587\naccuracy\n0.015665\n11.835034\n0.015665\n11.835034\n1\nTrue\n12\n\n\n12\nKNeighborsUnif\n0.294533\naccuracy\n1.363828\n6.506021\n1.363828\n6.506021\n1\nTrue\n1\n\n\n13\nNeuralNetFastAI\n0.289242\naccuracy\n0.012532\n8.623879\n0.012532\n8.623879\n1\nTrue\n3\n\n\n\n\n\n\n\n\npredictor.evaluate(df_test)\n\n{'accuracy': 0.6680497925311203,\n 'balanced_accuracy': 0.4269238301463123,\n 'mcc': 0.6136189980032133}\n\n\n\npredictor.predict(df_test)\n\n2802    INTP\n2166    INFJ\n1919    INTP\n360     ENFP\n1115    INTJ\n        ... \n1415    ENTP\n7269    INFP\n127     INFJ\n3474    INTP\n5960    INFJ\nName: type, Length: 4338, dtype: object\n\n\n\nmodel_names = predictor.model_names()\nyhats = {model_name:predictor.predict(df_test,model=model_name) for model_name in model_names}\n\n\ny = df_test['type']\n\n\nyhats['KNeighborsUnif']\n\n2802    ENFP\n2166    INFJ\n1919    INTJ\n360     INTJ\n1115    ENTP\n        ... \n1415    INTP\n7269    INTJ\n127     INFP\n3474    ENTP\n5960    ENFP\nName: type, Length: 4338, dtype: object\n\n\n\ny\n\n2802    INTP\n2166    INTJ\n1919    INTP\n360     ENFP\n1115    ENTJ\n        ... \n1415    ENFJ\n7269    ISFJ\n127     INFJ\n3474    INTP\n5960    INFP\nName: type, Length: 4338, dtype: object\n\n\n\nyhats.keys()\n\ndict_keys(['KNeighborsUnif', 'KNeighborsDist', 'NeuralNetFastAI', 'LightGBMXT', 'LightGBM', 'RandomForestGini', 'RandomForestEntr', 'CatBoost', 'ExtraTreesGini', 'ExtraTreesEntr', 'XGBoost', 'NeuralNetTorch', 'LightGBMLarge', 'WeightedEnsemble_L2'])\n\n\n\nprint(sklearn.metrics.classification_report(y,yhats['LightGBMLarge']))\n\n              precision    recall  f1-score   support\n\n        ENFJ       0.54      0.29      0.38        92\n        ENFP       0.64      0.63      0.63       327\n        ENTJ       0.69      0.35      0.46       115\n        ENTP       0.65      0.64      0.64       337\n        ESFJ       0.83      0.25      0.38        20\n        ESFP       0.25      0.04      0.07        24\n        ESTJ       0.50      0.12      0.20        24\n        ESTP       0.61      0.27      0.37        41\n        INFJ       0.69      0.70      0.70       745\n        INFP       0.66      0.80      0.72       916\n        INTJ       0.64      0.67      0.66       523\n        INTP       0.68      0.74      0.71       675\n        ISFJ       0.81      0.41      0.54        86\n        ISFP       0.57      0.50      0.53       130\n        ISTJ       0.78      0.44      0.56       113\n        ISTP       0.69      0.64      0.66       170\n\n    accuracy                           0.66      4338\n   macro avg       0.64      0.47      0.51      4338\nweighted avg       0.66      0.66      0.65      4338\n\n\n\n\n              precision    recall  f1-score   support\n\n        ENFJ       0.68      0.35      0.46        92\n        ENFP       0.63      0.63      0.63       327\n        ENTJ       0.65      0.41      0.50       115\n        ENTP       0.63      0.61      0.62       337\n        ESFJ       0.67      0.10      0.17        20\n        ESFP       0.00      0.00      0.00        24\n        ESTJ       0.50      0.08      0.14        24\n        ESTP       0.71      0.24      0.36        41\n        INFJ       0.70      0.71      0.70       745\n        INFP       0.64      0.81      0.72       916\n        INTJ       0.65      0.67      0.66       523\n        INTP       0.68      0.73      0.70       675\n        ISFJ       0.84      0.44      0.58        86\n        ISFP       0.59      0.42      0.49       130\n        ISTJ       0.71      0.43      0.54       113\n        ISTP       0.69      0.63      0.66       170\n\n    accuracy                           0.66      4338\n   macro avg       0.62      0.45      0.50      4338\nweighted avg       0.66      0.66      0.65      4338"
  },
  {
    "objectID": "연구/재인이랑/2023-12-20-(연구&재인) MBTI(정리) -- 실험셋업 시각화.html",
    "href": "연구/재인이랑/2023-12-20-(연구&재인) MBTI(정리) -- 실험셋업 시각화.html",
    "title": "(연구&재인) MBTI(정리) – 실험셋업 시각화",
    "section": "",
    "text": "1. Imports\n\nimport pandas as pd\nimport time\nimport pickle\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nimport plotly.express as px\nimport plotly.io as pio\nfrom plotly.subplots import make_subplots\npd.options.plotting.backend = \"plotly\"\npio.templates.default = \"plotly_white\"\n\n\n\n2. Data\n\n!ls '정리된자료(csv)'\n\ndf_gpt.csv           tidydata_실험3시나리오0.csv\ndf_kaggle.csv            tidydata_실험3시나리오1.csv\ntidydata_실험1시나리오1.csv  tidydata_실험3시나리오2.csv\ntidydata_실험1시나리오2.csv  tidydata_실험3시나리오3.csv\ntidydata_실험2시나리오0.csv  tidydata_실험3시나리오4.csv\ntidydata_실험2시나리오1.csv  tidydata_실험3시나리오5.csv\ntidydata_실험2시나리오2.csv  tidydata_실험3시나리오6.csv\ntidydata_실험2시나리오3.csv  tidydata_실험3시나리오7.csv\ntidydata_실험2시나리오4.csv\n\n\n\ndf_kaggle = pd.read_csv(\"정리된자료(csv)/df_kaggle.csv\")\ndf_gpt = pd.read_csv(\"정리된자료(csv)/df_gpt.csv\")\n\n\n\n3. 실험1의 계획 시각화\n- kaggle 데이터만\n\nfig = df_kaggle.type.value_counts().reset_index()\\\n.plot.bar(\n    x='type',y='count',\n    text='count',\n    title=\"\",\n    width=900,\n    height=400\n)\nfig.layout['xaxis']['title']['text'] = ''\nfig.layout['yaxis']['title']['text'] = ''\nwith open('Figures/원래자료.pkl','wb') as f:\n    pickle.dump(fig,f)\n\n- kaggle 데이터 + count&lt;100 하이라이팅\n\nfig = df_kaggle.type.value_counts().reset_index().eval('gen = count&lt;100').rename({'gen':'Count&lt;100'},axis=1)\\\n.plot.bar(\n    x='type',y='count',\n    text='count',\n    color='Count&lt;100',\n    opacity=1.0,\n    width=900,\n    height=400    \n)\nfig['data'][1]['marker']['color']='#636efa'\nfig['data'][0]['marker']['opacity']=0.2\nfig['data'][0]['showlegend'] = False\nfig['data'][1]['showlegend'] = False\nfig.layout['xaxis']['title']['text'] = ''\nfig.layout['yaxis']['title']['text'] = ''\nwith open('Figures/실험셋업시각화_실험1실험계획.pkl','wb') as f:\n    pickle.dump(fig,f)\n\n\n\n4. 실험1의 셋팅들 시각화\n\ntidydata = pd.read_csv(\"정리된자료(csv)/tidydata_실험1시나리오1.csv\")\nfig = px.bar(\n    tidydata,\n    x='type',\n    y='count',\n    text='count',\n    pattern_shape='DataType',\n    barmode='group',\n    width=900,\n    height=400        \n)\nfig.layout['xaxis']['title']['text'] = ''\nfig.layout['yaxis']['title']['text'] = ''\nwith open('Figures/실험셋업시각화_실험1시나리오1.pkl','wb') as f:\n    pickle.dump(fig,f)\n\n\ntidydata = pd.read_csv(\"정리된자료(csv)/tidydata_실험1시나리오2.csv\")\nfig = px.bar(\n    tidydata,\n    x='type',\n    y='count',\n    color=tidydata['col'],\n    text='count',\n    pattern_shape='DataType',\n    barmode='group',\n    hover_data='Source',\n    width=900,\n    height=400    \n)\nfig['data'][0]['marker']['color'] = ['#636efa']*16 + ['#EF553B']*4 \nfig['data'][1]['marker']['color'] = ['#636efa']*20\nfig['data'][0]['hovertemplate']='Type=%{x}&lt;br&gt;Count=%{text}&lt;br&gt;DataType=Train&lt;br&gt;Source=%{customdata[0]}&lt;br&gt;&lt;extra&gt;&lt;/extra&gt;'\nfig['data'][1]['hovertemplate']='Type=%{x}&lt;br&gt;Count=%{text}&lt;br&gt;DataType=Train&lt;br&gt;Source=%{customdata[0]}&lt;br&gt;&lt;extra&gt;&lt;/extra&gt;'\nfig.layout['xaxis']['title']['text'] = ''\nfig.layout['yaxis']['title']['text'] = ''\nwith open('Figures/실험셋업시각화_실험1시나리오2.pkl','wb') as f:\n    pickle.dump(fig,f)\n\n\n\n5. 실험2의 셋팅들 시각화\n\ndf0 = pd.read_csv(\"정리된자료(csv)/tidydata_실험2시나리오0.csv\").query('Setting != \"Real+Synthetic\"').assign(시나리오 = '0')[:2]\ndf1 = pd.read_csv(\"정리된자료(csv)/tidydata_실험2시나리오1.csv\").query('Setting != \"Real+Synthetic\"').assign(시나리오 = '1')\ndf2 = pd.read_csv(\"정리된자료(csv)/tidydata_실험2시나리오2.csv\").query('Setting != \"Real+Synthetic\"').assign(시나리오 = '2')\ndf3 = pd.read_csv(\"정리된자료(csv)/tidydata_실험2시나리오3.csv\").query('Setting != \"Real+Synthetic\"').assign(시나리오 = '3')\ntidydata = pd.concat([df0,df1,df2,df3]).reset_index(drop=True).assign(text = lambda df: [f'{c} ({s})' for s,c in zip(df.Source,df['count'].astype(str))])\nfig = px.bar(\n    tidydata,\n    y='type',\n    x='count',\n    color='col',\n    pattern_shape='DataType',\n    category_orders={'DataType':{'Train','Test'}},\n    barmode='group',\n    hover_data='Source',\n    text='text',\n    facet_col='Setting',\n    facet_row='시나리오',\n    width=900,\n    height=400\n)\nfor i in range(len(fig['data'])):\n    fig['data'][i]['marker']['color'] = list(pd.Series(fig['data'][i]['marker']['color']).map({0:'#636efa',1:'#EF553B'}))\n    fig['data'][i]['hovertemplate']='Type=%{x}&lt;br&gt;Count=%{text}&lt;br&gt;DataType=Train&lt;br&gt;Source=%{customdata[0]}&lt;br&gt;&lt;extra&gt;&lt;/extra&gt;'\n    if fig['data'][i]['marker']['pattern']['shape'] == '/':\n        fig['data'][i]['marker']['pattern']['shape'] = ''\n    else:\n        fig['data'][i]['marker']['pattern']['shape'] = '/'\nfig.layout['legend']['title']['text']=''\nfig.layout['annotations'][0]['text'] = \"\"\nfig.layout['annotations'][1]['text'] = \"\"\nfor ann in fig['layout']['annotations']:\n    ann['text'] =''\nfig.layout['xaxis']['title']['text']=''\nfig.layout['xaxis2']['title']['text']=''\nfig.layout['yaxis']['title']['text']=''\nfig.layout['yaxis3']['title']['text']=''\nfig.layout['yaxis5']['title']['text']=''\nfig.layout['yaxis7']['title']['text']=''\nfig.layout['xaxis']['title']['text'] = ''\nfig.layout['yaxis']['title']['text'] = ''\nwith open('Figures/실험셋업시각화_실험2시나리오0-3.pkl','wb') as f:\n    pickle.dump(fig,f)\n\n\n\n5. 실험3의 셋팅들 시각화\n\ndf0 = pd.read_csv(\"정리된자료(csv)/tidydata_실험3시나리오0.csv\").query('Setting != \"Real+Synthetic\"').assign(시나리오 = '0')\ndf1 = pd.read_csv(\"정리된자료(csv)/tidydata_실험3시나리오1.csv\").query('Setting != \"Real+Synthetic\"').assign(시나리오 = '1')\ndf2 = pd.read_csv(\"정리된자료(csv)/tidydata_실험3시나리오2.csv\").query('Setting != \"Real+Synthetic\"').assign(시나리오 = '2')\ndf3 = pd.read_csv(\"정리된자료(csv)/tidydata_실험3시나리오3.csv\").query('Setting != \"Real+Synthetic\"').assign(시나리오 = '3')\ndf4 = pd.read_csv(\"정리된자료(csv)/tidydata_실험3시나리오4.csv\").query('Setting != \"Real+Synthetic\"').assign(시나리오 = '4')\ndf5 = pd.read_csv(\"정리된자료(csv)/tidydata_실험3시나리오5.csv\").query('Setting != \"Real+Synthetic\"').assign(시나리오 = '5')\ndf6 = pd.read_csv(\"정리된자료(csv)/tidydata_실험3시나리오6.csv\").query('Setting != \"Real+Synthetic\"').assign(시나리오 = '6')\ndf7 = pd.read_csv(\"정리된자료(csv)/tidydata_실험3시나리오7.csv\").query('Setting != \"Real+Synthetic\"').assign(시나리오 = '7')\ntidydata = pd.concat([df0,df1,df2,df3,df4,df5,df6,df7]).reset_index(drop=True).assign(text = lambda df: [f'{c} ({s})' for s,c in zip(df.Source,df['count'].astype(str))])\n\n\n# fig = px.bar(\n#     tidydata.query(\"시나리오 =='0'\"),\n#     x='type',\n#     y='count',\n#     color='col',\n#     pattern_shape='DataType',\n#     barmode='group',\n#     hover_data='Source',\n#     facet_col='Setting',\n#     width=900,\n#     height=400    \n# )\n# for geom in fig['data']:\n#     geom['marker']['color'] = list(pd.Series(geom['marker']['color']).map({0:'#636efa',1:'#636efa'}))       \n# fig.layout['legend']['title']['text']=''\n# fig.layout['annotations'][0]['text'] = \"\"\n# for ann in fig['layout']['annotations']:\n#     ann['text'] =''\n# with open('Figures/실험셋업시각화_실험3시나리오0.pkl','wb') as f:\n#     pickle.dump(fig,f)\n# fig.write_image('Figures/실험셋업시각화_실험3시나리오0.svg')\n# fig\n\n\nfor i in '1234567': \n    fig = px.bar(\n        tidydata.query(f\"시나리오 =='{i}'\"),\n        x='type',\n        y='count',\n        color='col',\n        pattern_shape='DataType',\n        barmode='group',\n        hover_data='Source',\n        facet_col='Setting',\n        width=900,\n        height=400\n    )\n    for geom in fig['data']:\n        geom['marker']['color'] = list(pd.Series(geom['marker']['color']).map({0:'#636efa',1:'#EF553B'}))       \n    fig.layout['legend']['title']['text']=''\n    for ann in fig['layout']['annotations']:\n        ann['text'] =''\n    with open(f'Figures/실험셋업시각화_실험3시나리오{i}.pkl','wb') as f:\n        pickle.dump(fig,f)"
  },
  {
    "objectID": "연구/재인이랑/2023-12-27-(연구&재인) MBTI(정리) -- 그림정리.html",
    "href": "연구/재인이랑/2023-12-27-(연구&재인) MBTI(정리) -- 그림정리.html",
    "title": "(연구&재인) MBTI(정리) – 논문그림정리",
    "section": "",
    "text": "import pandas as pd \nimport plotly.express as px\nimport plotly.io as pio\nimport pickle\nimport itables\npio.templates.default = \"plotly_white\"\ndf_kaggle = pd.read_csv(\"mbti_1.csv\")\nfile_names = [\n    \"원래자료.pkl\",\n    \"실험1결과요약.pkl\",\n    \"실험1모델비교AUC.pkl\",\n    \"실험1모델비교F1.pkl\",\n    \"실험1모델비교PRE.pkl\",\n    \"실험1모델비교REC.pkl\",\n    \"실험셋업시각화_실험1시나리오1.pkl\",\n    \"실험셋업시각화_실험3시나리오2.pkl\",\n    \"실험셋업시각화_실험1시나리오2.pkl\",\n    \"실험셋업시각화_실험3시나리오3.pkl\",\n    \"실험셋업시각화_실험1실험계획.pkl\",\n    \"실험셋업시각화_실험3시나리오4.pkl\",\n    \"실험셋업시각화_실험2시나리오0-3.pkl\",\n    \"실험셋업시각화_실험3시나리오5.pkl\",\n    \"실험2결과요약.pkl\",\n    \"실험셋업시각화_실험3시나리오6.pkl\",\n#    \"실험셋업시각화_실험3시나리오0.pkl\",\n    \"실험셋업시각화_실험3시나리오7.pkl\",\n    \"실험셋업시각화_실험3시나리오1.pkl\",\n    \"실험3결과요약.pkl\",\n    \"실험2결과요약.pkl\"\n]\ndef _load(path):\n    with open(path,'rb') as f:\n        rtn = pickle.load(f)\n    return rtn \n    \nfigs = {fname.replace('.pkl',''): _load(f'./Figures/{fname}') for fname in file_names}\n\n\nfigs['원래자료'].layout['title']['text']=''\nfigs['원래자료'].layout['width']=700\nfigs['원래자료'].layout['height']=350\nfigs['원래자료'].write_image('Figures/원재자료.pdf')\n\n\n\nfigs['실험셋업시각화_실험1시나리오1'].layout['title']['text']=''\nfigs['실험셋업시각화_실험1시나리오1'].layout['width']=700\nfigs['실험셋업시각화_실험1시나리오1'].layout['height']=350\nfigs['실험셋업시각화_실험1시나리오1'].write_image('Figures/실험셋업_실험1_시나리오1.pdf')\n\n\nfigs['실험셋업시각화_실험1시나리오2'].layout['title']['text']=''\nfigs['실험셋업시각화_실험1시나리오2'].layout['width']=700\nfigs['실험셋업시각화_실험1시나리오2'].layout['height']=350\nfigs['실험셋업시각화_실험1시나리오2'].write_image('Figures/실험셋업_실험1_시나리오2.pdf')\n\n\nfigs['실험1결과요약'].layout['title']['text']=''\nfigs['실험1결과요약'].layout['width']=900\nfigs['실험1결과요약'].layout['height']=300\nfigs['실험1결과요약'].write_image('Figures/실험셋업_실험1_결과요약.pdf')\nfigs['실험1결과요약'].write_image('/home/cgb2/Dropbox/06_papers/2023_GTP_졸업논문ver/EP1_RESULTS.pdf')\n\n\nfigs['실험1모델비교REC'].layout['title']['text']='' #'(a): Recall of all Models'\nfigs['실험1모델비교REC'].layout['width']=700\nfigs['실험1모델비교REC'].layout['height']=200\nfigs['실험1모델비교REC'].write_image('Figures/실험1모델비교REC.pdf')\nfigs['실험1모델비교REC'].write_image('/home/cgb2/Dropbox/06_papers/2023_GTP_졸업논문ver/EP1_REC.pdf')\n\n\nfigs['실험1모델비교PRE'].layout['title']['text']='' #'(b): Precision of all Models'\nfigs['실험1모델비교PRE'].layout['width']=700\nfigs['실험1모델비교PRE'].layout['height']=200\nfigs['실험1모델비교PRE'].write_image('Figures/실험1모델비교PRE.pdf')\nfigs['실험1모델비교PRE'].write_image('/home/cgb2/Dropbox/06_papers/2023_GTP_졸업논문ver/EP1_PRE.pdf')\n\n\nfigs['실험1모델비교F1'].layout['title']['text']='' # '(c): F1 score of all Models'\nfigs['실험1모델비교F1'].layout['width']=700\nfigs['실험1모델비교F1'].layout['height']=200\nfigs['실험1모델비교F1'].write_image('Figures/실험1모델비교F1.pdf')\nfigs['실험1모델비교F1'].write_image('/home/cgb2/Dropbox/06_papers/2023_GTP_졸업논문ver/EP1_F1.pdf')\n\n\nfigs['실험1모델비교AUC'].layout['title']['text']='' #'(d): AUC of all Models'\nfigs['실험1모델비교AUC'].layout['width']=700\nfigs['실험1모델비교AUC'].layout['height']=200\nfigs['실험1모델비교AUC'].write_image('Figures/실험1모델비교AUC.pdf')\nfigs['실험1모델비교AUC'].write_image('/home/cgb2/Dropbox/06_papers/2023_GTP_졸업논문ver/EP1_AUC.pdf')\n\n\nfigs['실험셋업시각화_실험2시나리오0-3'].layout['title']['text']=''\nfigs['실험셋업시각화_실험2시나리오0-3'].layout['width']=700\nfigs['실험셋업시각화_실험2시나리오0-3'].layout['height']=350\nfigs['실험셋업시각화_실험2시나리오0-3'].write_image('Figures/실험셋업시각화_실험2시나리오03.pdf')\n\n\nfigs['실험2결과요약'].layout['title']['text']=''\nfigs['실험2결과요약'].layout['width']=900\nfigs['실험2결과요약'].layout['height']=350\nfigs['실험2결과요약'].write_image('Figures/실험2결과요약.pdf')\nfigs['실험2결과요약'].write_image('/home/cgb2/Dropbox/06_papers/2023_GTP_졸업논문ver/EP2_RESULTS.pdf')\n\n\n# figs['실험셋업시각화_실험3시나리오1'].layout['title']['text']='(a): Configuration of Experiment 3 (+20)'\n# figs['실험셋업시각화_실험3시나리오1'].layout['width']=1050\n# figs['실험셋업시각화_실험3시나리오1'].layout['height']=500\n# figs['실험셋업시각화_실험3시나리오1']\n\n\n# figs['실험셋업시각화_실험3시나리오2'].layout['title']['text']='(b): Configuration of Experiment 3 (+40)'\n# figs['실험셋업시각화_실험3시나리오2'].layout['width']=1050\n# figs['실험셋업시각화_실험3시나리오2'].layout['height']=500\n# figs['실험셋업시각화_실험3시나리오2']\n\n\n# figs['실험셋업시각화_실험3시나리오3'].layout['title']['text']='(c): Configuration of Experiment 3 (+60)'\n# figs['실험셋업시각화_실험3시나리오3'].layout['width']=1050\n# figs['실험셋업시각화_실험3시나리오3'].layout['height']=500\n# figs['실험셋업시각화_실험3시나리오3']\n\n\n# figs['실험셋업시각화_실험3시나리오4'].layout['title']['text']='(d): Configuration of Experiment 3 (+80)'\n# figs['실험셋업시각화_실험3시나리오4'].layout['width']=1050\n# figs['실험셋업시각화_실험3시나리오4'].layout['height']=500\n# figs['실험셋업시각화_실험3시나리오4']\n\n\n# figs['실험셋업시각화_실험3시나리오5'].layout['title']['text']='(e): Configuration of Experiment 3 (+100)'\n# figs['실험셋업시각화_실험3시나리오5'].layout['width']=1050\n# figs['실험셋업시각화_실험3시나리오5'].layout['height']=500\n# figs['실험셋업시각화_실험3시나리오5']\n\n\n# figs['실험셋업시각화_실험3시나리오6'].layout['title']['text']='(f): Configuration of Experiment 3 (+120)'\n# figs['실험셋업시각화_실험3시나리오6'].layout['width']=1050\n# figs['실험셋업시각화_실험3시나리오6'].layout['height']=500\n# figs['실험셋업시각화_실험3시나리오6']\n\n\n# figs['실험셋업시각화_실험3시나리오7'].layout['title']['text']='(g): Configuration of Experiment 3 (+140)'\n# figs['실험셋업시각화_실험3시나리오7'].layout['width']=1050\n# figs['실험셋업시각화_실험3시나리오7'].layout['height']=500\n# figs['실험셋업시각화_실험3시나리오7']\n\n\nfigs['실험3결과요약'].layout['title']['text']=''\nfigs['실험3결과요약'].layout['width']=900\nfigs['실험3결과요약'].layout['height']=350\nfigs['실험3결과요약'].write_image('Figures/실험3결과요약.pdf')\nfigs['실험3결과요약'].write_image('/home/cgb2/Dropbox/06_papers/2023_GTP_졸업논문ver/EP3_RESULTS.pdf')"
  },
  {
    "objectID": "연구/재인이랑/2023-10-12-(연구&재인) MBTI -- MBTI.html",
    "href": "연구/재인이랑/2023-10-12-(연구&재인) MBTI -- MBTI.html",
    "title": "(연구&재인) MBTI – MBTI",
    "section": "",
    "text": "import pandas as pd\nimport sklearn.model_selection \n\n\ndf = pd.read_csv('mbti_1.csv')\ndf_train, df_test = sklearn.model_selection.train_test_split(df,test_size=0.3)\n\n\ndf[:1]\n\n\n\n\n\n\n\n\ntype\nposts\n\n\n\n\n0\nINFJ\n'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n\n\n\n\n\n\n\n\nfrom autogluon.multimodal import MultiModalPredictor\nimport uuid\nmodel_path = f\"./tmp/{uuid.uuid4().hex}-automm_sst\"\npredictor = MultiModalPredictor(label='type', eval_metric='acc', path=model_path)\npredictor.fit(df_train)\n\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'libc10_cuda.so: cannot open shared object file: No such file or directory'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n  warn(\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/autogluon/core/utils/utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\nAutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n    First 10 (of 16) unique label values:  ['INFJ', 'ENTJ', 'ENFP', 'INFP', 'ISTJ', 'ISTP', 'ESFJ', 'INTP', 'INTJ', 'ISFP']\n    If 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\nGlobal seed set to 0\nAutoMM starts to create your model. ✨\n\n- AutoGluon version is 0.8.2.\n\n- Pytorch version is 2.0.0.post2.\n\n- Model will be saved to \"/home/cgb2/Dropbox/03_yechan3/posts/3_Researches/JAEIN/tmp/1c22bc85561c4fad9dbff452305364e5-automm_sst\".\n\n- Validation metric is \"acc\".\n\n- To track the learning progress, you can open a terminal and launch Tensorboard:\n    ```shell\n    # Assume you have installed tensorboard\n    tensorboard --logdir /home/cgb2/Dropbox/03_yechan3/posts/3_Researches/JAEIN/tmp/1c22bc85561c4fad9dbff452305364e5-automm_sst\n    ```\n\nEnjoy your coffee, and let AutoMM do the job ☕☕☕ Learn more at https://auto.gluon.ai\n\n0 GPUs are detected, and 0 GPUs will be used.\n\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/autogluon/multimodal/utils/environment.py:91: UserWarning: Only CPU is detected in the instance. This may result in slow speed for MultiModalPredictor. Consider using an instance with GPU support.\n  warnings.warn(\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\n\n  | Name              | Type                         | Params\n-------------------------------------------------------------------\n0 | model             | HFAutoModelForTextPrediction | 108 M \n1 | validation_metric | MulticlassAccuracy           | 0     \n2 | loss_func         | CrossEntropyLoss             | 0     \n-------------------------------------------------------------------\n108 M     Trainable params\n0         Non-trainable params\n108 M     Total params\n435.616   Total estimated model params size (MB)\nEpoch 0, global step 21: 'val_acc' reached 0.18750 (best 0.18750), saving model to '/home/cgb2/Dropbox/03_yechan3/posts/3_Researches/JAEIN/tmp/1c22bc85561c4fad9dbff452305364e5-automm_sst/epoch=0-step=21.ckpt' as top 3\n[rank: 0] Received SIGTERM: 15\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3534: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n\n\nEpoch 0:  50%|████▉     | 341/683 [1:30:43&lt;1:30:59, 15.96s/it]             Epoch 0:  73%|███████▎  | 501/683 [2:11:46&lt;47:52, 15.78s/it]  Epoch 0:  73%|███████▎  | 502/683 [2:12:01&lt;47:36, 15.78s/it]\n\n\nSIGTERMException: \n\n\n: \n\n\n\npost1 = \"http://www.youtube.com/watch?v=qsXHcwe3krw|||http://41.media.tumblr.com/tumblr_lfouy03PMA1qa1rooo1_500.jpg|||enfp and intj moments  https://www.youtube.com/watch?v=iz7lE1g4XM4  sportscenter not top ten plays  https://www.youtube.com/watch?v=uCdfze1etec  pranks|||What has been the most life-changing experience in your life?|||http://www.youtube.com/watch?v=vXZeYwwRDw8   http://www.youtube.com/watch?v=u8ejam5DP3E  On repeat for most of today.|||May the PerC Experience immerse you.|||The last thing my INFJ friend posted on his facebook before committing suicide the next day. Rest in peace~   http://vimeo.com/22842206|||Hello ENFJ7. Sorry to hear of your distress. It's only natural for a relationship to not be perfection all the time in every moment of existence. Try to figure the hard times as times of growth, as...|||84389  84390  http://wallpaperpassion.com/upload/23700/friendship-boy-and-girl-wallpaper.jpg  http://assets.dornob.com/wp-content/uploads/2010/04/round-home-design.jpg ...|||Welcome and stuff.|||http://playeressence.com/wp-content/uploads/2013/08/RED-red-the-pokemon-master-32560474-450-338.jpg  Game. Set. Match.|||Prozac, wellbrutin, at least thirty minutes of moving your legs (and I don't mean moving them while sitting in your same desk chair), weed in moderation (maybe try edibles as a healthier alternative...|||Basically come up with three items you've determined that each type (or whichever types you want to do) would more than likely use, given each types' cognitive functions and whatnot, when left by...|||All things in moderation.  Sims is indeed a video game, and a good one at that. Note: a good one at that is somewhat subjective in that I am not completely promoting the death of any given Sim...|||Dear ENFP:  What were your favorite video games growing up and what are your now, current favorite video games? :cool:|||https://www.youtube.com/watch?v=QyPqT8umzmY|||It appears to be too late. :sad:|||There's someone out there for everyone.|||Wait... I thought confidence was a good thing.|||I just cherish the time of solitude b/c i revel within my inner world more whereas most other time i'd be workin... just enjoy the me time while you can. Don't worry, people will always be around to...|||Yo entp ladies... if you're into a complimentary personality,well, hey.|||... when your main social outlet is xbox live conversations and even then you verbally fatigue quickly.|||http://www.youtube.com/watch?v=gDhy7rdfm14  I really dig the part from 1:46 to 2:50|||http://www.youtube.com/watch?v=msqXffgh7b8|||Banned because this thread requires it of me.|||Get high in backyard, roast and eat marshmellows in backyard while conversing over something intellectual, followed by massages and kisses.|||http://www.youtube.com/watch?v=Mw7eoU3BMbE|||http://www.youtube.com/watch?v=4V2uYORhQOk|||http://www.youtube.com/watch?v=SlVmgFQQ0TI|||Banned for too many b's in that sentence. How could you! Think of the B!|||Banned for watching movies in the corner with the dunces.|||Banned because Health class clearly taught you nothing about peer pressure.|||Banned for a whole host of reasons!|||http://www.youtube.com/watch?v=IRcrv41hgz4|||1) Two baby deer on left and right munching on a beetle in the middle.  2) Using their own blood, two cavemen diary today's latest happenings on their designated cave diary wall.  3) I see it as...|||a pokemon world  an infj society  everyone becomes an optimist|||49142|||http://www.youtube.com/watch?v=ZRCEq_JFeFM|||http://discovermagazine.com/2012/jul-aug/20-things-you-didnt-know-about-deserts/desert.jpg|||http://oyster.ignimgs.com/mediawiki/apis.ign.com/pokemon-silver-version/d/dd/Ditto.gif|||http://www.serebii.net/potw-dp/Scizor.jpg|||Not all artists are artists because they draw. It's the idea that counts in forming something of your own... like a signature.|||Welcome to the robot ranks, person who downed my self-esteem cuz I'm not an avid signature artist like herself. :proud:|||Banned for taking all the room under my bed. Ya gotta learn to share with the roaches.|||http://www.youtube.com/watch?v=w8IgImn57aQ|||Banned for being too much of a thundering, grumbling kind of storm... yep.|||Ahh... old high school music I haven't heard in ages.   http://www.youtube.com/watch?v=dcCRUPCdB1w|||I failed a public speaking class a few years ago and I've sort of learned what I could do better were I to be in that position again. A big part of my failure was just overloading myself with too...|||I like this person's mentality. He's a confirmed INTJ by the way. http://www.youtube.com/watch?v=hGKLI-GEc6M|||Move to the Denver area and start a new life for myself.\"\npredictions = predictor.predict({'posts': [post1]})\npredictions\n\narray(['ENTP'], dtype=object)"
  },
  {
    "objectID": "연구/재인이랑/2023-12-19-(연구&재인) MBTI(정리) -- 실험셋업.html",
    "href": "연구/재인이랑/2023-12-19-(연구&재인) MBTI(정리) -- 실험셋업.html",
    "title": "(연구&재인) MBTI(정리) – 실험셋업",
    "section": "",
    "text": "1. Imports\n\nimport pandas as pd\nimport sklearn.model_selection\nimport sklearn.metrics\nfrom autogluon.multimodal import MultiModalPredictor\nfrom autogluon.tabular import TabularPredictor\nimport warnings\nimport time\nimport pickle\nwarnings.filterwarnings('ignore')\n\n/root/anaconda3/envs/ag/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n\n\nimport plotly.express as px\nimport plotly.io as pio\nfrom plotly.subplots import make_subplots\npd.options.plotting.backend = \"plotly\"\npio.templates.default = \"plotly_white\"\n\n\ndef remove_emoji(inputString):\n    return inputString.encode('ascii', 'ignore').decode('ascii')\n\n\ndef generate_experiment2(train_size,test_size,added_n,experiments_index):\n    #---# A: 리얼데이터만 추가\n    df_train = pd.concat([\n        df_kaggle[df_kaggle['type'] != 'ENFJ'][::2],\n        df_kaggle[df_kaggle['type'] == 'ENFJ'][:train_size],\n        df_kaggle[df_kaggle['type'] == 'ENFJ'][train_size:(train_size+added_n)],\n    ]).reset_index(drop=True)\n    df_test = pd.concat([\n        df_kaggle[df_kaggle['type'] == 'ENFJ'][-test_size:],\n        df_kaggle[df_kaggle['type'] != 'ENFJ'][1::2]\n    ])\n    df_trains_dct[f'{experiments_index}a'] = df_train \n    df_tests_dct[f'{experiments_index}a'] = df_test\n    _df1 = df_train[:-added_n]['type'].value_counts().reset_index().assign(Source='Kaggle')\n    _df2 = df_train[-added_n:]['type'].value_counts().reset_index().assign(Source='Kaggle')\n    _train = pd.concat([_df1,_df2],axis=0).reset_index(drop=True).assign(DataType = 'Train')\n    _test = df_test['type'].value_counts().reset_index().assign(DataType = 'Test',Source='Kaggle')\n    tidydata1= pd.concat([_train,_test]).reset_index(drop=True).assign(col = lambda df: df.Source.map({'Kaggle':0,'ChatGPT':1})).query('type == \"ENFJ\"')\n    #---# B: GPT 자료만 추가 \n    df_train = pd.concat([\n        df_kaggle[df_kaggle['type'] != 'ENFJ'][::2],\n        df_kaggle[df_kaggle['type'] == 'ENFJ'][:train_size],\n        df_gpt_ENFJ[df_gpt_ENFJ['type'] == 'ENFJ'][:added_n],\n    ]).reset_index(drop=True)\n    df_test = pd.concat([\n        df_kaggle[df_kaggle['type'] == 'ENFJ'][-test_size:],\n        df_kaggle[df_kaggle['type'] != 'ENFJ'][1::2]\n    ])\n    df_trains_dct[f'{experiments_index}b'] = df_train \n    df_tests_dct[f'{experiments_index}b'] = df_test\n    _df1 = df_train[:-added_n]['type'].value_counts().reset_index().assign(Source='Kaggle')\n    _df2 = df_train[-added_n:]['type'].value_counts().reset_index().assign(Source='ChatGPT')\n    _train = pd.concat([_df1,_df2],axis=0).reset_index(drop=True).assign(DataType = 'Train')\n    _test = df_test['type'].value_counts().reset_index().assign(DataType = 'Test',Source='Kaggle')\n    tidydata2 = pd.concat([_train,_test]).reset_index(drop=True).assign(col = lambda df: df.Source.map({'Kaggle':0,'ChatGPT':1})).query('type==\"ENFJ\"')\n    #---# C: Real+GPT 동시추가 \n    df_train = pd.concat([\n        df_kaggle[df_kaggle['type'] != 'ENFJ'][::2],        \n        df_kaggle[df_kaggle['type'] == 'ENFJ'][:train_size],\n        df_gpt_ENFJ[df_gpt_ENFJ['type'] == 'ENFJ'][:added_n],\n        df_kaggle[df_kaggle['type'] == 'ENFJ'][train_size:(train_size+added_n)],\n    ]).reset_index(drop=True)\n    df_test = pd.concat([\n        df_kaggle[df_kaggle['type'] == 'ENFJ'][-test_size:],\n        df_kaggle[df_kaggle['type'] != 'ENFJ'][1::2]\n    ])\n    df_trains_dct[f'{experiments_index}c'] = df_train \n    df_tests_dct[f'{experiments_index}c'] = df_test\n    _df1 = df_train[:-added_n]['type'].value_counts().reset_index().assign(Source='Kaggle')\n    _df2 = df_train[-added_n:]['type'].value_counts().reset_index().assign(Source='ChatGPT')\n    _train = pd.concat([_df1,_df2],axis=0).reset_index(drop=True).assign(DataType = 'Train')\n    _test = df_test['type'].value_counts().reset_index().assign(DataType = 'Test',Source='Kaggle')\n    tidydata3 = pd.concat([_train,_test]).reset_index(drop=True).assign(col = lambda df: df.Source.map({'Kaggle':0,'ChatGPT':1})).query('type==\"ENFJ\"')\n    #---#\n    tidydata = pd.concat([tidydata1.assign(Setting = 'Real'),tidydata2.assign(Setting = 'Synthetic'),tidydata2.assign(Setting = 'Real+Synthetic')])\n    tidydata.to_csv(f\"정리된자료(csv)/tidydata_{experiments_index.replace('/','')}.csv\",index=False)    \n\n\ndef generate_experiment3(train_size,test_size,added_n,experiments_index):\n    #---# A: 리얼데이터만 추가\n    df_train = pd.concat([\n        df_kaggle.query('type in [\"ISTP\",\"ESTP\",\"INTP\",\"ISFP\",\"ISTJ\"]')[::2],\n        df_kaggle[df_kaggle['type'] == 'ENFJ'][:train_size],\n        df_kaggle[df_kaggle['type'] == 'ENFJ'][train_size:(train_size+added_n)],\n    ]).reset_index(drop=True)\n    df_test = pd.concat([\n        df_kaggle.query('type in [\"ISTP\",\"ESTP\",\"INTP\",\"ISFP\",\"ISTJ\"]')[::2],\n        df_kaggle[df_kaggle['type'] == 'ENFJ'][-test_size:],        \n    ])\n    df_trains_dct[f'{experiments_index}a'] = df_train \n    df_tests_dct[f'{experiments_index}a'] = df_test\n    _df1 = df_train[:-added_n]['type'].value_counts().reset_index().assign(Source='Kaggle')\n    _df2 = df_train[-added_n:]['type'].value_counts().reset_index().assign(Source='Kaggle')\n    _train = pd.concat([_df1,_df2],axis=0).reset_index(drop=True).assign(DataType = 'Train')\n    _test = df_test['type'].value_counts().reset_index().assign(DataType = 'Test',Source='Kaggle')\n    tidydata1= pd.concat([_train,_test]).reset_index(drop=True).assign(col = lambda df: df.Source.map({'Kaggle':0,'ChatGPT':1}))\n    #---# B: GPT 자료만 추가 \n    df_train = pd.concat([\n        df_kaggle.query('type in [\"ISTP\",\"ESTP\",\"INTP\",\"ISFP\",\"ISTJ\"]')[::2],\n        df_kaggle[df_kaggle['type'] == 'ENFJ'][:train_size],\n        df_gpt[df_gpt['type'] == 'ENFJ'][:added_n],\n    ]).reset_index(drop=True)\n    df_test = pd.concat([\n        df_kaggle[df_kaggle['type'] == 'ENFJ'][-test_size:],\n        df_kaggle.query('type in [\"ISTP\",\"ESTP\",\"INTP\",\"ISFP\",\"ISTJ\"]')[::2],\n    ])\n    df_trains_dct[f'{experiments_index}b'] = df_train \n    df_tests_dct[f'{experiments_index}b'] = df_test\n    _df1 = df_train[:-added_n]['type'].value_counts().reset_index().assign(Source='Kaggle')\n    _df2 = df_train[-added_n:]['type'].value_counts().reset_index().assign(Source='ChatGPT')\n    _train = pd.concat([_df1,_df2],axis=0).reset_index(drop=True).assign(DataType = 'Train')\n    _test = df_test['type'].value_counts().reset_index().assign(DataType = 'Test',Source='Kaggle')\n    tidydata2 = pd.concat([_train,_test]).reset_index(drop=True).assign(col = lambda df: df.Source.map({'Kaggle':0,'ChatGPT':1}))\n    tidydata = pd.concat([tidydata1.assign(Setting = 'Real'),tidydata2.assign(Setting = 'Synthetic')])\n    tidydata.to_csv(f\"정리된자료(csv)/tidydata_{experiments_index.replace('/','')}.csv\",index=False)    \n\n\n\n2. Data\n- 데이터의 정리\n\nlabels = ['ENTP', 'ESFP', 'ISFJ', 'INTJ', 'ISFP', 'ESTP', 'INTP', 'INFJ', 'ESTJ', 'ENFP', 'ISTJ', 'ENTJ', 'INFP', 'ISTP', 'ESFJ', 'ENFJ']\ndf_kaggle = pd.read_csv('원래자료(csv)/mbti_1.csv').sort_values('type').reset_index(drop=True)\ndf_gpt = pd.read_csv('원래자료(csv)/MBTI.csv')\nfor i,post in enumerate(df_gpt['posts']):\n    for label in labels:\n        if label in post: \n            df_gpt['posts'][i] = post.replace(label,'')\n            df_gpt['posts'][i] = remove_emoji(post)\ndf_gpt = df_gpt.set_index('type').rename(\n    {\n        'ESFJ ':'ESFJ',\n        'ESFP ': 'ESFP',\n        'ESTJ ': 'ESTJ',\n        'ESTP\"': 'ESTP',\n        'estp': 'ESTP'\n    }\n).reset_index().sort_values('type').reset_index(drop=True)\n\n\ndf는 원래 캐글에 공개된 자료\ndf_additional은 chatGPT를 이용하여 모은자료, 이중 자료로서의 가치가 없는 관측치는 제외함. (자료가 너무 적어서 제외하였음 {SFJ:2, ISFJ:32, ENFP:1})\n\n\n!rm -rf '정리된자료(csv)'\n![ -d \"정리된자료(csv)\" ] || mkdir \"정리된자료(csv)\"\ndf_kaggle.to_csv(\"정리된자료(csv)/df_kaggle.csv\",index=False)\ndf_gpt.to_csv(\"정리된자료(csv)/df_gpt.csv\",index=False)\n\n\ndf_kaggle = pd.read_csv(\"정리된자료(csv)/df_kaggle.csv\")\ndf_gpt = pd.read_csv(\"정리된자료(csv)/df_gpt.csv\")\n\n- 데이터의 분포상태\n\ndf_kaggle['type'].value_counts()\n\ntype\nINFP    1832\nINFJ    1470\nINTP    1304\nINTJ    1091\nENTP     685\nENFP     675\nISTP     337\nISFP     271\nENTJ     231\nISTJ     205\nENFJ     190\nISFJ     166\nESTP      89\nESFP      48\nESFJ      42\nESTJ      39\nName: count, dtype: int64\n\n\n\ndf_kaggle['type'].value_counts()\n\ntype\nINFP    1832\nINFJ    1470\nINTP    1304\nINTJ    1091\nENTP     685\nENFP     675\nISTP     337\nISFP     271\nENTJ     231\nISTJ     205\nENFJ     190\nISFJ     166\nESTP      89\nESFP      48\nESFJ      42\nESTJ      39\nName: count, dtype: int64\n\n\n- 데이터의 분포상태 시각화\n\n_df1 = df_kaggle['type'].value_counts().to_frame().reset_index().assign(data_source = 'kaggle')\n_df2 = df_gpt['type'].value_counts().reset_index().assign(data_source = 'ChatGPT')\ntidydata = pd.concat([_df1,_df2]).reset_index(drop=True)\npx.bar(\n    tidydata,\n    x='type',\n    y='count',\n    color='data_source',\n)\n\n                                                \n\n\n- 조사\n원래자료\n\n{'ESTP':162+89,'ESFP':195+48,'ESFJ':298+42,'ESTJ':486+39}\n\n{'ESTP': 251, 'ESFP': 243, 'ESFJ': 340, 'ESTJ': 525}\n\n\n총 숫자를 맞춘다면\n\n{'ESTP':151+89,'ESFP':192+48,'ESFJ':198+42,'ESTJ':201+39}\n\n{'ESTP': 240, 'ESFP': 240, 'ESFJ': 240, 'ESTJ': 240}\n\n\ntrain data의 숫자를 맞춘다면\n\n{'ESTP':155+45,'ESFP':176+24,'ESFJ':179+21,'ESTJ':181+19}\n\n{'ESTP': 200, 'ESFP': 200, 'ESFJ': 200, 'ESTJ': 200}\n\n\n- df_gpt를 나누자..\n\ndf_gpt_ENFJ = df_gpt[df_gpt['type'] == 'ENFJ'][:160] \n#---#\ndf_gpt_ESTP = df_gpt[df_gpt['type'] == 'ESTP'][:155]\ndf_gpt_ESFP = df_gpt[df_gpt['type'] == 'ESFP'][:176]\ndf_gpt_ESFJ = df_gpt[df_gpt['type'] == 'ESFJ'][:179]\ndf_gpt_ESTJ = df_gpt[df_gpt['type'] == 'ESTJ'][:181]\n\n\ndf_trains_dct = dict()\ndf_tests_dct = dict()\n\n\n\n3. 실험1 – 셋팅\n시나리오1\n\ndf_train = df_kaggle[::2].reset_index(drop=True)\ndf_test = df_kaggle[1::2].reset_index(drop=True)\ndf_trains_dct['실험1/시나리오1'] = df_train \ndf_tests_dct['실험1/시나리오1'] = df_test \n#---#\n_train = df_train['type'].value_counts().reset_index().assign(DataType = 'Train')\n_test = df_test['type'].value_counts().reset_index().assign(DataType = 'Test')\ntidydata = pd.concat([_train,_test]).reset_index(drop=True)\ntidydata.to_csv(\"정리된자료(csv)/tidydata_실험1시나리오1.csv\",index=False)\n\n시나리오2\n\ndf_train = pd.concat([\n    df_kaggle[::2],\n    df_gpt_ESTP,\n    df_gpt_ESFP,\n    df_gpt_ESFJ,\n    df_gpt_ESTJ,\n]).reset_index(drop=True)\ndf_test = df_kaggle[1::2].reset_index(drop=True)\ndf_trains_dct['실험1/시나리오2'] = df_train \ndf_tests_dct['실험1/시나리오2'] = df_test \n#---#\nn = len(df_kaggle[::2])\n_df1 = df_train[:n]['type'].value_counts().reset_index().assign(Source='Kaggle')\n_df2 = df_train[n:]['type'].value_counts().reset_index().assign(Source='ChatGpt')\n_train = pd.concat([_df1,_df2],axis=0).reset_index(drop=True).assign(DataType = 'Train')\n_test = df_test['type'].value_counts().reset_index().assign(DataType = 'Test',Source='Kaggle')\ntidydata = pd.concat([_train,_test]).reset_index(drop=True).assign(col = lambda df: df.Source.map({'Kaggle':0,'ChatGPT':1}))\ntidydata.to_csv(\"정리된자료(csv)/tidydata_실험1시나리오2.csv\",index=False)\n\n\n\n4. 실험2 – 셋팅\n\nprint(f\"df_kaggle에는 ENFJ가 {(df_kaggle['type'] == 'ENFJ').sum()}명 있음\")\nprint(f\"df_gpt에는 ENFJ가 {(df_gpt['type'] == 'ENFJ').sum()}명 있음\")\n\ndf_kaggle에는 ENFJ가 190명 있음\ndf_gpt에는 ENFJ가 164명 있음\n\n\n\ngenerate_experiment2(train_size=1,test_size=30,added_n=0,experiments_index='실험2/시나리오0')\ngenerate_experiment2(train_size=1,test_size=30,added_n=40,experiments_index='실험2/시나리오1')\ngenerate_experiment2(train_size=1,test_size=30,added_n=80,experiments_index='실험2/시나리오2')\ngenerate_experiment2(train_size=1,test_size=30,added_n=120,experiments_index='실험2/시나리오3')\ngenerate_experiment2(train_size=1,test_size=30,added_n=159,experiments_index='실험2/시나리오4')\n\n\n\n5. 실험3 – 셋팅\n\nprint(f\"df_kaggle에는 ENFJ가 {(df_kaggle['type'] == 'ENFJ').sum()}명 있음\")\nprint(f\"df_gpt에는 ENFJ가 {(df_gpt['type'] == 'ENFJ').sum()}명 있음\")\n\ndf_kaggle에는 ENFJ가 190명 있음\ndf_gpt에는 ENFJ가 164명 있음\n\n\n\ngenerate_experiment3(train_size=1,test_size=40,added_n=0,experiments_index='실험3/시나리오0')\ngenerate_experiment3(train_size=1,test_size=40,added_n=20,experiments_index='실험3/시나리오1')\ngenerate_experiment3(train_size=1,test_size=40,added_n=40,experiments_index='실험3/시나리오2')\ngenerate_experiment3(train_size=1,test_size=40,added_n=60,experiments_index='실험3/시나리오3')\ngenerate_experiment3(train_size=1,test_size=40,added_n=80,experiments_index='실험3/시나리오4')\ngenerate_experiment3(train_size=1,test_size=40,added_n=100,experiments_index='실험3/시나리오5')\ngenerate_experiment3(train_size=1,test_size=40,added_n=120,experiments_index='실험3/시나리오6')\ngenerate_experiment3(train_size=1,test_size=40,added_n=140,experiments_index='실험3/시나리오7')\n\n\ndf_trains_dct['실험3/시나리오1a']['type'].value_counts()\n\ntype\nINTP    652\nISTP    168\nISFP    135\nISTJ    103\nESTP     45\nENFJ     21\nName: count, dtype: int64\n\n\n\n\n4. 실험셋팅 저장\n\ndf_trains_dct.keys()\n\ndict_keys(['실험1/시나리오1', '실험1/시나리오2', '실험2/시나리오0a', '실험2/시나리오0b', '실험2/시나리오0c', '실험2/시나리오1a', '실험2/시나리오1b', '실험2/시나리오1c', '실험2/시나리오2a', '실험2/시나리오2b', '실험2/시나리오2c', '실험2/시나리오3a', '실험2/시나리오3b', '실험2/시나리오3c', '실험2/시나리오4a', '실험2/시나리오4b', '실험2/시나리오4c', '실험3/시나리오0a', '실험3/시나리오0b', '실험3/시나리오1a', '실험3/시나리오1b', '실험3/시나리오2a', '실험3/시나리오2b', '실험3/시나리오3a', '실험3/시나리오3b', '실험3/시나리오4a', '실험3/시나리오4b', '실험3/시나리오5a', '실험3/시나리오5b', '실험3/시나리오6a', '실험3/시나리오6b', '실험3/시나리오7a', '실험3/시나리오7b'])\n\n\n\n!rm -rf 실험셋업\n![ -d \"실험셋업\" ] || mkdir \"실험셋업\"\nwith open(file='실험셋업/df_trains_dct.pickle', mode='wb') as f:\n    pickle.dump(obj=df_trains_dct,file=f)    \nwith open(file='실험셋업/df_tests_dct.pickle', mode='wb') as f:\n    pickle.dump(obj=df_tests_dct,file=f)"
  },
  {
    "objectID": "연구/나혼자/gglitely/2024-01-19-연계.html",
    "href": "연구/나혼자/gglitely/2024-01-19-연계.html",
    "title": "(연구) gglitely – 연계",
    "section": "",
    "text": "Install\n\n!pip uninstall gglitely -y\n!pip install git+https://github.com/seoyeonc/gglitely.git\n\nFound existing installation: gglitely 0.0.1\nUninstalling gglitely-0.0.1:\n  Successfully uninstalled gglitely-0.0.1\nCollecting git+https://github.com/seoyeonc/gglitely.git\n  Cloning https://github.com/seoyeonc/gglitely.git to /tmp/pip-req-build-zweizd4k\n  Running command git clone --filter=blob:none --quiet https://github.com/seoyeonc/gglitely.git /tmp/pip-req-build-zweizd4k\n  Resolved https://github.com/seoyeonc/gglitely.git to commit 86f5c00a4a8e40a05e5fdaa927296f50ff290b24\n  Preparing metadata (setup.py) ... -\b \bdone\nRequirement already satisfied: pandas in /home/cgb2/anaconda3/lib/python3.11/site-packages (from gglitely==0.0.1) (2.0.3)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in /home/cgb2/anaconda3/lib/python3.11/site-packages (from pandas-&gt;gglitely==0.0.1) (2.8.2)\nRequirement already satisfied: pytz&gt;=2020.1 in /home/cgb2/anaconda3/lib/python3.11/site-packages (from pandas-&gt;gglitely==0.0.1) (2023.3.post1)\nRequirement already satisfied: tzdata&gt;=2022.1 in /home/cgb2/anaconda3/lib/python3.11/site-packages (from pandas-&gt;gglitely==0.0.1) (2023.3)\nRequirement already satisfied: numpy&gt;=1.21.0 in /home/cgb2/anaconda3/lib/python3.11/site-packages (from pandas-&gt;gglitely==0.0.1) (1.24.3)\nRequirement already satisfied: six&gt;=1.5 in /home/cgb2/anaconda3/lib/python3.11/site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas-&gt;gglitely==0.0.1) (1.16.0)\nBuilding wheels for collected packages: gglitely\n  Building wheel for gglitely (setup.py) ... -\b \b\\\b \bdone\n  Created wheel for gglitely: filename=gglitely-0.0.1-py3-none-any.whl size=2473 sha256=a44973c8caea399f7deb6e536c021569534974875b2ba77dc3dd4ab7dedb91b4\n  Stored in directory: /tmp/pip-ephem-wheel-cache-k1e0q26s/wheels/a5/b2/29/5db99646aa2b8d946b957bdf761a177612bf6709303d4ed579\nSuccessfully built gglitely\nInstalling collected packages: gglitely\nSuccessfully installed gglitely-0.0.1\n\n\n\n\nImports\n\nfrom gglitely import * \n\n\n\nConvert\n\nplt.plot([1,2,4,3],'o-.',color=\"C0\",label='A')\nplt.plot([2,1,5,1],'o-.',color=\"C1\",label='B')\nfig = plt.gcf()\nfig = litely(fig)\nfig"
  },
  {
    "objectID": "연구/나혼자/graft/2023-11-09-tutoral.html",
    "href": "연구/나혼자/graft/2023-11-09-tutoral.html",
    "title": "(연구) graft – tutorial",
    "section": "",
    "text": "1. Install\nconda create -n graft \nconda activate graft \nconda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\nconda install pyg -c pyg \nconda install -c conda-forge notebook \nconda install -c conda-forge graph-tool\nref: https://git.skewed.de/count0/graph-tool/-/wikis/installation-instructions\n\n!pip uninstall graft -y\n!pip install git+https://github.com/guebin/graft.git\n\nFound existing installation: graft 0.0.1\nUninstalling graft-0.0.1:\n  Successfully uninstalled graft-0.0.1\nCollecting git+https://github.com/guebin/graft.git\n  Cloning https://github.com/guebin/graft.git to /tmp/pip-req-build-ylrdrcb1\n  Running command git clone --filter=blob:none --quiet https://github.com/guebin/graft.git /tmp/pip-req-build-ylrdrcb1\n  Resolved https://github.com/guebin/graft.git to commit c09d8388736145c89e49e43f679e98f7e370277a\n  Preparing metadata (setup.py) ... done\nRequirement already satisfied: pandas in ./anaconda3/envs/graft/lib/python3.12/site-packages (from graft==0.0.1) (2.2.2)\nRequirement already satisfied: numpy&gt;=1.26.0 in ./anaconda3/envs/graft/lib/python3.12/site-packages (from pandas-&gt;graft==0.0.1) (1.26.4)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in ./anaconda3/envs/graft/lib/python3.12/site-packages (from pandas-&gt;graft==0.0.1) (2.9.0)\nRequirement already satisfied: pytz&gt;=2020.1 in ./anaconda3/envs/graft/lib/python3.12/site-packages (from pandas-&gt;graft==0.0.1) (2024.1)\nRequirement already satisfied: tzdata&gt;=2022.7 in ./anaconda3/envs/graft/lib/python3.12/site-packages (from pandas-&gt;graft==0.0.1) (2024.1)\nRequirement already satisfied: six&gt;=1.5 in ./anaconda3/envs/graft/lib/python3.12/site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas-&gt;graft==0.0.1) (1.16.0)\nBuilding wheels for collected packages: graft\n  Building wheel for graft (setup.py) ... done\n  Created wheel for graft: filename=graft-0.0.1-py3-none-any.whl size=8164 sha256=48e4e3a1d6b38fffada59c690b2481001ed3e94baa2e58ab0b0e47b618b500fa\n  Stored in directory: /tmp/pip-ephem-wheel-cache-83ebwark/wheels/5a/da/81/7f1de9f08d7753f35b8a3ca78aaacecedc86bc4077124d73fe\nSuccessfully built graft\nInstalling collected packages: graft\nSuccessfully installed graft-0.0.1\n\n\n\n\n2. Imports\n\nimport numpy as np\nimport torch\nimport torch_geometric\nimport graph_tool.all as gt\nimport graft\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n\n3. Undirected / Unweighted\n# Ex – default\n\nlinks = torch.tensor([[0, 1, 2, 3, 4, 3],\n                      [1, 0, 3, 2, 3, 4]], dtype=torch.long)\ng = torch_geometric.data.Data(\n    edge_index = links\n)\n\n\ngraft.plot(\n    g,\n    node_names=[0,1,2,3,4]\n)\n\n\n\n\n\n\n\n\n# Ex – node_names\n\ngraft.plot(\n    g, \n    node_names = ['a','b','c','d','e'], \n)\n\n\n\n\n\n\n\n\n# Ex – node_color (continuous)\n\nlinks = torch.tensor([[0, 1, 2, 3, 4, 3],\n                      [1, 0, 3, 2, 3, 4]], dtype=torch.long)\ng = torch_geometric.data.Data(\n    edge_index = links, \n    y = np.random.randn(5)\n)\n\n\ngraft.plot(\n    g,\n    node_colors=g.y\n)\n\n\n\n\n\n\n\n\n# Ex – node_color (discrete)\n\nlinks = torch.tensor([[0, 1, 2, 3, 4, 3],\n                      [1, 0, 3, 2, 3, 4]], dtype=torch.long)\ng = torch_geometric.data.Data(\n    edge_index = links, \n    y = torch.tensor([0,1,0,0,1])\n)\n\n\ngraft.plot(\n    g,\n    node_colors=g.y,\n)\n\n\n\n\n\n\n\n\n# Ex – node_color (discrete) / node_size\n\nlinks = torch.tensor([[0, 1, 2, 3, 4, 3],\n                      [1, 0, 3, 2, 3, 4]], dtype=torch.long)\ng = torch_geometric.data.Data(\n    edge_index = links, \n    y = torch.tensor([0,1,0,0,1]),\n    x = torch.tensor([10,50,15,20,35])\n)\n\n\ngraft.plot(\n    g,\n    node_colors=g.y,\n    node_sizes=g.x\n)\n\n\n\n\n\n\n\n\n# Ex – draw options\n\nlinks = torch.tensor([[0, 1, 2, 3, 4, 3],\n                      [1, 0, 3, 2, 3, 4]], dtype=torch.long)\ng = torch_geometric.data.Data(\n    edge_index = links\n)\n\n\ngraft.plot(\n    g,\n)\n\n\n\n\n\n\n\n\n\ndr_opts = {\n    'vertex_size':50\n}\ngraft.plot(\n    g,\n    draw_options= dr_opts\n)\n\n\n\n\n\n\n\n\n\ndr_opts = {\n    'output_size': (100,100)\n}\ngraft.plot(\n    g,\n    draw_options= dr_opts\n)\n\n\n\n\n\n\n\n\n\n\n4. Undirected / Weighted\n# Ex\n\nlinks = torch.tensor([[0, 1, 2, 3, 4, 3],\n                      [1, 0, 3, 2, 3, 4]], dtype=torch.long)\nweights = torch.tensor([5, 5, 1.5, 1.5, 0.19, 0.19], dtype=torch.float)\n\ng = torch_geometric.data.Data(\n    edge_index=links,\n    edge_attr=weights,\n)\n\n\ngraft.plot(\n    g,\n)\n\n\n\n\n\n\n\n\n# Ex\n\nlinks = torch.tensor([[0, 1, 2, 3, 4, 3],\n                      [1, 0, 3, 2, 3, 4]], dtype=torch.long)\nweights = torch.tensor([5, 5, 1.5, 1.5, 0.19, 0.19], dtype=torch.float)\n\ng = torch_geometric.data.Data(\n    edge_index=links,\n    edge_attr=weights,\n)\n\n# Ex\n\nlinks = torch.tensor([[0, 1, 2, 3, 4, 3],\n                      [1, 0, 3, 2, 3, 4]], dtype=torch.long)\nweights = torch.tensor([5, 5, 1.5, 1.5, 0.19, 0.19], dtype=torch.float)\ng = torch_geometric.data.Data(\n    edge_index=links,\n    edge_attr=weights,\n    y = torch.tensor([1,1,0,0,0])\n)\n\n\ngraft.plot(\n    g,\n    node_colors=g.y\n)\n\n\n\n\n\n\n\n\n# Ex\n\nlinks = torch.tensor([[0, 1, 2, 3, 4, 3],\n                      [1, 0, 3, 2, 3, 4]], dtype=torch.long)\nweights = torch.tensor([5, 5, 1.5, 1.5, 0.19, 0.19], dtype=torch.float)\ng = torch_geometric.data.Data(\n    edge_index = links, \n    edge_attr = weights,\n    y = torch.tensor([0,1,0,0,1]),\n    x = torch.tensor([1,3,1,2,4])\n)\n\n\ngraft.plot(\n    g,\n    node_colors=g.y,\n    node_sizes=g.x,\n)\n\n\n\n\n\n\n\n\n\n\n5. Directed / Unweighted\n\n# Define the graph components\nlinks = torch.tensor([[0, 2, 3, 3],\n                      [1, 3, 2, 4]], dtype=torch.long)\n\n# Create a PyTorch Geometric Data object\ng = torch_geometric.data.Data(\n    edge_index=links,\n    y=torch.tensor([0, 1, 0, 0, 1]),\n    x=torch.tensor([1, 3, 1, 2, 4])\n)\n\n# Example usage of the plot_directed_unweighted function\ngraft.plot(\n    g,\n    node_colors=g.y,\n    node_sizes=g.x\n)\n\n\n\n\n\n\n\n\n\n\n6. Directed / Weighted\n\n# Define the graph components\nlinks = torch.tensor([[0,  2, 3,  3],\n                      [1,  3, 2, 4]], dtype=torch.long)\nweights = torch.tensor([5, 5, 1.5, 1.5, 0.19, 0.19], dtype=torch.float)\n\n# Create a PyTorch Geometric Data object\ng = torch_geometric.data.Data(\n    edge_index=links,\n    edge_attr=weights,\n    y=torch.tensor([0, 1, 0, 0, 1]),\n    x=torch.tensor([1, 3, 1, 2, 4])\n)\n\n\n# Assuming the graph module with the new functions is imported as graft\n# Example usage of the plot_directed_weighted function\ngraft.plot(\n    g,\n    node_colors=g.y,\n    node_sizes=g.x,\n)\n\n\n\n\n\n\n\n\n\n# Assuming the graph module with the new functions is imported as graft\n# Example usage of the plot_directed_weighted function\ngraft.plot(\n    g,\n    node_colors=g.y,\n    node_sizes=g.x,\n    draw_options = {'edge_marker_size':20}\n)"
  },
  {
    "objectID": "연구/나혼자/gglite/2024-01-15-튜토리얼.html",
    "href": "연구/나혼자/gglite/2024-01-15-튜토리얼.html",
    "title": "(연구) gglite – 튜토리얼",
    "section": "",
    "text": "# options(jupyter.plot_scale=4)\n# options(repr.plot.width=6,repr.plot.height=4,repr.plot.res=300)"
  },
  {
    "objectID": "연구/나혼자/gglite/2024-01-15-튜토리얼.html#gglite-line-point",
    "href": "연구/나혼자/gglite/2024-01-15-튜토리얼.html#gglite-line-point",
    "title": "(연구) gglite – 튜토리얼",
    "section": "gglite + line + point",
    "text": "gglite + line + point\n\ny = rnorm(100)\n\n- 예시1\n\n\ngglite() + line(1:100, y, lty=2, col='gray60')\n\n\n\n\n\n\n\n\n- 예시2\n\ngglite() + point(y,pch=2,col=2,cex=5)\n\n\n\n\n\n\n\n\n- 예시3\n\ngglite() + point(y,pch=2,col=2,cex=5) + line(25:50, y[25:50], col=2, lwd=2)"
  },
  {
    "objectID": "연구/나혼자/gglite/2024-01-15-튜토리얼.html#ggplot2와-호환",
    "href": "연구/나혼자/gglite/2024-01-15-튜토리얼.html#ggplot2와-호환",
    "title": "(연구) gglite – 튜토리얼",
    "section": "ggplot2와 호환",
    "text": "ggplot2와 호환\n\ndf = data.frame(x=1:100,y=rnorm(100))\nhead(df)\n\n\nA data.frame: 6 × 2\n\n\n\nx\ny\n\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n1\n2.0186628\n\n\n2\n2\n-0.2538571\n\n\n3\n3\n-1.2151861\n\n\n4\n4\n-0.9871983\n\n\n5\n5\n-0.8421076\n\n\n6\n6\n0.6064969\n\n\n\n\n\n\ngglite(data=df) + \ngeom_point(aes(x=x,y=y)) + \nline(1:50,df$y[1:50],col=2,lty=2)\n\n\n\n\n\n\n\n\n\n완벽하게 호환가능"
  },
  {
    "objectID": "연구/나혼자/gglite/2024-01-15-튜토리얼.html#subplotting",
    "href": "연구/나혼자/gglite/2024-01-15-튜토리얼.html#subplotting",
    "title": "(연구) gglite – 튜토리얼",
    "section": "subplotting",
    "text": "subplotting\n\ny = rnorm(100)\np1 = gglite() + line(y,lty=2,col='gray60')\np2 = gglite() + point(y,pch=2,col=2,cex=5)\np3 = gglite() + point(y,pch=2,col=2,cex=5) + line(25:50, y[25:50], col=2, lwd=2)\np4 = gglite() + point(y) + line(1:50,y[1:50],col='orange')\n\n- 예시1: 좌우로 나란히\n\np1|p2|p3|p4\n\n\n\n\n\n\n\n\n- 예시2: 위아래로\n\nfigsize(10,5)\np1/p2/p3/p4\nfigsize()\n\n\n\n\n\n\n\n\n- 예시3: 그리드로!\n\nfigsize(10,5)\n(p1|p2)/(p3|p4)\nfigsize()\n\n\n\n\n\n\n\n\n- 예시4: 좀 더 난해한 모양으로 (1)\n\nfigsize(10,5)\n(p1|p2|p3)/p4\nfigsize()\n\n\n\n\n\n\n\n\n- 예시5: 좀 더 난해한 모양으로 (2)\n\nfigsize(10,5)\n(p1|p2|p3)/(p4|p1)\nfigsize()\n\n\n\n\n\n\n\n\n- 예시6: 좀 더 난해한 모양으로 (3)\n\nfigsize(10,5)\np1|(p2/p3/p4)\nfigsize()"
  },
  {
    "objectID": "연구/나혼자/gglite/2024-01-15-튜토리얼.html#ggtitle",
    "href": "연구/나혼자/gglite/2024-01-15-튜토리얼.html#ggtitle",
    "title": "(연구) gglite – 튜토리얼",
    "section": "ggtitle",
    "text": "ggtitle\n\ny = rnorm(100)\ngglite() + line(y,lty=2,col='gray60') + \nggtitle(\"(a) MY TITLE\")"
  },
  {
    "objectID": "연구/나혼자/gglite/2024-01-15-튜토리얼.html#xlab-ylab",
    "href": "연구/나혼자/gglite/2024-01-15-튜토리얼.html#xlab-ylab",
    "title": "(연구) gglite – 튜토리얼",
    "section": "xlab, ylab",
    "text": "xlab, ylab\n\ny = rnorm(100)\ngglite() + line(y,lty=2,col='gray60') + \nxlab(\"asdfasdfasdf\") + ylab(\"asdfasdfasdf\")"
  },
  {
    "objectID": "연구/나혼자/gglite/2024-01-15-튜토리얼.html#legends",
    "href": "연구/나혼자/gglite/2024-01-15-튜토리얼.html#legends",
    "title": "(연구) gglite – 튜토리얼",
    "section": "legends",
    "text": "legends\n\ny1 = rnorm(10)\ny2 = rnorm(10)\n\n\ngglite()+\nline(y1,label=\"y1\",lty=2)+point(y1,label=\"y1\",cex=3)+\nline(y2,label=\"y2\",lty=2)+point(y2,label=\"y2\",cex=3)"
  },
  {
    "objectID": "연구/나혼자/gglite/2024-01-15-튜토리얼.html#wide_y",
    "href": "연구/나혼자/gglite/2024-01-15-튜토리얼.html#wide_y",
    "title": "(연구) gglite – 튜토리얼",
    "section": "wide_y",
    "text": "wide_y\n- 예시1\n\ny1 = rnorm(10)\ny2 = rnorm(10)\n\n\ngglite()+line(cbind(y1,y2),lty=2)+point(cbind(y1,y2),cex=3)\n\n\n\n\n\n\n\n\n- 예시2\n\nx = 11:15\ny1 = rnorm(5)\ny2 = rnorm(5)\n\n\ngglite()+line(x,cbind(y1,y2),lty=2)+point(x,cbind(y1,y2),cex=3)\n\n\n\n\n\n\n\n\n- 예시3\n\nY = cbind(rnorm(5),rnorm(5))\n\n\ngglite()+line(Y,lty=2)\n\n\n\n\n\n\n\n\n- 예시3\n\ngglite()+line(Y,lty=2,col=\"gray60\")"
  },
  {
    "objectID": "연구/나혼자/gglite/2024-01-15-튜토리얼.html#smooth",
    "href": "연구/나혼자/gglite/2024-01-15-튜토리얼.html#smooth",
    "title": "(연구) gglite – 튜토리얼",
    "section": "smooth",
    "text": "smooth\n\nx = 1:100/100\ny1 = 2*x + rnorm(100)*0.3\ny2 = -3*x + rnorm(100)*0.3 +3\n\n- 예시1\n\ngglite()+point(x,y1,alpha=0.5,col=\"gray60\") + smooth(x,y1,col=2)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n- 예시2\n\ngglite()+point(x,y1,alpha=0.5,col=\"gray60\") +\nsmooth(x[1:60],y1[1:60],col=2) + \nsmooth(x[40:100],y1[40:100],col=4) \n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n- 예시3\n\ngglite()+point(x,cbind(y1,y2),alpha=0.5) +\nsmooth(x,cbind(y1,y2))\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'"
  },
  {
    "objectID": "연구/나혼자/gglite/2024-01-15-튜토리얼.html#step",
    "href": "연구/나혼자/gglite/2024-01-15-튜토리얼.html#step",
    "title": "(연구) gglite – 튜토리얼",
    "section": "step",
    "text": "step\n\ny1 = cumsum(rnorm(100))\ny2 = cumsum(rnorm(100))\n\n- 예시1\n\ngglite() + step(y1)\n\n\n\n\n\n\n\n\n- 예시2\n\ngglite() + step(cbind(y1,y2))"
  },
  {
    "objectID": "연구/나혼자/gglite/2024-01-15-튜토리얼.html#jitter",
    "href": "연구/나혼자/gglite/2024-01-15-튜토리얼.html#jitter",
    "title": "(연구) gglite – 튜토리얼",
    "section": "jitter",
    "text": "jitter\n\nx = sample(c(20,30,40,50),size=100,replace = TRUE)\ny = rnorm(100)\n\n\np1 = gglite()+point(x,y)+ggtitle(\"geom_point\")\np2 = gglite()+jitter(x,y,width = 1) + ggtitle(\"geom_jitter\")\nfigsize(10,5)\np1|p2\nfigsize()"
  },
  {
    "objectID": "연구/나혼자/gglite/2024-01-15-튜토리얼.html#histogram",
    "href": "연구/나혼자/gglite/2024-01-15-튜토리얼.html#histogram",
    "title": "(연구) gglite – 튜토리얼",
    "section": "histogram",
    "text": "histogram\n\ny1 = rnorm(1000)\ny2 = rnorm(1000)*0.5 + 3 \n\n- 예시1\n\ngglite()+histogram(c(y1,y2),fill=\"gray60\")\n\nWarning message:\n“`stat(density)` was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(density)` instead.\nℹ The deprecated feature was likely used in the gglite package.\n  Please report the issue to the authors.”\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n- 예시2\n\ngglite()+histogram(y1,label=\"A\")+histogram(y2,label=\"B\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n- 예시3\n\ngglite()+histogram(cbind(y1,y2))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "연구/나혼자/gglite/2024-01-15-튜토리얼.html#density",
    "href": "연구/나혼자/gglite/2024-01-15-튜토리얼.html#density",
    "title": "(연구) gglite – 튜토리얼",
    "section": "density",
    "text": "density\n\ny1 = rnorm(1000)\ny2 = rnorm(1000)*0.5 + 3 \n\n- 예시1\n\ngglite()+density(c(y1,y2))\n\n\n\n\n\n\n\n\n- 예시2\n\ngglite()+density(y1,label=\"A\")+density(y2,label=\"B\")\n\n\n\n\n\n\n\n\n- 예시3\n\ngglite()+density(cbind(y1,y2))\n\n\n\n\n\n\n\n\n- 예시4\n\ngglite()+histogram(cbind(y1,y2))+density(cbind(y1,y2))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "연구/나혼자/gglite/2024-01-15-튜토리얼.html#qq",
    "href": "연구/나혼자/gglite/2024-01-15-튜토리얼.html#qq",
    "title": "(연구) gglite – 튜토리얼",
    "section": "qq",
    "text": "qq\n\ny1 = rnorm(100)\ny2 = rchisq(100,df=5)\n\n\ngglite()+\nqq(y1,label='y1')+qq_line(y1,label='y1')+\nqq(y2,label='y2')+qq_line(y2,label='y2')"
  },
  {
    "objectID": "연구/나혼자/gglite/2024-01-15-튜토리얼.html#col",
    "href": "연구/나혼자/gglite/2024-01-15-튜토리얼.html#col",
    "title": "(연구) gglite – 튜토리얼",
    "section": "col",
    "text": "col\n\ny1=c(1,2,3,5)\ny2=c(1,4,2,1)\n\n\ngglite()+col(y1,fill=2)\n\n\n\n\n\n\n\n\n\ngglite()+col(cbind(y1,y2))"
  },
  {
    "objectID": "연구/나혼자/gglite/2024-01-15-튜토리얼.html#boxplot",
    "href": "연구/나혼자/gglite/2024-01-15-튜토리얼.html#boxplot",
    "title": "(연구) gglite – 튜토리얼",
    "section": "boxplot",
    "text": "boxplot\n\ny1=rnorm(100)\ny2=rnorm(100)+3\n\n- 예시1\n\ngglite()+boxplot(y1)\n\n\n\n\n\n\n\n\n- 예시2\n\ngglite()+boxplot(cbind(y1,y2))\n\n\n\n\n\n\n\n\n- 예시3\n\ngglite()+boxplot(x='A',y1,label='A')+boxplot(x='B',y2,label='B')"
  },
  {
    "objectID": "연구/나혼자/gglite/2024-01-15-튜토리얼.html#violin",
    "href": "연구/나혼자/gglite/2024-01-15-튜토리얼.html#violin",
    "title": "(연구) gglite – 튜토리얼",
    "section": "violin",
    "text": "violin\n\ny1=rnorm(100)\ny2=rnorm(100)+3\n\n- 예시1\n\ngglite()+violin(y1)\n\n\n\n\n\n\n\n\n- 예시2\n\ngglite()+violin(cbind(y1,y2),color = \"transparent\")\n\n\n\n\n\n\n\n\n- 예시3\n\ngglite()+violin(x='A',y1,label='A')+violin(x='B',y2,label='B')"
  },
  {
    "objectID": "연구/보람이랑/신용카드거래 사기탐지/2024-04-11-결과시각화-- 실험1.html",
    "href": "연구/보람이랑/신용카드거래 사기탐지/2024-04-11-결과시각화-- 실험1.html",
    "title": "(연구&보람) 결과시각화 – Experiment 1",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\n#import sklearn\nimport pickle \nimport time \nimport datetime\nimport warnings\nimport matplotlib.pyplot as plt\nwarnings.filterwarnings('ignore')\n\n/tmp/ipykernel_426569/2539883587.py:1: DeprecationWarning: \nPyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\nbut was not found to be installed on your system.\nIf this would cause problems for you,\nplease provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n        \n  import pandas as pd\n\n\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.io as pio\npd.options.plotting.backend = \"plotly\"\npio.templates.default = \"plotly_white\"\n\n\ndf = pd.read_csv('./240404_meged.csv')\ndf = df[['L2' not in l and 'L1' not in l for l in df.model]]\n#df['diff'] = abs(merged_df['train_frate'] - merged_df['test_frate'])\ndf = df[(df.test_frate &lt; 0.005) & (0.009 &lt; df.train_frate) & (df.train_frate &lt; 0.51)]\n\n\nfig = px.scatter(\n    df,\n    x='train_frate',y='auc',\n    color='method',\n    hover_data='model',\n    opacity=0.2,\n    #---#\n    width = 750,\n    height = 800  \n)\nfig.data[3]['marker']['opacity'] = 0.7\nfig.data[3]['marker']['size'] = 9\nfig"
  },
  {
    "objectID": "연구/보람이랑/신용카드거래 사기탐지/2023-05-12-Try1.html",
    "href": "연구/보람이랑/신용카드거래 사기탐지/2023-05-12-Try1.html",
    "title": "(연구&보람) 신용카드거래 사기탐지 – Try1",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport networkx as nx\nimport sklearn\n\n# sklearn\nfrom sklearn import model_selection # split함수이용\nfrom sklearn import ensemble # RF \nfrom sklearn import metrics \n\n# embedding \nfrom node2vec import Node2Vec\nfrom node2vec.edges import HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder\n\n/home/cgb2/anaconda3/envs/py38/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n\n\ndef build_graph_bipartite(df_input, graph_type=nx.Graph()):\n    df=df_input.copy()\n    mapping={x:node_id for node_id, x in enumerate(set(df[\"cc_num\"].values.tolist()+\\\n                                                      df[\"merchant\"].values.tolist()))}\n    \n    df[\"from\"]=df[\"cc_num\"].apply(lambda x:mapping[x])  #엣지의 출발점\n    df[\"to\"]=df[\"merchant\"].apply(lambda x:mapping[x])  #엣지의 도착점\n    \n    df = df[['from', 'to', \"amt\", \"is_fraud\"]].groupby(['from','to']).agg({\"is_fraud\":\"sum\",\"amt\":\"sum\"}).reset_index()\n    df[\"is_fraud\"]=df[\"is_fraud\"].apply(lambda x:1 if x&gt;0 else 0)\n    \n    G=nx.from_edgelist(df[[\"from\",\"to\"]].values, create_using=graph_type)\n    \n    nx.set_edge_attributes(G,{(int(x[\"from\"]),int(x[\"to\"])):x[\"is_fraud\"] for idx, x in df[[\"from\",\"to\",\"is_fraud\"]].iterrows()}, \"label\")  #엣지 속성 설정,각 속성의 사기 여부부     \n    nx.set_edge_attributes(G,{(int(x[\"from\"]),int(x[\"to\"])):x[\"amt\"] for idx,x in df[[\"from\",\"to\",\"amt\"]].iterrows()}, \"weight\") # 엣지 속성 설정, 각 엣지의 거래 금액\n\n    return G\n\n\ndef build_graph_tripartite(df_input, graph_type=nx.Graph()):\n    df=df_input.copy()\n    mapping={x:node_id for node_id, x in enumerate(set(df.index.values.tolist() + \n                                                       df[\"cc_num\"].values.tolist() +\n                                                       df[\"merchant\"].values.tolist()))}\n    df[\"in_node\"]= df[\"cc_num\"].apply(lambda x: mapping[x])\n    df[\"out_node\"]=df[\"merchant\"].apply(lambda x:mapping[x])\n    \n        \n    G=nx.from_edgelist([(x[\"in_node\"], mapping[idx]) for idx, x in df.iterrows()] +\\\n                        [(x[\"out_node\"], mapping[idx]) for idx, x in df.iterrows()], create_using=graph_type)\n    \n    nx.set_edge_attributes(G,{(x[\"in_node\"], mapping[idx]):x[\"is_fraud\"] for idx, x in df.iterrows()}, \"label\")     \n    nx.set_edge_attributes(G,{(x[\"out_node\"], mapping[idx]):x[\"is_fraud\"] for idx, x in df.iterrows()}, \"label\")   \n    nx.set_edge_attributes(G,{(x[\"in_node\"], mapping[idx]):x[\"amt\"] for idx, x in df.iterrows()}, \"weight\")  \n    nx.set_edge_attributes(G,{(x[\"out_node\"], mapping[idx]):x[\"amt\"] for idx, x in df.iterrows()}, \"weight\")\n\n    return G\n    \n    \ndef down_sample_textbook(df):\n    df_majority = df[df.is_fraud==0].copy()\n    df_minority = df[df.is_fraud==1].copy()\n    df_maj_dowsampled = sklearn.utils.resample(df_majority, n_samples=len(df_minority), replace=False, random_state=42)\n    df_downsampled = pd.concat([df_minority, df_maj_dowsampled])\n    return df_downsampled\n\ndef embedding(Graph):\n    # Graph -&gt; X (feature)\n    _edgs = list(Graph.edges)\n    subGraph = Graph.edge_subgraph([_edgs[x] for x in range(len(Graph.edges))]).copy()\n    subGraph.add_nodes_from(list(set(Graph.nodes) - set(subGraph.nodes)))    \n    embedded = AverageEmbedder(Node2Vec(subGraph, weight_key='weight').fit(window=10).wv)\n    X = [embedded[str(_edgs[x][0]), str(_edgs[x][1])] for x in range(len(Graph.edges))]\n    # Graph -&gt; y (label)\n    y = np.array(list(nx.get_edge_attributes(Graph, \"label\").values()))\n    return X,y \n\ndef anal(df):\n    Graph = build_graph_bipartite(df)\n    X,XX,y,yy = embedding(Graph)\n    lrnr = RandomForestClassifier(n_estimators=100, random_state=42) \n    lrnr.fit(X,y)\n    yyhat = lrnr.predict(XX)\n    df = pd.DataFrame({\n        'acc':[sklearn.metrics.accuracy_score(yy,yyhat)], \n        'pre':[sklearn.metrics.precision_score(yy,yyhat)], \n        'rec':[sklearn.metrics.recall_score(yy,yyhat)],\n        'f1':[sklearn.metrics.f1_score(yy,yyhat)]}\n    )    \n    return df\n\ndef our_sampling1(df):\n    cus_list = set(df.query('is_fraud==1').cc_num.tolist())\n    return df.query(\"cc_num in @ cus_list\")"
  },
  {
    "objectID": "연구/보람이랑/신용카드거래 사기탐지/2023-05-12-Try1.html#데이터-종류",
    "href": "연구/보람이랑/신용카드거래 사기탐지/2023-05-12-Try1.html#데이터-종류",
    "title": "(연구&보람) 신용카드거래 사기탐지 – Try1",
    "section": "데이터 종류",
    "text": "데이터 종류\n\nfraudTrain.csv: (1048575, 23), 기본데이터\ndf02: (214520, 23), is_fraud==0 에서는 20퍼의 샘플만, is_fraud==1 에서는 모든 샘플을 뽑아서 정리한 새로운 자료\ndf50 = (12012, 23), df20에서 is_fraud==0 와 is_fraud==1 의 비율을 맞추어서 샘플을 뽑은 것\n\n\n\n\n\n\n\n\n\n\n데이터\nshape\n사기거래빈도\n설명\n\n\n\n\nfraudTrain\n(1048575, 22)\n0.00573\n원래자료\n\n\ndf02\n(214520, 22)\n0.028\nis_fraud==0 에서는 20퍼의 샘플만, is_fraud==1 에서는 모든 샘플을 뽑아서 정리한 새로운 자료\n\n\ndf50\n(12012, 22)\n0.5\ndf02에서 사기비율을 50퍼로 맞추어 샘플링한 자료\n\n\ndf50_tr\n(9009, 22)\n0.49828\ndf50에서 랜덤으로 train/test를 분리하여 얻은 train dataset\n\n\ndf50_test\n(3003, 22)\n0.50516\ndf50에서 랜덤으로 train/test를 분리하여 얻은 test dataset\n\n\ndf02_tr\n(211517, 22)\n0.02122\ndf02에서 df50_test에 해당하는 인덱스를 제외\n\n\nfraudTrain_tr\n(1045572, 22)\n0.00429\nfraudTrain에서 df50_test에 해당하는 인덱스를 제외\n\n\n\n- fraudTrain\n\nfraudTrain = pd.read_csv(\"fraudTrain.csv\").iloc[:,1:]\nfraudTrain.shape\n\n(1048575, 22)\n\n\n\nfraudTrain.is_fraud.mean().round(5)\n\n0.00573\n\n\n- df20\n\n_df1 = fraudTrain[fraudTrain[\"is_fraud\"] == 0].sample(frac=0.20, random_state=42)\n_df2 = fraudTrain[fraudTrain[\"is_fraud\"] == 1]\ndf02 = pd.concat([_df1,_df2])\ndf02.shape\n\n(214520, 22)\n\n\n\ndf02.is_fraud.mean().round(5)\n\n0.028\n\n\n- df50\n\ndf50 = down_sample_textbook(df02)\ndf50.shape\n\n(12012, 22)\n\n\n\ndf50\n\n\n\n\n\n\n\n\ntrans_date_trans_time\ncc_num\nmerchant\ncategory\namt\nfirst\nlast\ngender\nstreet\ncity\n...\nlat\nlong\ncity_pop\njob\ndob\ntrans_num\nunix_time\nmerch_lat\nmerch_long\nis_fraud\n\n\n\n\n2449\n2019-01-02 1:06\n4.613310e+12\nfraud_Rutherford-Mertz\ngrocery_pos\n281.06\nJason\nMurphy\nM\n542 Steve Curve Suite 011\nCollettsville\n...\n35.9946\n-81.7266\n885\nSoil scientist\n1988-09-15\ne8a81877ae9a0a7f883e15cb39dc4022\n1325466397\n36.430124\n-81.179483\n1\n\n\n2472\n2019-01-02 1:47\n3.401870e+14\nfraud_Jenkins, Hauck and Friesen\ngas_transport\n11.52\nMisty\nHart\nF\n27954 Hall Mill Suite 575\nSan Antonio\n...\n29.4400\n-98.4590\n1595797\nHorticultural consultant\n1960-10-28\nbc7d41c41103877b03232f03f1f8d3f5\n1325468849\n29.819364\n-99.142791\n1\n\n\n2523\n2019-01-02 3:05\n3.401870e+14\nfraud_Goodwin-Nitzsche\ngrocery_pos\n276.31\nMisty\nHart\nF\n27954 Hall Mill Suite 575\nSan Antonio\n...\n29.4400\n-98.4590\n1595797\nHorticultural consultant\n1960-10-28\nb98f12f4168391b2203238813df5aa8c\n1325473523\n29.273085\n-98.836360\n1\n\n\n2546\n2019-01-02 3:38\n4.613310e+12\nfraud_Erdman-Kertzmann\ngas_transport\n7.03\nJason\nMurphy\nM\n542 Steve Curve Suite 011\nCollettsville\n...\n35.9946\n-81.7266\n885\nSoil scientist\n1988-09-15\n397894a5c4c02e3c61c784001f0f14e4\n1325475483\n35.909292\n-82.091010\n1\n\n\n2553\n2019-01-02 3:55\n3.401870e+14\nfraud_Koepp-Parker\ngrocery_pos\n275.73\nMisty\nHart\nF\n27954 Hall Mill Suite 575\nSan Antonio\n...\n29.4400\n-98.4590\n1595797\nHorticultural consultant\n1960-10-28\n7863235a750d73a244c07f1fb7f0185a\n1325476547\n29.786426\n-98.683410\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n363827\n2019-06-17 19:30\n2.475090e+15\nfraud_Frami Group\nentertainment\n81.13\nJohn\nMiller\nM\n153 Mccullough Springs Apt. 857\nLamberton\n...\n44.2378\n-95.2739\n1507\nLand/geomatics surveyor\n1993-10-12\nc66cb411019c7dfd4d89f42a1ba4765f\n1339961448\n44.212695\n-95.661879\n0\n\n\n140154\n2019-03-17 14:33\n2.131550e+14\nfraud_Bahringer-Streich\nfood_dining\n55.00\nChristopher\nSheppard\nM\n39218 Baker Shoals\nBristow\n...\n38.1981\n-86.6821\n965\nHorticultural therapist\n1982-02-10\n316b9d25b9fa7d08a6831b7dab6634cd\n1331994839\n38.394240\n-86.413557\n0\n\n\n860597\n2019-12-17 12:31\n2.280870e+15\nfraud_Lubowitz-Walter\nkids_pets\n8.12\nKatherine\nCooper\nF\n3854 Lauren Springs Suite 648\nOakford\n...\n40.0994\n-89.9601\n530\nTransport planner\n1967-09-23\nd92e9e63d9b24c3ccb92d05cba4cac54\n1355747517\n39.695248\n-89.853063\n0\n\n\n29341\n2019-01-18 9:20\n4.878360e+15\nfraud_Denesik and Sons\nshopping_pos\n3.52\nTina\nAlvarez\nF\n1976 Tyler Underpass\nEarly\n...\n42.4483\n-95.1726\n885\nPilot, airline\n1949-08-14\n8390ce51cfb8482b618ebc4ac370bcf7\n1326878457\n42.633204\n-95.598143\n0\n\n\n529797\n2019-08-16 13:17\n4.450830e+15\nfraud_Beier and Sons\nhome\n84.15\nDonna\nDavis\nF\n6760 Donovan Lakes\nClayton\n...\n34.5906\n-95.3800\n1760\nOccupational psychologist\n1972-01-20\n04e1be9bcb18ea8b96048659bd02177b\n1345123058\n33.885236\n-95.885110\n0\n\n\n\n\n12012 rows × 22 columns\n\n\n\n\ndf50.is_fraud.mean().round(5)\n\n0.5\n\n\n- df50_tr, df50_test\n\ndf50_tr,df50_test = sklearn.model_selection.train_test_split(df50, random_state=42)\n\n\ndf50_tr.is_fraud.mean().round(5), df50_test.is_fraud.mean().round(5)\n\n(0.49828, 0.50516)\n\n\n- df02_tr, fraudTrain_tr\n\ndf02_tr = df02.loc[[i not in df50_test.index for i in df02.index],:].copy()\nfraudTrain_tr = fraudTrain.loc[[i not in df50_test.index for i in fraudTrain.index],:].copy()\n\n\ndf02_tr.shape, fraudTrain_tr.shape\n\n((211517, 22), (1045572, 22))\n\n\n\ndf02_tr.is_fraud.mean().round(5), fraudTrain_tr.is_fraud.mean().round(5)\n\n(0.02122, 0.00429)"
  },
  {
    "objectID": "연구/보람이랑/신용카드거래 사기탐지/2023-07-19-그래프자료로 데이터정리.html",
    "href": "연구/보람이랑/신용카드거래 사기탐지/2023-07-19-그래프자료로 데이터정리.html",
    "title": "(연구&보람) 신용카드거래 사기탐지 – 그래프자료로 데이터정리",
    "section": "",
    "text": "imports\n\nimport numpy as np\nimport pandas as pd\nimport torch \nimport torch_geometric\n\n- 모든엣지를 고려\n\nN = 10 \nedge_index = torch.tensor([[i,j] for i in range(N) for j in range(N)]).T\n# edge_attr = 그래프의 웨이트 \n\n\nfraudTrain = pd.read_csv(\"fraudTrain.csv\").iloc[:,1:]\n\n\nfraudTrain = fraudTrain.assign(trans_date_trans_time= list(map(lambda x: pd.to_datetime(x), fraudTrain.trans_date_trans_time)))\nfraudTrain\n\n\n\n\n\n\n\n\ntrans_date_trans_time\ncc_num\nmerchant\ncategory\namt\nfirst\nlast\ngender\nstreet\ncity\n...\nlat\nlong\ncity_pop\njob\ndob\ntrans_num\nunix_time\nmerch_lat\nmerch_long\nis_fraud\n\n\n\n\n0\n2019-01-01 00:00:00\n2.703190e+15\nfraud_Rippin, Kub and Mann\nmisc_net\n4.97\nJennifer\nBanks\nF\n561 Perry Cove\nMoravian Falls\n...\n36.0788\n-81.1781\n3495\nPsychologist, counselling\n1988-03-09\n0b242abb623afc578575680df30655b9\n1325376018\n36.011293\n-82.048315\n0\n\n\n1\n2019-01-01 00:00:00\n6.304230e+11\nfraud_Heller, Gutmann and Zieme\ngrocery_pos\n107.23\nStephanie\nGill\nF\n43039 Riley Greens Suite 393\nOrient\n...\n48.8878\n-118.2105\n149\nSpecial educational needs teacher\n1978-06-21\n1f76529f8574734946361c461b024d99\n1325376044\n49.159047\n-118.186462\n0\n\n\n2\n2019-01-01 00:00:00\n3.885950e+13\nfraud_Lind-Buckridge\nentertainment\n220.11\nEdward\nSanchez\nM\n594 White Dale Suite 530\nMalad City\n...\n42.1808\n-112.2620\n4154\nNature conservation officer\n1962-01-19\na1a22d70485983eac12b5b88dad1cf95\n1325376051\n43.150704\n-112.154481\n0\n\n\n3\n2019-01-01 00:01:00\n3.534090e+15\nfraud_Kutch, Hermiston and Farrell\ngas_transport\n45.00\nJeremy\nWhite\nM\n9443 Cynthia Court Apt. 038\nBoulder\n...\n46.2306\n-112.1138\n1939\nPatent attorney\n1967-01-12\n6b849c168bdad6f867558c3793159a81\n1325376076\n47.034331\n-112.561071\n0\n\n\n4\n2019-01-01 00:03:00\n3.755340e+14\nfraud_Keeling-Crist\nmisc_pos\n41.96\nTyler\nGarcia\nM\n408 Bradley Rest\nDoe Hill\n...\n38.4207\n-79.4629\n99\nDance movement psychotherapist\n1986-03-28\na41d7549acf90789359a9aa5346dcb46\n1325376186\n38.674999\n-78.632459\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1048570\n2020-03-10 16:07:00\n6.011980e+15\nfraud_Fadel Inc\nhealth_fitness\n77.00\nHaley\nWagner\nF\n05561 Farrell Crescent\nAnnapolis\n...\n39.0305\n-76.5515\n92106\nAccountant, chartered certified\n1943-05-28\n45ecd198c65e81e597db22e8d2ef7361\n1362931649\n38.779464\n-76.317042\n0\n\n\n1048571\n2020-03-10 16:07:00\n4.839040e+15\nfraud_Cremin, Hamill and Reichel\nmisc_pos\n116.94\nMeredith\nCampbell\nF\n043 Hanson Turnpike\nHedrick\n...\n41.1826\n-92.3097\n1583\nGeochemist\n1999-06-28\nc00ce51c6ebb7657474a77b9e0b51f34\n1362931670\n41.400318\n-92.726724\n0\n\n\n1048572\n2020-03-10 16:08:00\n5.718440e+11\nfraud_O'Connell, Botsford and Hand\nhome\n21.27\nSusan\nMills\nF\n005 Cody Estates\nLouisville\n...\n38.2507\n-85.7476\n736284\nEngineering geologist\n1952-04-02\n17c9dc8b2a6449ca2473726346e58e6c\n1362931711\n37.293339\n-84.798122\n0\n\n\n1048573\n2020-03-10 16:08:00\n4.646850e+18\nfraud_Thompson-Gleason\nhealth_fitness\n9.52\nJulia\nBell\nF\n576 House Crossroad\nWest Sayville\n...\n40.7320\n-73.1000\n4056\nFilm/video editor\n1990-06-25\n5ca650881b48a6a38754f841c23b77ab\n1362931718\n39.773077\n-72.213209\n0\n\n\n1048574\n2020-03-10 16:08:00\n2.283740e+15\nfraud_Buckridge PLC\nmisc_pos\n6.81\nShannon\nWilliams\nF\n9345 Spencer Junctions Suite 183\nAlpharetta\n...\n34.0770\n-84.3033\n165556\nPrison officer\n1997-12-27\n8d0a575fe635bbde12f1a2bffc126731\n1362931730\n33.601468\n-83.891921\n0\n\n\n\n\n1048575 rows × 22 columns\n\n\n\n\ndiff = fraudTrain.trans_date_trans_time[10]-fraudTrain.trans_date_trans_time[0]\n\n\ntheta = 86400*1.2\nnp.exp(-diff.total_seconds()/theta)\n\n0.9965337989703691\n\n\n\n!git add .\n!git commit -m. \n!git push \n!quarto publish --no-browser --no-prompt"
  },
  {
    "objectID": "연구/보람이랑/신용카드거래 사기탐지/2024-01-25-pyod 사용.html",
    "href": "연구/보람이랑/신용카드거래 사기탐지/2024-01-25-pyod 사용.html",
    "title": "(연구&보람) 신용카드거래 사기탐지 – pyod 사용",
    "section": "",
    "text": "ref: https://pyod.readthedocs.io/en/latest/pyod.models.html#all-models\n\n1. Imports\n\nimport pandas as pd\nimport numpy as np\n\n\nfrom pyod.models.abod import ABOD\n#from pyod.models.alad import ALAD\n#from pyod.models.anogan import AnoGAN\n#from pyod.models.auto_encoder import AutoEncoder\nfrom pyod.models.cblof import CBLOF\nfrom pyod.models.cof import COF\nfrom pyod.models.cd import CD\nfrom pyod.models.copod import COPOD\n#from pyod.models.deep_svdd import DeepSVDD\n#from pyod.models.dif import DIF\nfrom pyod.models.ecod import ECOD\n#from pyod.models.feature_bagging import FeatureBagging\nfrom pyod.models.gmm import GMM\nfrom pyod.models.hbos import HBOS\nfrom pyod.models.iforest import IForest\nfrom pyod.models.inne import INNE\nfrom pyod.models.kde import KDE\nfrom pyod.models.knn import KNN\nfrom pyod.models.kpca import KPCA\nfrom pyod.models.kpca import PyODKernelPCA\nfrom pyod.models.lmdd import LMDD\nfrom pyod.models.loda import LODA\nfrom pyod.models.lof import LOF\nfrom pyod.models.loci import LOCI\n#from pyod.models.lunar import LUNAR\nfrom pyod.models.lscp import LSCP\nfrom pyod.models.mad import MAD\nfrom pyod.models.mcd import MCD\n#from pyod.models.mo_gaal import MO_GAAL\nfrom pyod.models.ocsvm import OCSVM\nfrom pyod.models.pca import PCA\nfrom pyod.models.qmcd import QMCD\nfrom pyod.models.rgraph import RGraph\nfrom pyod.models.rod import ROD\nfrom pyod.models.sampling import Sampling\nfrom pyod.models.sod import SOD\n#from pyod.models.so_gaal import SO_GAAL\nfrom pyod.models.sos import SOS\n#from pyod.models.suod import SUOD\n#from pyod.models.vae import VAE\n#from pyod.models.xgbod import XGBOD\n\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n\n2. Data\n\nX = pd.DataFrame({'amt':[5000.0,1,2,3000,3,4,2000,5,6]})\ny = pd.DataFrame({'is_fraud':[1,0,0,1,0,0,1,0,0]})\nXX = pd.DataFrame({'amt':[3500.0,1.5]})\n\n\n\n3. Predictor 만들기\n- 1인것의 비율을 계산해서 fraud_ratio를 설정해야함. (즉 사기거래 비율)\n\nfraud_ratio = 0.33\npredictors = {\n    'ABOD': ABOD(contamination=fraud_ratio),\n#    'ALAD': ALAD(contamination=fraud_ratio),\n#    'AnoGAN': AnoGAN(contamination=fraud_ratio),\n#    'AutoEncoder':AutoEncoder(contamination=fraud_ratio),\n##    'CBLOF': CBLOF(contamination=fraud_ratio,n_clusters=2),\n##    'COF': COF(contamination=fraud_ratio),\n##    'CD': CD(contamination=fraud_ratio),\n    'COPOD': COPOD(contamination=fraud_ratio),\n#    'DeepSVDD': DeepSVDD(contamination=fraud_ratio),\n#    'DIF': DIF(contamination=fraud_ratio),    \n    'ECOD': ECOD(contamination=fraud_ratio),\n#    'FeatureBagging': FeatureBagging(contamination=fraud_ratio),\n    'GMM': GMM(contamination=fraud_ratio),\n    'HBOS': HBOS(contamination=fraud_ratio),\n    'IForest': IForest(contamination=fraud_ratio),\n    'INNE': INNE(contamination=fraud_ratio),\n    'KDE': KDE(contamination=fraud_ratio),\n    'KNN': KNN(contamination=fraud_ratio),\n    'KPCA': KPCA(contamination=fraud_ratio),\n#    'PyODKernelPCA': PyODKernelPCA(contamination=fraud_ratio),\n##    'LMDD': LMDD(contamination=fraud_ratio),\n    'LODA': LODA(contamination=fraud_ratio),\n    'LOF': LOF(contamination=fraud_ratio),\n    'LOCI': LOCI(contamination=fraud_ratio),\n#    'LUNAR': LUNAR(contamination=fraud_ratio),\n    'LODA': LODA(contamination=fraud_ratio),\n#    'LSCP': LSCP(contamination=fraud_ratio),\n    'MAD': MAD(contamination=fraud_ratio),\n    'MCD': MCD(contamination=fraud_ratio),\n#    'MO_GAAL': MO_GAAL(contamination=fraud_ratio),\n    'OCSVM': OCSVM(contamination=fraud_ratio),\n    'PCA': PCA(contamination=fraud_ratio),\n###    'QMCD': QMCD(contamination=fraud_ratio),\n    'RGraph': RGraph(contamination=fraud_ratio),\n    'ROD': ROD(contamination=fraud_ratio),\n##    'Sampling': Sampling(contamination=fraud_ratio),\n##   'SOD': SOD(contamination=fraud_ratio),\n#    'SO_GAAL': SO_GAAL(contamination=fraud_ratio),\n    'SOS': SOS(contamination=fraud_ratio),\n#    'SUOD': SUOD(contamination=fraud_ratio),\n#    'VAE': VAE(contamination=fraud_ratio),\n#    'XGBOD': XGBOD(contamination=fraud_ratio),  \n}\n\n\n주석처리는 안만들어지는 것\n#은 tensorflow 등이 없어서 ..\n##은 만들어지는데 .fit 할때 오류가 나느것\n###은 fit은 되는데 test할때 nan이 출력되는것\n\n\n\n4. 학습 & 결과저장\n\nyyhat_dict = dict()\nfor name,predictor in predictors.items():\n    predictor.fit(X,y)\n    yyhat_dict[name] = predictor.predict_proba(XX)[:,-1]\n\n0/9\nTest block 0/1\n0/11\n\n\n\nyyhat_dict # [1,0] 으로 예측해야 올바른것임 \n\n{'ABOD': array([1., 0.]),\n 'COPOD': array([0.69400716, 0.19400716]),\n 'ECOD': array([0.69400716, 0.69400716]),\n 'GMM': array([0.34286978, 0.03145675]),\n 'HBOS': array([1., 0.]),\n 'IForest': array([0.72671218, 0.16035735]),\n 'INNE': array([0.22556971, 0.08458866]),\n 'KDE': array([1.        , 0.16995667]),\n 'KNN': array([6.99379131e-01, 1.00140196e-04]),\n 'KPCA': array([1., 1.]),\n 'LODA': array([0.58679469, 0.56      ]),\n 'LOF': array([0., 0.]),\n 'LOCI': array([0., 0.]),\n 'MAD': array([0.6996997, 0.0007007]),\n 'MCD': array([4.19839700e-01, 2.99759832e-04]),\n 'OCSVM': array([1., 0.]),\n 'PCA': array([0.18657712, 0.99981342]),\n 'RGraph': array([0., 1.]),\n 'ROD': array([1.66712365e-04, 6.44434498e-08]),\n 'SOS': array([0., 0.])}\n\n\n\n\nAppendix: 환경설정\nconda create -n pyod \nconda activate pyod \nconda install -c conda-forge pyod \n\n!conda env list \n\n# conda environments:\n#\nbase                     /home/cgb2/anaconda3\npyod                  *  /home/cgb2/anaconda3/envs/pyod\nr                        /home/cgb2/anaconda3/envs/r\n\n\n\n\n!conda list \n\n# packages in environment at /home/cgb2/anaconda3/envs/pyod:\n#\n# Name                    Version                   Build  Channel\n_libgcc_mutex             0.1                        main  \n_openmp_mutex             5.1                       1_gnu  \naiofiles                  22.1.0             pyhd8ed1ab_0    conda-forge\naiosqlite                 0.19.0             pyhd8ed1ab_0    conda-forge\nanyio                     3.7.1              pyhd8ed1ab_0    conda-forge\nargon2-cffi               23.1.0             pyhd8ed1ab_0    conda-forge\nargon2-cffi-bindings      21.2.0          py311h5eee18b_0  \narrow                     1.3.0              pyhd8ed1ab_0    conda-forge\nasttokens                 2.4.1              pyhd8ed1ab_0    conda-forge\nattrs                     23.2.0             pyh71513ae_0    conda-forge\nbabel                     2.14.0             pyhd8ed1ab_0    conda-forge\nbeautifulsoup4            4.12.3             pyha770c72_0    conda-forge\nblas                      1.0                         mkl  \nbleach                    6.1.0              pyhd8ed1ab_0    conda-forge\nbottleneck                1.3.5           py311hbed6279_0  \nbrotli                    1.0.9                h5eee18b_7  \nbrotli-bin                1.0.9                h5eee18b_7  \nbzip2                     1.0.8                h7b6447c_0  \nca-certificates           2023.11.17           hbcca054_0    conda-forge\ncached-property           1.5.2                hd8ed1ab_1    conda-forge\ncached_property           1.5.2              pyha770c72_1    conda-forge\ncertifi                   2023.11.17         pyhd8ed1ab_0    conda-forge\ncffi                      1.16.0          py311h5eee18b_0  \ncharset-normalizer        3.3.2              pyhd8ed1ab_0    conda-forge\ncomm                      0.2.1              pyhd8ed1ab_0    conda-forge\ncontourpy                 1.2.0           py311hdb19cb5_0  \ncycler                    0.11.0             pyhd3eb1b0_0  \ndebugpy                   1.6.7           py311h6a678d5_0  \ndecorator                 5.1.1              pyhd8ed1ab_0    conda-forge\ndefusedxml                0.7.1              pyhd8ed1ab_0    conda-forge\nentrypoints               0.4                pyhd8ed1ab_0    conda-forge\nexceptiongroup            1.2.0              pyhd8ed1ab_2    conda-forge\nexecuting                 2.0.1              pyhd8ed1ab_0    conda-forge\nfonttools                 4.25.0             pyhd3eb1b0_0  \nfqdn                      1.5.1              pyhd8ed1ab_0    conda-forge\nfreetype                  2.12.1               h4a9f257_0  \ngiflib                    5.2.1                h5eee18b_3  \nidna                      3.6                pyhd8ed1ab_0    conda-forge\nimportlib-metadata        7.0.1              pyha770c72_0    conda-forge\nimportlib_resources       6.1.1              pyhd8ed1ab_0    conda-forge\nintel-openmp              2023.1.0         hdb19cb5_46306  \nipykernel                 6.23.1             pyh210e3f2_0    conda-forge\nipython                   8.20.0             pyh707e725_0    conda-forge\nipython_genutils          0.2.0                      py_1    conda-forge\nisoduration               20.11.0            pyhd8ed1ab_0    conda-forge\njedi                      0.19.1             pyhd8ed1ab_0    conda-forge\njinja2                    3.1.3              pyhd8ed1ab_0    conda-forge\njoblib                    1.2.0           py311h06a4308_0  \njpeg                      9e                   h5eee18b_1  \njson5                     0.9.14             pyhd8ed1ab_0    conda-forge\njsonpointer               2.4             py311h38be061_3    conda-forge\njsonschema                4.21.1             pyhd8ed1ab_0    conda-forge\njsonschema-specifications 2023.12.1          pyhd8ed1ab_0    conda-forge\njsonschema-with-format-nongpl 4.21.1             pyhd8ed1ab_0    conda-forge\njupyter_client            7.4.9              pyhd8ed1ab_0    conda-forge\njupyter_core              5.7.1           py311h38be061_0    conda-forge\njupyter_events            0.9.0              pyhd8ed1ab_0    conda-forge\njupyter_server            1.24.0             pyhd8ed1ab_0    conda-forge\njupyter_server_fileid     0.9.1              pyhd8ed1ab_0    conda-forge\njupyter_server_ydoc       0.8.0              pyhd8ed1ab_0    conda-forge\njupyter_ydoc              0.2.4           py311h06a4308_0  \njupyterlab                3.6.7              pyhd8ed1ab_0    conda-forge\njupyterlab_pygments       0.3.0              pyhd8ed1ab_0    conda-forge\njupyterlab_server         2.25.2             pyhd8ed1ab_0    conda-forge\nkiwisolver                1.4.4           py311h6a678d5_0  \nlcms2                     2.12                 h3be6417_0  \nld_impl_linux-64          2.38                 h1181459_1  \nlerc                      3.0                  h295c915_0  \nlibbrotlicommon           1.0.9                h5eee18b_7  \nlibbrotlidec              1.0.9                h5eee18b_7  \nlibbrotlienc              1.0.9                h5eee18b_7  \nlibdeflate                1.17                 h5eee18b_1  \nlibffi                    3.4.4                h6a678d5_0  \nlibgcc-ng                 11.2.0               h1234567_1  \nlibgfortran-ng            11.2.0               h00389a5_1  \nlibgfortran5              11.2.0               h1234567_1  \nlibgomp                   11.2.0               h1234567_1  \nlibllvm14                 14.0.6               hdb19cb5_3  \nlibpng                    1.6.39               h5eee18b_0  \nlibsodium                 1.0.18               h36c2ea0_1    conda-forge\nlibstdcxx-ng              11.2.0               h1234567_1  \nlibtiff                   4.5.1                h6a678d5_0  \nlibuuid                   1.41.5               h5eee18b_0  \nlibwebp                   1.3.2                h11a3e52_0  \nlibwebp-base              1.3.2                h5eee18b_0  \nllvmlite                  0.41.0          py311he621ea3_0  \nlz4-c                     1.9.4                h6a678d5_0  \nmarkupsafe                2.1.3           py311h5eee18b_0  \nmatplotlib-base           3.8.0           py311ha02d727_0  \nmatplotlib-inline         0.1.6              pyhd8ed1ab_0    conda-forge\nmistune                   3.0.2              pyhd8ed1ab_0    conda-forge\nmkl                       2023.1.0         h213fc3f_46344  \nmkl-service               2.4.0           py311h5eee18b_1  \nmkl_fft                   1.3.8           py311h5eee18b_0  \nmkl_random                1.2.4           py311hdb19cb5_0  \nmunkres                   1.1.4                      py_0  \nnbclassic                 1.0.0              pyh8b2e9e2_0    conda-forge\nnbclient                  0.8.0              pyhd8ed1ab_0    conda-forge\nnbconvert-core            7.14.2             pyhd8ed1ab_0    conda-forge\nnbformat                  5.9.2              pyhd8ed1ab_0    conda-forge\nncurses                   6.4                  h6a678d5_0  \nnest-asyncio              1.6.0              pyhd8ed1ab_0    conda-forge\nnotebook                  6.5.6              pyha770c72_0    conda-forge\nnotebook-shim             0.2.3              pyhd8ed1ab_0    conda-forge\nnumba                     0.58.1          py311ha02d727_0  \nnumexpr                   2.8.7           py311h65dcdc2_0  \nnumpy                     1.26.3          py311h08b1b3b_0  \nnumpy-base                1.26.3          py311hf175353_0  \nopenjpeg                  2.4.0                h3ad879b_0  \nopenssl                   3.0.12               h7f8727e_0  \npackaging                 23.1            py311h06a4308_0  \npandas                    2.1.4           py311ha02d727_0  \npandocfilters             1.5.0              pyhd8ed1ab_0    conda-forge\nparso                     0.8.3              pyhd8ed1ab_0    conda-forge\npatsy                     0.5.3           py311h06a4308_0  \npexpect                   4.9.0              pyhd8ed1ab_0    conda-forge\npickleshare               0.7.5                   py_1003    conda-forge\npillow                    10.0.1          py311ha6cbd5a_0  \npip                       23.3.1          py311h06a4308_0  \npkgutil-resolve-name      1.3.10             pyhd8ed1ab_1    conda-forge\nplatformdirs              4.1.0              pyhd8ed1ab_0    conda-forge\nprometheus_client         0.19.0             pyhd8ed1ab_0    conda-forge\nprompt-toolkit            3.0.42             pyha770c72_0    conda-forge\npsutil                    5.9.0           py311h5eee18b_0  \nptyprocess                0.7.0              pyhd3deb0d_0    conda-forge\npure_eval                 0.2.2              pyhd8ed1ab_0    conda-forge\npycparser                 2.21               pyhd8ed1ab_0    conda-forge\npygments                  2.17.2             pyhd8ed1ab_0    conda-forge\npyod                      1.1.2              pyhd8ed1ab_0    conda-forge\npyparsing                 3.0.9           py311h06a4308_0  \npython                    3.11.7               h955ad1f_0  \npython-dateutil           2.8.2              pyhd3eb1b0_0  \npython-fastjsonschema     2.19.1             pyhd8ed1ab_0    conda-forge\npython-json-logger        2.0.7              pyhd8ed1ab_0    conda-forge\npython-tzdata             2023.3             pyhd3eb1b0_0  \npython_abi                3.11                    2_cp311    conda-forge\npytz                      2023.3.post1    py311h06a4308_0  \npyyaml                    6.0.1           py311h5eee18b_0  \npyzmq                     23.2.0          py311h6a678d5_0  \nreadline                  8.2                  h5eee18b_0  \nreferencing               0.32.1             pyhd8ed1ab_0    conda-forge\nrequests                  2.31.0             pyhd8ed1ab_0    conda-forge\nrfc3339-validator         0.1.4              pyhd8ed1ab_0    conda-forge\nrfc3986-validator         0.1.1              pyh9f0ad1d_0    conda-forge\nrpds-py                   0.10.6          py311hb02cf49_0  \nscikit-learn              1.2.2           py311h6a678d5_1  \nscipy                     1.11.4          py311h08b1b3b_0  \nsend2trash                1.8.2              pyh41d4057_0    conda-forge\nsetuptools                68.2.2          py311h06a4308_0  \nsix                       1.16.0             pyhd3eb1b0_1  \nsniffio                   1.3.0              pyhd8ed1ab_0    conda-forge\nsoupsieve                 2.5                pyhd8ed1ab_1    conda-forge\nsqlite                    3.41.2               h5eee18b_0  \nstack_data                0.6.2              pyhd8ed1ab_0    conda-forge\nstatsmodels               0.14.0          py311hf4808d0_0  \ntbb                       2021.8.0             hdb19cb5_0  \nterminado                 0.18.0             pyh0d859eb_0    conda-forge\nthreadpoolctl             2.2.0              pyh0d69192_0  \ntinycss2                  1.2.1              pyhd8ed1ab_0    conda-forge\ntk                        8.6.12               h1ccaba5_0  \ntomli                     2.0.1              pyhd8ed1ab_0    conda-forge\ntornado                   6.3.3           py311h5eee18b_0  \ntraitlets                 5.14.1             pyhd8ed1ab_0    conda-forge\ntypes-python-dateutil     2.8.19.20240106    pyhd8ed1ab_0    conda-forge\ntyping-extensions         4.9.0                hd8ed1ab_0    conda-forge\ntyping_extensions         4.9.0              pyha770c72_0    conda-forge\ntzdata                    2023d                h04d1e81_0  \nuri-template              1.3.0              pyhd8ed1ab_0    conda-forge\nurllib3                   2.1.0           py311h06a4308_0  \nwcwidth                   0.2.13             pyhd8ed1ab_0    conda-forge\nwebcolors                 1.13               pyhd8ed1ab_0    conda-forge\nwebencodings              0.5.1              pyhd8ed1ab_2    conda-forge\nwebsocket-client          1.7.0              pyhd8ed1ab_0    conda-forge\nwheel                     0.41.2          py311h06a4308_0  \nxz                        5.4.5                h5eee18b_0  \ny-py                      0.5.9           py311h52d8a92_0  \nyaml                      0.2.5                h7f98852_2    conda-forge\nypy-websocket             0.8.2           py311h06a4308_0  \nzeromq                    4.3.5                h6a678d5_0  \nzipp                      3.17.0             pyhd8ed1ab_0    conda-forge\nzlib                      1.2.13               h5eee18b_0  \nzstd                      1.5.5                hc292b87_0"
  },
  {
    "objectID": "연구/보람이랑/신용카드거래 사기탐지/2023-05-19-Try2.html",
    "href": "연구/보람이랑/신용카드거래 사기탐지/2023-05-19-Try2.html",
    "title": "(연구&보람) 신용카드거래 사기탐지 – Try2",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport networkx as nx\nimport sklearn\n\n# sklearn\nfrom sklearn import model_selection # split함수이용\nfrom sklearn import ensemble # RF,GBM\nfrom sklearn import metrics \n\n# embedding \nfrom node2vec import Node2Vec\nfrom node2vec.edges import HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder\n\n/home/cgb2/anaconda3/envs/py38/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n\n\ndef build_graph_bipartite(df_input, graph_type=nx.Graph()):\n    df=df_input.copy()\n    mapping={x:node_id for node_id, x in enumerate(set(df[\"cc_num\"].values.tolist()+\\\n                                                      df[\"merchant\"].values.tolist()))}\n    \n    df[\"from\"]=df[\"cc_num\"].apply(lambda x:mapping[x])  #엣지의 출발점\n    df[\"to\"]=df[\"merchant\"].apply(lambda x:mapping[x])  #엣지의 도착점\n    \n    df = df[['from', 'to', \"amt\", \"is_fraud\"]].groupby(['from','to']).agg({\"is_fraud\":\"sum\",\"amt\":\"sum\"}).reset_index()\n    df[\"is_fraud\"]=df[\"is_fraud\"].apply(lambda x:1 if x&gt;0 else 0)\n    \n    G=nx.from_edgelist(df[[\"from\",\"to\"]].values, create_using=graph_type)\n    \n    nx.set_edge_attributes(G,{(int(x[\"from\"]),int(x[\"to\"])):x[\"is_fraud\"] for idx, x in df[[\"from\",\"to\",\"is_fraud\"]].iterrows()}, \"label\")  #엣지 속성 설정,각 속성의 사기 여부부     \n    nx.set_edge_attributes(G,{(int(x[\"from\"]),int(x[\"to\"])):x[\"amt\"] for idx,x in df[[\"from\",\"to\",\"amt\"]].iterrows()}, \"weight\") # 엣지 속성 설정, 각 엣지의 거래 금액\n\n    return G\n\n\ndef build_graph_tripartite(df_input, graph_type=nx.Graph()):\n    df=df_input.copy()\n    mapping={x:node_id for node_id, x in enumerate(set(df.index.values.tolist() + \n                                                       df[\"cc_num\"].values.tolist() +\n                                                       df[\"merchant\"].values.tolist()))}\n    df[\"in_node\"]= df[\"cc_num\"].apply(lambda x: mapping[x])\n    df[\"out_node\"]=df[\"merchant\"].apply(lambda x:mapping[x])\n    \n        \n    G=nx.from_edgelist([(x[\"in_node\"], mapping[idx]) for idx, x in df.iterrows()] +\\\n                        [(x[\"out_node\"], mapping[idx]) for idx, x in df.iterrows()], create_using=graph_type)\n    \n    nx.set_edge_attributes(G,{(x[\"in_node\"], mapping[idx]):x[\"is_fraud\"] for idx, x in df.iterrows()}, \"label\")     \n    nx.set_edge_attributes(G,{(x[\"out_node\"], mapping[idx]):x[\"is_fraud\"] for idx, x in df.iterrows()}, \"label\")   \n    nx.set_edge_attributes(G,{(x[\"in_node\"], mapping[idx]):x[\"amt\"] for idx, x in df.iterrows()}, \"weight\")  \n    nx.set_edge_attributes(G,{(x[\"out_node\"], mapping[idx]):x[\"amt\"] for idx, x in df.iterrows()}, \"weight\")\n\n    return G\n    \n    \ndef down_sample_textbook(df):\n    df_majority = df[df.is_fraud==0].copy()\n    df_minority = df[df.is_fraud==1].copy()\n    df_maj_dowsampled = sklearn.utils.resample(df_majority, n_samples=len(df_minority), replace=False, random_state=42)\n    df_downsampled = pd.concat([df_minority, df_maj_dowsampled])\n    return df_downsampled\n\ndef embedding(Graph):\n    # Graph -&gt; X (feature)\n    _edgs = list(Graph.edges)\n    subGraph = Graph.edge_subgraph([_edgs[x] for x in range(len(Graph.edges))]).copy()\n    subGraph.add_nodes_from(list(set(Graph.nodes) - set(subGraph.nodes)))    \n    embedded = AverageEmbedder(Node2Vec(subGraph, weight_key='weight').fit(window=10).wv)\n    X = [embedded[str(_edgs[x][0]), str(_edgs[x][1])] for x in range(len(Graph.edges))]\n    # Graph -&gt; y (label)\n    y = np.array(list(nx.get_edge_attributes(Graph, \"label\").values()))\n    return X,y \n\ndef anal(df):\n    Graph = build_graph_bipartite(df)\n    X,XX,y,yy = embedding(Graph)\n    lrnr = RandomForestClassifier(n_estimators=100, random_state=42) \n    lrnr.fit(X,y)\n    yyhat = lrnr.predict(XX)\n    df = pd.DataFrame({\n        'acc':[sklearn.metrics.accuracy_score(yy,yyhat)], \n        'pre':[sklearn.metrics.precision_score(yy,yyhat)], \n        'rec':[sklearn.metrics.recall_score(yy,yyhat)],\n        'f1':[sklearn.metrics.f1_score(yy,yyhat)]}\n    )    \n    return df\n\ndef our_sampling1(df):\n    cus_list = set(df.query('is_fraud==1').cc_num.tolist())\n    return df.query(\"cc_num in @ cus_list\")\n\n\ndef amtano1(df_train):\n    df = df_train.copy()\n    df = df.assign(amtano=0)\n    normalize = lambda arr: (arr-np.median(arr))/np.std(arr) if np.std(arr)!=0 else arr*0 \n    for cc_num, sub_df in df.groupby('cc_num'):\n        df.loc[df.cc_num == cc_num,['amtano']] = normalize(sub_df.amt).cumsum()\n    return df"
  },
  {
    "objectID": "연구/보람이랑/신용카드거래 사기탐지/2023-05-19-Try2.html#데이터-종류",
    "href": "연구/보람이랑/신용카드거래 사기탐지/2023-05-19-Try2.html#데이터-종류",
    "title": "(연구&보람) 신용카드거래 사기탐지 – Try2",
    "section": "데이터 종류",
    "text": "데이터 종류\n\nfraudTrain.csv: (1048575, 23), 기본데이터\ndf02: (214520, 23), is_fraud==0 에서는 20퍼의 샘플만, is_fraud==1 에서는 모든 샘플을 뽑아서 정리한 새로운 자료\ndf50 = (12012, 23), df20에서 is_fraud==0 와 is_fraud==1 의 비율을 맞추어서 샘플을 뽑은 것\n\n\n\n\n\n\n\n\n\n\n데이터\nshape\n사기거래빈도\n설명\n\n\n\n\nfraudTrain\n(1048575, 22)\n0.00573\n원래자료\n\n\ndf02\n(214520, 22)\n0.028\nis_fraud==0 에서는 20퍼의 샘플만, is_fraud==1 에서는 모든 샘플을 뽑아서 정리한 새로운 자료\n\n\ndf50\n(12012, 22)\n0.5\ndf02에서 사기비율을 50퍼로 맞추어 샘플링한 자료\n\n\ndf50_tr\n(9009, 22)\n0.49828\ndf50에서 랜덤으로 train/test를 분리하여 얻은 train dataset\n\n\ndf50_test\n(3003, 22)\n0.50516\ndf50에서 랜덤으로 train/test를 분리하여 얻은 test dataset\n\n\ndf02_tr\n(211517, 22)\n0.02122\ndf02에서 df50_test에 해당하는 인덱스를 제외\n\n\nfraudTrain_tr\n(1045572, 22)\n0.00429\nfraudTrain에서 df50_test에 해당하는 인덱스를 제외\n\n\n\n- fraudTrain\n\nfraudTrain = pd.read_csv(\"fraudTrain.csv\").iloc[:,1:]\n\n\nfraudTrain.is_fraud.mean().round(5)\n\n0.00573\n\n\n- df20\n\n_df1 = fraudTrain[fraudTrain[\"is_fraud\"] == 0].sample(frac=0.20, random_state=42)\n_df2 = fraudTrain[fraudTrain[\"is_fraud\"] == 1]\ndf02 = pd.concat([_df1,_df2])\ndf02.shape\n\n(214520, 22)\n\n\n\ndf02.is_fraud.mean().round(5)\n\n0.028\n\n\n- df50\n\ndf50 = down_sample_textbook(df02)\ndf50.shape\n\n(12012, 22)\n\n\n\ndf50\n\n\n\n\n\n\n\n\ntrans_date_trans_time\ncc_num\nmerchant\ncategory\namt\nfirst\nlast\ngender\nstreet\ncity\n...\nlat\nlong\ncity_pop\njob\ndob\ntrans_num\nunix_time\nmerch_lat\nmerch_long\nis_fraud\n\n\n\n\n2449\n2019-01-02 1:06\n4.613310e+12\nfraud_Rutherford-Mertz\ngrocery_pos\n281.06\nJason\nMurphy\nM\n542 Steve Curve Suite 011\nCollettsville\n...\n35.9946\n-81.7266\n885\nSoil scientist\n1988-09-15\ne8a81877ae9a0a7f883e15cb39dc4022\n1325466397\n36.430124\n-81.179483\n1\n\n\n2472\n2019-01-02 1:47\n3.401870e+14\nfraud_Jenkins, Hauck and Friesen\ngas_transport\n11.52\nMisty\nHart\nF\n27954 Hall Mill Suite 575\nSan Antonio\n...\n29.4400\n-98.4590\n1595797\nHorticultural consultant\n1960-10-28\nbc7d41c41103877b03232f03f1f8d3f5\n1325468849\n29.819364\n-99.142791\n1\n\n\n2523\n2019-01-02 3:05\n3.401870e+14\nfraud_Goodwin-Nitzsche\ngrocery_pos\n276.31\nMisty\nHart\nF\n27954 Hall Mill Suite 575\nSan Antonio\n...\n29.4400\n-98.4590\n1595797\nHorticultural consultant\n1960-10-28\nb98f12f4168391b2203238813df5aa8c\n1325473523\n29.273085\n-98.836360\n1\n\n\n2546\n2019-01-02 3:38\n4.613310e+12\nfraud_Erdman-Kertzmann\ngas_transport\n7.03\nJason\nMurphy\nM\n542 Steve Curve Suite 011\nCollettsville\n...\n35.9946\n-81.7266\n885\nSoil scientist\n1988-09-15\n397894a5c4c02e3c61c784001f0f14e4\n1325475483\n35.909292\n-82.091010\n1\n\n\n2553\n2019-01-02 3:55\n3.401870e+14\nfraud_Koepp-Parker\ngrocery_pos\n275.73\nMisty\nHart\nF\n27954 Hall Mill Suite 575\nSan Antonio\n...\n29.4400\n-98.4590\n1595797\nHorticultural consultant\n1960-10-28\n7863235a750d73a244c07f1fb7f0185a\n1325476547\n29.786426\n-98.683410\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n363827\n2019-06-17 19:30\n2.475090e+15\nfraud_Frami Group\nentertainment\n81.13\nJohn\nMiller\nM\n153 Mccullough Springs Apt. 857\nLamberton\n...\n44.2378\n-95.2739\n1507\nLand/geomatics surveyor\n1993-10-12\nc66cb411019c7dfd4d89f42a1ba4765f\n1339961448\n44.212695\n-95.661879\n0\n\n\n140154\n2019-03-17 14:33\n2.131550e+14\nfraud_Bahringer-Streich\nfood_dining\n55.00\nChristopher\nSheppard\nM\n39218 Baker Shoals\nBristow\n...\n38.1981\n-86.6821\n965\nHorticultural therapist\n1982-02-10\n316b9d25b9fa7d08a6831b7dab6634cd\n1331994839\n38.394240\n-86.413557\n0\n\n\n860597\n2019-12-17 12:31\n2.280870e+15\nfraud_Lubowitz-Walter\nkids_pets\n8.12\nKatherine\nCooper\nF\n3854 Lauren Springs Suite 648\nOakford\n...\n40.0994\n-89.9601\n530\nTransport planner\n1967-09-23\nd92e9e63d9b24c3ccb92d05cba4cac54\n1355747517\n39.695248\n-89.853063\n0\n\n\n29341\n2019-01-18 9:20\n4.878360e+15\nfraud_Denesik and Sons\nshopping_pos\n3.52\nTina\nAlvarez\nF\n1976 Tyler Underpass\nEarly\n...\n42.4483\n-95.1726\n885\nPilot, airline\n1949-08-14\n8390ce51cfb8482b618ebc4ac370bcf7\n1326878457\n42.633204\n-95.598143\n0\n\n\n529797\n2019-08-16 13:17\n4.450830e+15\nfraud_Beier and Sons\nhome\n84.15\nDonna\nDavis\nF\n6760 Donovan Lakes\nClayton\n...\n34.5906\n-95.3800\n1760\nOccupational psychologist\n1972-01-20\n04e1be9bcb18ea8b96048659bd02177b\n1345123058\n33.885236\n-95.885110\n0\n\n\n\n\n12012 rows × 22 columns\n\n\n\n\ndf50.is_fraud.mean().round(5)\n\n0.5\n\n\n- df50_tr, df50_test\n\ndf50_tr,df50_test = sklearn.model_selection.train_test_split(df50, random_state=42)\n\n\ndf50_tr.is_fraud.mean().round(5), df50_test.is_fraud.mean().round(5)\n\n(0.49828, 0.50516)\n\n\n- df02_tr, fraudTrain_tr\n\ndf02_tr = df02.loc[[i not in df50_test.index for i in df02.index],:].copy()\nfraudTrain_tr = fraudTrain.loc[[i not in df50_test.index for i in fraudTrain.index],:].copy()\n\n\ndf02_tr.shape, fraudTrain_tr.shape\n\n((211517, 22), (1045572, 22))\n\n\n\ndf02_tr.is_fraud.mean().round(5), fraudTrain_tr.is_fraud.mean().round(5)\n\n(0.02122, 0.00429)"
  },
  {
    "objectID": "연구/보람이랑/신용카드거래 사기탐지/2024-04-11-결과시각화.html",
    "href": "연구/보람이랑/신용카드거래 사기탐지/2024-04-11-결과시각화.html",
    "title": "Experiment 1(꺾은선)",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\n#import sklearn\nimport pickle \nimport time \nimport datetime\nimport warnings\nimport matplotlib.pyplot as plt\nwarnings.filterwarnings('ignore')\n\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.io as pio\npd.options.plotting.backend = \"plotly\"\npio.templates.default = \"plotly_white\"\n\n\ndf = pd.read_csv('./240404_meged.csv')\ndf = df[['L2' not in l and 'L1' not in l for l in df.model]]\n#df['diff'] = abs(merged_df['train_frate'] - merged_df['test_frate'])\ndf = df[(df.test_frate &lt;= 0.005) & (0.009 &lt; df.train_frate) & (df.train_frate &lt; 0.51)]\n\n\nfig = px.scatter(\n    df,\n    x='train_frate',y='auc',\n    color='method',\n    hover_data='model',\n    opacity=0.2,\n    #---#\n    width = 750,\n    height = 800  \n)\nfig.data[3]['marker']['opacity'] = 0.7\nfig.data[3]['marker']['size'] = 9\nfig\n\n                                                \n\n\n\ndf.sort_values('auc',ascending=False)\n\n\n\n\n\n\n\n\nmodel\ntime\nacc\npre\nrec\nf1\nauc\ngraph_based\nmethod\nthrow_rate\ntrain_size\ntrain_cols\ntrain_frate\ntest_size\ntest_frate\nhyper_params\ntheta\ngamma\n\n\n\n\n449\nLightGBMLarge\nNaN\n0.969253\n0.014235\n1.000000\n0.028070\n0.993073\nFalse\nAuto_not_best\n0.200000\n21021\n['amt']\n0.285524\n9009\n0.000444\nNaN\nNaN\nNaN\n\n\n440\nLightGBM\nNaN\n0.978688\n0.015464\n0.750000\n0.030303\n0.992018\nFalse\nAuto_not_best\n0.200000\n21021\n['amt']\n0.285524\n9009\n0.000444\nNaN\nNaN\nNaN\n\n\n447\nXGBoost\nNaN\n0.976801\n0.014218\n0.750000\n0.027907\n0.986355\nFalse\nAuto_not_best\n0.200000\n21021\n['amt']\n0.285524\n9009\n0.000444\nNaN\nNaN\nNaN\n\n\n596\nLightGBM\nNaN\n0.923909\n0.059794\n0.966667\n0.112621\n0.986175\nFalse\nAuto_not_best\n0.300000\n14014\n['amt']\n0.426431\n6006\n0.004995\nNaN\nNaN\nNaN\n\n\n167\nLightGBMLarge\nNaN\n0.998218\n0.000000\n0.000000\n0.000000\n0.986131\nFalse\nAutogluon\n0.107023\n39284\n['amt']\n0.152123\n16835\n0.001782\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1489\nPCA\n0.002272\n0.366235\n0.000523\n0.225131\n0.001044\n0.295787\nFalse\npyod\n0.018146\n10010\n['amt']\n0.450649\n259642\n0.001471\nNaN\nNaN\nNaN\n\n\n1618\nPCA\n0.002297\n0.367720\n0.000457\n0.204918\n0.000913\n0.286434\nFalse\npyod\n0.048196\n10010\n['amt']\n0.452747\n86555\n0.001410\nNaN\nNaN\nNaN\n\n\n219\nPCA\n0.002264\n0.362902\n0.000490\n0.209302\n0.000978\n0.286217\nFalse\npyod\n0.117780\n10010\n['amt']\n0.453047\n28859\n0.001490\nNaN\nNaN\nNaN\n\n\n633\nPCA\n0.002195\n0.382297\n0.000375\n0.176471\n0.000748\n0.279519\nFalse\npyod\n0.125497\n10010\n['amt']\n0.447453\n25951\n0.001310\nNaN\nNaN\nNaN\n\n\n235\nPCA\n0.002498\n0.419414\n0.000866\n0.100000\n0.001718\n0.260509\nFalse\npyod\n0.300000\n14014\n['amt']\n0.426431\n6006\n0.004995\nNaN\nNaN\nNaN\n\n\n\n\n649 rows × 18 columns"
  },
  {
    "objectID": "연구/보람이랑/신용카드거래 사기탐지/2023-07-19-관련연구 리뷰.html#abstract",
    "href": "연구/보람이랑/신용카드거래 사기탐지/2023-07-19-관련연구 리뷰.html#abstract",
    "title": "(연구&보람) 신용카드거래 사기탐지 – 관련연구 리뷰",
    "section": "Abstract",
    "text": "Abstract\n이 논문에서는 최근 몇 년간 그래프 신경망(Graph Neural Networks, GNNs)이 사기 탐지 문제에 널리 적용되어, 다양한 관계를 통해 이웃 정보를 집계함으로써 노드의 수상성을 밝혀내는 것을 소개하고 있습니다. 그러나 몇몇 이전 연구들은 사기꾼들의 가장 큰 문제인 위장 행위(camouflage behavior)에 주목하지 않았습니다. 이러한 위장 행위는 GNN 기반 사기 탐지기의 집계 과정에서 성능을 저하시킬 수 있습니다. 따라서 이 논문에서는 최근의 경험적 연구를 기반으로 두 가지 유형의 위장 행위, 즉 특성 위장과 관계 위장을 소개하고 있습니다. 기존의 GNN은 이러한 두 가지 위장 행위에 대응하지 않았기 때문에 사기 탐지 문제에서 성능이 떨어지는 것입니다. 이에 대응하여 새로운 모델인 CAmouflage-REsistant GNN (CARE-GNN)을 제안하고 있으며, 이 모델은 위장 행위에 대응하기 위해 세 가지 독특한 모듈을 포함하고 있습니다. 구체적으로, 먼저 정보성이 있는 이웃 노드를 찾기 위해 레이블 기반 유사도 측정 방법을 고안합니다. 그런 다음, 강화 학습 (Reinforcement Learning, RL)을 활용하여 선택할 최적의 이웃 수를 결정합니다. 마지막으로, 다양한 관계 사이에서 선택된 이웃들을 함께 집계합니다. 두 개의 실제 사기 데이터셋에 대한 포괄적인 실험을 통해 RL 알고리즘의 효과를 입증하였습니다. 제안된 CARE-GNN은 최첨단 GNN 및 GNN 기반 사기 탐지기보다 뛰어난 성능을 보여줍니다. 또한, 모든 GNN 기반 사기 탐지기를 통합하여 오픈 소스 도구 상자(https://github.com/YingtongDou/CARE-GNN)로 제공하고 있습니다. CARE-GNN 코드와 데이터셋을 이용할 수 있습니다.]"
  },
  {
    "objectID": "연구/보람이랑/신용카드거래 사기탐지/2023-07-19-관련연구 리뷰.html#introduction",
    "href": "연구/보람이랑/신용카드거래 사기탐지/2023-07-19-관련연구 리뷰.html#introduction",
    "title": "(연구&보람) 신용카드거래 사기탐지 – 관련연구 리뷰",
    "section": "Introduction",
    "text": "Introduction\n인터넷 서비스의 번창과 함께 다양한 유형의 사기 행위도 발생하고 있습니다 [14]. 사기꾼들은 일반 사용자로 위장하여 안티 사기 시스템을 우회하고 불명확한 정보를 퍼뜨리거나 최종 사용자의 개인정보를 빼앗습니다 [32]. 이러한 사기 행위를 탐지하기 위해 그래프 기반 방법이 학계 [7, 21, 38]와 산업계 [2, 28, 50] 모두에서 효과적인 접근 방법이 되었습니다. 그래프 기반 방법은 서로 다른 관계로 엔티티를 연결하고, 동일한 목표를 가진 사기꾼들은 서로 연결되기 때문에 이러한 엔티티들의 수상성을 그래프 수준에서 드러낼 수 있습니다 [1].\n최근에는 그래프 신경망(Graph Neural Networks, GNNs)의 발전으로 많은 GNN 기반 사기 탐지기들이 제안되었습니다. (예: GCN [17], GAT [34], 그리고 GraphSAGE [12]) 이들은 의견 사기 [19, 25, 39], 금융 사기 [23, 24, 37], 모바일 사기 [41], 그리고 사이버 범죄 [48]를 탐지하기 위해 사용됩니다. 기존의 전통적인 그래프 기반 접근 방법과는 달리, GNN 기반 방법은 이웃 정보를 집계하여 중심 노드의 표현을 학습합니다. 이들은 end-to-end 및 반지도 학습 방식으로 훈련될 수 있으며, 이는 많은 특성 엔지니어링과 데이터 주석 비용을 절약할 수 있습니다.\n그러나 기존의 GNN 기반 사기 탐지 연구들은 GNN을 제한적인 범위에서만 적용하면서 사기꾼들의 위장 행위를 무시하고 있습니다. 이러한 위장 행위는 연구자들 [8, 15, 16, 49]과 실무자들 [2, 19, 41] 양쪽에서 큰 관심을 받고 있습니다. 한편, 이론적인 연구들은 그래프에 노이즈가 있는 노드와 엣지가 있는 경우 GNN의 한계와 취약점을 입증하고 있습니다 [3, 4, 13, 33]. 따라서, 위장된 사기꾼들에 대응하지 못한다면 GNN 기반 사기 탐지기의 성능을 저하시킬 수 있습니다. 최근 몇몇 연구들 [4, 9, 13, 25, 41]은 비슷한 도전에 주목했지만, 이들의 해결책은 사기 탐지 문제에 적합하지 않거나 GNN의 end-to-end 학습 방식을 파괴하는 경우가 있습니다."
  },
  {
    "objectID": "연구/보람이랑/신용카드거래 사기탐지/2024-01-18-pygod 셋팅.html",
    "href": "연구/보람이랑/신용카드거래 사기탐지/2024-01-18-pygod 셋팅.html",
    "title": "(연구&보람) 신용카드거래 사기탐지 – pygod 셋팅",
    "section": "",
    "text": "- 환경셋팅\nconda create -n pyod \nconda activate pyod\nconda install -c conda-forge pyod\n- 실행해볼코드\nfrom pygod.utils import load_data\nfrom pygod.detector import DOMINANT\n\ndata = load_data('inj_cora')\ndetector = DOMINANT(hid_dim=64, num_layers=4, epoch=100)\ndetector.fit(data)\n\n!cat pygod_env.txt\n\n# packages in environment at /home/cgb2/anaconda3/envs/pygod:\n#\n# Name                    Version                   Build  Channel\n_libgcc_mutex             0.1                        main  \n_openmp_mutex             5.1                       1_gnu  \nblas                      1.0                         mkl  \nbrotli-python             1.0.9           py311h6a678d5_7  \nbzip2                     1.0.8                h7b6447c_0  \nca-certificates           2023.12.12           h06a4308_0  \ncertifi                   2023.11.17      py311h06a4308_0  \ncffi                      1.16.0          py311h5eee18b_0  \ncharset-normalizer        2.0.4              pyhd3eb1b0_0  \ncryptography              41.0.7          py311hdda0065_0  \ncuda-cudart               12.1.105                      0    nvidia\ncuda-cupti                12.1.105                      0    nvidia\ncuda-libraries            12.1.0                        0    nvidia\ncuda-nvrtc                12.1.105                      0    nvidia\ncuda-nvtx                 12.1.105                      0    nvidia\ncuda-opencl               12.3.101                      0    nvidia\ncuda-runtime              12.1.0                        0    nvidia\nffmpeg                    4.3                  hf484d3e_0    pytorch\nfilelock                  3.13.1          py311h06a4308_0  \nfreetype                  2.12.1               h4a9f257_0  \ngiflib                    5.2.1                h5eee18b_3  \ngmp                       6.2.1                h295c915_3  \ngmpy2                     2.1.2           py311hc9b5ff0_0  \ngnutls                    3.6.15               he1e5248_0  \nidna                      3.4             py311h06a4308_0  \nintel-openmp              2023.1.0         hdb19cb5_46306  \njinja2                    3.1.2           py311h06a4308_0  \njoblib                    1.2.0           py311h06a4308_0  \njpeg                      9e                   h5eee18b_1  \nlame                      3.100                h7b6447c_0  \nlcms2                     2.12                 h3be6417_0  \nld_impl_linux-64          2.38                 h1181459_1  \nlerc                      3.0                  h295c915_0  \nlibcublas                 12.1.0.26                     0    nvidia\nlibcufft                  11.0.2.4                      0    nvidia\nlibcufile                 1.8.1.2                       0    nvidia\nlibcurand                 10.3.4.107                    0    nvidia\nlibcusolver               11.4.4.55                     0    nvidia\nlibcusparse               12.0.2.55                     0    nvidia\nlibdeflate                1.17                 h5eee18b_1  \nlibffi                    3.4.4                h6a678d5_0  \nlibgcc-ng                 11.2.0               h1234567_1  \nlibgfortran-ng            11.2.0               h00389a5_1  \nlibgfortran5              11.2.0               h1234567_1  \nlibgomp                   11.2.0               h1234567_1  \nlibiconv                  1.16                 h7f8727e_2  \nlibidn2                   2.3.4                h5eee18b_0  \nlibjpeg-turbo             2.0.0                h9bf148f_0    pytorch\nlibnpp                    12.0.2.50                     0    nvidia\nlibnvjitlink              12.1.105                      0    nvidia\nlibnvjpeg                 12.1.1.14                     0    nvidia\nlibpng                    1.6.39               h5eee18b_0  \nlibstdcxx-ng              11.2.0               h1234567_1  \nlibtasn1                  4.19.0               h5eee18b_0  \nlibtiff                   4.5.1                h6a678d5_0  \nlibunistring              0.9.10               h27cfd23_0  \nlibuuid                   1.41.5               h5eee18b_0  \nlibwebp                   1.3.2                h11a3e52_0  \nlibwebp-base              1.3.2                h5eee18b_0  \nllvm-openmp               14.0.6               h9e868ea_0  \nlz4-c                     1.9.4                h6a678d5_0  \nmarkupsafe                2.1.3           py311h5eee18b_0  \nmkl                       2023.1.0         h213fc3f_46344  \nmkl-service               2.4.0           py311h5eee18b_1  \nmkl_fft                   1.3.8           py311h5eee18b_0  \nmkl_random                1.2.4           py311hdb19cb5_0  \nmpc                       1.1.0                h10f8cd9_1  \nmpfr                      4.0.2                hb69a4c5_1  \nmpmath                    1.3.0           py311h06a4308_0  \nncurses                   6.4                  h6a678d5_0  \nnettle                    3.7.3                hbbd107a_1  \nnetworkx                  3.1             py311h06a4308_0  \nnumpy                     1.26.3          py311h08b1b3b_0  \nnumpy-base                1.26.3          py311hf175353_0  \nopenh264                  2.1.1                h4ff587b_0  \nopenjpeg                  2.4.0                h3ad879b_0  \nopenssl                   3.0.12               h7f8727e_0  \npillow                    10.0.1          py311ha6cbd5a_0  \npip                       23.3.1          py311h06a4308_0  \npsutil                    5.9.0           py311h5eee18b_0  \npycparser                 2.21               pyhd3eb1b0_0  \npyg                       2.4.0           py311_torch_2.1.0_cu121    pyg\npygod                     1.0.0                    pypi_0    pypi\npyopenssl                 23.2.0          py311h06a4308_0  \npyparsing                 3.0.9           py311h06a4308_0  \npysocks                   1.7.1           py311h06a4308_0  \npython                    3.11.7               h955ad1f_0  \npytorch                   2.1.2           py3.11_cuda12.1_cudnn8.9.2_0    pytorch\npytorch-cuda              12.1                 ha16c6d3_5    pytorch\npytorch-mutex             1.0                        cuda    pytorch\npytorch-scatter           2.1.2           py311_torch_2.1.0_cu121    pyg\npytorch-sparse            0.6.18          py311_torch_2.1.0_cu121    pyg\npyyaml                    6.0.1           py311h5eee18b_0  \nreadline                  8.2                  h5eee18b_0  \nrequests                  2.31.0          py311h06a4308_0  \nscikit-learn              1.2.2           py311h6a678d5_1  \nscipy                     1.11.4          py311h08b1b3b_0  \nsetuptools                68.2.2          py311h06a4308_0  \nsqlite                    3.41.2               h5eee18b_0  \nsympy                     1.12            py311h06a4308_0  \ntbb                       2021.8.0             hdb19cb5_0  \nthreadpoolctl             2.2.0              pyh0d69192_0  \ntk                        8.6.12               h1ccaba5_0  \ntorchaudio                2.1.2               py311_cu121    pytorch\ntorchtriton               2.1.0                     py311    pytorch\ntorchvision               0.16.2              py311_cu121    pytorch\ntqdm                      4.65.0          py311h92b7b1e_0  \ntyping_extensions         4.9.0           py311h06a4308_0  \ntzdata                    2023d                h04d1e81_0  \nurllib3                   1.26.18         py311h06a4308_0  \nwheel                     0.41.2          py311h06a4308_0  \nxz                        5.4.5                h5eee18b_0  \nyaml                      0.2.5                h7b6447c_0  \nzlib                      1.2.13               h5eee18b_0  \nzstd                      1.5.5                hc292b87_0"
  },
  {
    "objectID": "연구/보람이랑/CTGAN/2023-07-03-신용카드.html",
    "href": "연구/보람이랑/CTGAN/2023-07-03-신용카드.html",
    "title": "(연구&보람) CTGAN – 신용카드",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \n\n\n# from ctgan import CTGAN\n# from ctgan import load_demo\n\n\nfrom sklearn import model_selection # split함수이용\nfrom sklearn import ensemble # RF,GBM\nfrom sklearn import metrics \n\n\ndef down_sample_textbook(df):\n    df_majority = df[df.is_fraud==0].copy()\n    df_minority = df[df.is_fraud==1].copy()\n    df_maj_dowsampled = sklearn.utils.resample(df_majority, n_samples=len(df_minority), replace=False, random_state=42)\n    df_downsampled = pd.concat([df_minority, df_maj_dowsampled])\n    return df_downsampled"
  },
  {
    "objectID": "연구/보람이랑/CTGAN/2023-07-03-신용카드.html#데이터-종류",
    "href": "연구/보람이랑/CTGAN/2023-07-03-신용카드.html#데이터-종류",
    "title": "(연구&보람) CTGAN – 신용카드",
    "section": "데이터 종류",
    "text": "데이터 종류\n\nfraudTrain.csv: (1048575, 23), 기본데이터\ndf02: (214520, 23), is_fraud==0 에서는 20퍼의 샘플만, is_fraud==1 에서는 모든 샘플을 뽑아서 정리한 새로운 자료\ndf50 = (12012, 23), df20에서 is_fraud==0 와 is_fraud==1 의 비율을 맞추어서 샘플을 뽑은 것\n\n\n\n\n\n\n\n\n\n\n데이터\nshape\n사기거래빈도\n설명\n\n\n\n\nfraudTrain\n(1048575, 22)\n0.00573\n원래자료\n\n\ndf02\n(214520, 22)\n0.028\nis_fraud==0 에서는 20퍼의 샘플만, is_fraud==1 에서는 모든 샘플을 뽑아서 정리한 새로운 자료\n\n\ndf50\n(12012, 22)\n0.5\ndf02에서 사기비율을 50퍼로 맞추어 샘플링한 자료\n\n\ndf50_tr\n(9009, 22)\n0.49828\ndf50에서 랜덤으로 train/test를 분리하여 얻은 train dataset\n\n\ndf50_test\n(3003, 22)\n0.50516\ndf50에서 랜덤으로 train/test를 분리하여 얻은 test dataset\n\n\ndf02_tr\n(211517, 22)\n0.02122\ndf02에서 df50_test에 해당하는 인덱스를 제외\n\n\nfraudTrain_tr\n(1045572, 22)\n0.00429\nfraudTrain에서 df50_test에 해당하는 인덱스를 제외\n\n\n\n- fraudTrain\n\nfraudTrain = pd.read_csv(\"fraudTrain.csv\").iloc[:,1:]\n\n\nfraudTrain.columns\n\nIndex(['trans_date_trans_time', 'cc_num', 'merchant', 'category', 'amt',\n       'first', 'last', 'gender', 'street', 'city', 'state', 'zip', 'lat',\n       'long', 'city_pop', 'job', 'dob', 'trans_num', 'unix_time', 'merch_lat',\n       'merch_long', 'is_fraud'],\n      dtype='object')\n\n\n\nfraudTrain['is_fraud']\n\n0          0\n1          0\n2          0\n3          0\n4          0\n          ..\n1048570    0\n1048571    0\n1048572    0\n1048573    0\n1048574    0\nName: is_fraud, Length: 1048575, dtype: int64\n\n\n\nfraudTrain.is_fraud.mean().round(5)\n\n0.00573\n\n\n- df20\n\n_df1 = fraudTrain[fraudTrain[\"is_fraud\"] == 0].sample(frac=0.20, random_state=42)\n_df2 = fraudTrain[fraudTrain[\"is_fraud\"] == 1]\ndf02 = pd.concat([_df1,_df2])\ndf02.shape\n\n(214520, 22)\n\n\n\ndf02.is_fraud.mean().round(5)\n\n0.028\n\n\n- df50\n\ndf50 = down_sample_textbook(df02)\ndf50.shape\n\nNameError: name 'sklearn' is not defined\n\n\n\ndf50\n\nNameError: name 'df50' is not defined\n\n\n\ndf50.is_fraud.mean().round(5)\n\n0.5\n\n\n- df50_tr, df50_test\n\ndf50_tr,df50_test = sklearn.model_selection.train_test_split(df50, random_state=42)\n\n\ndf50_tr.is_fraud.mean().round(5), df50_test.is_fraud.mean().round(5)\n\n(0.49828, 0.50516)\n\n\n- df02_tr, fraudTrain_tr\n\ndf02_tr = df02.loc[[i not in df50_test.index for i in df02.index],:].copy()\nfraudTrain_tr = fraudTrain.loc[[i not in df50_test.index for i in fraudTrain.index],:].copy()\n\n\ndf02_tr.shape, fraudTrain_tr.shape\n\n((211517, 22), (1045572, 22))\n\n\n\ndf02_tr.is_fraud.mean().round(5), fraudTrain_tr.is_fraud.mean().round(5)\n\n(0.02122, 0.00429)"
  },
  {
    "objectID": "지윤.html",
    "href": "지윤.html",
    "title": "지윤",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nAug 14, 2023\n\n\n(연구&지윤) 태양광자료분석 – GConvLSTM +++++++ 이거!!! ++++++++++++\n\n\nJiyunLim \n\n\n\n\nJul 20, 2023\n\n\n(연구&지윤) 태양광자료분석 – EPT + RGCN (시뮬레이션)\n\n\n신록예찬 \n\n\n\n\nJul 17, 2023\n\n\n(연구&지윤) 태양광자료분석 – EPT + RGCN\n\n\n신록예찬 \n\n\n\n\nApr 4, 2023\n\n\n(연구&지윤) 태양광자료분석\n\n\n신록예찬 \n\n\n\n\nApr 3, 2023\n\n\n(연구&지윤) 태양광자료분석 – 일사량자료정리\n\n\n임지윤, 신록예찬\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "연구.html",
    "href": "연구.html",
    "title": "연구",
    "section": "",
    "text": "나혼자: 나혼자\n교수님이랑: 교수님이랑\n학생들이랑: 재인이랑, 서연이랑, 보람이랑, 지윤이랑\n\n\n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\n \n\n\n(연구&교수님) EBT – 첫 논문 재현 // 11월28일 다시~!\n\n\n \n\n\n\n\nAug 14, 2024\n\n\n(연구&서연) Ebayesthresh Layer\n\n\n최규빈 \n\n\n\n\nAug 14, 2024\n\n\n(연구&서연) GODE – CLT\n\n\n최규빈 \n\n\n\n\nAug 14, 2024\n\n\n(연구&서연) GODE – Ex2 Distance Histogram 시각화\n\n\n최규빈 \n\n\n\n\nAug 14, 2024\n\n\n(연구&서연) GODE – Ex2 Distance의분포/Kappa에따른AUC 시각화\n\n\n최규빈 \n\n\n\n\nAug 14, 2024\n\n\n(연구&서연) GODE – Ex2 Kappa에 따른 성능 시각화\n\n\n최규빈 \n\n\n\n\nAug 14, 2024\n\n\n(연구&서연) GODE – Ex2 Kappa에 따른 성능 시각화\n\n\n최규빈 \n\n\n\n\nAug 12, 2024\n\n\n(연구&서연) GODE – 환경설정\n\n\n최규빈 \n\n\n\n\nAug 6, 2024\n\n\n(연구&교수님) 다중척도논문 – EMD 2\n\n\n최규빈 \n\n\n\n\nAug 1, 2024\n\n\n(연구&교수님) EBT – 첫 논문 재현\n\n\n최규빈 \n\n\n\n\nAug 1, 2024\n\n\n(연구&교수님) EBT – 첫 논문 재현 // 2024년 8월\n\n\n최규빈 \n\n\n\n\nJul 30, 2024\n\n\n(연구&교수님) EBT – ECG 자료 시각화\n\n\n최규빈 \n\n\n\n\nJul 27, 2024\n\n\n(연구&교수님) 다중척도논문 – TPT-FirstFig\n\n\n최규빈 \n\n\n\n\nJul 24, 2024\n\n\n(연구&교수님) 다중척도논문 – TPT, 미국지수분석\n\n\n최규빈 \n\n\n\n\nJul 24, 2024\n\n\n(연구&교수님) 다중척도논문 – TPT, 미국지수분석 (2)\n\n\n최규빈 \n\n\n\n\nJul 23, 2024\n\n\n(연구&교수님) 다중척도논문 – Beat\n\n\n최규빈 \n\n\n\n\nJul 23, 2024\n\n\n(연구&교수님) 다중척도논문 – FFT\n\n\n최규빈 \n\n\n\n\nJul 22, 2024\n\n\n(연구&교수님) 다중척도논문 – TPT, TPMA 설명\n\n\n최규빈 \n\n\n\n\nJul 22, 2024\n\n\n(연구&교수님) 다중척도논문 – librosa\n\n\n최규빈 \n\n\n\n\nJul 17, 2024\n\n\n(연구) graft – tutorial 2\n\n\n신록예찬 \n\n\n\n\nJul 10, 2024\n\n\n(연구&교수님) 다중척도논문 – DWT\n\n\n최규빈 \n\n\n\n\nJul 10, 2024\n\n\n(연구&교수님) 다중척도논문 – EMD\n\n\n최규빈 \n\n\n\n\nJul 10, 2024\n\n\n(연구&교수님) 다중척도논문 – STFT\n\n\n최규빈 \n\n\n\n\nJul 10, 2024\n\n\n(연구&교수님) 다중척도논문 – SiZer\n\n\n최규빈 \n\n\n\n\nJul 10, 2024\n\n\n(연구&교수님) 다중척도논문 – 그림들\n\n\n최규빈 \n\n\n\n\nJun 9, 2024\n\n\n(연구&교수님) 다중척도논문 – 환경설정\n\n\n최규빈 \n\n\n\n\nMay 2, 2024\n\n\n(연구&보람) AutoGluon\n\n\n김보람 \n\n\n\n\nMay 2, 2024\n\n\n(연구&보람) GCN (시뮬레이션)\n\n\n김보람 \n\n\n\n\nApr 24, 2024\n\n\n(연구&보람) 데이터정리\n\n\n김보람 \n\n\n\n\nApr 3, 2024\n\n\n(연구&보람) 결과시각화 – Experiment 1\n\n\n김보람 \n\n\n\n\nApr 3, 2024\n\n\nExperiment 1(꺾은선)\n\n\n김보람 \n\n\n\n\nJan 25, 2024\n\n\n(연구&보람) 신용카드거래 사기탐지 – pyod 사용\n\n\n신록예찬,김보람 \n\n\n\n\nJan 24, 2024\n\n\n(연구&서연) IT-STGCN – ToyExam\n\n\nSEOYEON CHOI\n\n\n\n\nJan 19, 2024\n\n\n(연구) gglitely – 서브플랏\n\n\n신록예찬 \n\n\n\n\nJan 19, 2024\n\n\n(연구) gglitely – 연계\n\n\n신록예찬 \n\n\n\n\nJan 19, 2024\n\n\n(연구) gglitely – 튜토리얼\n\n\n신록예찬 \n\n\n\n\nJan 18, 2024\n\n\n(연구&보람) 신용카드거래 사기탐지 – pygod 셋팅\n\n\n신록예찬,김보람 \n\n\n\n\nJan 16, 2024\n\n\n(연구&교수님) EBT – 미구현코드\n\n\n최규빈 \n\n\n\n\nJan 15, 2024\n\n\n(연구) gglite – 내부기능\n\n\n신록예찬 \n\n\n\n\nJan 15, 2024\n\n\n(연구) gglite – 튜토리얼\n\n\n신록예찬 \n\n\n\n\nJan 8, 2024\n\n\n(연구&서연) IT-STGCN – 실험결과시각화\n\n\nSEOYEON CHOI\n\n\n\n\nDec 27, 2023\n\n\n(연구&재인) MBTI(정리) – 논문그림정리\n\n\n신록예찬 \n\n\n\n\nDec 22, 2023\n\n\n(연구&재인) MBTI(정리) – 실험결과 시각화\n\n\n신록예찬 \n\n\n\n\nDec 21, 2023\n\n\n(연구&재인) MBTI(정리) – TabularPredictor 실험\n\n\n신록예찬 \n\n\n\n\nDec 20, 2023\n\n\n(연구&재인) MBTI(정리) – 실험셋업 시각화\n\n\n신록예찬 \n\n\n\n\nDec 19, 2023\n\n\n(연구&재인) MBTI(정리) – 실험셋업\n\n\n신록예찬 \n\n\n\n\nDec 13, 2023\n\n\n(연구&재인) MBTI – 추가자료분석 (429)\n\n\n신록예찬 \n\n\n\n\nDec 13, 2023\n\n\n(연구&재인) MBTI – 추가자료분석 (all)\n\n\n신록예찬 \n\n\n\n\nNov 9, 2023\n\n\n(연구) graft – tutorial\n\n\n신록예찬 \n\n\n\n\nOct 12, 2023\n\n\n(연구&재인) MBTI – MBTI\n\n\n신록예찬 \n\n\n\n\nOct 11, 2023\n\n\n(연구&재인) MBTI – 감성분석\n\n\n신록예찬 \n\n\n\n\nSep 14, 2023\n\n\n(연구&서연) IT-STGCN – 논문리비전\n\n\n최서연 \n\n\n\n\nAug 25, 2023\n\n\n(연구&보람) 신용카드거래 사기탐지 – 데이터(8, df02)커널죽음\n\n\n김보람 \n\n\n\n\nAug 18, 2023\n\n\n(연구&교수님) EPT-DISSIM – PRCP_KOR2 데이터정리\n\n\n신록예찬 \n\n\n\n\nAug 14, 2023\n\n\n(연구&지윤) 태양광자료분석 – GConvLSTM +++++++ 이거!!! ++++++++++++\n\n\nJiyunLim \n\n\n\n\nAug 8, 2023\n\n\n(연구&교수님) EPT-DISSIM – 진행사항\n\n\n신록예찬 \n\n\n\n\nAug 7, 2023\n\n\n(연구&교수님) EPT-DISSIM – PRCP_KOR 데이터정리\n\n\n신록예찬 \n\n\n\n\nJul 30, 2023\n\n\n(연구&보람) CTGAN – 신용카드\n\n\n신록예찬 \n\n\n\n\nJul 20, 2023\n\n\n(연구&지윤) 태양광자료분석 – EPT + RGCN (시뮬레이션)\n\n\n신록예찬 \n\n\n\n\nJul 19, 2023\n\n\n(연구&보람) 신용카드거래 사기탐지 – 관련연구 리뷰\n\n\n신록예찬 \n\n\n\n\nJul 19, 2023\n\n\n(연구&보람) 신용카드거래 사기탐지 – 그래프자료로 데이터정리\n\n\n신록예찬 \n\n\n\n\nJul 17, 2023\n\n\n(연구&지윤) 태양광자료분석 – EPT + RGCN\n\n\n신록예찬 \n\n\n\n\nJul 12, 2023\n\n\n(연구&교수님) old_hst\n\n\n신록예찬 \n\n\n\n\nJul 12, 2023\n\n\n(연구&교수님) 그래프신호만들고시각화하기\n\n\n신록예찬 \n\n\n\n\nJul 12, 2023\n\n\n(연구&교수님) 링형태의자료만들기\n\n\n신록예찬 \n\n\n\n\nJul 1, 2023\n\n\n(연구&보람) CTGAN – Start\n\n\n신록예찬 \n\n\n\n\nJul 1, 2023\n\n\n(연구&보람) CTGAN – TOY\n\n\n신록예찬 \n\n\n\n\nMay 19, 2023\n\n\n(연구&보람) 신용카드거래 사기탐지 – Try2\n\n\n신록예찬 \n\n\n\n\nMay 19, 2023\n\n\n(연구&보람) 신용카드거래 사기탐지 – Try2변형\n\n\n신록예찬 \n\n\n\n\nMay 12, 2023\n\n\n(연구&보람) 신용카드거래 사기탐지 – Try1\n\n\n신록예찬 \n\n\n\n\nMay 12, 2023\n\n\n(연구&보람) 신용카드거래 사기탐지 – Try1변형\n\n\n신록예찬 \n\n\n\n\nMay 6, 2023\n\n\n(연구&보람) 신용카드거래 사기탐지 – Start\n\n\n신록예찬 \n\n\n\n\nApr 27, 2023\n\n\n(연구&서연) IT-STGCN – Toy Example Figure(Intro)\n\n\n최서연 \n\n\n\n\nApr 4, 2023\n\n\n(연구&지윤) 태양광자료분석\n\n\n신록예찬 \n\n\n\n\nApr 3, 2023\n\n\n(연구&지윤) 태양광자료분석 – 일사량자료정리\n\n\n임지윤, 신록예찬\n\n\n\n\nMar 18, 2023\n\n\n(연구&서연) IT-STGCN – SimualtionPlanner-Tutorial\n\n\nSEOYEON CHOI\n\n\n\n\nMar 17, 2023\n\n\n(연구&서연) IT-STGCN – ITSTGCN-Tutorial\n\n\nSEOYEON CHOI\n\n\n\n\nDec 30, 2022\n\n\n(연구&서연) IT-STGCN – Toy Example\n\n\n신록예찬 \n\n\n\n\nDec 29, 2022\n\n\n(연구&서연) IT-STGCN – Tables\n\n\n신록예찬 \n\n\n\n\nDec 29, 2022\n\n\n(연구&서연) IT-STGCN – Tutorial\n\n\n신록예찬, 최서연\n\n\n\n\nDec 10, 2021\n\n\n(연구&교수님) HST example 3\n\n\n신록예찬 \n\n\n\n\nOct 29, 2021\n\n\n(연구&교수님) HST example 3, 파이썬으로 변경\n\n\n신록예찬 \n\n\n\n\nSep 18, 2021\n\n\n(연구&교수님) hst plots\n\n\n신록예찬 \n\n\n\n\nAug 15, 2021\n\n\n(연구&교수님) HST example 3\n\n\n신록예찬 \n\n\n\n\nAug 9, 2021\n\n\n(연구&교수님) HST example 1, Appendix 추가 (1)\n\n\n신록예찬 \n\n\n\n\nAug 9, 2021\n\n\n(연구&교수님) HST example 1, Appendix 추가 (2)\n\n\n신록예찬 \n\n\n\n\nAug 9, 2021\n\n\n(연구&교수님) HST example 2 (1)\n\n\n신록예찬 \n\n\n\n\nAug 9, 2021\n\n\n(연구&교수님) HST example 2 (2)\n\n\n신록예찬 \n\n\n\n\nAug 9, 2021\n\n\n(연구&교수님) HST example 2 (3)\n\n\n신록예찬 \n\n\n\n\nAug 9, 2021\n\n\n(연구&교수님) HST example 2 (4)\n\n\n신록예찬 \n\n\n\n\nAug 9, 2021\n\n\n(연구&교수님) HST example 2 (5)\n\n\n신록예찬 \n\n\n\n\nAug 9, 2021\n\n\n(연구&교수님) HST example 2 (6)\n\n\n신록예찬 \n\n\n\n\nAug 9, 2021\n\n\n(연구&교수님) HST example 2 (7)\n\n\n신록예찬 \n\n\n\n\nAug 9, 2021\n\n\n(연구&교수님) HST example 2 이거로하자\n\n\n신록예찬 \n\n\n\n\nAug 5, 2021\n\n\n(연구&교수님) HST example 1, Appendix 추가\n\n\n신록예찬 \n\n\n\n\nAug 5, 2021\n\n\n(연구&교수님) HST example 2, Appendix 추가\n\n\n신록예찬 \n\n\n\n\nAug 5, 2021\n\n\n(연구&교수님) HST 이론개발\n\n\n신록예찬 \n\n\n\n\nAug 3, 2021\n\n\n(연구&교수님) HST example 2 (1)\n\n\n신록예찬 \n\n\n\n\nAug 3, 2021\n\n\n(연구&교수님) HST example 2 (2)\n\n\n신록예찬 \n\n\n\n\nAug 3, 2021\n\n\n(연구&교수님) HST example 2 (3)\n\n\n신록예찬 \n\n\n\n\nAug 3, 2021\n\n\n(연구&교수님) HST example 2 (4), 결과좋다\n\n\n신록예찬 \n\n\n\n\nAug 3, 2021\n\n\n(연구&교수님) HST example 2 (5)\n\n\n신록예찬 \n\n\n\n\nAug 3, 2021\n\n\n(연구&교수님) HST example 2 (6)\n\n\n신록예찬 \n\n\n\n\nAug 3, 2021\n\n\n(연구&교수님) HST example 2 (7)\n\n\n신록예찬 \n\n\n\n\nAug 3, 2021\n\n\n(연구&교수님) HST example 2 (8)\n\n\n신록예찬 \n\n\n\n\nAug 2, 2021\n\n\n(연구&교수님) HST example 1 (1)\n\n\n신록예찬 \n\n\n\n\nAug 2, 2021\n\n\n(연구&교수님) HST example 1 (2)\n\n\n신록예찬 \n\n\n\n\nAug 2, 2021\n\n\n(연구&교수님) HST example 1 (3)\n\n\n신록예찬 \n\n\n\n\nAug 2, 2021\n\n\n(연구&교수님) HST example 1 (4)\n\n\n신록예찬 \n\n\n\n\nAug 2, 2021\n\n\n(연구&교수님) HST example 1 (5), 이것도 좋아\n\n\n신록예찬 \n\n\n\n\nAug 2, 2021\n\n\n(연구&교수님) HST example 1 (6)\n\n\n신록예찬 \n\n\n\n\nAug 2, 2021\n\n\n(연구&교수님) HST example 1 (7)\n\n\n신록예찬 \n\n\n\n\nAug 2, 2021\n\n\n(연구&교수님) HST example 1 (8), 결과좋음\n\n\n신록예찬 \n\n\n\n\nJul 27, 2021\n\n\n(연구&교수님) HST example 2\n\n\n신록예찬 \n\n\n\n\nJul 22, 2021\n\n\n(연구&교수님) HST example 1\n\n\n신록예찬 \n\n\n\n\nJul 14, 2021\n\n\n(연구&교수님) HST old exam (Python)\n\n\n신록예찬 \n\n\n\n\nJul 14, 2021\n\n\n(연구&교수님) HST old exam (R)\n\n\n신록예찬 \n\n\n\n\n\nNo matching items",
    "crumbs": [
      "DL2024",
      "연구"
    ]
  },
  {
    "objectID": "메모/2000-01-09-(메모) docker.html",
    "href": "메모/2000-01-09-(메모) docker.html",
    "title": "(메모) docker",
    "section": "",
    "text": "- 우분투에서 설치\nref: https://docs.docker.com/engine/install/ubuntu/\n\n1. 기본명령어\n- 기본명령들\n## 이미지 \ndocker images \ndocker image pull penguin \ndocker run {이미지이름}\ndocker image ls {이미지이름} # 특정 이미지의 버전을 명시하여 해당 이미지의 정보를 확인.\ndocker image history {이미지이름} # 특정 이미지의 레이어별 변경 내역을 확인.\n\n## 컨테이너\ndocker ps \ndocker ps -a \ndocker start {컨테이너이름or컨테이너ID}\ndocker stop {컨테이너이름or컨테이너ID}\ndocker rm {컨테이너이름or컨테이너ID} # 컨테이너가 중단된 상태에서 실행해야함\ndocker container inspect {컨테이너이름or컨테이너ID} # 특정 컨테이너의 자세한 정보를 확인.\ndocker logs {컨테이너이름or컨테이너ID} # 컨테이너의 로그를 확인.\ndocker container stats # 실행 중인 컨테이너의 실시간 리소스 사용량을 모니터링.\n\n\nAppendix\n- 기본적으로는 docker run {옵션들} {이미지이름} {내부명령}와 같은 포맷임\n- docker run -ti --rm r-base\n\n-ti: 이 옵션은 두 개의 플래그인 -t와 -i를 결합. –&gt; 터미널 쓸려면 필수임.\n\n-t (또는 --tty): 이 플래그는 유사 터미널을 할당하고 터미널 상호작용을 가능하게 함. 컨테이너 내부에서 터미널 환경을 사용할 수 있게 해줌.\n-i (또는 --interactive): 이 플래그는 컨테이너와 상호작용할 수 있도록 표준 입력(STDIN)을 열어줌. 컨테이너 내부에서 입력을 주고 받을 수 있게 해줌.\n\n–rm: 이 옵션은 컨테이너가 실행을 마칠 때 자동으로 컨테이너를 삭제.\n\n- docker run -ti --rm -v \"$PWD\":/home/docker -w /home/docker -u docker r-base R CMD check\n\n-ti: 이 옵션은 터미널 상호작용을 위한 옵션\n–rm: 컨테이너가 실행을 마칠 때 자동으로 컨테이너를 삭제.\n-v “$PWD”:/home/docker: 이 옵션은 호스트 시스템의 현재 작업 디렉토리를 컨테이너 내의 /home/docker 디렉토리와 공유 마운트. 이렇게 함으로써 호스트 시스템의 파일을 컨테이너 내부에서 사용할 수 있게 됨.\n-w /home/docker: 컨테이너가 실행될 작업 디렉토리를 /home/docker로 설정. 즉, 컨테이너가 실행될 때 기본 디렉토리가 /home/docker가 된다.\n-u docker: 이 옵션은 컨테이너 안에서 사용자를 변경하여 실행하는 것을 의미. docker라는 사용자로 컨테이너를 실행.\nr-base: Docker 이미지 이름.\nR CMD check: 실제로 실행되는 컨테이너 내부의 명령어. 이 경우 R 패키지를 체크하는 R 명령어 R CMD check가 실행.\n\n- run vs start\n\nrun: 이미지 -&gt; 컨테이너\nstart: 중단된 컨테이너 재시작"
  },
  {
    "objectID": "메모/2000-01-07-(메모) 줄리아 설치 및 실행.html",
    "href": "메모/2000-01-07-(메모) 줄리아 설치 및 실행.html",
    "title": "(메모) 줄리아 설치 및 실행",
    "section": "",
    "text": "설치\n- 여기에 접속한다. 스크롤링하여 ’Generic Linux Binaries for x86 / 64-bit(GPG)’를 찾는다. 그리고 ’64-bit’를 클릭해서 다운받는다. (참고로 왼쪽에 ’help’를 누르면 설치페이지 설명서가 나온다.) 그러면 아래와 같은 파일이 나온다.\njulia-1.3.1-linux-x86_64.tar.gz\n이 파일을 더블클릭해서 압축을 풀어준다. 압축을 풀면 julia-1.3.1라는 폴더가 생긴다. 이 폴더를 원하는 위치로 (줄리아가 설치되기를 원하는 위치) 이동시킨다. 나는 home에 이동시켰다.\n- 아래를 실행하면 줄리아가 실행된다. (둘중 아무거나)\n/home/cgb/julia-1.3.1/bin/julia\n~/julia-1.3.1/bin/julia\n\n\n주피터와 연결\n- 아래중 하나를 실행하여 줄리아를 킨다.\n/home/cgb/julia-1.3.1/bin/julia\n~/julia-1.3.1/bin/julia\n- 줄리아를 실행한뒤에 아래를 입력하면 주피터노트북에 연결된다.\nusing Pkg\nPkg.add(\"IJulia\")\n- 한 가지 의문점이 있다. 나같은 경우는 ’(base)’에서 줄리아를 실행하고 연결하였다. 그런데 혹시 몰라서 (py38r40)에서도 줄리아를 실행해봤는데 잘 실행되었다. 줄리아를 실행시키고 위의 명령 Pkg.add(\"IJulia\")를 다시쳤는데, 이미 연결되어서 더이상 변화시킨게 없다는 메시지가 떴다. 이러면 (base)에 설치된 줄리아가 (py38r40)에서도 실행된 줄리아와 동일하다는 의미일까? \\(\\Longrightarrow\\) 그렇다. 왜냐하면 줄리아는 anaconda내의 폴더에 설치한 것이 아니기 때문에. home에 보통 설치하니깐.\n\n\n환경변수 조정\n- 참고로 어디서든 줄리아를 실행시키고 싶다면 환경변수를 조작하면 된다. 아래를 실행해서 나노에디터를 킨다.\nsudo nano /etc/environment\n맨끝에 다음과 같이 되어있을 것이다.\n~~ usr/local/games\"\n마지막에 /home/cgb/julia-1.3.1/bin/julia를 추가한다. 즉 아래와 같이 만든다.\n~~ usr/local/games:/home/cgb/julia-1.3.1/bin/julia\"\n세이브하고 나온다. (그런데 이 과정을 안거쳐도 되는것 같음.) 이제 커맨드에서 아래를 실행한다.\nexport PATH=$PATH:/home/cgb/julia-1.3.1/bin\n이렇게하면 이제 단순히 julia라고만 쳐도 julia가 실행된다.\n\n\n플루토에서 강의영상 넣는 방법\n- 아래를 삽입\nhtml\"\"\"\n&lt;div style=\"display: flex; justify-content: center;\"&gt;\n&lt;div  notthestyle=\"position: relative; right: 0; top: 0; z-index: 300;\"&gt;\n&lt;iframe src=\n\"\nhttps://www.youtube.com/embed/\n\"\nwidth=600 height=375  frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen&gt;&lt;/iframe&gt;\n\"\"\"\n\n\n플루토를 이용한 홈페이지 만드는 방법\n- 단계1: https://github.com/JuliaPluto/static-export-template 에 가서 Clone\n- 단계2: Setting -&gt; GitHub Pages -&gt; Source -&gt; gh-pages / root\n\n\n플루토 키는 방법\nimport Pluto\nPluto.run(host=\"0.0.0.0\",port=1234,launch_browser=false,require_secret_for_open_links=false,require_secret_for_access=false,threads=\"8\")"
  },
  {
    "objectID": "메모/2000-01-02-(메모) 우분투 포맷 및 개발용 서버 셋팅2.html",
    "href": "메모/2000-01-02-(메모) 우분투 포맷 및 개발용 서버 셋팅2.html",
    "title": "(메모) 우분투 포맷 및 개발용 서버 셋팅2",
    "section": "",
    "text": "- 우분투에서 여러가지 개발환경을 설정하는 방법을 포스팅 (시대가 너무 바뀌어서 새로정리)"
  },
  {
    "objectID": "메모/2000-01-02-(메모) 우분투 포맷 및 개발용 서버 셋팅2.html#a.-주피터-원격제어-설정",
    "href": "메모/2000-01-02-(메모) 우분투 포맷 및 개발용 서버 셋팅2.html#a.-주피터-원격제어-설정",
    "title": "(메모) 우분투 포맷 및 개발용 서버 셋팅2",
    "section": "A. 주피터 원격제어 설정",
    "text": "A. 주피터 원격제어 설정\n- 설정파일 생성\njupyter notebook --generate-config\n- 패스워드 설정\njupyter notebook password\n## 패스워드 치고\n## 확인해야함\n- 설정파일을 열고\nvi /home/cgb2/.jupyter/jupyter_notebook_config.py\n아래의 내용을 수정한다.\nc.??????App.ip = '192.168.0.4'\nc.??????App.port = 1306\nc.??????App.allow_origin = '*'\nc.??????App.allow_remote_access = True\nc.??????App.allow_root = True"
  },
  {
    "objectID": "메모/2000-01-02-(메모) 우분투 포맷 및 개발용 서버 셋팅2.html#b.-vscode",
    "href": "메모/2000-01-02-(메모) 우분투 포맷 및 개발용 서버 셋팅2.html#b.-vscode",
    "title": "(메모) 우분투 포맷 및 개발용 서버 셋팅2",
    "section": "B. vscode",
    "text": "B. vscode\n- ref: https://code.visualstudio.com/docs/remote/tunnels\n- 아래를 실행하면 된다.\ncurl -Lk 'https://code.visualstudio.com/sha/download?build=stable&os=cli-alpine-x64' --output vscode_cli.tar.gz\ntar -xf vscode_cli.tar.gz\n- 이후로는 ./code tunnel을 실행할것!\n- 백엔드에서 하려면\nnohup ./code tunnel &gt; /dev/null 2&gt;&1 &\n- 패키지설치"
  },
  {
    "objectID": "메모/2000-01-02-(메모) 우분투 포맷 및 개발용 서버 셋팅2.html#a.-rpython-사용가능한-개발환경",
    "href": "메모/2000-01-02-(메모) 우분투 포맷 및 개발용 서버 셋팅2.html#a.-rpython-사용가능한-개발환경",
    "title": "(메모) 우분투 포맷 및 개발용 서버 셋팅2",
    "section": "\bA. R+Python 사용가능한 개발환경",
    "text": "\bA. R+Python 사용가능한 개발환경\n- 아래를 실행\n(base) conda create -n r \n(base) conda activate r\n(r) conda install -c conda-forge r-essentials\n(r) conda install -c conda-forge plotly\n(r) conda install -c conda-forge rpy2\n\nimport rpy2\n\n- 여기에서 conda install -c conda-forge r-essentials로 인하여 R, Python, Jupyter 가 모두 최신버전으로 설치된다.\n- 또한 R에는 이미 tidyverse, IRkernel 등의 패키지가 기본으로 깔려있다.\n- 커널연결\n콘다환경에서 R을 실행한다. Rstudio가 아니라 커맨드에서 R을 실행해야한다. 그리고 아래를 실행하면 주피터랩과 R환경이 연결된다.\nIRkernel::installspec()\n이제 주피터랩에서 R kernel을 사용할 수 있다.\n- R은 아래의 경로에 설치되어있다.\n\n- 실행파일은 bin 폴더에 있다.\n\n(base) 환경이지만 이곳의 실행파일에 직접 접근하여 실행할 수도 있다.\n\n- 설치한 패키지는 library 폴더에 있다. /// EPT도 보인다.."
  },
  {
    "objectID": "메모/2000-01-02-(메모) 우분투 포맷 및 개발용 서버 셋팅2.html#b.-torch",
    "href": "메모/2000-01-02-(메모) 우분투 포맷 및 개발용 서버 셋팅2.html#b.-torch",
    "title": "(메모) 우분투 포맷 및 개발용 서버 셋팅2",
    "section": "B. torch",
    "text": "B. torch\n- 아래를 실행\n(base) conda create -n torch\n(base) conda activate torch\n#---#\n(torch) conda install -c conda-forge notebook \n(torch) conda install -c conda-forge plotly \n#---torch--#\n(torch) conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\n#---pyg---#\n#(torch) conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\n(torch) conda install pyg -c pyg \n#---stgcn---#\n#(torch) conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\n#(torch) conda install pyg -c pyg \n(torch) sudo apt install gcc\n(torch) sudo apt install build-essential\n(torch) pip install torch-geometric-temporal\n#---ctgan---#\n#(torch) conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\n(torch) conda install -c pytorch -c conda-forge ctgan  \n#---gym---#\n#(torch) conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\n(torch) pip install gymnasium \n#(torch) sudo apt install gcc\n#(torch) sudo apt install build-essential\n(torch) sudo apt-get install swig\n(torch) pip install gymnasium[box2d]\nrefs\n\nPyTorch: https://pytorch.org/get-started/locally/\nPyG: https://pytorch-geometric.readthedocs.io/en/latest/install/installation.html\nPyTorch Geometric Temporal1: https://pytorch-geometric-temporal.readthedocs.io/en/latest/notes/installation.html\nCTGAN: https://github.com/sdv-dev/CTGAN\nGymnasium: https://gymnasium.farama.org/index.html2\n\n1 이 패키지는 꼭 PyG 이후에 설치할것2 설치방법은 따로 없음.."
  },
  {
    "objectID": "메모/2000-01-02-(메모) 우분투 포맷 및 개발용 서버 셋팅2.html#a1.-r-삭제하는-방법",
    "href": "메모/2000-01-02-(메모) 우분투 포맷 및 개발용 서버 셋팅2.html#a1.-r-삭제하는-방법",
    "title": "(메모) 우분투 포맷 및 개발용 서버 셋팅2",
    "section": "A1. R 삭제하는 방법",
    "text": "A1. R 삭제하는 방법\n- R 삭제\nconda remove r-base -y \nsudo apt-get remove r-base-core \nsudo apt purge r-base* r-recommended r-cran-*\nsudo apt autoremove"
  },
  {
    "objectID": "메모/2000-01-02-(메모) 우분투 포맷 및 개발용 서버 셋팅2.html#a2.-r-패키지-설치",
    "href": "메모/2000-01-02-(메모) 우분투 포맷 및 개발용 서버 셋팅2.html#a2.-r-패키지-설치",
    "title": "(메모) 우분투 포맷 및 개발용 서버 셋팅2",
    "section": "A2. R 패키지 설치",
    "text": "A2. R 패키지 설치\n- 주피터등에서 직접설치\n- conda를 이용한 설치\nconda install -c r package-name\n\nhttps://docs.anaconda.com/free/anaconda/reference/packages/r-language-pkg-docs/"
  },
  {
    "objectID": "메모/2000-01-02-(메모) 우분투 포맷 및 개발용 서버 셋팅2.html#a3.-우분투를-주컴퓨터로-사용할-경우-한글설정",
    "href": "메모/2000-01-02-(메모) 우분투 포맷 및 개발용 서버 셋팅2.html#a3.-우분투를-주컴퓨터로-사용할-경우-한글설정",
    "title": "(메모) 우분투 포맷 및 개발용 서버 셋팅2",
    "section": "A3. 우분투를 주컴퓨터로 사용할 경우 한글설정",
    "text": "A3. 우분투를 주컴퓨터로 사용할 경우 한글설정\n- 아래와 같이 커맨드에 친다.\nibus-setup\n이걸 치면 IBus Preferences 라는 창이 나오는데 여기에서 (1) Input Method 탭 클릭 (2) Add 버튼 클릭 (3) Korean 선택 (4) Hangul 선택을 한다.\n- 위의 단계에서 Korean이 안보이면 Language Support로 가서 한국어팩을 설치하고 리부팅 하면 된다. (보통 실행하자마자 알아서 설치되더라.. 설치가 안되면 Install / Remove Languages... 이라는 탭을 클릭해서 설치하자) 리부팅을 꼭 해야한다는 것에 주의하자.\n- 이제 Region & Language로 가서 설정하면 된다."
  },
  {
    "objectID": "메모/2000-01-02-(메모) 우분투 포맷 및 개발용 서버 셋팅2.html#a4.-sublime-text-and-tex",
    "href": "메모/2000-01-02-(메모) 우분투 포맷 및 개발용 서버 셋팅2.html#a4.-sublime-text-and-tex",
    "title": "(메모) 우분투 포맷 및 개발용 서버 셋팅2",
    "section": "A4. sublime text and TeX",
    "text": "A4. sublime text and TeX\n- ‘Ubuntu Software’에 가서 ’sublime Text’를 치면 다운받을 수 있다. 다운받은뒤에 ’file’ -&gt; ’open folder’를 활용하여 깃허브의 로칼저장소를 열어두면 편리하다.\n- 아래를 실행하여 TeX을 깐다.\nsudo apt install texlive-full\n- 이제 sublime과 latex을 연결하여보자. 여기를 참고하자. (1) sublime을 키고 ‘컨트롤+쉬프트+p’를 눌러 ’Install Package Control’ 선택 (2) 다시 ‘컨트롤+쉬프트+p’ 를 눌러 ‘Package Control: Install Package’를 실행 (3) 그러면 바로 검색창이 나오는데 거기서 ’LaTeXTools’를 입력해서 실행 (4) 다시 ’컨트롤+쉬프트+p’를 누르고 ’LaTeXTools: Check system’ 선택. 모두 ’available’이 나오면 잘 설치된 것이다.\n- *.tex파일을 열고 ’컨트롤+b’를 누르자. 처음이면 어떤 메뉴들이 보일텐데 그냥 ’Latex’을 선택하자. 그러면 코딩결과가 pdf로 나온다.\n- (수식미리보기) ‘Perferences’ &gt; ‘Packages Setting’ &gt; ‘LaTeXTools’ &gt; ‘Settings-User’를 선택한다. ’93번째라인’에 ’preview_math_mode’를 “all”로 바꾼다. 그러면 수식들이 미리 출력된다. 그외에도 자유롭게 셋팅을 조정할 수 있다. 원래셋팅은 ’Perferences’ &gt; ‘Packages Setting’ &gt; ‘LaTeXTools’ &gt; ‘Settings-Defaults’ 에 있다."
  },
  {
    "objectID": "메모/2000-01-02-(메모) 우분투 포맷 및 개발용 서버 셋팅2.html#a5.-터미널-예쁘게-만들기",
    "href": "메모/2000-01-02-(메모) 우분투 포맷 및 개발용 서버 셋팅2.html#a5.-터미널-예쁘게-만들기",
    "title": "(메모) 우분투 포맷 및 개발용 서버 셋팅2",
    "section": "A5. 터미널 예쁘게 만들기",
    "text": "A5. 터미널 예쁘게 만들기\n- zsh 설치 + oh my zsh 설치\nsudo install zsh \nsh -c \"$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\"\n- 테마변경\n\n.zshrc 파일 열기\n\nnano ~/.zshrc \n\n아래의 내용 수정\n\n...\nZSH_THEME=\"agnoster\"\n...\n- 색상변경\n\n아래의 파일 열기\n\ncd ~/.oh-my-zsh/themes/\nnano agnoster.zsh-theme  \n\n내용수정\n\n...\nprompt_dir() {\n  prompt_segment 39d $CURRENT_FG '%~'\n}\n..."
  },
  {
    "objectID": "메모/2000-01-06-(메모) 깃 익히기.html",
    "href": "메모/2000-01-06-(메모) 깃 익히기.html",
    "title": "(메모) 깃 익히기",
    "section": "",
    "text": "clone\ngithub repository \\(\\to\\) code \\(\\to\\) clone tab, ssh를 복사 (git@github.com:miruetoto/yechan.git처럼 생김)\n터미널에서 아래를 입력\ngit clone git@github.com:miruetoto/yechan.git 01_yechan\n\n\npull\n- 깃이 설치된 가장 상위폴더(Documents/Github/miruetoto.github.io)에 가서 아래를 입력한다.\ngit pull\n\n\nbranch\n- 서버에 이미 guebin이라는 브랜치가 있다면 아래와 같이 동기화 시킨다.\ngit chechout guebin\ngit push -u origin guebin\n여기에서 git push -u origin guebin을 안해도 동기화가 잘될때도 있는데 아닐때도 있다.\n\n\nremote\n- 깃이 설치된 가장 상위폴더(Documents/Github/miruetoto.github.io)에 가서 아래를 입력하면 깃허브의 url 주소를 확인할 수 있다.\n(base) lgcgb2@lgcgb2:~/Documents/GitHub/miruetoto.github.io$ git remote -v\norigin https://github.com/miruetoto/miruetoto.github.io.git (fetch)\norigin https://github.com/miruetoto/miruetoto.github.io.git (push)\nupstream https://github.com/daattali/beautiful-jekyll.git (fetch)\nupstream https://github.com/daattali/beautiful-jekyll.git (push)\n\n\nconfig\n- 설정보기\ngit config —list \n- 설정삭제\ngit config --unset user.name\ngit config --unser user.email\n- 전역설정삭제\ngit config --unset --global user.name\ngit config --unset --global user.email\n- 중복값 설정삭제\ngit config --unset-all user.name\ngit config --unset-all user.email\n- 중복값 전역으로 설정삭제\ngit config --unset-all --global user.name\ngit config --unset-all --global user.email\n- 비번안치고 푸쉬하는법?\ngit config credential.helper store\n입력이후에 git push\n\n\nGit token\nhttps://github.com/settings/tokens 에서 확인가능\n\nAppendix\n\n리눅스에서 github desktop 설치\n\n여기로 간다.\n한 챕터의 (2.3.1 Linux RC1 와 같이 되어있음) 아래쪽에 보면 ▶ Assets 라고 되어있는데 이걸 클릭하면 다운받을 수 있는 파일들이 나온다. 확장자가 .deb로 끝나는걸 골라서 다운받은뒤에 실행한다."
  },
  {
    "objectID": "메모/2000-01-17-(메모) tmux.html",
    "href": "메모/2000-01-17-(메모) tmux.html",
    "title": "(메모) tmux",
    "section": "",
    "text": "tmux는 터미널 멀티플렉서로, 하나의 터미널 세션 내에서 여러 창을 열고, 각 창에서 여러 창 패널을 생성할 수 있게 해줍니다. 이는 특히 원격 서버에 접속하여 여러 작업을 병렬로 수행하거나, 세션을 종료해도 작업을 지속할 수 있는 상황에서 매우 유용합니다.\n아래는 tmux의 기본적인 사용 방법입니다.\n\n1. tmux 시작하기\ntmux\n이 명령어는 새 tmux 세션을 시작합니다.\n\n\n2. 새로운 세션 생성하기\n새로운 tmux 세션을 시작하면서 세션 이름을 지정할 수 있습니다:\ntmux new -s 세션이름\n\n\n3. tmux 세션 목록 보기\n현재 실행 중인 tmux 세션을 보려면:\ntmux ls\n\n\n4. tmux 세션에 재접속하기\n특정 세션에 재접속하려면:\ntmux attach -t 세션이름\n\n\n5. tmux 세션에서 나가기\n세션을 종료하지 않고 tmux에서 나가려면:\nCtrl+b, d\n위의 키 조합을 사용하면 세션은 백그라운드에서 계속 실행됩니다.\n\n\n6. 창 관리\n\n새 창 생성: Ctrl+b, c\n창 사이 이동: Ctrl+b, 숫자 (예: Ctrl+b, 1)\n창 닫기: exit 또는 Ctrl+d\n창 목록 보기: Ctrl+b, w\n\n\n\n7. 창 패널 관리\n\n패널 수직 분할: Ctrl+b, %\n패널 수평 분할: Ctrl+b, \"\n패널 간 전환: Ctrl+b, 화살표키 (또는 Ctrl+b, o)\n패널 닫기: exit 또는 Ctrl+d\n패널 크기 조절: Ctrl+b, 화살표키 (Ctrl을 누른 상태에서 화살표키로 조절)\n\n\n\n8. tmux 세션 종료\n세션을 완전히 종료하려면 모든 창과 패널을 닫거나, 다음 명령어를 입력합니다:\nexit\n\n\n9. tmux 설정\n기본적으로 ~/.tmux.conf 파일을 만들어 tmux의 기본 동작을 커스터마이징할 수 있습니다. 예를 들어, tmux에서 사용되는 기본 키 바인딩을 변경하려면 이 파일에 관련 설정을 추가하면 됩니다.\n\n\n10. 자주 사용하는 명령어 요약\n\nCtrl+b, ?: tmux의 모든 단축키 보기\nCtrl+b, [: 복사 모드로 진입 (텍스트 스크롤 및 복사 가능)\nCtrl+b, d: 세션 분리 (detach)\nCtrl+b, :: 명령어 모드로 진입 (예: 세션 이름 변경 등)\n\n이러한 기본적인 사용법을 익히고 나면 tmux를 사용해 보다 효율적으로 터미널 작업을 수행할 수 있습니다. 추가적으로 tmux 플러그인 매니저(TPM)를 사용하여 다양한 플러그인을 설치하고 관리할 수도 있습니다."
  },
  {
    "objectID": "메모/2000-01-05-(메모) vi 익히기.html",
    "href": "메모/2000-01-05-(메모) vi 익히기.html",
    "title": "(메모) vi 익히기",
    "section": "",
    "text": "예제: vi를 이용하여 파일 만들고 asdf 입력 후 저장 및 종료를 수행하여 보자.\n\n\nstep1step2step3step4step5\n\n\n- 파일생성\nvim test230803.txt \n\n\n\n- 편집모드로 전환: i를 누른다.\n\n아래에 -- INSERT -- 라고 표현되어 있으면 편집모드라는 의미\n\n\n\n\n- asdf 입력\n\n\n\n- 편집모드 종료, 노말모드 진입:esc 입력\n\n아래에 -- INSERT -- 라는 표현이 사라져있음. 이 상황에서 명령어 입력가능.\n\n\n\n\n- 저장(w)+종료(q): : 입력하여 명령모드로 진입. w+ q + Enter 입력\n\n\n\n\n\n\n\n\n예제: vi 에서 좌우로 커서를 이동해보자.\n\n\nstep1step2step3\n\n\n- 생성된 파일로 들어가기\nvim test230803.txt \n\n\n\n- l을 세번눌러서 오른쪽으로 3칸 이동\n\nl이 아니라 실수로 ㅣ를 누르면 동작하지 않음.\n대충 화살표 눌러도 동작함\n\n\n\n\n- h을 세번눌러서 왼쪽으로 3칸 이동\n\nh가 아니라 실수로 ㅗ를 누르면 동작하지 않음.\n대충 화살표 눌러도 동작함\n\n\n\n\n\n\n\n\n\n예제: vi에서 새로운라인을 추가하고 asdf2입력하여 보자.\n\n\nstep1step2step3\n\n\n- 준비작업: 명령모드에서 다음라인을 만들고 싶은 라인에 커서를 위치\n\n\n\n- o를 누른다: 편집모드로 전환 + 새로운 라인이 추가의 효과\n\n\n\n- asdf2입력\n\n\n\n\n\n\n\n\n예제: vi에서 j,k를 이용하여 커서를 이동하여 보자. (풀이는 생략)\n\n\n\n\n\n예제: vi에서 home/end 와 같은 방식으로 커서를 이동해보자\n\n\nstep1step2step3\n\n\n- 준비작업: 명령모드에서 home/end를 사용할 line으로 커서를 이동시킴\n\n\n\n- 라인의 맨 마지막으로 가고싶다면? $를 입력한다.\n\n\n\n- 다시 라인의 맨 처음으로 가고싶다면? 숫자 0을 입력한다.\n\n\n\n\n\n\n\n\n예제: vi에서 하나의 줄을 복사하고 아래로 붙여넣기 해보자.\n\n\nstep1step2step3\n\n\n- 복사하고싶은 라인으로 이동 + yy 입력\n\n\n\n- 아래로 붙여넣을 라인으로 이동\n\n\n\n- p 입력\n\n\n\n\n\n\n\n\n예제: vi에서 w와 b를 이용하여 단어단위로 커서를 이동시켜보자. (풀이생략)\n\n\n\n\n\n예제: vi에서 원하는 단어는 찾아보자.\n\n\nstep1step2step3step4\n\n\n- /asdf2 입력\n\n\n\n- Enter 입력\n\n\n\n- n 입력하여 다음단어로 이동\n\n\n\n- shift+n 입력하여 이전단어로 이동 (?로 검색할 경우 n와 shift+n의 역할이 뒤바뀜)"
  },
  {
    "objectID": "메모/2000-01-05-(메모) vi 익히기.html#i-esc-w-q-편집-명령-저장-종료",
    "href": "메모/2000-01-05-(메모) vi 익히기.html#i-esc-w-q-편집-명령-저장-종료",
    "title": "(메모) vi 익히기",
    "section": "",
    "text": "예제: vi를 이용하여 파일 만들고 asdf 입력 후 저장 및 종료를 수행하여 보자.\n\n\nstep1step2step3step4step5\n\n\n- 파일생성\nvim test230803.txt \n\n\n\n- 편집모드로 전환: i를 누른다.\n\n아래에 -- INSERT -- 라고 표현되어 있으면 편집모드라는 의미\n\n\n\n\n- asdf 입력\n\n\n\n- 편집모드 종료, 노말모드 진입:esc 입력\n\n아래에 -- INSERT -- 라는 표현이 사라져있음. 이 상황에서 명령어 입력가능.\n\n\n\n\n- 저장(w)+종료(q): : 입력하여 명령모드로 진입. w+ q + Enter 입력"
  },
  {
    "objectID": "메모/2000-01-05-(메모) vi 익히기.html#hl-좌우로-커서이동",
    "href": "메모/2000-01-05-(메모) vi 익히기.html#hl-좌우로-커서이동",
    "title": "(메모) vi 익히기",
    "section": "",
    "text": "예제: vi 에서 좌우로 커서를 이동해보자.\n\n\nstep1step2step3\n\n\n- 생성된 파일로 들어가기\nvim test230803.txt \n\n\n\n- l을 세번눌러서 오른쪽으로 3칸 이동\n\nl이 아니라 실수로 ㅣ를 누르면 동작하지 않음.\n대충 화살표 눌러도 동작함\n\n\n\n\n- h을 세번눌러서 왼쪽으로 3칸 이동\n\nh가 아니라 실수로 ㅗ를 누르면 동작하지 않음.\n대충 화살표 눌러도 동작함"
  },
  {
    "objectID": "메모/2000-01-05-(메모) vi 익히기.html#o-새로운라인-추가",
    "href": "메모/2000-01-05-(메모) vi 익히기.html#o-새로운라인-추가",
    "title": "(메모) vi 익히기",
    "section": "",
    "text": "예제: vi에서 새로운라인을 추가하고 asdf2입력하여 보자.\n\n\nstep1step2step3\n\n\n- 준비작업: 명령모드에서 다음라인을 만들고 싶은 라인에 커서를 위치\n\n\n\n- o를 누른다: 편집모드로 전환 + 새로운 라인이 추가의 효과\n\n\n\n- asdf2입력"
  },
  {
    "objectID": "메모/2000-01-05-(메모) vi 익히기.html#jk-위-아래-이동",
    "href": "메모/2000-01-05-(메모) vi 익히기.html#jk-위-아래-이동",
    "title": "(메모) vi 익히기",
    "section": "",
    "text": "예제: vi에서 j,k를 이용하여 커서를 이동하여 보자. (풀이는 생략)"
  },
  {
    "objectID": "메모/2000-01-05-(메모) vi 익히기.html#homeend와-같은-기능",
    "href": "메모/2000-01-05-(메모) vi 익히기.html#homeend와-같은-기능",
    "title": "(메모) vi 익히기",
    "section": "",
    "text": "예제: vi에서 home/end 와 같은 방식으로 커서를 이동해보자\n\n\nstep1step2step3\n\n\n- 준비작업: 명령모드에서 home/end를 사용할 line으로 커서를 이동시킴\n\n\n\n- 라인의 맨 마지막으로 가고싶다면? $를 입력한다.\n\n\n\n- 다시 라인의 맨 처음으로 가고싶다면? 숫자 0을 입력한다."
  },
  {
    "objectID": "메모/2000-01-05-(메모) vi 익히기.html#yy-p-라인복사-붙여넣기",
    "href": "메모/2000-01-05-(메모) vi 익히기.html#yy-p-라인복사-붙여넣기",
    "title": "(메모) vi 익히기",
    "section": "",
    "text": "예제: vi에서 하나의 줄을 복사하고 아래로 붙여넣기 해보자.\n\n\nstep1step2step3\n\n\n- 복사하고싶은 라인으로 이동 + yy 입력\n\n\n\n- 아래로 붙여넣을 라인으로 이동\n\n\n\n- p 입력"
  },
  {
    "objectID": "메모/2000-01-05-(메모) vi 익히기.html#wb-다음단어로-점프-이전단어로-점프",
    "href": "메모/2000-01-05-(메모) vi 익히기.html#wb-다음단어로-점프-이전단어로-점프",
    "title": "(메모) vi 익히기",
    "section": "",
    "text": "예제: vi에서 w와 b를 이용하여 단어단위로 커서를 이동시켜보자. (풀이생략)"
  },
  {
    "objectID": "메모/2000-01-05-(메모) vi 익히기.html#단어-찾기",
    "href": "메모/2000-01-05-(메모) vi 익히기.html#단어-찾기",
    "title": "(메모) vi 익히기",
    "section": "",
    "text": "예제: vi에서 원하는 단어는 찾아보자.\n\n\nstep1step2step3step4\n\n\n- /asdf2 입력\n\n\n\n- Enter 입력\n\n\n\n- n 입력하여 다음단어로 이동\n\n\n\n- shift+n 입력하여 이전단어로 이동 (?로 검색할 경우 n와 shift+n의 역할이 뒤바뀜)"
  },
  {
    "objectID": "메모/2000-01-05-(메모) vi 익히기.html#esc-normal-모드",
    "href": "메모/2000-01-05-(메모) vi 익히기.html#esc-normal-모드",
    "title": "(메모) vi 익히기",
    "section": "esc: normal 모드",
    "text": "esc: normal 모드\n- 기능1: 되돌리기, 되돌리기를 되돌리기\n- 기능2: 커서이동 (기본) – 방향키, 쉬프트+방향키, home/end, pageup/pagedown 으로 대체가능\n\nk,j,h,l: 상,하,좌,우\nw,b: 다음 단어의 시작으로 이동, 이전 단어의 시작으로 이동\n0 (숫자 0), $: 줄의 맨 앞, 맨 끝으로 이동\ncontrol + d, control + u: 반페이지씩 page down, page up\n{, }: 문단 시작, 끝으로 이동\n\n- 기눙3: 커서이동 (고급)\n\n%: 현재 괄호의 짝으로 이동\ne: 현재단어의 끝으로 이동\ngg: 파일의 첫 줄로 이동\nG: 파일의 마지막 줄로 이동\n\n- 기능4: 다른모드로 진입하기 위한 중간허브\n\nv,V: 선택모드, 줄단위선택모드로 변환\ni, I, a, A: 커서앞, 줄맨앞, 커서뒤, 줄맨뒤에서 삽입모드로 전환\nr, R: 한글자 수정후 복귀, 수정모드로 진입\n\n- 기능5: 들여쓰기, 내어쓰기\n\n&gt; + Enter, &lt; + Enter: 들여쓰기, 내어쓰기"
  },
  {
    "objectID": "메모/2000-01-05-(메모) vi 익히기.html#i-삽입모드",
    "href": "메모/2000-01-05-(메모) vi 익히기.html#i-삽입모드",
    "title": "(메모) vi 익히기",
    "section": "i: 삽입모드",
    "text": "i: 삽입모드"
  },
  {
    "objectID": "메모/2000-01-05-(메모) vi 익히기.html#d-삭제모드",
    "href": "메모/2000-01-05-(메모) vi 익히기.html#d-삭제모드",
    "title": "(메모) vi 익히기",
    "section": "d: 삭제모드",
    "text": "d: 삭제모드"
  },
  {
    "objectID": "메모/2000-01-05-(메모) vi 익히기.html#명령모드",
    "href": "메모/2000-01-05-(메모) vi 익히기.html#명령모드",
    "title": "(메모) vi 익히기",
    "section": ":: 명령모드",
    "text": ":: 명령모드"
  },
  {
    "objectID": "메모/2000-01-05-(메모) vi 익히기.html#검색모드",
    "href": "메모/2000-01-05-(메모) vi 익히기.html#검색모드",
    "title": "(메모) vi 익히기",
    "section": "/: 검색모드",
    "text": "/: 검색모드"
  },
  {
    "objectID": "메모/2000-01-05-(메모) vi 익히기.html#v-비주얼모드선택모드",
    "href": "메모/2000-01-05-(메모) vi 익히기.html#v-비주얼모드선택모드",
    "title": "(메모) vi 익히기",
    "section": "v: 비주얼모드(선택모드)",
    "text": "v: 비주얼모드(선택모드)"
  },
  {
    "objectID": "메모/2000-01-05-(메모) vi 익히기.html#r-수정모드",
    "href": "메모/2000-01-05-(메모) vi 익히기.html#r-수정모드",
    "title": "(메모) vi 익히기",
    "section": "R: 수정모드",
    "text": "R: 수정모드"
  },
  {
    "objectID": "메모/2024-06-07-(메모) 학과서버 공지.html",
    "href": "메모/2024-06-07-(메모) 학과서버 공지.html",
    "title": "(메모) 학과서버 공지",
    "section": "",
    "text": "학과서버(GPU) 사용안내 특강\n\n일정\n\n날짜: 7월 11일 - 12일\n시간: 10:00 ~ 16:30\n장소: 학습도서관 202호\n\n\n\n강의 목표\n\n고성능 GPU 계산을 위한 리눅스 지식 습득.\n개인 원격 서버 구축 및 관리 능력 배양.\n\n\n\n강의 범위\n\n리눅스 명령어: 디렉토리 관리, 리소스 관리, 터미널의 이해, tmux 사용법, vi 사용법, 보안 설정, 애플리케이션 설치, 포트 관리, 프로세스 종료.\n아나콘다: 가상환경의 이해, 가상환경 생성 및 삭제, 아나콘다를 이용한 PyTorch, TensorFlow 실습 환경 생성.\n원격 서버 접속: 주피터랩, RStudio, VSCode 원격 서버 생성 및 접속\n\n\n\n대상\n\n공모전 및 경진대회 준비를 위해 고성능 GPU 서버 사용법을 익히고자 하는 통계학과 대학생.\n학습을 위해 개인용 서버가 필요한 통계학과 대학생.\n\n\n\n신청 방법\n아래의 내용을 작성하여 성적증명서와 함께 guebin@jbnu.ac.kr 로 제출. (7월7일 23:59까지) 1. 이름/학번/학년 2. github 주소\n3. 신청동기\n★ 1-3 외에 기타 우수성 입증자료 (예: 기술블로그 주소, 공모전/경진대회 활동내역, 데이터분석,프로그래밍 관련동아리 활동내역)가 있다면 작성 할 것\n\n\n수강생 선별 원칙\n신청 인원이 많을 경우 아래 원칙에 따라 수강 인원을 제한. (수강가능여부 개별통보) 1. 저학년 위주로 선발. 2. 프로그래밍, 통계학 관련 교과목 성적순으로 선발. 3. 선착순으로 선발.\n★ 신청동기 및 기타 우수성 입증 자료에 근거하여 1-3의 원칙을 무시하고 선발할 수도 있음\n\n\n운영 방식\n\n보안이슈로 인해 별도의 강의 노트 및 영상 촬영은 제공되지 않음. (개인적으로 녹화/녹음/필기 하는것은 제한하지 않음)\n특강 이후 테스트를 진행함. 테스트에 통과할 경우에만 개인용 서버 제공."
  },
  {
    "objectID": "자료/데이터생성 -- 성별,몸무게 --> 키.html",
    "href": "자료/데이터생성 -- 성별,몸무게 --> 키.html",
    "title": "(자료) 데이터생성 – 성별,몸무게 –> 키",
    "section": "",
    "text": "- imports\n\nimport numpy as np\nimport pandas as pd\nimport sklearn.model_selection\nimport seaborn as sns\n\n- 결측이 있는 자료\n\nnp.random.seed(42)\ndata = np.array(['male'] * 500 + ['female'] * 500)\ndef sample_data(data, male_prob, female_prob, size):\n    male_sample = np.random.choice(data[data=='male'], size=int(size * male_prob))\n    female_sample = np.random.choice(data[data=='female'], size=int(size * female_prob))\n    return np.concatenate([male_sample, female_sample])\ntrain = sample_data(data, 0.8, 0.2, 280)\ntest = sample_data(data, 0.2, 0.8, 120)\nnp.random.shuffle(train)\nnp.random.shuffle(test)\nsex = np.concatenate([train,test])\nweight = np.random.randn(400)*7\nheight = np.random.randn(400)*3\nfor i,s in enumerate(sex):\n    if s =='male':\n        weight[i] = 75+weight[i]\n        height[i] = height[i]+0.8*weight[i]+120\n    else:\n        weight[i] = 50+weight[i]*0.6\n        height[i] = height[i]+1.3*weight[i]+100\ndf = pd.DataFrame({'weight':weight,'sex':sex,'height':height})\nmissing_ratio = 0.2\nnum_missing = int(len(df) * missing_ratio)\nmissing_indices = np.random.choice(df.index, size=num_missing, replace=False)\ndf.loc[missing_indices, 'weight'] = np.nan\ndf_train, df_test = sklearn.model_selection.train_test_split(df,test_size=120)\n\n\nsns.scatterplot(df, x='weight', y='height', hue='sex')\n\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n  if pd.api.types.is_categorical_dtype(vector):\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n  if pd.api.types.is_categorical_dtype(vector):\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n  if pd.api.types.is_categorical_dtype(vector):\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n  if pd.api.types.is_categorical_dtype(vector):\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n  if pd.api.types.is_categorical_dtype(vector):\n\n\n\n\n\n\n\n\n\n자료특징\n\n결측값이 있다.\ntr에는 남자가, test에는 여자가 많다.\n남녀의 (몸무게,키)의 분포는 서로 다르다."
  },
  {
    "objectID": "보람.html",
    "href": "보람.html",
    "title": "보람",
    "section": "",
    "text": "https://github.com/boram-coco\nhttps://boram-coco.github.io/coco/\nhttps://boram-coco.github.io/Scribbling/\n\n\n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nMay 2, 2024\n\n\n(연구&보람) GCN (시뮬레이션)\n\n\n김보람 \n\n\n\n\nMay 2, 2024\n\n\n(연구&보람) AutoGluon\n\n\n김보람 \n\n\n\n\nApr 24, 2024\n\n\n(연구&보람) 데이터정리\n\n\n김보람 \n\n\n\n\nApr 3, 2024\n\n\nExperiment 1(꺾은선)\n\n\n김보람 \n\n\n\n\nApr 3, 2024\n\n\n(연구&보람) 결과시각화 – Experiment 1\n\n\n김보람 \n\n\n\n\nJan 25, 2024\n\n\n(연구&보람) 신용카드거래 사기탐지 – pyod 사용\n\n\n신록예찬,김보람 \n\n\n\n\nJan 18, 2024\n\n\n(연구&보람) 신용카드거래 사기탐지 – pygod 셋팅\n\n\n신록예찬,김보람 \n\n\n\n\nAug 25, 2023\n\n\n(연구&보람) 신용카드거래 사기탐지 – 데이터(8, df02)커널죽음\n\n\n김보람 \n\n\n\n\nJul 30, 2023\n\n\n(연구&보람) CTGAN – 신용카드\n\n\n신록예찬 \n\n\n\n\nJul 19, 2023\n\n\n(연구&보람) 신용카드거래 사기탐지 – 관련연구 리뷰\n\n\n신록예찬 \n\n\n\n\nJul 19, 2023\n\n\n(연구&보람) 신용카드거래 사기탐지 – 그래프자료로 데이터정리\n\n\n신록예찬 \n\n\n\n\nJul 1, 2023\n\n\n(연구&보람) CTGAN – Start\n\n\n신록예찬 \n\n\n\n\nJul 1, 2023\n\n\n(연구&보람) CTGAN – TOY\n\n\n신록예찬 \n\n\n\n\nMay 19, 2023\n\n\n(연구&보람) 신용카드거래 사기탐지 – Try2\n\n\n신록예찬 \n\n\n\n\nMay 19, 2023\n\n\n(연구&보람) 신용카드거래 사기탐지 – Try2변형\n\n\n신록예찬 \n\n\n\n\nMay 12, 2023\n\n\n(연구&보람) 신용카드거래 사기탐지 – Try1변형\n\n\n신록예찬 \n\n\n\n\nMay 12, 2023\n\n\n(연구&보람) 신용카드거래 사기탐지 – Try1\n\n\n신록예찬 \n\n\n\n\nMay 6, 2023\n\n\n(연구&보람) 신용카드거래 사기탐지 – Start\n\n\n신록예찬 \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "자료/신용카드사기거래.html",
    "href": "자료/신용카드사기거래.html",
    "title": "(자료) 신용카드 사기거래",
    "section": "",
    "text": "1. Links\n\nhttps://www.kaggle.com/datasets/mlg-ulb/creditcardfraud //\nhttps://www.kaggle.com/datasets/whenamancodes/fraud-detection // y가 없는듯\nhttps://www.kaggle.com/datasets/dhanushnarayananr/credit-card-fraud\nhttps://www.kaggle.com/datasets/ealaxi/paysim1\nhttps://www.kaggle.com/datasets/mishra5001/credit-card\nhttps://www.kaggle.com/datasets/joebeachcapital/credit-card-fraud // 복잡함..\nhttps://www.kaggle.com/datasets/nelgiriyewithana/credit-card-fraud-detection-dataset-2023\nhttps://www.kaggle.com/datasets/jainilcoder/online-payment-fraud-detection\nhttps://www.kaggle.com/datasets/rupakroy/online-payments-fraud-detection-dataset // 시간이없당\nhttps://www.kaggle.com/datasets/kartik2112/fraud-detection\nhttps://www.kaggle.com/datasets/vardhansiramdasu/fraudulent-transactions-prediction\n\n\n\n2. Imports\n\nimport pandas as pd\n\n\n\n3. Data\n\ndf = pd.read_csv(\"fraud1.csv\")"
  },
  {
    "objectID": "메모/2024-04-08-(메모) graphviz.html",
    "href": "메모/2024-04-08-(메모) graphviz.html",
    "title": "(메모) grahpviz",
    "section": "",
    "text": "import graphviz\ndef gv(s): return graphviz.Source('digraph G{ rankdir=\"LR\"'+s + '; }');\n\n\ngv('''\nsplines=line\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"X1\"\n    \"X2\"\n    \"..\"\n    \"X784\"\n    label = \"Layer: \"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"X1\" -&gt; \"node1\"\n    \"X2\" -&gt; \"node1\"\n    \"..\" -&gt; \"node1\"\n    \"X784\" -&gt; \"node1\"\n    \n    \"X1\" -&gt; \"node2\"\n    \"X2\" -&gt; \"node2\"\n    \"..\" -&gt; \"node2\"\n    \"X784\" -&gt; \"node2\"\n    \n    \"X1\" -&gt; \"...\"\n    \"X2\" -&gt; \"...\"\n    \"..\" -&gt; \"...\"\n    \"X784\" -&gt; \"...\"\n    \n    \"X1\" -&gt; \"node32\"\n    \"X2\" -&gt; \"node32\"\n    \"..\" -&gt; \"node32\"\n    \"X784\" -&gt; \"node32\"\n\n    label = \"Layer: ReLU\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n    \"node1\" -&gt; \"y1\"\n    \"node2\" -&gt; \"y1\"\n    \"...\" -&gt; \"y1\"\n    \"node32\" -&gt; \"y1\"\n    \n    \"node1\" -&gt; \"y2\"\n    \"node2\" -&gt; \"y2\"\n    \"...\" -&gt; \"y2\"\n    \"node32\" -&gt; \"y2\"    \n    label = \"Layer: Softmax\"\n}\n''')\n\n\n\n\n\n\n\n\n\ngv('''\nsplines=line\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"X1\"\n    \"X2\"\n    \"..\"\n    \"X784\"\n    label = \"Layer: \"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"X1\" -&gt; \"node1\"\n    \"X2\" -&gt; \"node1\"\n    \"..\" -&gt; \"node1\"\n    \"X784\" -&gt; \"node1\"\n    \n    \"X1\" -&gt; \"node2\"\n    \"X2\" -&gt; \"node2\"\n    \"..\" -&gt; \"node2\"\n    \"X784\" -&gt; \"node2\"\n    \n    \"X1\" -&gt; \"...\"\n    \"X2\" -&gt; \"...\"\n    \"..\" -&gt; \"...\"\n    \"X784\" -&gt; \"...\"\n    \n    \"X1\" -&gt; \"node32\"\n    \"X2\" -&gt; \"node32\"\n    \"..\" -&gt; \"node32\"\n    \"X784\" -&gt; \"node32\"\n\n    label = \"Layer: ReLU\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n    \"node1\" -&gt; \"y\"\n    \"node2\" -&gt; \"y\"\n    \"...\" -&gt; \"y\"\n    \"node32\" -&gt; \"y\"\n    label = \"Layer: Sigmoid\"\n}\n''')"
  },
  {
    "objectID": "메모/2000-01-10-(메모) DGX staion.html",
    "href": "메모/2000-01-10-(메모) DGX staion.html",
    "title": "(메모) DGX station 설정",
    "section": "",
    "text": "- root 획득\nsudo -i \n- 모든 GPU enable\nnvidia-smi -mig 1 \nsudo systemctl stop nvidia-mig-manager.service\nsudo systemctl disable nvidia-mig-manager.service\nreboot\n- 모든 특정 GPU만 enable\n#nvidia-smi -i {GPUdev-ID} -mig 1\nnvidia-smi -i 0 -mig 1 \nsudo systemctl stop nvidia-mig-manager.service\nsudo systemctl disable nvidia-mig-manager.service\nreboot \n- GPU가 MIG 모드로 되면 아래와 같이 GPU-Util 에 N/A로 표시된다. 아래는 0,1,2,4 에 대응하는 GPU가 MIG모드로 설정된 상태임\n\n\n\n\n- 용어정리\n\nGPU: 말 그대로 GPU\nGI: GPU INSTANCE, 하나의 GPU에 여러개의 GPU INSTANCE가 존재할 수 있음.\nCI: COMPUTE INSTANCE, 하나의 GPU INSTANCE에 여러개의 COMPUTE INSTANCE를 만들 수 있음.\n\n- 상황확인\nnvidia-smi \n\n- GPU의 해석\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.141.03   Driver Version: 470.141.03   CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  NVIDIA A100-SXM...  On   | 00000000:01:00.0 Off |                   On |\n| N/A   37C    P0    53W / 275W |      0MiB / 81251MiB |     N/A      Default |\n|                               |                      |              Enabled |\n+-------------------------------+----------------------+----------------------+\n|   1  NVIDIA A100-SXM...  On   | 00000000:47:00.0 Off |                   On |\n| N/A   38C    P0    52W / 275W |      0MiB / 81251MiB |     N/A      Default |\n|                               |                      |              Enabled |\n+-------------------------------+----------------------+----------------------+\n|   2  NVIDIA A100-SXM...  On   | 00000000:81:00.0 Off |                   On |\n| N/A   37C    P0    54W / 275W |      0MiB / 81251MiB |     N/A      Default |\n|                               |                      |              Enabled |\n+-------------------------------+----------------------+----------------------+\n|   3  NVIDIA DGX Display  On   | 00000000:C1:00.0 Off |                  N/A |\n| 36%   39C    P8    N/A /  50W |      1MiB /  3911MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n|   4  NVIDIA A100-SXM...  On   | 00000000:C2:00.0 Off |                   On |\n| N/A   37C    P0    55W / 275W |      0MiB / 81251MiB |     N/A      Default |\n|                               |                      |              Enabled |\n+-------------------------------+----------------------+----------------------+\n총 4개의 GPU가 있으며 아이디는 0,1,2,4 임을 알 수 있다.\n- GPUdev-ID, GI-ID, CI-ID, MIGdev-ID 확인\n+-----------------------------------------------------------------------------+\n| MIG devices:                                                                |\n+------------------+----------------------+-----------+-----------------------+\n| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |\n|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|\n|                  |                      |        ECC|                       |\n|==================+======================+===========+=======================|\n|  1    0   0   0  |      0MiB / 81251MiB | 98      0 |  7   0    5    1    1 |\n|                  |      1MiB / 13107... |           |                       |\n+------------------+----------------------+-----------+-----------------------+\n|  2    0   0   0  |      0MiB / 81251MiB | 98      0 |  7   0    5    1    1 |\n|                  |      1MiB / 13107... |           |                       |\n+------------------+----------------------+-----------+-----------------------+\n아래와 같은 상황을 유추할 수 있다.\n\n\n\nGPUdev ID\nGI ID\nCI ID\nMIGdev ID\n\n\n\n\n1\n0 (80G)\n0 (98SM)\n0\n\n\n2\n0 (80G)\n0 (98SM)\n0\n\n\n\n- 생성가능한 gi 확인\n\n- 생성가능한 ci 확인\n\n\n\nNote: GPU 1,2 에만 GI가 존재하므로, 목록에는 GPU 1,2 만 보임\n\n\n\n\n\n- GPUdev = 4 에서 생성가능한 GI 조회\n#nvidia-smi mig -i {GPUdev-ID} -lgip\nnvidia-smi mig -i 4 -lgip\n\n- 아래에 해당하는 GI를 2개 생성하고 싶다고 하자. (GPU-INSTANCE-PROFILE-ID=9 임을 유의)\n+-----------------------------------------------------------------------------+\n| GPU instance profiles:                                                      |\n| GPU   Name             ID    Instances   Memory     P2P    SM    DEC   ENC  |\n|                              Free/Total   GiB              CE    JPEG  OFA  |\n|=============================================================================|\n|   4  MIG 3g.40gb        9     0/2        39.50      No     42     2     0   |\n|                                                             3     0     0   |\n+-----------------------------------------------------------------------------+\n#nvidia-smi mig -i {GPUdev-ID} -cgi {GPU-INSTANCE-PROFILE-ID}\nnvidia-smi mig -i 4 -cgi 9 \nnvidia-smi mig -i 4 -cgi 9 \n\n\n\nNote: 2개까지는 잘 ㅁ나들어지고 그 이후에는 리소스 부족으로 에러가 발생한다.\n\n\n\n2개까지는 잘 만들어지고 그 이후에는 리소스부족으로 에러발생\n\n- 만들어진 GI 확인\n\n\n\nNote: 1,2번 GPU에 각각 GI가 1개씩 있고 4번 GPU에 GI가 2개 있다.\n\n\n- 생성가능한 CI 확인\nnvidia-smi mig -lcip\n\n\n\nNote: {GPU ID: GPU INSTANCE ID} 의 조합에서 {1:0}, {2:0}, {4:1}, {4:2} 에 해당하는 GI에서 생성가능한 CI들이 각각 출력된다. 4번 GPU의 GI들은 40기가가 한계이므로 생성가능 CI목록이 상대적으로 제한적임을 캐치하라\n\n\n\n\n\n- GPUdev=4 에서 생성가능한 CI 조회\n#nvidia-smi mig -i {GPU ID} -lcip\nnvidia-smi mig -i 4 -lcip\n\n\n\nNote: 각 GPU-인스턴스(GI)에서는 3개 계산-인스턴스(CI)를 만들수 있음. 만약에 Profile ID = 0 으로 만든다면 14의 계산능력을 가진 CI를 3개까지 만들수 있음, 만약 Profile ID = 2* 로 만든다면 42개의 계산능력을 가진 CI를 1개만 만들 수 있음\n\n\n- {GPUdev-ID:GI-ID} = {4:1} 에서 COMPUTE-INSTANCE-PROFILE-ID=0 에 해당하는 CI를 3개 생성\n#nvidia-smi mig -i {GPUdev-ID} -gi {GI-ID} -cci {COMPUTE-INSTANCE-PROFILE-ID}\nnvidia-smi mig -i 4 -gi 1 -cci 0\n\n\n\nNote: 자원부족으로 3개까지 밖에 못만든다..\n\n\n- {GPUdev-ID:GI-ID}={4:2} 에서 COMPUTE-INSTANCE-PROFILE-ID=2 에 해당하는 CI를 1개 생성\n#nvidia-smi mig -i {GPUdev-ID} -gi {GI-ID} -cci {COMPUTE-INSTANCE-PROFILE-ID}\nnvidia-smi mig -i 4 -gi 2 -cci 2 \n\n\n\nNote: 자원이 부족해서 1개밖에 못 만든다.\n\n\n- 현재 상황\n\n\n\n\nGPUdev ID\nGI ID\nCI ID\nMIGdev ID\n\n\n\n\n1\n0 (80G)\n0 (98SM)\n0\n\n\n2\n0 (80G)\n0 (98SM)\n0\n\n\n4\n1 (80G)\n0 (14SM)\n0\n\n\n4\n1 (80G)\n1 (14SM)\n1\n\n\n4\n1 (80G)\n2 (14SM)\n2\n\n\n4\n2 (80G)\n0 (42SM)\n3\n\n\n\n\n\n\nnvidia-smi mig -i 0 -cgi 0   \nnvidia-smi mig -i 1 -cgi 0   \nnvidia-smi mig -i 2 -cgi 0   \nnvidia-smi mig -i 4 -cgi 0   \nnvidia-smi mig -i 0 -gi 0 -cci 4\nnvidia-smi mig -i 1 -gi 0 -cci 4\nnvidia-smi mig -i 2 -gi 0 -cci 4\nnvidia-smi mig -i 4 -gi 0 -cci 4"
  },
  {
    "objectID": "메모/2000-01-10-(메모) DGX staion.html#a.-mig-모드-enable",
    "href": "메모/2000-01-10-(메모) DGX staion.html#a.-mig-모드-enable",
    "title": "(메모) DGX station 설정",
    "section": "",
    "text": "- root 획득\nsudo -i \n- 모든 GPU enable\nnvidia-smi -mig 1 \nsudo systemctl stop nvidia-mig-manager.service\nsudo systemctl disable nvidia-mig-manager.service\nreboot\n- 모든 특정 GPU만 enable\n#nvidia-smi -i {GPUdev-ID} -mig 1\nnvidia-smi -i 0 -mig 1 \nsudo systemctl stop nvidia-mig-manager.service\nsudo systemctl disable nvidia-mig-manager.service\nreboot \n- GPU가 MIG 모드로 되면 아래와 같이 GPU-Util 에 N/A로 표시된다. 아래는 0,1,2,4 에 대응하는 GPU가 MIG모드로 설정된 상태임"
  },
  {
    "objectID": "메모/2000-01-10-(메모) DGX staion.html#b.-gpu-gi-ci-확인",
    "href": "메모/2000-01-10-(메모) DGX staion.html#b.-gpu-gi-ci-확인",
    "title": "(메모) DGX station 설정",
    "section": "",
    "text": "- 용어정리\n\nGPU: 말 그대로 GPU\nGI: GPU INSTANCE, 하나의 GPU에 여러개의 GPU INSTANCE가 존재할 수 있음.\nCI: COMPUTE INSTANCE, 하나의 GPU INSTANCE에 여러개의 COMPUTE INSTANCE를 만들 수 있음.\n\n- 상황확인\nnvidia-smi \n\n- GPU의 해석\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.141.03   Driver Version: 470.141.03   CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  NVIDIA A100-SXM...  On   | 00000000:01:00.0 Off |                   On |\n| N/A   37C    P0    53W / 275W |      0MiB / 81251MiB |     N/A      Default |\n|                               |                      |              Enabled |\n+-------------------------------+----------------------+----------------------+\n|   1  NVIDIA A100-SXM...  On   | 00000000:47:00.0 Off |                   On |\n| N/A   38C    P0    52W / 275W |      0MiB / 81251MiB |     N/A      Default |\n|                               |                      |              Enabled |\n+-------------------------------+----------------------+----------------------+\n|   2  NVIDIA A100-SXM...  On   | 00000000:81:00.0 Off |                   On |\n| N/A   37C    P0    54W / 275W |      0MiB / 81251MiB |     N/A      Default |\n|                               |                      |              Enabled |\n+-------------------------------+----------------------+----------------------+\n|   3  NVIDIA DGX Display  On   | 00000000:C1:00.0 Off |                  N/A |\n| 36%   39C    P8    N/A /  50W |      1MiB /  3911MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n|   4  NVIDIA A100-SXM...  On   | 00000000:C2:00.0 Off |                   On |\n| N/A   37C    P0    55W / 275W |      0MiB / 81251MiB |     N/A      Default |\n|                               |                      |              Enabled |\n+-------------------------------+----------------------+----------------------+\n총 4개의 GPU가 있으며 아이디는 0,1,2,4 임을 알 수 있다.\n- GPUdev-ID, GI-ID, CI-ID, MIGdev-ID 확인\n+-----------------------------------------------------------------------------+\n| MIG devices:                                                                |\n+------------------+----------------------+-----------+-----------------------+\n| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |\n|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|\n|                  |                      |        ECC|                       |\n|==================+======================+===========+=======================|\n|  1    0   0   0  |      0MiB / 81251MiB | 98      0 |  7   0    5    1    1 |\n|                  |      1MiB / 13107... |           |                       |\n+------------------+----------------------+-----------+-----------------------+\n|  2    0   0   0  |      0MiB / 81251MiB | 98      0 |  7   0    5    1    1 |\n|                  |      1MiB / 13107... |           |                       |\n+------------------+----------------------+-----------+-----------------------+\n아래와 같은 상황을 유추할 수 있다.\n\n\n\nGPUdev ID\nGI ID\nCI ID\nMIGdev ID\n\n\n\n\n1\n0 (80G)\n0 (98SM)\n0\n\n\n2\n0 (80G)\n0 (98SM)\n0\n\n\n\n- 생성가능한 gi 확인\n\n- 생성가능한 ci 확인\n\n\n\nNote: GPU 1,2 에만 GI가 존재하므로, 목록에는 GPU 1,2 만 보임"
  },
  {
    "objectID": "메모/2000-01-10-(메모) DGX staion.html#c.-gi-생성",
    "href": "메모/2000-01-10-(메모) DGX staion.html#c.-gi-생성",
    "title": "(메모) DGX station 설정",
    "section": "",
    "text": "- GPUdev = 4 에서 생성가능한 GI 조회\n#nvidia-smi mig -i {GPUdev-ID} -lgip\nnvidia-smi mig -i 4 -lgip\n\n- 아래에 해당하는 GI를 2개 생성하고 싶다고 하자. (GPU-INSTANCE-PROFILE-ID=9 임을 유의)\n+-----------------------------------------------------------------------------+\n| GPU instance profiles:                                                      |\n| GPU   Name             ID    Instances   Memory     P2P    SM    DEC   ENC  |\n|                              Free/Total   GiB              CE    JPEG  OFA  |\n|=============================================================================|\n|   4  MIG 3g.40gb        9     0/2        39.50      No     42     2     0   |\n|                                                             3     0     0   |\n+-----------------------------------------------------------------------------+\n#nvidia-smi mig -i {GPUdev-ID} -cgi {GPU-INSTANCE-PROFILE-ID}\nnvidia-smi mig -i 4 -cgi 9 \nnvidia-smi mig -i 4 -cgi 9 \n\n\n\nNote: 2개까지는 잘 ㅁ나들어지고 그 이후에는 리소스 부족으로 에러가 발생한다.\n\n\n\n2개까지는 잘 만들어지고 그 이후에는 리소스부족으로 에러발생\n\n- 만들어진 GI 확인\n\n\n\nNote: 1,2번 GPU에 각각 GI가 1개씩 있고 4번 GPU에 GI가 2개 있다.\n\n\n- 생성가능한 CI 확인\nnvidia-smi mig -lcip\n\n\n\nNote: {GPU ID: GPU INSTANCE ID} 의 조합에서 {1:0}, {2:0}, {4:1}, {4:2} 에 해당하는 GI에서 생성가능한 CI들이 각각 출력된다. 4번 GPU의 GI들은 40기가가 한계이므로 생성가능 CI목록이 상대적으로 제한적임을 캐치하라"
  },
  {
    "objectID": "메모/2000-01-10-(메모) DGX staion.html#d.-ci-생성",
    "href": "메모/2000-01-10-(메모) DGX staion.html#d.-ci-생성",
    "title": "(메모) DGX station 설정",
    "section": "",
    "text": "- GPUdev=4 에서 생성가능한 CI 조회\n#nvidia-smi mig -i {GPU ID} -lcip\nnvidia-smi mig -i 4 -lcip\n\n\n\nNote: 각 GPU-인스턴스(GI)에서는 3개 계산-인스턴스(CI)를 만들수 있음. 만약에 Profile ID = 0 으로 만든다면 14의 계산능력을 가진 CI를 3개까지 만들수 있음, 만약 Profile ID = 2* 로 만든다면 42개의 계산능력을 가진 CI를 1개만 만들 수 있음\n\n\n- {GPUdev-ID:GI-ID} = {4:1} 에서 COMPUTE-INSTANCE-PROFILE-ID=0 에 해당하는 CI를 3개 생성\n#nvidia-smi mig -i {GPUdev-ID} -gi {GI-ID} -cci {COMPUTE-INSTANCE-PROFILE-ID}\nnvidia-smi mig -i 4 -gi 1 -cci 0\n\n\n\nNote: 자원부족으로 3개까지 밖에 못만든다..\n\n\n- {GPUdev-ID:GI-ID}={4:2} 에서 COMPUTE-INSTANCE-PROFILE-ID=2 에 해당하는 CI를 1개 생성\n#nvidia-smi mig -i {GPUdev-ID} -gi {GI-ID} -cci {COMPUTE-INSTANCE-PROFILE-ID}\nnvidia-smi mig -i 4 -gi 2 -cci 2 \n\n\n\nNote: 자원이 부족해서 1개밖에 못 만든다.\n\n\n- 현재 상황\n\n\n\n\nGPUdev ID\nGI ID\nCI ID\nMIGdev ID\n\n\n\n\n1\n0 (80G)\n0 (98SM)\n0\n\n\n2\n0 (80G)\n0 (98SM)\n0\n\n\n4\n1 (80G)\n0 (14SM)\n0\n\n\n4\n1 (80G)\n1 (14SM)\n1\n\n\n4\n1 (80G)\n2 (14SM)\n2\n\n\n4\n2 (80G)\n0 (42SM)\n3"
  },
  {
    "objectID": "메모/2000-01-10-(메모) DGX staion.html#e.-요약",
    "href": "메모/2000-01-10-(메모) DGX staion.html#e.-요약",
    "title": "(메모) DGX station 설정",
    "section": "",
    "text": "nvidia-smi mig -i 0 -cgi 0   \nnvidia-smi mig -i 1 -cgi 0   \nnvidia-smi mig -i 2 -cgi 0   \nnvidia-smi mig -i 4 -cgi 0   \nnvidia-smi mig -i 0 -gi 0 -cci 4\nnvidia-smi mig -i 1 -gi 0 -cci 4\nnvidia-smi mig -i 2 -gi 0 -cci 4\nnvidia-smi mig -i 4 -gi 0 -cci 4"
  },
  {
    "objectID": "메모/2000-01-10-(메모) DGX staion.html#a.-컨테이너-생성",
    "href": "메모/2000-01-10-(메모) DGX staion.html#a.-컨테이너-생성",
    "title": "(메모) DGX station 설정",
    "section": "A. 컨테이너 생성",
    "text": "A. 컨테이너 생성\n- 아래와 같은 방식으로 컨테이너 생성\n# nvidia-docker run --gpus '\"device={GPUdev-ID}:{MIGdev-ID}\"' -ti --rm -d -t -p {HOST-PORT}:{CONTAINER-PORT} {DOCKER-IMAGE-NAME} /bin/bash\nnvidia-docker run --gpus '\"device=1:0\"' -ti --rm -d -t -p 7749:7749  -p 1307:1307 ubuntu /bin/bash\nnvidia-docker run --gpus '\"device=2:0\"' -ti -d -t -p 4653:4653  -p 1212:1212 -p 1213:1213 -p 1214:1214 ubuntu /bin/bash\n\n-ti: 컨테이너를 대화형(interactive) 모드로 실행. 이 모드에서 컨테이너와 상호작용할 수 있음.\n--rm: 컨테이너가 종료되면 자동으로 컨테이너를 삭제. 이 옵션을 사용하면 컨테이너를 실행한 후 자동으로 정리.\n-d: 컨테이너를 백그라운드(background) 모드로 실행. 이 옵션을 사용하면 컨테이너가 백그라운드에서 실행되며 터미널이 차지되지 않음.\n-t: 컨테이너에 tty (터미널)를 할당. 이것은 대화형 모드와 함께 사용.\n/bin/bash: 컨테이너가 시작될 때 실행할 명령어. 이 경우, Bash 셸을 실행."
  },
  {
    "objectID": "메모/2000-01-10-(메모) DGX staion.html#b.-컨테이너-실행",
    "href": "메모/2000-01-10-(메모) DGX staion.html#b.-컨테이너-실행",
    "title": "(메모) DGX station 설정",
    "section": "B. 컨테이너 실행",
    "text": "B. 컨테이너 실행\ndocker exec -ti {CONTAINER-ID} bash\n\n여기에서 {CONTAINER-ID}는 docker ps 혹은 docker ps -a로 확인한다."
  },
  {
    "objectID": "메모/2000-01-10-(메모) DGX staion.html#c.-요약",
    "href": "메모/2000-01-10-(메모) DGX staion.html#c.-요약",
    "title": "(메모) DGX station 설정",
    "section": "C. 요약",
    "text": "C. 요약\nnvidia-docker run --gpus '\"device=2:0\"' -ti -d -t -p ????:???? -p ????:???? -p ????:???? -p ????:???? -p ????:???? --name cgb ubuntu /bin/bash\ndocker exec -ti cgb bash"
  },
  {
    "objectID": "메모/2000-01-10-(메모) DGX staion.html#a.-passwd",
    "href": "메모/2000-01-10-(메모) DGX staion.html#a.-passwd",
    "title": "(메모) DGX station 설정",
    "section": "A. passwd",
    "text": "A. passwd\n- 아래를 실행하여 비밀번호를 바꿀것\npasswd root"
  },
  {
    "objectID": "메모/2000-01-10-(메모) DGX staion.html#b.-update-쓸만한-패키지-설치",
    "href": "메모/2000-01-10-(메모) DGX staion.html#b.-update-쓸만한-패키지-설치",
    "title": "(메모) DGX station 설정",
    "section": "B. update & 쓸만한 패키지 설치",
    "text": "B. update & 쓸만한 패키지 설치\n- update\napt update \napt install gcc\napt install build-essential\n- 쓸만한 패키지 설치\napt install vim # vim \napt install openssh-server # ssh \napt install git # git \napt install tmux\n- 요약\napt update && apt install -y gcc build-essential vim openssh-server git tmux"
  },
  {
    "objectID": "메모/2000-01-10-(메모) DGX staion.html#d.-ssh-설정",
    "href": "메모/2000-01-10-(메모) DGX staion.html#d.-ssh-설정",
    "title": "(메모) DGX station 설정",
    "section": "D. ssh 설정",
    "text": "D. ssh 설정\n- /etc/ssh/sshd_config 열기\n# apt install openssh-server\nvi /etc/ssh/sshd_config \n- /etc/ssh/sshd_config 파일내용 맨아래 아래를 추가\n\n...\n...\nPort {My-SSH-Port}\nPermitRootLogin yes\nPasswordAuthentication yes\n- 아래를 실행\nservice ssh restart"
  },
  {
    "objectID": "메모/2000-01-10-(메모) DGX staion.html#e.-anaconda",
    "href": "메모/2000-01-10-(메모) DGX staion.html#e.-anaconda",
    "title": "(메모) DGX station 설정",
    "section": "E. anaconda",
    "text": "E. anaconda\n- 다운로드: https://www.anaconda.com/download\n- (아나콘다 설치) 아나콘다를 다운받은 폴더로 가서 아래와 같이 실행한다.\nbash Anaconda3-2019.03-Linux-x86_64.sh\n대충 bash Ana 정도까지만 치고 tab을 누르면 알아서 완성된다."
  },
  {
    "objectID": "메모/2000-01-10-(메모) DGX staion.html#f.-vscode",
    "href": "메모/2000-01-10-(메모) DGX staion.html#f.-vscode",
    "title": "(메모) DGX station 설정",
    "section": "F. vscode",
    "text": "F. vscode\n- 아래를 이용하여 설치\ncurl -Lk 'https://code.visualstudio.com/sha/download?build=stable&os=cli-alpine-x64' --output vscode_cli.tar.gz\ntar -xf vscode_cli.tar.gz\n- 아래를 이용하여 초기 설정 (깃헙아이디로 인증)\n./code tunnel \n- 초기설정 이후 아래를 이용하여 백그라운드에서 실행\nnohup ./code tunnel &gt; /dev/null 2&gt;&1 &"
  },
  {
    "objectID": "메모/2000-01-10-(메모) DGX staion.html#g.-jupyter",
    "href": "메모/2000-01-10-(메모) DGX staion.html#g.-jupyter",
    "title": "(메모) DGX station 설정",
    "section": "G. Jupyter",
    "text": "G. Jupyter\n- 설정파일 생성\njupyter notebook --generate-config\n- 패스워드 설정\njupyter notebook password\n## 패스워드 치고\n## 확인해야함\n- 설정파일을 열고\nvi /home/cgb2/.jupyter/jupyter_notebook_config.py\n아래의 내용을 수정한다.\nc.??????App.ip = '0.0.0.0'\nc.??????App.port = 1307\nc.??????App.allow_origin = '*'\nc.??????App.allow_remote_access = True\nc.??????App.allow_root = True\n- 주피터 실행할때 아래로 실행\nnohup jupyter lab --ip=\"0.0.0.0\" --port={MY-PORT} --no-browser --allow-root &gt; /dev/null 2&gt;&1 &"
  },
  {
    "objectID": "메모/2000-01-04-(메모) 우분투 익히기.html",
    "href": "메모/2000-01-04-(메모) 우분투 익히기.html",
    "title": "(메모) 우분투 익히기",
    "section": "",
    "text": "/root\n\n루트사용자의 홈 디렉토리\nsudo로도 들어갈 수 없음\n\n/etc\n\n리눅스 시스템 전반적인 환경설정 파일들을 모은 디렉터리임.\n이 디렉터리의 모든 파일은 텍스트형식임.\n/etc/password 사용자 계정정보\n\n/home\n\n사용자의 홈 디렉터리\n\n/mnt\n\n다른 파일 시스템이 파일 시스템에 연결되거나 마운트 되는 위치\n\n/media\n\nCD, USB 장치가 파일 시스템에 연결되거나 마운트되는 위치임\n\n/bin\n\n시스템 부팅과 실행에 필요한 바이너리(=윈도도의 실행파일=macOS의 애플리케이션)들을 포함\n\n/lib\n\n시스템 프로그램에서 사용하는 공유 라이브러리가 저장. 윈도우즈의 DLL과 비슷한 것.\n\n/usr\n\n사용자가 사용하는 모든 프로그램과 지원파일들 (Program files + 프로그램들의 설정값)\n/usr/bin 리눅스 배포판이 설치한 실행 프로그램들이 있다. (여기에 R이 깔린다!!)\n\nhp-align, hp-check, hp-config_usb-printer …\nX11\nvi\ngcc\nsu, sudo\nsar\nssh, ssh-agent, ssh-keygen, ….\nnvidia-smi\n\n/usr/lib 여기에는 /usr/bin에 있는 프로그램들을 위한 공유라이브러리가 저장된다. 여기에 R folder가 있다. (R패키지는 여기말고 다른데 깔림)\n/usr/local/bin 소스코드로 컴파일된 파일, 보통 비어있음\n/usr/local/lib/R/site-library R패키지가 설치되어있음, 예를들면 tidyverse"
  },
  {
    "objectID": "메모/2000-01-04-(메모) 우분투 익히기.html#pwd-whoami",
    "href": "메모/2000-01-04-(메모) 우분투 익히기.html#pwd-whoami",
    "title": "(메모) 우분투 익히기",
    "section": "pwd, whoami",
    "text": "pwd, whoami\n- 현재위치확인\n(base) cgb2@cgb2-desktop:~$ pwd\n/home/cgb2\n- 유저확인\n### 예시1: 유저확인 \n(base) cgb2@cgb2-desktop:~$ whoami \ncgb2 \n\n### 예시2: 루트권한 획득이후 유저확인 \n(base) cgb2@cgb2-desktop:~$ sudo -i # 루트권한 획득\nroot@cgb2-desktop:~# whoami \nroot \n\n### 예시3: 일반유저로 전환후 유저확인\nroot@cgb2-desktop:~# su - cgb2 \n(base) cgb2@cgb2-desktop:~$ whoami\ncgb2"
  },
  {
    "objectID": "메모/2000-01-04-(메모) 우분투 익히기.html#cd-ls",
    "href": "메모/2000-01-04-(메모) 우분투 익히기.html#cd-ls",
    "title": "(메모) 우분투 익히기",
    "section": "cd, ls",
    "text": "cd, ls\n- 홈디렉토리로 이동 + 목록\n(base) cgb2@cgb2-desktop:~/Dropbox$ cd ~\n(base) cgb2@cgb2-desktop:~$ ls\nDesktop                 julia-1.8.5\nDocuments               julia-1.8.5-linux-x86_64.tar.gz\nDownloads               lm.txt\nDropbox                 nbdev_tst\nMusic                   quarto-1.0.37-linux-amd64.deb\nPictures                rstudio-server-2021.09.2-382-amd64.deb\nPublic                  scikit_learn_data\nR                       snap\nTemplates               test.txt\nVideos                  v3net\nanaconda3               v3net-linux-3.6.10.11.805.tar.Z\nblacklist-nouveau.conf  vscode_cli.tar.gz\ncode\n- 루트로 이동 + 목록\n(base) cgb2@cgb2-desktop:~/Dropbox$ cd /\n(base) cgb2@cgb2-desktop:/$ ls\nbin    dev   lib    libx32      media  proc  sbin  swapfile  usr\nboot   etc   lib32  log         mnt    root  snap  sys       var\ncdrom  home  lib64  lost+found  opt    run   srv   tmp\n- ls 자세하게\n(base) cgb2@cgb2-desktop:/$ ls -l\ntotal 2097256\nlrwxrwxrwx   1 root  root           7  2월 11  2022 bin -&gt; usr/bin\ndrwxr-xr-x   3 root  root        4096  7월 27 12:19 boot\ndrwxrwxr-x   2 root  root        4096  2월 11  2022 cdrom\ndrwxr-xr-x  19 root  root        4480  7월 28 12:19 dev\ndrwxr-xr-x 143 root  root       12288  7월 27 21:08 etc\ndrwxr-xr-x   6 root  root        4096  7월  7 11:14 home\nlrwxrwxrwx   1 root  root           7  2월 11  2022 lib -&gt; usr/lib\nlrwxrwxrwx   1 root  root           9  2월 11  2022 lib32 -&gt; usr/lib32\nlrwxrwxrwx   1 root  root           9  2월 11  2022 lib64 -&gt; usr/lib64\nlrwxrwxrwx   1 root  root          10  2월 11  2022 libx32 -&gt; usr/libx32\ndrwxr-x---   2 root  root        4096  2월 11  2022 log\ndrwx------   2 root  root       16384  2월 11  2022 lost+found\ndrwxr-xr-x   2 root  root        4096  8월 19  2021 media\ndrwxr-xr-x   2 root  root        4096  8월 19  2021 mnt\ndrwxr-xr-x   4 jaein saned       4096  7월 16 11:21 opt\ndr-xr-xr-x 418 root  root           0  7월 28 12:16 proc\ndrwx------   6 root  root        4096  7월 27 12:21 root\ndrwxr-xr-x  40 root  root        1220  8월  3 13:31 run\nlrwxrwxrwx   1 root  root           8  2월 11  2022 sbin -&gt; usr/sbin\ndrwxr-xr-x  14 root  root        4096  7월 16 11:10 snap\ndrwxr-xr-x   2 root  root        4096  8월 19  2021 srv\n-rw-------   1 root  root  2147483648  2월 11  2022 swapfile\ndr-xr-xr-x  13 root  root           0  7월 28 12:16 sys\ndrwxrwxrwt  19 root  root       20480  8월  3 13:29 tmp\ndrwxr-xr-x  14 root  root        4096  8월 19  2021 usr\ndrwxr-xr-x  15 root  root        4096  7월 30  2022 var"
  },
  {
    "objectID": "메모/2000-01-04-(메모) 우분투 익히기.html#h-man",
    "href": "메모/2000-01-04-(메모) 우분투 익히기.html#h-man",
    "title": "(메모) 우분투 익히기",
    "section": "-h, man",
    "text": "-h, man\n- 도움말확인\n(base) cgb2@cgb2-desktop:~$ git --help\nusage: git [--version] [--help] [-C &lt;path&gt;] [-c &lt;name&gt;=&lt;value&gt;]\n           [--exec-path[=&lt;path&gt;]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=&lt;path&gt;] [--work-tree=&lt;path&gt;] [--namespace=&lt;name&gt;]\n           &lt;command&gt; [&lt;args&gt;]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help &lt;command&gt;' or 'git help &lt;concept&gt;'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n- 메뉴얼 확인\n(base) cgb2@cgb2-desktop:~$ man git"
  },
  {
    "objectID": "메모/2000-01-04-(메모) 우분투 익히기.html#cp-mv-mkdir-rm",
    "href": "메모/2000-01-04-(메모) 우분투 익히기.html#cp-mv-mkdir-rm",
    "title": "(메모) 우분투 익히기",
    "section": "cp, mv, mkdir, rm",
    "text": "cp, mv, mkdir, rm\n- 카피\ncp file1 file2 # file1을 복사하여 file2를 새로 만듬. file2가 이미 있다면 file1의 내용을 덮어씀 \ncp -r dir1 dir2 # dir1의 모든파일을 복사하여 dir2로 이동한뒤 붙어넣음. dir2가 없다면 새로 만듬. 기존의 dir2에 있던 파일이 삭제되는건 아님 \n- 이동\nmv file1 file2 # file1을 이동하여 file2로 이름바꿈. file2가 이미 있다면 file1의 내용을 덮어씀 \nmv -r dir1 dir2 # dir1의 모든파일을 잘라내어 dir2로 이동. \n- 디렉토리 생성\nmkdir temp\nmkdir temp1, temp2, temp3 # 여러개를 만듬\n- 삭제\nrm file1 # file1삭제 \nrm -r file1 dir1 # file1삭제 dir1폴더삭제 \nrm -rf file1 dir1 # 위와 동일한데 file1이나 dir1이 존재하지 않더라고 rm이 실행\n- -v(verbose)를 쓰면 친절한 느낌이 든다.\n(base) cgb2@cgb2-desktop:~/Dropbox$ cp *.txt temppp -v\n'colab.txt' -&gt; 'temppp/colab.txt'"
  },
  {
    "objectID": "메모/2000-01-04-(메모) 우분투 익히기.html#scp",
    "href": "메모/2000-01-04-(메모) 우분투 익히기.html#scp",
    "title": "(메모) 우분투 익히기",
    "section": "scp",
    "text": "scp\n- cgb2에 있는 lm.txt를 cgb5로 옮김. 포트는 cgb5에 대응하는 포트\ncgb2@cgb2-desktop:~$ scp -P 4653 lm.txt cgb5@210.117.173.185:~\n- cgb2에 있는 lm.txt를 맥으로 가져옴. 포트는 cgb2에 대응하는 포트"
  },
  {
    "objectID": "메모/2000-01-04-(메모) 우분투 익히기.html#find",
    "href": "메모/2000-01-04-(메모) 우분투 익히기.html#find",
    "title": "(메모) 우분투 익히기",
    "section": "find",
    "text": "find\n- Dropbox라는 이름이 포함된 폴더 찾기\nfind ~ -type d -name \"Dropbox\"\n\n여기에서 ~는 검색을 시작할 최상위 디렉토리를 쓴다.\n여기에서 -type d는 디렉토리라는 의미이다.\n\n- sy.tex이라는 파일찾기\nfind ~ -type f -name \"sy.tex\"\n\n여기에서 ~는 검색을 시작할 최상위 디렉토리를 쓴다.\n여기에서 -type d는 디렉토리라는 의미이다."
  },
  {
    "objectID": "메모/2000-01-04-(메모) 우분투 익히기.html#wget",
    "href": "메모/2000-01-04-(메모) 우분투 익히기.html#wget",
    "title": "(메모) 우분투 익히기",
    "section": "wget",
    "text": "wget\n- 인터넷에서 파일 다운로드\nwget https://download2.rstudio.org/server/bionic/amd64/rstudio-server-1.2.5033-amd64.deb"
  },
  {
    "objectID": "메모/2000-01-04-(메모) 우분투 익히기.html#gdebi-deb",
    "href": "메모/2000-01-04-(메모) 우분투 익히기.html#gdebi-deb",
    "title": "(메모) 우분투 익히기",
    "section": "gdebi, deb",
    "text": "gdebi, deb\n- deb파일을 gdebi로 설치하는 방법\nsudo gdebi rstudio-server-1.2.5033-amd64.deb\n- deb파일을 dpkg를 이용하여 설치하는 방법\ndpkg -i quarto-1.2.335-linux-amd64.deb # 설치\ndpkg -r quarto # 삭제 \n- gdebi, deb의 차이\n\ngdebi는 관련패키지를 모두 찾아서 설치 dpkg는 하나의 패키지만 설치. 즉 gdebi는 conda 느낌이고 dpkg는 pip 느낌\ngdebi는 별도의 삭제옵션을 지원하지 않음. 따라서 gdebi로 설치한 deb을 삭제하려면 머리아플수도?\n\n- gdebi로 설치한 패키지를 삭제하는 방법\n\n\n\n\n\n\nChat-GPT 답변\n\n\n\ngdebi로 패키지를 삭제하는 것은 아쉽게도 직접적으로 지원하지 않습니다. gdebi는 주로 패키지를 설치할 때 사용되는 도구이며, 패키지의 삭제에는 사용되지 않습니다. 패키지를 삭제하려면 다른 도구인 dpkg나 패키지 관리자 명령을 사용해야 합니다.\n패키지를 삭제하는 방법은 아래와 같습니다. 패키지를 삭제하기 전에 해당 패키지가 다른 의존하는 패키지에 영향을 주지 않는지 주의깊게 확인하시기 바랍니다.\ndpkg를 사용하여 패키지 삭제하기:\nsudo dpkg -r 패키지이름\n여기서 패키지이름은 삭제하려는 패키지의 이름입니다. 이 명령을 실행하면 해당 패키지가 삭제됩니다.\napt를 사용하여 패키지 삭제하기 (의존성 관리 포함):\nsudo apt remove 패키지이름\n위 명령은 apt를 통해 패키지를 삭제하며, 의존성을 포함하여 관련된 패키지들도 자동으로 처리합니다. 이 방법은 일반적으로 패키지 삭제에 더 효과적입니다.\n위의 방법 중 하나를 선택하여 패키지를 삭제할 수 있습니다. 패키지 삭제 시에는 주의하여 의존성 문제가 발생하지 않도록 해야 합니다."
  },
  {
    "objectID": "메모/2000-01-04-(메모) 우분투 익히기.html#apt",
    "href": "메모/2000-01-04-(메모) 우분투 익히기.html#apt",
    "title": "(메모) 우분투 익히기",
    "section": "apt",
    "text": "apt\nsudo apt update\nsudo apt list \nsudo apt install {openssh-server}  \nsudo apt remove {r-base-core}\nsudo apt purge {r-base* r-recommended r-cran-*}\nsudo apt autoremove\n- sudo apt-get과 sudo apt 차이? 별 차이 없는듯\n\nhttps://askubuntu.com/questions/445384/what-is-the-difference-between-apt-and-apt-get\n\n\nThey are very similar command line tools available in Trusty (14.04) and later. apt-get and apt-cache’s most commonly used commands are available in apt. apt-get may be considered as lower-level and “back-end”, and support other APT-based tools. apt is designed for end-users (human) and its output may be changed between versions."
  },
  {
    "objectID": "메모/2000-01-04-(메모) 우분투 익히기.html#conda",
    "href": "메모/2000-01-04-(메모) 우분투 익히기.html#conda",
    "title": "(메모) 우분투 익히기",
    "section": "conda",
    "text": "conda\nconda env list\nconda list \nconda install -c conda-forge jupyterlab \nconda install -c conda-forge r-devtools\nconda remove jupyterlab \nconda remove r-base\nconda update -n py38r40 scipy # conda update scipy"
  },
  {
    "objectID": "메모/2000-01-04-(메모) 우분투 익히기.html#pip",
    "href": "메모/2000-01-04-(메모) 우분투 익히기.html#pip",
    "title": "(메모) 우분투 익히기",
    "section": "pip",
    "text": "pip\npip\npip list\npip list &gt; list.txt\npip freeze # 좀 더 자세히 나온다 \npip freeze &gt; list.txt \npip show matplotlib # 설치된패키지 정보가 나옴. 좋음.\npip install rpy2\npip install -r list.txt \npip install dash==1.13.3\npip install jupyterlab \"ipywidgets&gt;=7.5\"\npip install -U numpy\npip install --upgrade pip\npip install --upgrade tensorflow\npip uninstall matplotlib"
  },
  {
    "objectID": "메모/2000-01-04-(메모) 우분투 익히기.html#a1.-덜-중요한-명령어",
    "href": "메모/2000-01-04-(메모) 우분투 익히기.html#a1.-덜-중요한-명령어",
    "title": "(메모) 우분투 익히기",
    "section": "A1. 덜 중요한 명령어",
    "text": "A1. 덜 중요한 명령어\n\nfile\n- 뭐하는 파일인지 알고싶다면?\n(base) cgb2@cgb2-desktop:~/Dropbox/03_yechan3$ file 1_essays.qmd \n1_essays.qmd: ASCII text\n\n\ndate, cal\n- 날짜\n(base) cgb2@cgb2-desktop:~$ date\n2023. 08. 03. (목) 16:10:38 KST\n- 달력\n(base) cgb2@cgb2-desktop:~$ cal\n      8월 2023         \n일 월 화 수 목 금 토  \n       1  2  3  4  5  \n 6  7  8  9 10 11 12  \n13 14 15 16 17 18 19  \n20 21 22 23 24 25 26  \n27 28 29 30 31"
  },
  {
    "objectID": "메모/2000-01-08-(메모) 주피터랩, 설정 및 몇가지 팁.html",
    "href": "메모/2000-01-08-(메모) 주피터랩, 설정 및 몇가지 팁.html",
    "title": "(메모) 주피터랩, 설정 및 몇가지 팁",
    "section": "",
    "text": "주피터에 R커널을 연결할 경우 그림크기 조정\noptions(repr.plot.width=10, repr.plot.height=3,repr.plot.res=300)\n\n\n깃허브에서 *.py파일 불러오기\nimport requests\nexec(requests.get('http://miruetoto.github.io/my_code/datahandling.py').text)\n\n\nrpy2 magic\nimport rpy2\n%load_ext rpy2.ipython\n\n\n깃허브에서 *.R파일 불러오기\nimport rpy2\n%load_ext rpy2.ipython\n%R library(devtools)\n%R source_url(\"http://miruetoto.github.io/my_code/datahandling.r\")\n\n\nmatplotlib 그림크기조정\nimport matplotlib as mpl \nimport matplotlib.pyplot as plt \nIpython_default=plt.rcParams.copy() # save initial value \nfrom matplotlib import cycler\nplt.rc('figure',dpi=150) # default value 4 figure.dpi is 72.0 \n# plt.rcParams.update(Ipython_default) # load initial value \n\n\n깃랩관련 (회사아니면 필요없음)\n- load *.py from gitlab\nimport gitlab\ngl = gitlab.Gitlab('http://10.178.145.54:9000', private_token='RkZz465zdyyEChamLKy8')\ngl.auth()\nproject = gl.projects.get(2)\n\n# (1) load RF.py, RF_withGIT.py, RF_withR.py\nRF_py = project.files.get(file_path='modeling/RF.py', ref='fridge').decode()\nRF_GIT_py = project.files.get(file_path='utils/RF_withGIT.py', ref='fridge').decode()\nRF_R_py = project.files.get(file_path='utils/RF_withR.py', ref='fridge').decode()\nexec(str(RF_py, 'utf-8'))\nexec(str(RF_GIT_py, 'utf-8'))\nexec(str(RF_R_py, 'utf-8'))\n- load *.R in gitlab\nimport gitlab\ngl = gitlab.Gitlab('http://10.178.145.54:9000', private_token='RkZz465zdyyEChamLKy8')\ngl.auth()\nproject = gl.projects.get(2)\nRF_R_rcode = project.files.get(file_path='utils/RF_Rfunctions.r', ref='fridge').decode()\n# tricks for source('Rfunctions.r')\nfile1 = open(\"RF_Rfunctions.r\",\"w\") \nfile1.write(str(RF_R_rcode, 'utf-8'))\nfile1.close() \nro.r(\"source('RF_Rfunctions.r')\")\nimport os\nos.remove('RF_Rfunctions.r')\n\n\n& 옵션으로 주피터 실행\n- 서버에 접속한다.\nssh lgcgb@10.178.144.65\n아래와 같이 끝에 &을 붙이면 된다.\nconda activate py20190129\njupyter lab &\n실행하고 난뒤에는 엔터를 쳐서 빠져나온다. 이렇게 하면 서버자체에 모니터를 연결하고 커널창을 띄운것과 같은 효과를 준다. 즉 서버에 접속한 컴퓨터를 끄는것과 상관없이 서버에서는 항상 주피터가 열려 있게 된다.\n\n\n& 옵션으로 실행한 주피터프로세스 죽이기\n- 서버에 접속한다.\nssh lgcgb@10.178.144.65\n실행된 프로세스를 찾기위해 아래를 실행한다.\nps aux | grep jupyter-lab\n결과는 아래와 같이 나온다.\nlgcgb    26888  0.2  0.1 326760 86724 ?        Sl   10:14   0:12 /home/lgcgb/anaconda3/envs/py20190129/bin/python3.7 /home/lgcgb/anaconda3/envs/py20190129/bin/jupyter-lab\nlgcgb    27146  0.0  0.0  15720  1008 pts/3    S+   11:56   0:00 grep --color=auto jupyter-lab\n26888에 해당하는 것이 주피터를 띄운 커널이다. 이 번호를 기억했다가 프로세스를 아래와 같은 명령으로 죽인다.\nkill 26888\n\n\n패스워드 없이 주피터 실행\n- 아래와 같이 하면 외부에서 접속할때 패스워드를 입력하지 않음.\njupyter notebook --ServerApp.token='' --ServerApp.password=''"
  },
  {
    "objectID": "메모/2000-01-01-(메모) 우분투 포맷 및 개발용 서버 셋팅(old).html",
    "href": "메모/2000-01-01-(메모) 우분투 포맷 및 개발용 서버 셋팅(old).html",
    "title": "(메모) 우분투 포맷 및 개발용 서버 셋팅 (old)",
    "section": "",
    "text": "About this doc\n- 우분투에서 여러가지 개발환경을 설정하는 방법을 포스팅 하겠다.\n- 이 포스트는 우분투를 메인OS(사무용+연구용)로 사용하고 싶은 사람, 우분투를 활용하여 개발용 서버를 구축하고 싶은 사람에게 모두 유용한다.\n- 이 포스트는 2080 이상의 GPU를 활용한 학습을 원하는 사람에게 유용하다.\n- 이 포스트는 R과 파이썬을 동시에 쓰는 사람에게 유용하다.\n- 이 포스트는 Rstudio, Jupyter Lab을 동시에 쓰는 사람에게 유용하다.\n- 매년 조금씩 셋팅방법이 다른것 같다.\n- 가장 최근에는 2023년 3월8일에 이 블로그 내용으로 셋팅해보았음.\n\n\n우분투설치\n- 22.04부터는 파티션 나누지 않고 그냥 설치해도 잘 되는것 같다.\n\n\n네트워크 설정\n- ?표시있는 아이콘 \\(\\to\\) Wired Connected \\(\\to\\) Wired Settings \\(\\to\\) Connection의 설정 \\(\\to\\) IPv4 \\(\\to\\) Manual \\(\\to\\) Address, Netmask, Gateway, DNS 설정 \\(\\to\\) 네트워크 토글\n\n\n한글설정 (개발용 서버일 경우 생략 가능)\n- 아래와 같이 커맨드에 친다.\nibus-setup\n이걸 치면 IBus Preferences 라는 창이 나오는데 여기에서 (1) Input Method 탭 클릭 (2) Add 버튼 클릭 (3) Korean 선택 (4) Hangul 선택을 한다.\n- 위의 단계에서 Korean이 안보이면 Language Support로 가서 한국어팩을 설치하고 리부팅 하면 된다. (보통 실행하자마자 알아서 설치되더라.. 설치가 안되면 Install / Remove Languages... 이라는 탭을 클릭해서 설치하자) 리부팅을 꼭 해야한다는 것에 주의하자.\n- 이제 Region & Language로 가서 설정하면 된다.\n\n\n그래픽카드 드라이버설치\n- 전체적인 내용은 여기를 참고하자.\n- 준비작업\nsudo apt update \nsudo apt install gcc\nsudo apt install build-essential\n- 우선 gedit를 열고 아래를 복사해서 붙여넣는다.\nblacklist nouveau\noptions nouveau modeset=0\n파일이름을 blacklist-nouveau.conf로 home에 저장\n- 루트권한획득\nsudo -i\n아이디와 비밀번호를 입력하고 루트권한을 얻는다.\n- 아래를 입력한다.\nsudo cp /home/cgb2/blacklist-nouveau.conf /etc/modprobe.d\nsudo update-initramfs -u\nsudo reboot \n- 그래픽카드 다운로드: 드라이버 설치파일을 다운받는다. 앤비디아공식홈페이지에서 다운받자. OS를 리눅스 64-bit으로 선택하고 검색을 누르면 다운받아진다.\n- 그래픽키다 설치: 다운받은뒤에는 파일이 있는 폴더로 이동하여\nchmod +x NVIDIA-Linux-x86_64-410.78.run\n를 실행하자. 보통 NVI까지치고 적당히 탭을 누르면 알아서 뒷부분이 완성된다. 이 과정은 추후에 드라이버를 실행할수 있도록 권한을 풀어두는 것이다. 그리고 아래를 실행한다.\nsudo ./NVIDIA-Linux-x86_64-410.78.run\n그 다음 드라이버가 잘 설치되었는지 확인한다.\nnvidia-smi\n\n\n아나콘다\n- (아나콘다 설치) 아나콘다를 다운받은 폴더로 가서 아래와 같이 실행한다.\nbash Anaconda3-2019.03-Linux-x86_64.sh\n대충 bash Ana 정도까지만 치고 tab을 누르면 알아서 완성된다.\n- (환경만들기) 커맨드를 키고 아래를 실행한다.\n(base) conda create -n py38r40 python=3.8\n(base) conda create --name py38r40 python=3.8\n둘 중 아무거나 실행해도 된다. 파이썬 환경이 너무 높으면 나중에 conda tensorflow-gpu가 먹히지 않으니 환경을 만들때 파이썬버전을 3.8.x로 하자. (현시점 2021년 2월25일기준 3.9.x이면 conda tensorflow-gpu 가 동작하지 않음.)\n\n\nssh연결\n- 처음에 ssh를 연결하기위해서는 연결당하는 컴퓨터에 가서 아래를 실행해야 한다.\nsudo apt install openssh-server\n22번포트 우회하기\n- step1: /etc/ssh/sshd_config 파일을 연다.\nsudo vi /etc/ssh/sshd_config \n- step2: Port 22 라고 된 부분의 주석을 풀고 원하는 포트번호 설정\n...\n\n#Port 22\n#AddressFamily any\n#ListenAddress 0.0.0.0\n#ListenAddress ::\n\n...\n- step3: 수정내용을 적용\nsudo systemctl restart ssh.service\n- step4: 수정한 포트로 ssh접속\n\n\n주피터 원격제어\n- 1단계: 주피랩설치\n(py38) conda install -c conda-forge jupyterlab\n\nNote: 사실 위에서 주피터랩을 따로 설치안해도 주피터랩이 잘만 실행된다. 하지만 이렇게하니까 나중에 R커널을 만들기위해 IRkernel::installspec()을 실행할때 에러가 난다.\n\n- 2단계: 패스워드 설정\n(py38) jupyter lab --generate-config\n(py38) jupyter lab password\n- 3단계: jupyter lab 환경설정\nnano /home/cgb/.jupyter/jupyter_lab_config.py \n아래를 변경\nc.ServerApp.ip = '192.168.0.4'\nc.ServerApp.port = 1306\nc.ServerApp.open_browser = False\n여기에서 192.168.0.4 는 내부아이피다. 고정아피이가 있다면 고정아이피 주소를 쓰면 된다.\n\n\n주피터노트북 원격제어\n- 1단계: 주피터노트북 설치 (보통 lab을 설치하면 이미 설치되어있음)\n(py38) conda install -c conda-forge notebook \n- 2단계: 패스워드 설정\nfrom notebook.auth import passwd\npasswd()\nEnter password: \nVerify password: \n생성된값 (argon 어쩌고..)을 복사\n- 3단계: 환경설정\njupyter notebook --generate-config\nnano /home/cgb/.jupyter/jupyter_notebook_config.py\n아이피주소와 패스워드를 바꾼다. (port는 선택, browser도 선택 )\nc.NotebookApp.open_browser = False\nc.NotebookApp.ip = '192.168.0.4'\nc.NotebookApp.port = 1307\nc.NotebookApp.password = ''\n여기에서 192.168.0.4 는 내부아이피다. 고정아피이가 있다면 고정아이피 주소를 쓰면 된다.\n\nTip: 주피터노트북과 랩을 양쪽으로 셋팅후 주피터 노트북으로 실행하면 2개를 모두 쓸 수 있음\n\n\n\nR설치ver1: (base)에 설치\n- 설치전: 기존의 R 삭제\nconda remove r-base -y \nsudo apt-get remove r-base-core \nsudo apt purge r-base* r-recommended r-cran-*\nsudo apt autoremove\n- R설치전 준비작업: 나노에디터를 키고 /etc/apt/sources.list를 연다.\nsudo nano /etc/apt/sources.list\n화살표로 이동하여 맨아래로 간뒤에 아래중 하나를 추가한다. (나는 focal-cran40으로 추가함)\ndeb https://cloud.r-project.org/bin/linux/ubuntu impish-cran40/\ndeb https://cloud.r-project.org/bin/linux/ubuntu hirsute-cran40/\ndeb https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/\ndeb https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/\ndeb https://cloud.r-project.org/bin/linux/ubuntu xenial-cran40/\n저장후 나노에디터 종료. 그리고 아래를 실행.\nsudo apt-get update\n경우에 따라서 아래와 같은 에러메시지가 뜰 수 있다.\n...\nW: GPG error: https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9 \n...\n공개키가 없어서 생기는 에러이므로 아래와 같이 가져온다.\nwget -qO- https://cloud.r-project.org/bin/linux/ubuntu/marutter_pubkey.asc | sudo tee -a /etc/apt/trusted.gpg.d/cran_ubuntu_key.asc\nsudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9\n#sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 51716619E084DAB9\n그리고 다시 아래를 실행\nsudo apt-get update\n에러가 없이 뭔가 마무리 되어야한다.\n(base) cgb3@cgb3:~$ sudo apt-get update\nIgn:1 http://linux.dropbox.com/ubuntu disco InRelease\nHit:2 http://security.ubuntu.com/ubuntu focal-security InRelease  \nHit:3 http://kr.archive.ubuntu.com/ubuntu focal InRelease                                 \nHit:4 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease                \nHit:5 http://linux.dropbox.com/ubuntu disco Release                 \nGet:6 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\nHit:8 http://kr.archive.ubuntu.com/ubuntu focal-updates InRelease\nGet:9 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ Packages [46.4 kB]\nHit:10 http://kr.archive.ubuntu.com/ubuntu focal-backports InRelease\nFetched 50.0 kB in 1s (36.5 kB/s)                   \nReading package lists... Done\n- R설치\nwget http://security.ubuntu.com/ubuntu/pool/main/i/icu/libicu66_66.1-2ubuntu2_amd64.deb\nsudo dpkg -i libicu66_66.1-2ubuntu2_amd64.deb\nsudo apt-get install r-base\n- tidyverse 설치 (R studio 설치전에 tidyverse 설치해야함)\n- Rstudio 설치: https://www.rstudio.com/products/rstudio/download-server/debian-ubuntu/\n\n우분투22로 설정할것!!\n\nsudo apt remove rstudio-server\nsudo apt-get install gdebi-core\nwget https://download2.rstudio.org/server/jammy/amd64/rstudio-server-2022.12.0-353-amd64.deb\nsudo gdebi rstudio-server-2022.12.0-353-amd64.deb\n- Rstudio를 설치하면 ~/R/x86_64-conda-linux-gnu-library/4.1이 새로 생성된다.\n\nRstudio에서 설치한 패키지는 이 폴더에 저장된다.\n\n- 주피터와 R커널 연결\nR # sudo R \ninstall.packages(\"IRkernel\")\nIRkernel::installspec()\n\n\nR설치ver2: (py38r40)에 설치\n- R설치\n(py38r40) conda install -c conda-forge r-essentials=4.0\n이러면 콘다환경에는 R이 깔리고 base에는 R이 깔리지 않는다.\n- 커널연결\n콘다환경에서 R을 실행한다. Rstudio가 아니라 커맨드에서 R을 실행해야한다. 그리고 아래를 실행하면 주피터랩과 R환경이 연결된다.\nIRkernel::installspec()\n이제 주피터랩에서 R kernel을 사용할 수 있다.\n\n\n가상환경에서 Rstudio server 설치 (어려움)\n- 이제 Rstudio server를 설치하는 방법을 다룬다.\n- 먼저 Rstudio를 설치한다. 참고로 Rstudio server 설치하는법은 여기를 참고하라. 요약하면 터미널에서 아래3줄을 입력하기만 하면된다.\n(py38r40) sudo apt-get install gdebi-core\n(py38r40) wget https://download2.rstudio.org/server/bionic/amd64/rstudio-server-1.2.5033-amd64.deb\n(py38r40) sudo gdebi rstudio-server-1.2.5033-amd64.deb\n\nWarning: Rstudio 1.3x 이상을 설치하지말고 1.2x를 설치해야 한다. 이상하게 1.3x이상은 후에 서술할 Gregor Strurm가 그의 깃허브에서 제안하는 방식이 잘 동작하지 않았다. 이는 알려진 문제였고 이를 해결하는 해결책을 서술한 스레드가 있어보이긴 했지만 나는 그냥 Rstudio 1.2x를 설치하고 쓰는 것을 선택했다.\n\n\nNote: 이미 rstudio server 가 다른버전으로 깔려있다면 sudo apt remove rstudio-server 를 통하여 삭제하고 설치하자.\n\n- 이제 Rstudio 설치가 끝났다. 설치된 Rstudio를 아나콘다 가상환경에 설치된 R과 연결해보자. 우선 아래를 실행한다.\n(py38r40) sudo apt install uuid\n(py38r40) sudo apt install git\n(py38r40) git clone https://github.com/grst/rstudio-server-conda.git\n위에 두줄은 Gregor Sturm이 만든 어떤 프로그램을 쓰기 위한 사전준비작업이다. 마지막줄을 실행하면 Gregor Sturm이 만든 프로그램이 다운받아진다. 이게 프로그램 설치가 완료된것이다. 이제 컴퓨터 껐다 킬때마다 아래를 실행한다.\n(py38r40) ./rstudio-server-conda/local/start_rstudio_server.sh 8787 # use any free port number here. \n이제 192.168.0.4:8787 따위의 주소로 접속하면 Rstudio를 쓸 수 있다. 참고로 system-wide Rstudio server를 죽여야 할 때가 있다. 그럴땐 아래 명령을 치면 된다.\n(py38r40) sudo systemctl disable rstudio-server.service\n(py38r40) sudo systemctl stop rstudio-server.service\n\n\n자주 설치하는 패키지 리스트\n- 아래를 미리 깔아두자..\n# conda install -c conda-forge notebook\nconda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch\nconda install -c conda-forge plotly \npip install plotnine\npip install seaborn\npip install opencv-python\npip install folium\npip install pandas_datareader\nconda install -c conda-forge r-essentials=4 \npip install rpy2\nconda install -c conda-forge python-graphviz\n- tensorflow-gpu 는 현재(2022-03-06) python=3.10 에서 동작함\nconda create -n py310 python=3.10 \nconda activate py310 \nconda install -c conda-forge tensorflow-gpu \n- 아래를 설치하면 좋음\nsudo apt install mc \n\n\n터미널 예쁘게 만들기\n- zsh 설치 + oh my zsh 설치\nsudo install zsh \nsh -c \"$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\"\n- 테마변경\n\n.zshrc 파일 열기\n\nnano ~/.zshrc \n\n아래의 내용 수정\n\n...\nZSH_THEME=\"agnoster\"\n...\n- 색상변경\n\n아래의 파일 열기\n\ncd ~/.oh-my-zsh/themes/\nnano agnoster.zsh-theme  \n\n내용수정\n\n...\nprompt_dir() {\n  prompt_segment 39d $CURRENT_FG '%~'\n}\n...\n\n\nsublime text and TeX (개발용 서버일 경우 생략 가능)\n- ‘Ubuntu Software’에 가서 ’sublime Text’를 치면 다운받을 수 있다. 다운받은뒤에 ’file’ -&gt; ’open folder’를 활용하여 깃허브의 로칼저장소를 열어두면 편리하다.\n- 아래를 실행하여 TeX을 깐다.\nsudo apt install texlive-full\n- 이제 sublime과 latex을 연결하여보자. 여기를 참고하자. (1) sublime을 키고 ‘컨트롤+쉬프트+p’를 눌러 ’Install Package Control’ 선택 (2) 다시 ‘컨트롤+쉬프트+p’ 를 눌러 ‘Package Control: Install Package’를 실행 (3) 그러면 바로 검색창이 나오는데 거기서 ’LaTeXTools’를 입력해서 실행 (4) 다시 ’컨트롤+쉬프트+p’를 누르고 ’LaTeXTools: Check system’ 선택. 모두 ’available’이 나오면 잘 설치된 것이다.\n- *.tex파일을 열고 ’컨트롤+b’를 누르자. 처음이면 어떤 메뉴들이 보일텐데 그냥 ’Latex’을 선택하자. 그러면 코딩결과가 pdf로 나온다.\n- (수식미리보기) ‘Perferences’ &gt; ‘Packages Setting’ &gt; ‘LaTeXTools’ &gt; ‘Settings-User’를 선택한다. ’93번째라인’에 ’preview_math_mode’를 “all”로 바꾼다. 그러면 수식들이 미리 출력된다. 그외에도 자유롭게 셋팅을 조정할 수 있다. 원래셋팅은 ’Perferences’ &gt; ‘Packages Setting’ &gt; ‘LaTeXTools’ &gt; ‘Settings-Defaults’ 에 있다."
  },
  {
    "objectID": "메모/2024-01-16-(메모) R package 만들기.html",
    "href": "메모/2024-01-16-(메모) R package 만들기.html",
    "title": "(메모) R package 만들기",
    "section": "",
    "text": "- devtools 설치\nconda install conda-forge::r-devtools"
  },
  {
    "objectID": "메모.html",
    "href": "메모.html",
    "title": "메모",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nJul 1, 2024\n\n\n(메모) 학과서버 공지\n\n\n신록예찬 \n\n\n\n\nApr 8, 2024\n\n\n(메모) grahpviz\n\n\n신록예찬 \n\n\n\n\nJan 16, 2024\n\n\n(메모) R package 만들기\n\n\n신록예찬 \n\n\n\n\nJan 10, 2000\n\n\n(메모) DGX station 설정\n\n\n신록예찬 \n\n\n\n\nJan 9, 2000\n\n\n(메모) docker\n\n\n신록예찬 \n\n\n\n\nJan 8, 2000\n\n\n(메모) 주피터랩, 설정 및 몇가지 팁\n\n\n신록예찬 \n\n\n\n\nJan 7, 2000\n\n\n(메모) 줄리아 설치 및 실행\n\n\n신록예찬 \n\n\n\n\nJan 6, 2000\n\n\n(메모) 깃 익히기\n\n\n신록예찬 \n\n\n\n\nJan 5, 2000\n\n\n(메모) vi 익히기\n\n\n신록예찬 \n\n\n\n\nJan 4, 2000\n\n\n(메모) tmux\n\n\n신록예찬 \n\n\n\n\nJan 4, 2000\n\n\n(메모) 우분투 익히기\n\n\n신록예찬 \n\n\n\n\nJan 2, 2000\n\n\n(메모) 우분투 포맷 및 개발용 서버 셋팅2\n\n\n신록예찬 \n\n\n\n\nJan 1, 2000\n\n\n(메모) 우분투 포맷 및 개발용 서버 셋팅 (old)\n\n\n신록예찬 \n\n\n\n\n\nNo matching items",
    "crumbs": [
      "DL2024",
      "메모"
    ]
  },
  {
    "objectID": "공부.html",
    "href": "공부.html",
    "title": "공부",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\n \n\n\n(공부) 추정\n\n\n \n\n\n\n\n \n\n\n(공부&서연) 지수분포 가설검정\n\n\n \n\n\n\n\n \n\n\n \n\n\n \n\n\n\n\n \n\n\n(공부) 리뷰 – EbayesThresh: R Programs for Empirical Bayes\n\n\n \n\n\n\n\n \n\n\n(공부&지윤) Imputer와 Scaler의 적용\n\n\n \n\n\n\n\n \n\n\n(공부) 코드 – ggraph\n\n\n \n\n\n\n\n \n\n\n(공부) 퓨리에변환\n\n\n \n\n\n\n\nNov 16, 2024\n\n\n(강의) 데이터콜렉터\n\n\n신록예찬 \n\n\n\n\nNov 9, 2024\n\n\n(강의) Dataset\n\n\n신록예찬 \n\n\n\n\nNov 8, 2024\n\n\n(강의) Model\n\n\n신록예찬 \n\n\n\n\nNov 7, 2024\n\n\n(강의) 선인장이미지분류 – ROC\n\n\n최규빈 \n\n\n\n\nNov 3, 2024\n\n\n(강의) with의 사용\n\n\n최규빈 \n\n\n\n\nNov 2, 2024\n\n\n(강의) numpy와 torch의 차이\n\n\n최규빈 \n\n\n\n\nNov 1, 2024\n\n\n(강의) 모듈설치 및 변경\n\n\n최규빈 \n\n\n\n\nOct 31, 2024\n\n\n(강의) 이미지캡셔닝2\n\n\n신록예찬 \n\n\n\n\nOct 31, 2024\n\n\n(강의) pipeline의 이해\n\n\n신록예찬 \n\n\n\n\nOct 31, 2024\n\n\n(강의) torch.tensor 이해\n\n\n신록예찬 \n\n\n\n\nOct 30, 2024\n\n\n(강의) 평가지표의 이해\n\n\n신록예찬 \n\n\n\n\nOct 30, 2024\n\n\n(강의) 이미지분류 SIIM-ISIC\n\n\n신록예찬 \n\n\n\n\nOct 29, 2024\n\n\n(강의) 이상탐지살펴봄\n\n\n신록예찬 \n\n\n\n\nOct 10, 2024\n\n\n(강의) 음성인식\n\n\n신록예찬 \n\n\n\n\nOct 10, 2024\n\n\n(강의) 이미지캡셔닝\n\n\n신록예찬 \n\n\n\n\nOct 1, 2024\n\n\n(강의) 음성분류\n\n\n신록예찬 \n\n\n\n\nOct 1, 2024\n\n\n(강의) 비디오분류\n\n\n신록예찬 \n\n\n\n\nSep 29, 2024\n\n\n(강의) 이미지분류\n\n\n신록예찬 \n\n\n\n\nSep 18, 2024\n\n\n(강의) 감성분석 파고들기\n\n\n신록예찬 \n\n\n\n\nSep 8, 2024\n\n\n(강의) 감성분류\n\n\n신록예찬 \n\n\n\n\nAug 29, 2024\n\n\n(공부) image_classification\n\n\n신록예찬 \n\n\n\n\nAug 29, 2024\n\n\n(공부) image_classification 2\n\n\n신록예찬 \n\n\n\n\nAug 28, 2024\n\n\n(강의) IMDB 자료 살펴보기, 지도학습의 개념\n\n\n신록예찬 \n\n\n\n\nAug 23, 2024\n\n\n(공부) xgboost 재현\n\n\n신록예찬 \n\n\n\n\nAug 12, 2024\n\n\n(공부) CGSP – Chap 12.2: Weakly Stationary Graph Processes\n\n\n신록예찬 \n\n\n\n\nAug 12, 2024\n\n\n(공부) 시계열과 GSP\n\n\n신록예찬 \n\n\n\n\nJan 31, 2024\n\n\n(공부) 코드 – AUC sklearn\n\n\n신록예찬 \n\n\n\n\nJan 26, 2024\n\n\n(공부) 조건부확률, 조건부기대값\n\n\n신록예찬 \n\n\n\n\nOct 26, 2023\n\n\n(공부) Julia – Vector\n\n\n신록예찬 \n\n\n\n\nOct 25, 2023\n\n\n(공부) Julia – 문자와 문자열\n\n\n신록예찬 \n\n\n\n\nOct 21, 2023\n\n\n(공부&지윤) Imputer와 Scaler의 적용\n\n\n신록예찬 \n\n\n\n\nSep 24, 2023\n\n\n(공부) 코드 – ggraph\n\n\n신록예찬 \n\n\n\n\nJul 19, 2023\n\n\n(공부) PyG – lesson6: GCN\n\n\n신록예찬 \n\n\n\n\nJul 14, 2023\n\n\n(공부) PyG – lesson5: Learning Methods on Graphs\n\n\n신록예찬 \n\n\n\n\nJul 12, 2023\n\n\n(공부) PyG – lesson4: Data Transform???\n\n\n신록예찬 \n\n\n\n\nJul 12, 2023\n\n\n(공부) PyG – lesson3: 미니배치\n\n\n신록예찬 \n\n\n\n\nJul 7, 2023\n\n\n(공부) PyG – lesson2: 벤치마크 데이터셋 (train/test분리)\n\n\n신록예찬 \n\n\n\n\nJul 4, 2023\n\n\n(공부) 토폴로지\n\n\n신록예찬 \n\n\n\n\nJul 2, 2023\n\n\n(공부) PyG – lesson1: 자료형\n\n\n신록예찬 \n\n\n\n\nJun 23, 2023\n\n\n(공부&지윤) 퓨리에변환(detailed)\n\n\n신록예찬 \n\n\n\n\nJun 23, 2023\n\n\n(공부&지윤) 커널리그레션\n\n\n신록예찬 \n\n\n\n\nJun 23, 2023\n\n\n(공부&지윤) 퓨리에변환4jy\n\n\n신록예찬 \n\n\n\n\nJun 14, 2023\n\n\n(공부&지윤) 추정\n\n\n신록예찬 \n\n\n\n\nMar 1, 2023\n\n\n(공부&서연) 지수분포 가설검정\n\n\n신록예찬 \n\n\n\n\nJan 20, 2023\n\n\n(공부) 추정\n\n\n신록예찬 \n\n\n\n\nJan 15, 2023\n\n\n(공부) CGSP – Chap 12.4: Node Subsampling for PSD Estimation\n\n\n신록예찬 \n\n\n\n\nJan 12, 2023\n\n\n(공부&서연) 지수분포 평균검정\n\n\n신록예찬 \n\n\n\n\nDec 27, 2022\n\n\n(공부) CGSP – Chap 12.2 ~ 3: Power Spectral Density and its Estimators\n\n\n신록예찬 \n\n\n\n\nDec 24, 2022\n\n\n(공부) CGSP – Chap 8.3: Discrete Fourier Transform\n\n\n신록예찬 \n\n\n\n\nDec 23, 2022\n\n\n(공부) 리뷰 – EbayesThresh: R Programs for Empirical Bayes Thresholding\n\n\n신록예찬 \n\n\n\n\nSep 21, 2022\n\n\n(공부) 파이토치 라이트닝 선형회귀\n\n\n최규빈 \n\n\n\n\nApr 26, 2019\n\n\n(공부) 퓨리에변환\n\n\n신록예찬 \n\n\n\n\n\nNo matching items",
    "crumbs": [
      "DL2024",
      "공부"
    ]
  },
  {
    "objectID": "연구/보람이랑/CTGAN/2023-07-01-Start.html",
    "href": "연구/보람이랑/CTGAN/2023-07-01-Start.html",
    "title": "(연구&보람) CTGAN – Start",
    "section": "",
    "text": "!conda env list\n\n# conda environments:\n#\nbase                     /home/cgb2/anaconda3\nctgan                 *  /home/cgb2/anaconda3/envs/ctgan\npy38                     /home/cgb2/anaconda3/envs/py38\nstgcn                    /home/cgb2/anaconda3/envs/stgcn\n\n\n\n- Ref: https://github.com/sdv-dev/CTGAN\n\nfrom ctgan import CTGAN\nfrom ctgan import load_demo\n\nreal_data = load_demo()\n\n# Names of the columns that are discrete\ndiscrete_columns = [\n    'workclass',\n    'education',\n    'marital-status',\n    'occupation',\n    'relationship',\n    'race',\n    'sex',\n    'native-country',\n    'income'\n]\n\nctgan = CTGAN(epochs=10)\nctgan.fit(real_data, discrete_columns)\n\n# Create synthetic data\nsynthetic_data = ctgan.sample(1000)\n\n/home/cgb2/anaconda3/envs/ctgan/lib/python3.10/site-packages/torch/cuda/__init__.py:126: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11070). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /opt/conda/conda-bld/pytorch_1688109080043/work/c10/cuda/CUDAFunctions.cpp:108.)\n  return torch._C._cuda_getDeviceCount() &gt; 0\n/home/cgb2/anaconda3/envs/ctgan/lib/python3.10/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n  warnings.warn(\n/home/cgb2/anaconda3/envs/ctgan/lib/python3.10/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n  warnings.warn(\n/home/cgb2/anaconda3/envs/ctgan/lib/python3.10/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n  warnings.warn(\n/home/cgb2/anaconda3/envs/ctgan/lib/python3.10/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n  warnings.warn(\n/home/cgb2/anaconda3/envs/ctgan/lib/python3.10/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n  warnings.warn(\n/home/cgb2/anaconda3/envs/ctgan/lib/python3.10/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n  warnings.warn(\n\n\n- 실제자료\n\nreal_data\n\n\n\n\n\n\n\n\nage\nworkclass\nfnlwgt\neducation\neducation-num\nmarital-status\noccupation\nrelationship\nrace\nsex\ncapital-gain\ncapital-loss\nhours-per-week\nnative-country\nincome\n\n\n\n\n0\n39\nState-gov\n77516\nBachelors\n13\nNever-married\nAdm-clerical\nNot-in-family\nWhite\nMale\n2174\n0\n40\nUnited-States\n&lt;=50K\n\n\n1\n50\nSelf-emp-not-inc\n83311\nBachelors\n13\nMarried-civ-spouse\nExec-managerial\nHusband\nWhite\nMale\n0\n0\n13\nUnited-States\n&lt;=50K\n\n\n2\n38\nPrivate\n215646\nHS-grad\n9\nDivorced\nHandlers-cleaners\nNot-in-family\nWhite\nMale\n0\n0\n40\nUnited-States\n&lt;=50K\n\n\n3\n53\nPrivate\n234721\n11th\n7\nMarried-civ-spouse\nHandlers-cleaners\nHusband\nBlack\nMale\n0\n0\n40\nUnited-States\n&lt;=50K\n\n\n4\n28\nPrivate\n338409\nBachelors\n13\nMarried-civ-spouse\nProf-specialty\nWife\nBlack\nFemale\n0\n0\n40\nCuba\n&lt;=50K\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n32556\n27\nPrivate\n257302\nAssoc-acdm\n12\nMarried-civ-spouse\nTech-support\nWife\nWhite\nFemale\n0\n0\n38\nUnited-States\n&lt;=50K\n\n\n32557\n40\nPrivate\n154374\nHS-grad\n9\nMarried-civ-spouse\nMachine-op-inspct\nHusband\nWhite\nMale\n0\n0\n40\nUnited-States\n&gt;50K\n\n\n32558\n58\nPrivate\n151910\nHS-grad\n9\nWidowed\nAdm-clerical\nUnmarried\nWhite\nFemale\n0\n0\n40\nUnited-States\n&lt;=50K\n\n\n32559\n22\nPrivate\n201490\nHS-grad\n9\nNever-married\nAdm-clerical\nOwn-child\nWhite\nMale\n0\n0\n20\nUnited-States\n&lt;=50K\n\n\n32560\n52\nSelf-emp-inc\n287927\nHS-grad\n9\nMarried-civ-spouse\nExec-managerial\nWife\nWhite\nFemale\n15024\n0\n40\nUnited-States\n&gt;50K\n\n\n\n\n32561 rows × 15 columns\n\n\n\n- 합성된자료\n\nsynthetic_data\n\n\n\n\n\n\n\n\nage\nworkclass\nfnlwgt\neducation\neducation-num\nmarital-status\noccupation\nrelationship\nrace\nsex\ncapital-gain\ncapital-loss\nhours-per-week\nnative-country\nincome\n\n\n\n\n0\n31\nPrivate\n317142\nAssoc-acdm\n10\nMarried-spouse-absent\nTransport-moving\nOwn-child\nWhite\nMale\n92\n0\n56\nChina\n&lt;=50K\n\n\n1\n40\nPrivate\n248817\nSome-college\n11\nMarried-civ-spouse\nProf-specialty\nOwn-child\nWhite\nMale\n-101\n4\n40\nUnited-States\n&lt;=50K\n\n\n2\n21\nPrivate\n201022\nBachelors\n2\nNever-married\nOther-service\nOwn-child\nWhite\nMale\n-20\n-4\n40\nUnited-States\n&lt;=50K\n\n\n3\n33\nFederal-gov\n407226\nMasters\n5\nNever-married\nOther-service\nNot-in-family\nWhite\nFemale\n-103\n1683\n61\nYugoslavia\n&lt;=50K\n\n\n4\n49\nFederal-gov\n261481\nSome-college\n14\nNever-married\nFarming-fishing\nOwn-child\nWhite\nFemale\n5\n-4\n40\nUnited-States\n&lt;=50K\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n995\n39\nPrivate\n228408\nHS-grad\n13\nMarried-civ-spouse\nProf-specialty\nNot-in-family\nAsian-Pac-Islander\nFemale\n-73\n-2\n16\nPhilippines\n&lt;=50K\n\n\n996\n31\nPrivate\n125109\nHS-grad\n0\nNever-married\nCraft-repair\nNot-in-family\nWhite\nFemale\n-86\n-4\n59\nUnited-States\n&lt;=50K\n\n\n997\n31\nPrivate\n291146\n11th\n13\nNever-married\nAdm-clerical\nWife\nBlack\nFemale\n-52\n5\n40\nUnited-States\n&gt;50K\n\n\n998\n25\nPrivate\n170115\nSome-college\n13\nNever-married\nMachine-op-inspct\nOwn-child\nWhite\nFemale\n-124\n-4\n40\nUnited-States\n&lt;=50K\n\n\n999\n37\nWithout-pay\n363805\nProf-school\n10\nMarried-civ-spouse\nSales\nUnmarried\nWhite\nFemale\n51\n-5\n40\nIran\n&lt;=50K\n\n\n\n\n1000 rows × 15 columns"
  },
  {
    "objectID": "연구/보람이랑/CTGAN/2023-07-02-TOY.html",
    "href": "연구/보람이랑/CTGAN/2023-07-02-TOY.html",
    "title": "(연구&보람) CTGAN – TOY",
    "section": "",
    "text": "imports\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom ctgan import CTGAN\nfrom ctgan import load_demo\n\n\n\ndata\n\nx1 = np.random.randn(1000).tolist()\ny1 = ['A']*1000\nx2 = (np.random.randn(100)+5).tolist()\ny2 = ['B']*100\n\n\ndf = pd.DataFrame({'x':x1+x2, 'y':y1+y2})\ndf\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n-0.905509\nA\n\n\n1\n0.844968\nA\n\n\n2\n-0.374190\nA\n\n\n3\n-1.311042\nA\n\n\n4\n-1.657453\nA\n\n\n...\n...\n...\n\n\n1095\n4.890136\nB\n\n\n1096\n6.158887\nB\n\n\n1097\n4.367205\nB\n\n\n1098\n4.704626\nB\n\n\n1099\n4.428676\nB\n\n\n\n\n1100 rows × 2 columns\n\n\n\n\nplt.hist(df.x,bins=50)\n\n(array([ 3.,  0.,  1.,  3.,  7.,  9., 20., 26., 43., 39., 44., 46., 72.,\n        76., 78., 69., 80., 89., 59., 49., 59., 48., 27., 22., 12.,  5.,\n         8.,  3.,  2.,  1.,  1.,  4.,  1.,  4.,  3.,  8.,  9.,  7., 11.,\n         6.,  6.,  6.,  8.,  8.,  6.,  4.,  5.,  2.,  0.,  1.]),\n array([-3.13891042, -2.93493634, -2.73096226, -2.52698818, -2.3230141 ,\n        -2.11904002, -1.91506594, -1.71109186, -1.50711778, -1.3031437 ,\n        -1.09916962, -0.89519554, -0.69122146, -0.48724738, -0.2832733 ,\n        -0.07929922,  0.12467486,  0.32864894,  0.53262302,  0.7365971 ,\n         0.94057118,  1.14454526,  1.34851934,  1.55249342,  1.7564675 ,\n         1.96044158,  2.16441566,  2.36838974,  2.57236382,  2.7763379 ,\n         2.98031198,  3.18428606,  3.38826014,  3.59223422,  3.7962083 ,\n         4.00018238,  4.20415646,  4.40813053,  4.61210461,  4.81607869,\n         5.02005277,  5.22402685,  5.42800093,  5.63197501,  5.83594909,\n         6.03992317,  6.24389725,  6.44787133,  6.65184541,  6.85581949,\n         7.05979357]),\n &lt;BarContainer object of 50 artists&gt;)\n\n\n\n\n\n\n\n\n\n\n\nCTGAN\n\n# Names of the columns that are discrete\ndiscrete_columns = ['y']\nctgan = CTGAN(epochs=500) # 겁나많이해야하네?\nctgan.fit(df, discrete_columns)\n\n# Create synthetic data\ndf2 = ctgan.sample(1000)\n\n/home/cgb2/anaconda3/envs/ctgan/lib/python3.10/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n  warnings.warn(\n\n\n\ndf2.groupby('y').count()\n\n\n\n\n\n\n\n\nx\n\n\ny\n\n\n\n\n\nA\n364\n\n\nB\n636\n\n\n\n\n\n\n\n\nplt.hist(df.x,bins=50,alpha=0.5,label='real')\nplt.hist(df2.x,bins=50,alpha=0.5,label='syn')\nplt.legend()\n\n\n\n\n\n\n\n\n\ndf2[df2.y=='A'].hist()\n\narray([[&lt;Axes: title={'center': 'x'}&gt;]], dtype=object)\n\n\n\n\n\n\n\n\n\n\ndf2[df2.y=='B'].hist()\n\narray([[&lt;Axes: title={'center': 'x'}&gt;]], dtype=object)"
  },
  {
    "objectID": "연구/보람이랑/신용카드거래 사기탐지/2023-05-24-Try1변형.html",
    "href": "연구/보람이랑/신용카드거래 사기탐지/2023-05-24-Try1변형.html",
    "title": "(연구&보람) 신용카드거래 사기탐지 – Try1변형",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport networkx as nx\nimport sklearn\n\n# sklearn\nfrom sklearn import model_selection # split함수이용\nfrom sklearn import ensemble # RF \nfrom sklearn import metrics \n\n# embedding \nfrom node2vec import Node2Vec\nfrom node2vec.edges import HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder\n\n/home/cgb2/anaconda3/envs/py38/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n\n\ndef build_graph_bipartite(df_input, graph_type=nx.Graph()):\n    df=df_input.copy()\n    mapping={x:node_id for node_id, x in enumerate(set(df[\"cc_num\"].values.tolist()+\\\n                                                      df[\"merchant\"].values.tolist()))}\n    \n    df[\"from\"]=df[\"cc_num\"].apply(lambda x:mapping[x])  #엣지의 출발점\n    df[\"to\"]=df[\"merchant\"].apply(lambda x:mapping[x])  #엣지의 도착점\n    \n    df = df[['from', 'to', \"amt\", \"is_fraud\"]].groupby(['from','to']).agg({\"is_fraud\":\"sum\",\"amt\":\"sum\"}).reset_index()\n    df[\"is_fraud\"]=df[\"is_fraud\"].apply(lambda x:1 if x&gt;0 else 0)\n    \n    G=nx.from_edgelist(df[[\"from\",\"to\"]].values, create_using=graph_type)\n    \n    nx.set_edge_attributes(G,{(int(x[\"from\"]),int(x[\"to\"])):x[\"is_fraud\"] for idx, x in df[[\"from\",\"to\",\"is_fraud\"]].iterrows()}, \"label\")  #엣지 속성 설정,각 속성의 사기 여부부     \n    nx.set_edge_attributes(G,{(int(x[\"from\"]),int(x[\"to\"])):x[\"amt\"] for idx,x in df[[\"from\",\"to\",\"amt\"]].iterrows()}, \"weight\") # 엣지 속성 설정, 각 엣지의 거래 금액\n\n    return G\n\n\ndef build_graph_tripartite(df_input, graph_type=nx.Graph()):\n    df=df_input.copy()\n    mapping={x:node_id for node_id, x in enumerate(set(df.index.values.tolist() + \n                                                       df[\"cc_num\"].values.tolist() +\n                                                       df[\"merchant\"].values.tolist()))}\n    df[\"in_node\"]= df[\"cc_num\"].apply(lambda x: mapping[x])\n    df[\"out_node\"]=df[\"merchant\"].apply(lambda x:mapping[x])\n    \n        \n    G=nx.from_edgelist([(x[\"in_node\"], mapping[idx]) for idx, x in df.iterrows()] +\\\n                        [(x[\"out_node\"], mapping[idx]) for idx, x in df.iterrows()], create_using=graph_type)\n    \n    nx.set_edge_attributes(G,{(x[\"in_node\"], mapping[idx]):x[\"is_fraud\"] for idx, x in df.iterrows()}, \"label\")     \n    nx.set_edge_attributes(G,{(x[\"out_node\"], mapping[idx]):x[\"is_fraud\"] for idx, x in df.iterrows()}, \"label\")   \n    nx.set_edge_attributes(G,{(x[\"in_node\"], mapping[idx]):x[\"amt\"] for idx, x in df.iterrows()}, \"weight\")  \n    nx.set_edge_attributes(G,{(x[\"out_node\"], mapping[idx]):x[\"amt\"] for idx, x in df.iterrows()}, \"weight\")\n\n    return G\n    \n    \ndef down_sample_textbook(df):\n    df_majority = df[df.is_fraud==0].copy()\n    df_minority = df[df.is_fraud==1].copy()\n    df_maj_dowsampled = sklearn.utils.resample(df_majority, n_samples=len(df_minority), replace=False, random_state=42)\n    df_downsampled = pd.concat([df_minority, df_maj_dowsampled])\n    return df_downsampled\n\ndef embedding(Graph):\n    # Graph -&gt; X (feature)\n    _edgs = list(Graph.edges)\n    subGraph = Graph.edge_subgraph([_edgs[x] for x in range(len(Graph.edges))]).copy()\n    subGraph.add_nodes_from(list(set(Graph.nodes) - set(subGraph.nodes)))    \n    embedded = AverageEmbedder(Node2Vec(subGraph, weight_key='weight').fit(window=10).wv)\n    X = [embedded[str(_edgs[x][0]), str(_edgs[x][1])] for x in range(len(Graph.edges))]\n    # Graph -&gt; y (label)\n    y = np.array(list(nx.get_edge_attributes(Graph, \"label\").values()))\n    return X,y \n\ndef anal(df):\n    Graph = build_graph_bipartite(df)\n    X,XX,y,yy = embedding(Graph)\n    lrnr = RandomForestClassifier(n_estimators=100, random_state=42) \n    lrnr.fit(X,y)\n    yyhat = lrnr.predict(XX)\n    df = pd.DataFrame({\n        'acc':[sklearn.metrics.accuracy_score(yy,yyhat)], \n        'pre':[sklearn.metrics.precision_score(yy,yyhat)], \n        'rec':[sklearn.metrics.recall_score(yy,yyhat)],\n        'f1':[sklearn.metrics.f1_score(yy,yyhat)]}\n    )    \n    return df\n\ndef our_sampling1(df):\n    cus_list = set(df.query('is_fraud==1').cc_num.tolist())\n    return df.query(\"cc_num in @ cus_list\")"
  },
  {
    "objectID": "연구/보람이랑/신용카드거래 사기탐지/2023-05-24-Try1변형.html#데이터-종류",
    "href": "연구/보람이랑/신용카드거래 사기탐지/2023-05-24-Try1변형.html#데이터-종류",
    "title": "(연구&보람) 신용카드거래 사기탐지 – Try1변형",
    "section": "데이터 종류",
    "text": "데이터 종류\n\nfraudTrain.csv: (1048575, 23), 기본데이터\ndf02: (214520, 23), is_fraud==0 에서는 20퍼의 샘플만, is_fraud==1 에서는 모든 샘플을 뽑아서 정리한 새로운 자료\ndf50 = (12012, 23), df20에서 is_fraud==0 와 is_fraud==1 의 비율을 맞추어서 샘플을 뽑은 것\n\n\n\n\n\n\n\n\n\n\n데이터\nshape\n사기거래빈도\n설명\n\n\n\n\nfraudTrain\n(1048575, 22)\n0.00573\n원래자료\n\n\ndf02\n(214520, 22)\n0.028\nis_fraud==0 에서는 20퍼의 샘플만, is_fraud==1 에서는 모든 샘플을 뽑아서 정리한 새로운 자료\n\n\ndf50\n(12012, 22)\n0.5\ndf02에서 사기비율을 50퍼로 맞추어 샘플링한 자료\n\n\ndf50_tr\n(9009, 22)\n0.49828\ndf50에서 랜덤으로 train/test를 분리하여 얻은 train dataset\n\n\ndf50_test\n(3003, 22)\n0.50516\ndf50에서 랜덤으로 train/test를 분리하여 얻은 test dataset\n\n\ndf02_tr\n(211517, 22)\n0.02122\ndf02에서 df50_test에 해당하는 인덱스를 제외\n\n\nfraudTrain_tr\n(1045572, 22)\n0.00429\nfraudTrain에서 df50_test에 해당하는 인덱스를 제외\n\n\n\n- fraudTrain\n\nfraudTrain = pd.read_csv(\"fraudTrain.csv\").iloc[:,1:]\nfraudTrain.shape\n\n(1048575, 22)\n\n\n\nfraudTrain.is_fraud.mean().round(5)\n\n0.00573\n\n\n- df20\n\n_df1 = fraudTrain[fraudTrain[\"is_fraud\"] == 0].sample(frac=0.20, random_state=42)\n_df2 = fraudTrain[fraudTrain[\"is_fraud\"] == 1]\ndf02 = pd.concat([_df1,_df2])\ndf02.shape\n\n(214520, 22)\n\n\n\ndf02.is_fraud.mean().round(5)\n\n0.028\n\n\n- df50\n\ndf50 = down_sample_textbook(df02)\ndf50.shape\n\n(12012, 22)\n\n\n\ndf50\n\n\n\n\n\n\n\n\ntrans_date_trans_time\ncc_num\nmerchant\ncategory\namt\nfirst\nlast\ngender\nstreet\ncity\n...\nlat\nlong\ncity_pop\njob\ndob\ntrans_num\nunix_time\nmerch_lat\nmerch_long\nis_fraud\n\n\n\n\n2449\n2019-01-02 1:06\n4.613310e+12\nfraud_Rutherford-Mertz\ngrocery_pos\n281.06\nJason\nMurphy\nM\n542 Steve Curve Suite 011\nCollettsville\n...\n35.9946\n-81.7266\n885\nSoil scientist\n1988-09-15\ne8a81877ae9a0a7f883e15cb39dc4022\n1325466397\n36.430124\n-81.179483\n1\n\n\n2472\n2019-01-02 1:47\n3.401870e+14\nfraud_Jenkins, Hauck and Friesen\ngas_transport\n11.52\nMisty\nHart\nF\n27954 Hall Mill Suite 575\nSan Antonio\n...\n29.4400\n-98.4590\n1595797\nHorticultural consultant\n1960-10-28\nbc7d41c41103877b03232f03f1f8d3f5\n1325468849\n29.819364\n-99.142791\n1\n\n\n2523\n2019-01-02 3:05\n3.401870e+14\nfraud_Goodwin-Nitzsche\ngrocery_pos\n276.31\nMisty\nHart\nF\n27954 Hall Mill Suite 575\nSan Antonio\n...\n29.4400\n-98.4590\n1595797\nHorticultural consultant\n1960-10-28\nb98f12f4168391b2203238813df5aa8c\n1325473523\n29.273085\n-98.836360\n1\n\n\n2546\n2019-01-02 3:38\n4.613310e+12\nfraud_Erdman-Kertzmann\ngas_transport\n7.03\nJason\nMurphy\nM\n542 Steve Curve Suite 011\nCollettsville\n...\n35.9946\n-81.7266\n885\nSoil scientist\n1988-09-15\n397894a5c4c02e3c61c784001f0f14e4\n1325475483\n35.909292\n-82.091010\n1\n\n\n2553\n2019-01-02 3:55\n3.401870e+14\nfraud_Koepp-Parker\ngrocery_pos\n275.73\nMisty\nHart\nF\n27954 Hall Mill Suite 575\nSan Antonio\n...\n29.4400\n-98.4590\n1595797\nHorticultural consultant\n1960-10-28\n7863235a750d73a244c07f1fb7f0185a\n1325476547\n29.786426\n-98.683410\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n363827\n2019-06-17 19:30\n2.475090e+15\nfraud_Frami Group\nentertainment\n81.13\nJohn\nMiller\nM\n153 Mccullough Springs Apt. 857\nLamberton\n...\n44.2378\n-95.2739\n1507\nLand/geomatics surveyor\n1993-10-12\nc66cb411019c7dfd4d89f42a1ba4765f\n1339961448\n44.212695\n-95.661879\n0\n\n\n140154\n2019-03-17 14:33\n2.131550e+14\nfraud_Bahringer-Streich\nfood_dining\n55.00\nChristopher\nSheppard\nM\n39218 Baker Shoals\nBristow\n...\n38.1981\n-86.6821\n965\nHorticultural therapist\n1982-02-10\n316b9d25b9fa7d08a6831b7dab6634cd\n1331994839\n38.394240\n-86.413557\n0\n\n\n860597\n2019-12-17 12:31\n2.280870e+15\nfraud_Lubowitz-Walter\nkids_pets\n8.12\nKatherine\nCooper\nF\n3854 Lauren Springs Suite 648\nOakford\n...\n40.0994\n-89.9601\n530\nTransport planner\n1967-09-23\nd92e9e63d9b24c3ccb92d05cba4cac54\n1355747517\n39.695248\n-89.853063\n0\n\n\n29341\n2019-01-18 9:20\n4.878360e+15\nfraud_Denesik and Sons\nshopping_pos\n3.52\nTina\nAlvarez\nF\n1976 Tyler Underpass\nEarly\n...\n42.4483\n-95.1726\n885\nPilot, airline\n1949-08-14\n8390ce51cfb8482b618ebc4ac370bcf7\n1326878457\n42.633204\n-95.598143\n0\n\n\n529797\n2019-08-16 13:17\n4.450830e+15\nfraud_Beier and Sons\nhome\n84.15\nDonna\nDavis\nF\n6760 Donovan Lakes\nClayton\n...\n34.5906\n-95.3800\n1760\nOccupational psychologist\n1972-01-20\n04e1be9bcb18ea8b96048659bd02177b\n1345123058\n33.885236\n-95.885110\n0\n\n\n\n\n12012 rows × 22 columns\n\n\n\n\ndf50.is_fraud.mean().round(5)\n\n0.5\n\n\n- df50_tr, df50_test\n\ndf50_tr,df50_test = sklearn.model_selection.train_test_split(df50, random_state=42)\n\n\ndf50_tr.is_fraud.mean().round(5), df50_test.is_fraud.mean().round(5)\n\n(0.49828, 0.50516)\n\n\n- df02_tr, fraudTrain_tr\n\ndf02_tr = df02.loc[[i not in df50_test.index for i in df02.index],:].copy()\nfraudTrain_tr = fraudTrain.loc[[i not in df50_test.index for i in fraudTrain.index],:].copy()\n\n\ndf02_tr.shape, fraudTrain_tr.shape\n\n((211517, 22), (1045572, 22))\n\n\n\ndf02_tr.is_fraud.mean().round(5), fraudTrain_tr.is_fraud.mean().round(5)\n\n(0.02122, 0.00429)"
  },
  {
    "objectID": "연구/보람이랑/신용카드거래 사기탐지/2024-05-02-GCN.html",
    "href": "연구/보람이랑/신용카드거래 사기탐지/2024-05-02-GCN.html",
    "title": "(연구&보람) GCN (시뮬레이션)",
    "section": "",
    "text": "1. Imports\n\nimport torch\nimport torch_geometric\nimport pandas as pd\nimport numpy as np\nimport sklearn.metrics\nimport pickle\nimport time\nimport os \nimport datetime\n\n\ndef evaluate(y, yhat, yhat_prob): # gcn \n    acc = sklearn.metrics.accuracy_score(y,yhat)\n    pre = sklearn.metrics.precision_score(y,yhat)\n    rec = sklearn.metrics.recall_score(y,yhat)\n    f1 = sklearn.metrics.f1_score(y,yhat)\n    auc = sklearn.metrics.roc_auc_score(y,yhat_prob)\n    return {'acc':acc,'pre':pre,'rec':rec,'f1':f1,'auc':auc}\ndef summarize_results(yy,yyhat,yyhat_prob,data,prev_results):\n    eval_result = evaluate(yy, yyhat, yyhat_prob)\n    result = {\n        'model': ['GCN'],\n        'time': [None],\n        'acc': [eval_result['acc']],\n        'pre': [eval_result['pre']],\n        'rec': [eval_result['rec']],\n        'f1': [eval_result['f1']],\n        'auc': [eval_result['auc']],\n        'graph_based': [True],\n        'method': ['Proposed'],\n        'throw_rate': [None],\n        'train_size': [data._train_size],\n        'train_cols': ['amt'],\n        'train_frate': [data._train_frate],\n        'test_size': [data._test_size],\n        'test_frate': [data._test_frate],\n        'hyper_params': [None],\n        'theta': [data._theta],\n        'gamma': [data._gamma]\n    } \n    return pd.DataFrame(result)\n\n\n\n2. Load Data\n\nfnames = [l for l in os.listdir('./data') if l.split('.')[-1] == 'pkl']\nfnames.sort()\nfnames\n\n['torch_geometric_data1_1.0e+07_0.8.pkl',\n 'torch_geometric_data1_1.0e+07_0.95.pkl',\n 'torch_geometric_data2_1.0e+07_0.8.pkl',\n 'torch_geometric_data2_1.0e+07_0.95.pkl',\n 'torch_geometric_data3_1.0e+07_0.8.pkl',\n 'torch_geometric_data3_1.0e+07_0.95.pkl',\n 'torch_geometric_data4_1.0e+07_0.8.pkl',\n 'torch_geometric_data4_1.0e+07_0.95.pkl',\n 'torch_geometric_data5_1.0e+07_0.8.pkl',\n 'torch_geometric_data5_1.0e+07_0.95.pkl',\n 'torch_geometric_data6_1.0e+07_0.8.pkl',\n 'torch_geometric_data6_1.0e+07_0.95.pkl',\n 'torch_geometric_data7_1.0e+07_0.8.pkl',\n 'torch_geometric_data7_1.0e+07_0.95.pkl',\n 'torch_geometric_data8_1.0e+07_0.8.pkl',\n 'torch_geometric_data8_1.0e+07_0.95.pkl']\n\n\n\ngeodata_list = [] \ndf_train_list = [] \ndf_trainindex_list = []\nfor fname in fnames:\n    i = fname[20]\n    df_trainindex_list.append(i)\n    df_train_list.append(pd.read_csv(f'./data/df_train{i}.csv')) \n    with open(f'./data/{fname}', 'rb') as file:\n        geodata_list.append(pickle.load(file))        \n\n\nfor i,data in enumerate(geodata_list):\n    print(f\"data-{i}\")\n    print(f\"train_size = {data._train_size}\")\n    print(f\"train_size = {data._test_size}\")\n    print(f\"train_frate = {data._train_frate:.4f}\")\n    print(f\"test_frate = {data._test_frate:.4f}\")\n    print(f\"theta = {data._theta}\")\n    print(f\"gamma = {data._gamma}\")\n    print(\"---\")\n\ndata-0\ntrain_size = 734003\ntrain_size = 314572\ntrain_frate = 0.0057\ntest_frate = 0.0057\ntheta = 10000000.0\ngamma = 0.8\n---\ndata-1\ntrain_size = 734003\ntrain_size = 314572\ntrain_frate = 0.0057\ntest_frate = 0.0057\ntheta = 10000000.0\ngamma = 0.95\n---\ndata-2\ntrain_size = 420500\ntrain_size = 314572\ntrain_frate = 0.0100\ntest_frate = 0.0057\ntheta = 10000000.0\ngamma = 0.8\n---\ndata-3\ntrain_size = 420500\ntrain_size = 314572\ntrain_frate = 0.0100\ntest_frate = 0.0057\ntheta = 10000000.0\ngamma = 0.95\n---\ndata-4\ntrain_size = 84100\ntrain_size = 314572\ntrain_frate = 0.0500\ntest_frate = 0.0057\ntheta = 10000000.0\ngamma = 0.8\n---\ndata-5\ntrain_size = 84100\ntrain_size = 314572\ntrain_frate = 0.0500\ntest_frate = 0.0057\ntheta = 10000000.0\ngamma = 0.95\n---\ndata-6\ntrain_size = 42050\ntrain_size = 314572\ntrain_frate = 0.1000\ntest_frate = 0.0057\ntheta = 10000000.0\ngamma = 0.8\n---\ndata-7\ntrain_size = 42050\ntrain_size = 314572\ntrain_frate = 0.1000\ntest_frate = 0.0057\ntheta = 10000000.0\ngamma = 0.95\n---\ndata-8\ntrain_size = 21025\ntrain_size = 314572\ntrain_frate = 0.2000\ntest_frate = 0.0057\ntheta = 10000000.0\ngamma = 0.8\n---\ndata-9\ntrain_size = 21025\ntrain_size = 314572\ntrain_frate = 0.2000\ntest_frate = 0.0057\ntheta = 10000000.0\ngamma = 0.95\n---\ndata-10\ntrain_size = 14017\ntrain_size = 314572\ntrain_frate = 0.3000\ntest_frate = 0.0057\ntheta = 10000000.0\ngamma = 0.8\n---\ndata-11\ntrain_size = 14017\ntrain_size = 314572\ntrain_frate = 0.3000\ntest_frate = 0.0057\ntheta = 10000000.0\ngamma = 0.95\n---\ndata-12\ntrain_size = 10512\ntrain_size = 314572\ntrain_frate = 0.4000\ntest_frate = 0.0057\ntheta = 10000000.0\ngamma = 0.8\n---\ndata-13\ntrain_size = 10512\ntrain_size = 314572\ntrain_frate = 0.4000\ntest_frate = 0.0057\ntheta = 10000000.0\ngamma = 0.95\n---\ndata-14\ntrain_size = 8410\ntrain_size = 314572\ntrain_frate = 0.5000\ntest_frate = 0.0057\ntheta = 10000000.0\ngamma = 0.8\n---\ndata-15\ntrain_size = 8410\ntrain_size = 314572\ntrain_frate = 0.5000\ntest_frate = 0.0057\ntheta = 10000000.0\ngamma = 0.95\n---\n\n\n\n\n3. 적합 & 결과저장 – one data set\n\ndf_test = pd.read_csv(\"./data/df_test.csv\")\n\n\ndata = geodata_list[0]\ndf_train = df_train_list[0]\ni = df_trainindex_list[0]\n\n\nEPOCHS = 1000\nLR = 0.001\nWEIGHT_DECAY = 0.0005\nFILTERS = [16,8]\nGAMMA = data._gamma.__str__().replace('.','')\n#--#\nclass GCN(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = torch_geometric.nn.GCNConv(1, FILTERS[0])\n        self.conv2 = torch_geometric.nn.GCNConv(FILTERS[0], FILTERS[1])\n        self.linr = torch.nn.Linear(FILTERS[1], 2)\n    def forward(self, data):\n        x, edge_index = data.x, data.edge_index\n        x = self.conv1(x, edge_index)\n        x = torch.nn.functional.relu(x)\n        x = torch.nn.functional.dropout(x, training=self.training)\n        x = self.conv2(x, edge_index)\n        x = torch.nn.functional.relu(x)\n        x = self.linr(x)\n        return torch.nn.functional.log_softmax(x, dim=1)\n    def get_hidden(self,data):\n        x, edge_index = data.x, data.edge_index\n        x = self.conv1(x, edge_index)\n        x = torch.nn.functional.relu(x)\n        x = self.conv2(x, edge_index)\n        x = torch.nn.functional.relu(x)        \n        return x          \n#--#\n\n\nnet = GCN()\nnet.to(\"cuda:0\")\nloss_fn = torch.nn.functional.nll_loss\noptimizr = torch.optim.Adam(net.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\nnet.train()\nfor epoc in range(1,EPOCHS+1):\n    netout = net(data.to(\"cuda:0\"))\n    loss = loss_fn(netout[data.train_mask], data.y[data.train_mask])\n    loss.backward()\n    optimizr.step()\n    optimizr.zero_grad()\n    #--#\n    if epoc % 200 == 0: \n        print(f\"epoch = {epoc}/{EPOCHS}\\tloss = {loss:.4f}\")\nnet.eval()\nnet.to(\"cpu\")\ndata.to(\"cpu\")\n#--#\n\nepoch = 200/1000    loss = 0.0763\nepoch = 400/1000    loss = 0.0610\nepoch = 600/1000    loss = 0.0378\nepoch = 800/1000    loss = 0.0286\nepoch = 1000/1000   loss = 0.0280\n\n\n\ny = (data.y[data.train_mask])\nyy = (data.y[data.test_mask])\nhidden = net.get_hidden(data).detach()\nh = hidden[data.train_mask]\nhh = hidden[data.test_mask]\nnetout = net(data).detach()\n#--#\nyhat_prob = torch.exp(netout[data.train_mask])[:,-1]\nyhat = (yhat_prob &gt; 0.5)\nyyhat_prob = torch.exp(netout[data.test_mask])[:,-1]\nyyhat = (yyhat_prob &gt; 0.5)\n#--#\ndf_result = pd.DataFrame(summarize_results(yy,yyhat,yyhat_prob,data,prev_results=None))\ndf_result['epoch'] = EPOCHS\ndf_result['lr'] = LR\ndf_result['weight_decay'] = WEIGHT_DECAY\ndf_result['filters'] = f\"{FILTERS[0]},{FILTERS[1]}\"\ndate = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\ndf_result.T.to_csv(f'./results/df_gcn_result_{date}_gamma{GAMMA}.csv')\n#--#\ndf_train_h = pd.DataFrame(h)\ndf_train_h.columns = [f\"h{i}\" for i in df_train_h.columns]\ndf_test_h = pd.DataFrame(hh)\ndf_test_h.columns = [f\"h{i}\" for i in df_test_h.columns]\npd.concat(\n    [df_train_h, \n     df_train.assign(is_fraud_hat = yhat,is_fraud_hat_prob = yhat_prob)]\n    ,axis=1\n).to_csv(f'./results/df_train{i}_{date}_gamma{GAMMA}.csv',index=False)\npd.concat(\n    [df_test_h, \n     df_test.assign(is_fraud_hat = yyhat,is_fraud_hat_prob = yyhat_prob)]\n    ,axis=1\n).to_csv(f'./results/df_test_{date}_gamma{GAMMA}.csv',index=False)\nprint(\"result saved\")\n\n\n\n4. 적합 & 결과저장 – 배치\n\ndef run(df_test,data,df_train,i):\n    EPOCHS = 4000\n    LR = 0.001\n    WEIGHT_DECAY = 0.0005\n    FILTERS = [16,8]\n    GAMMA = data._gamma.__str__().replace('.','')\n    #--#\n    class GCN(torch.nn.Module):\n        def __init__(self):\n            super().__init__()\n            self.conv1 = torch_geometric.nn.GCNConv(1, FILTERS[0])\n            self.conv2 = torch_geometric.nn.GCNConv(FILTERS[0], FILTERS[1])\n            self.linr = torch.nn.Linear(FILTERS[1], 2)\n        def forward(self, data):\n            x, edge_index = data.x, data.edge_index\n            x = self.conv1(x, edge_index)\n            x = torch.nn.functional.relu(x)\n            x = torch.nn.functional.dropout(x, training=self.training)\n            x = self.conv2(x, edge_index)\n            x = torch.nn.functional.relu(x)\n            x = self.linr(x)\n            return torch.nn.functional.log_softmax(x, dim=1)\n        def get_hidden(self,data):\n            x, edge_index = data.x, data.edge_index\n            x = self.conv1(x, edge_index)\n            x = torch.nn.functional.relu(x)\n            x = self.conv2(x, edge_index)\n            x = torch.nn.functional.relu(x)        \n            return x          \n    #--#\n    net = GCN()\n    net.to(\"cuda:0\")\n    loss_fn = torch.nn.functional.nll_loss\n    optimizr = torch.optim.Adam(net.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n    net.train()\n    for epoc in range(1,EPOCHS+1):\n        netout = net(data.to(\"cuda:0\"))\n        loss = loss_fn(netout[data.train_mask], data.y[data.train_mask])\n        loss.backward()\n        optimizr.step()\n        optimizr.zero_grad()\n        #--#\n        if epoc % 200 == 0: \n            print(f\"epoch = {epoc}/{EPOCHS}\\tloss = {loss:.4f}\")\n    net.eval()\n    net.to(\"cpu\")\n    data.to(\"cpu\")\n    #--#\n    y = (data.y[data.train_mask])\n    yy = (data.y[data.test_mask])\n    hidden = net.get_hidden(data).detach()\n    h = hidden[data.train_mask]\n    hh = hidden[data.test_mask]\n    netout = net(data).detach()\n    #--#\n    yhat_prob = torch.exp(netout[data.train_mask])[:,-1]\n    yhat = (yhat_prob &gt; 0.5)\n    yyhat_prob = torch.exp(netout[data.test_mask])[:,-1]\n    yyhat = (yyhat_prob &gt; 0.5)\n    #--#\n    df_result = pd.DataFrame(summarize_results(yy,yyhat,yyhat_prob,data,prev_results=None))\n    df_result['epoch'] = EPOCHS\n    df_result['lr'] = LR\n    df_result['weight_decay'] = WEIGHT_DECAY\n    df_result['filters'] = f\"{FILTERS[0]},{FILTERS[1]}\"\n    date = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n    df_result.T.to_csv(f'./results/df_gcn_result_{date}_gamma{GAMMA}.csv')\n    #--#\n    df_train_h = pd.DataFrame(h)\n    df_train_h.columns = [f\"h{i}\" for i in df_train_h.columns]\n    df_test_h = pd.DataFrame(hh)\n    df_test_h.columns = [f\"h{i}\" for i in df_test_h.columns]\n    pd.concat(\n        [df_train_h, \n         df_train.assign(is_fraud_hat = yhat,is_fraud_hat_prob = yhat_prob)]\n        ,axis=1\n    ).to_csv(f'./results/df_train{i}_{date}_gamma{GAMMA}.csv',index=False)\n    pd.concat(\n        [df_test_h, \n         df_test.assign(is_fraud_hat = yyhat,is_fraud_hat_prob = yyhat_prob)]\n        ,axis=1\n    ).to_csv(f'./results/df_test_{date}_gamma{GAMMA}.csv',index=False)\n    print(\"result saved\")    \n\n\ndf_test = pd.read_csv(\"./data/df_test.csv\")\nfor data,df_train, i in zip(geodata_list,df_train_list,df_trainindex_list):\n    run(df_test,data,df_train,i)\n\nepoch = 200/4000    loss = 0.0649\nepoch = 400/4000    loss = 0.0564\nepoch = 600/4000    loss = 0.0351\nepoch = 800/4000    loss = 0.0281\nepoch = 1000/4000   loss = 0.0278\nepoch = 1200/4000   loss = 0.0272\nepoch = 1400/4000   loss = 0.0276\nepoch = 1600/4000   loss = 0.0275\nepoch = 1800/4000   loss = 0.0270\nepoch = 2000/4000   loss = 0.0273\nepoch = 2200/4000   loss = 0.0270\nepoch = 2400/4000   loss = 0.0272\nepoch = 2600/4000   loss = 0.0271\nepoch = 2800/4000   loss = 0.0271\nepoch = 3000/4000   loss = 0.0272\nepoch = 3200/4000   loss = 0.0270\nepoch = 3400/4000   loss = 0.0272\nepoch = 3600/4000   loss = 0.0268\nepoch = 3800/4000   loss = 0.0273\nepoch = 4000/4000   loss = 0.0271\nresult saved\nepoch = 200/4000    loss = 0.1208\nepoch = 400/4000    loss = 0.0897\nepoch = 600/4000    loss = 0.0444\nepoch = 800/4000    loss = 0.0304\nepoch = 1000/4000   loss = 0.0251\nepoch = 1200/4000   loss = 0.0227\nepoch = 1400/4000   loss = 0.0206\nepoch = 1600/4000   loss = 0.0189\nepoch = 1800/4000   loss = 0.0180\nepoch = 2000/4000   loss = 0.0173\nepoch = 2200/4000   loss = 0.0173\nepoch = 2400/4000   loss = 0.0166\nepoch = 2600/4000   loss = 0.0165\nepoch = 2800/4000   loss = 0.0162\nepoch = 3000/4000   loss = 0.0158\nepoch = 3200/4000   loss = 0.0161\nepoch = 3400/4000   loss = 0.0166\nepoch = 3600/4000   loss = 0.0155\nepoch = 3800/4000   loss = 0.0153\nepoch = 4000/4000   loss = 0.0151\nresult saved\nepoch = 200/4000    loss = 0.1362\nepoch = 400/4000    loss = 0.1162\nepoch = 600/4000    loss = 0.0983\nepoch = 800/4000    loss = 0.0799\nepoch = 1000/4000   loss = 0.0509\nepoch = 1200/4000   loss = 0.0407\nepoch = 1400/4000   loss = 0.0392\nepoch = 1600/4000   loss = 0.0391\nepoch = 1800/4000   loss = 0.0393\nepoch = 2000/4000   loss = 0.0391\nepoch = 2200/4000   loss = 0.0392\nepoch = 2400/4000   loss = 0.0391\nepoch = 2600/4000   loss = 0.0392\nepoch = 2800/4000   loss = 0.0391\nepoch = 3000/4000   loss = 0.0391\nepoch = 3200/4000   loss = 0.0390\nepoch = 3400/4000   loss = 0.0389\nepoch = 3600/4000   loss = 0.0390\nepoch = 3800/4000   loss = 0.0392\nepoch = 4000/4000   loss = 0.0390\nresult saved\nepoch = 200/4000    loss = 0.1958\nepoch = 400/4000    loss = 0.1145\nepoch = 600/4000    loss = 0.0316\nepoch = 800/4000    loss = 0.0252\nepoch = 1000/4000   loss = 0.0225\nepoch = 1200/4000   loss = 0.0215\nepoch = 1400/4000   loss = 0.0210\nepoch = 1600/4000   loss = 0.0207\nepoch = 1800/4000   loss = 0.0204\nepoch = 2000/4000   loss = 0.0203\nepoch = 2200/4000   loss = 0.0201\nepoch = 2400/4000   loss = 0.0198\nepoch = 2600/4000   loss = 0.0198\nepoch = 2800/4000   loss = 0.0195\nepoch = 3000/4000   loss = 0.0193\nepoch = 3200/4000   loss = 0.0193\nepoch = 3400/4000   loss = 0.0191\nepoch = 3600/4000   loss = 0.0191\nepoch = 3800/4000   loss = 0.0191\nepoch = 4000/4000   loss = 0.0189\nresult saved\nepoch = 200/4000    loss = 0.4493\nepoch = 400/4000    loss = 0.4154\nepoch = 600/4000    loss = 0.2855\nepoch = 800/4000    loss = 0.1510\nepoch = 1000/4000   loss = 0.1238\nepoch = 1200/4000   loss = 0.1165\nepoch = 1400/4000   loss = 0.1160\nepoch = 1600/4000   loss = 0.1140\nepoch = 1800/4000   loss = 0.1141\nepoch = 2000/4000   loss = 0.1126\nepoch = 2200/4000   loss = 0.1116\nepoch = 2400/4000   loss = 0.1127\nepoch = 2600/4000   loss = 0.1125\nepoch = 2800/4000   loss = 0.1110\nepoch = 3000/4000   loss = 0.1100\nepoch = 3200/4000   loss = 0.1109\nepoch = 3400/4000   loss = 0.1104\nepoch = 3600/4000   loss = 0.1104\nepoch = 3800/4000   loss = 0.1095\nepoch = 4000/4000   loss = 0.1097\nresult saved\nepoch = 200/4000    loss = 0.5610\nepoch = 400/4000    loss = 0.4081\nepoch = 600/4000    loss = 0.2604\nepoch = 800/4000    loss = 0.1274\nepoch = 1000/4000   loss = 0.0934\nepoch = 1200/4000   loss = 0.0846\nepoch = 1400/4000   loss = 0.0814\nepoch = 1600/4000   loss = 0.0776\nepoch = 1800/4000   loss = 0.0751\nepoch = 2000/4000   loss = 0.0726\nepoch = 2200/4000   loss = 0.0722\nepoch = 2400/4000   loss = 0.0721\nepoch = 2600/4000   loss = 0.0703\nepoch = 2800/4000   loss = 0.0705\nepoch = 3000/4000   loss = 0.0696\nepoch = 3200/4000   loss = 0.0697\nepoch = 3400/4000   loss = 0.0695\nepoch = 3600/4000   loss = 0.0692\nepoch = 3800/4000   loss = 0.0675\nepoch = 4000/4000   loss = 0.0674\nresult saved\nepoch = 200/4000    loss = 0.6334\nepoch = 400/4000    loss = 0.4550\nepoch = 600/4000    loss = 0.3294\nepoch = 800/4000    loss = 0.2412\nepoch = 1000/4000   loss = 0.1844\nepoch = 1200/4000   loss = 0.1635\nepoch = 1400/4000   loss = 0.1530\nepoch = 1600/4000   loss = 0.1472\nepoch = 1800/4000   loss = 0.1448\nepoch = 2000/4000   loss = 0.1397\nepoch = 2200/4000   loss = 0.1383\nepoch = 2400/4000   loss = 0.1360\nepoch = 2600/4000   loss = 0.1329\nepoch = 2800/4000   loss = 0.1331\nepoch = 3000/4000   loss = 0.1315\nepoch = 3200/4000   loss = 0.1304\nepoch = 3400/4000   loss = 0.1290\nepoch = 3600/4000   loss = 0.1278\nepoch = 3800/4000   loss = 0.1268\nepoch = 4000/4000   loss = 0.1268\nresult saved\nepoch = 200/4000    loss = 0.3996\nepoch = 400/4000    loss = 0.2193\nepoch = 600/4000    loss = 0.1322\nepoch = 800/4000    loss = 0.1088\nepoch = 1000/4000   loss = 0.1001\nepoch = 1200/4000   loss = 0.0936\nepoch = 1400/4000   loss = 0.0915\nepoch = 1600/4000   loss = 0.0852\nepoch = 1800/4000   loss = 0.0863\nepoch = 2000/4000   loss = 0.0818\nepoch = 2200/4000   loss = 0.0773\nepoch = 2400/4000   loss = 0.0773\nepoch = 2600/4000   loss = 0.0744\nepoch = 2800/4000   loss = 0.0723\nepoch = 3000/4000   loss = 0.0715\nepoch = 3200/4000   loss = 0.0702\nepoch = 3400/4000   loss = 0.0693\nepoch = 3600/4000   loss = 0.0684\nepoch = 3800/4000   loss = 0.0690\nepoch = 4000/4000   loss = 0.0668\nresult saved\nepoch = 200/4000    loss = 0.8783\nepoch = 400/4000    loss = 0.5070\nepoch = 600/4000    loss = 0.3302\nepoch = 800/4000    loss = 0.2486\nepoch = 1000/4000   loss = 0.2313\nepoch = 1200/4000   loss = 0.2305\nepoch = 1400/4000   loss = 0.2303\nepoch = 1600/4000   loss = 0.2290\nepoch = 1800/4000   loss = 0.2256\nepoch = 2000/4000   loss = 0.2267\nepoch = 2200/4000   loss = 0.2250\nepoch = 2400/4000   loss = 0.2232\nepoch = 2600/4000   loss = 0.2251\nepoch = 2800/4000   loss = 0.2224\nepoch = 3000/4000   loss = 0.2223\nepoch = 3200/4000   loss = 0.2216\nepoch = 3400/4000   loss = 0.2213\nepoch = 3600/4000   loss = 0.2225\nepoch = 3800/4000   loss = 0.2224\nepoch = 4000/4000   loss = 0.2219\nresult saved\nepoch = 200/4000    loss = 0.3485\nepoch = 400/4000    loss = 0.1257\nepoch = 600/4000    loss = 0.1029\nepoch = 800/4000    loss = 0.0975\nepoch = 1000/4000   loss = 0.0955\nepoch = 1200/4000   loss = 0.0956\nepoch = 1400/4000   loss = 0.0949\nepoch = 1600/4000   loss = 0.0905\nepoch = 1800/4000   loss = 0.0928\nepoch = 2000/4000   loss = 0.0905\nepoch = 2200/4000   loss = 0.0884\nepoch = 2400/4000   loss = 0.0870\nepoch = 2600/4000   loss = 0.0865\nepoch = 2800/4000   loss = 0.0837\nepoch = 3000/4000   loss = 0.0831\nepoch = 3200/4000   loss = 0.0837\nepoch = 3400/4000   loss = 0.0837\nepoch = 3600/4000   loss = 0.0824\nepoch = 3800/4000   loss = 0.0825\nepoch = 4000/4000   loss = 0.0827\nresult saved\nepoch = 200/4000    loss = 0.7408\nepoch = 400/4000    loss = 0.6031\nepoch = 600/4000    loss = 0.5059\nepoch = 800/4000    loss = 0.4405\nepoch = 1000/4000   loss = 0.3784\nepoch = 1200/4000   loss = 0.3079\nepoch = 1400/4000   loss = 0.2650\nepoch = 1600/4000   loss = 0.2489\nepoch = 1800/4000   loss = 0.2407\nepoch = 2000/4000   loss = 0.2376\nepoch = 2200/4000   loss = 0.2368\nepoch = 2400/4000   loss = 0.2392\nepoch = 2600/4000   loss = 0.2351\nepoch = 2800/4000   loss = 0.2366\nepoch = 3000/4000   loss = 0.2360\nepoch = 3200/4000   loss = 0.2374\nepoch = 3400/4000   loss = 0.2350\nepoch = 3600/4000   loss = 0.2395\nepoch = 3800/4000   loss = 0.2351\nepoch = 4000/4000   loss = 0.2332\nresult saved\nepoch = 200/4000    loss = 0.4860\nepoch = 400/4000    loss = 0.2489\nepoch = 600/4000    loss = 0.1704\nepoch = 800/4000    loss = 0.1351\nepoch = 1000/4000   loss = 0.1194\nepoch = 1200/4000   loss = 0.1101\nepoch = 1400/4000   loss = 0.1087\nepoch = 1600/4000   loss = 0.1035\nepoch = 1800/4000   loss = 0.1050\nepoch = 2000/4000   loss = 0.1017\nepoch = 2200/4000   loss = 0.1017\nepoch = 2400/4000   loss = 0.1020\nepoch = 2600/4000   loss = 0.1000\nepoch = 2800/4000   loss = 0.1004\nepoch = 3000/4000   loss = 0.0987\nepoch = 3200/4000   loss = 0.0965\nepoch = 3400/4000   loss = 0.0961\nepoch = 3600/4000   loss = 0.0953\nepoch = 3800/4000   loss = 0.0947\nepoch = 4000/4000   loss = 0.0971\nresult saved\nepoch = 200/4000    loss = 0.5633\nepoch = 400/4000    loss = 0.5212\nepoch = 600/4000    loss = 0.4854\nepoch = 800/4000    loss = 0.4538\nepoch = 1000/4000   loss = 0.4290\nepoch = 1200/4000   loss = 0.4026\nepoch = 1400/4000   loss = 0.3818\nepoch = 1600/4000   loss = 0.3249\nepoch = 1800/4000   loss = 0.2734\nepoch = 2000/4000   loss = 0.2672\nepoch = 2200/4000   loss = 0.2682\nepoch = 2400/4000   loss = 0.2643\nepoch = 2600/4000   loss = 0.2634\nepoch = 2800/4000   loss = 0.2625\nepoch = 3000/4000   loss = 0.2618\nepoch = 3200/4000   loss = 0.2619\nepoch = 3400/4000   loss = 0.2579\nepoch = 3600/4000   loss = 0.2566\nepoch = 3800/4000   loss = 0.2529\nepoch = 4000/4000   loss = 0.2526\nresult saved\nepoch = 200/4000    loss = 0.5484\nepoch = 400/4000    loss = 0.3951\nepoch = 600/4000    loss = 0.2918\nepoch = 800/4000    loss = 0.1903\nepoch = 1000/4000   loss = 0.1475\nepoch = 1200/4000   loss = 0.1398\nepoch = 1400/4000   loss = 0.1402\nepoch = 1600/4000   loss = 0.1289\nepoch = 1800/4000   loss = 0.1237\nepoch = 2000/4000   loss = 0.1269\nepoch = 2200/4000   loss = 0.1171\nepoch = 2400/4000   loss = 0.1183\nepoch = 2600/4000   loss = 0.1200\nepoch = 2800/4000   loss = 0.1193\nepoch = 3000/4000   loss = 0.1131\nepoch = 3200/4000   loss = 0.1156\nepoch = 3400/4000   loss = 0.1141\nepoch = 3600/4000   loss = 0.1070\nepoch = 3800/4000   loss = 0.1094\nepoch = 4000/4000   loss = 0.1096\nresult saved\nepoch = 200/4000    loss = 0.5610\nepoch = 400/4000    loss = 0.4101\nepoch = 600/4000    loss = 0.3081\nepoch = 800/4000    loss = 0.2641\nepoch = 1000/4000   loss = 0.2505\nepoch = 1200/4000   loss = 0.2429\nepoch = 1400/4000   loss = 0.2375\nepoch = 1600/4000   loss = 0.2322\nepoch = 1800/4000   loss = 0.2288\nepoch = 2000/4000   loss = 0.2226\nepoch = 2200/4000   loss = 0.2238\nepoch = 2400/4000   loss = 0.2197\nepoch = 2600/4000   loss = 0.2185\nepoch = 2800/4000   loss = 0.2223\nepoch = 3000/4000   loss = 0.2205\nepoch = 3200/4000   loss = 0.2186\nepoch = 3400/4000   loss = 0.2193\nepoch = 3600/4000   loss = 0.2220\nepoch = 3800/4000   loss = 0.2222\nepoch = 4000/4000   loss = 0.2222\nresult saved\nepoch = 200/4000    loss = 0.6451\nepoch = 400/4000    loss = 0.4291\nepoch = 600/4000    loss = 0.3601\nepoch = 800/4000    loss = 0.3217\nepoch = 1000/4000   loss = 0.2784\nepoch = 1200/4000   loss = 0.2327\nepoch = 1400/4000   loss = 0.1580\nepoch = 1600/4000   loss = 0.1418\nepoch = 1800/4000   loss = 0.1329\nepoch = 2000/4000   loss = 0.1335\nepoch = 2200/4000   loss = 0.1251\nepoch = 2400/4000   loss = 0.1162\nepoch = 2600/4000   loss = 0.1117\nepoch = 2800/4000   loss = 0.1083\nepoch = 3000/4000   loss = 0.1066\nepoch = 3200/4000   loss = 0.1090\nepoch = 3400/4000   loss = 0.1066\nepoch = 3600/4000   loss = 0.1042\nepoch = 3800/4000   loss = 0.1055\nepoch = 4000/4000   loss = 0.1053\nresult saved"
  },
  {
    "objectID": "연구/보람이랑/신용카드거래 사기탐지/2023-08-22-데이터(8, df02)커널죽음.html",
    "href": "연구/보람이랑/신용카드거래 사기탐지/2023-08-22-데이터(8, df02)커널죽음.html",
    "title": "(연구&보람) 신용카드거래 사기탐지 – 데이터(8, df02)커널죽음",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nfrom sklearn import model_selection # split함수이용\n\n- fraudTrain\n\nfraudTrain = pd.read_csv(\"fraudTrain.csv\").iloc[:,1:]\n\n\nfraudTrain = fraudTrain.assign(trans_date_trans_time= list(map(lambda x: pd.to_datetime(x), fraudTrain.trans_date_trans_time)))\nfraudTrain\n\n\n\n\n\n\n\n\ntrans_date_trans_time\ncc_num\nmerchant\ncategory\namt\nfirst\nlast\ngender\nstreet\ncity\n...\nlat\nlong\ncity_pop\njob\ndob\ntrans_num\nunix_time\nmerch_lat\nmerch_long\nis_fraud\n\n\n\n\n0\n2019-01-01 00:00:00\n2.703190e+15\nfraud_Rippin, Kub and Mann\nmisc_net\n4.97\nJennifer\nBanks\nF\n561 Perry Cove\nMoravian Falls\n...\n36.0788\n-81.1781\n3495\nPsychologist, counselling\n1988-03-09\n0b242abb623afc578575680df30655b9\n1325376018\n36.011293\n-82.048315\n0\n\n\n1\n2019-01-01 00:00:00\n6.304230e+11\nfraud_Heller, Gutmann and Zieme\ngrocery_pos\n107.23\nStephanie\nGill\nF\n43039 Riley Greens Suite 393\nOrient\n...\n48.8878\n-118.2105\n149\nSpecial educational needs teacher\n1978-06-21\n1f76529f8574734946361c461b024d99\n1325376044\n49.159047\n-118.186462\n0\n\n\n2\n2019-01-01 00:00:00\n3.885950e+13\nfraud_Lind-Buckridge\nentertainment\n220.11\nEdward\nSanchez\nM\n594 White Dale Suite 530\nMalad City\n...\n42.1808\n-112.2620\n4154\nNature conservation officer\n1962-01-19\na1a22d70485983eac12b5b88dad1cf95\n1325376051\n43.150704\n-112.154481\n0\n\n\n3\n2019-01-01 00:01:00\n3.534090e+15\nfraud_Kutch, Hermiston and Farrell\ngas_transport\n45.00\nJeremy\nWhite\nM\n9443 Cynthia Court Apt. 038\nBoulder\n...\n46.2306\n-112.1138\n1939\nPatent attorney\n1967-01-12\n6b849c168bdad6f867558c3793159a81\n1325376076\n47.034331\n-112.561071\n0\n\n\n4\n2019-01-01 00:03:00\n3.755340e+14\nfraud_Keeling-Crist\nmisc_pos\n41.96\nTyler\nGarcia\nM\n408 Bradley Rest\nDoe Hill\n...\n38.4207\n-79.4629\n99\nDance movement psychotherapist\n1986-03-28\na41d7549acf90789359a9aa5346dcb46\n1325376186\n38.674999\n-78.632459\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1048570\n2020-03-10 16:07:00\n6.011980e+15\nfraud_Fadel Inc\nhealth_fitness\n77.00\nHaley\nWagner\nF\n05561 Farrell Crescent\nAnnapolis\n...\n39.0305\n-76.5515\n92106\nAccountant, chartered certified\n1943-05-28\n45ecd198c65e81e597db22e8d2ef7361\n1362931649\n38.779464\n-76.317042\n0\n\n\n1048571\n2020-03-10 16:07:00\n4.839040e+15\nfraud_Cremin, Hamill and Reichel\nmisc_pos\n116.94\nMeredith\nCampbell\nF\n043 Hanson Turnpike\nHedrick\n...\n41.1826\n-92.3097\n1583\nGeochemist\n1999-06-28\nc00ce51c6ebb7657474a77b9e0b51f34\n1362931670\n41.400318\n-92.726724\n0\n\n\n1048572\n2020-03-10 16:08:00\n5.718440e+11\nfraud_O'Connell, Botsford and Hand\nhome\n21.27\nSusan\nMills\nF\n005 Cody Estates\nLouisville\n...\n38.2507\n-85.7476\n736284\nEngineering geologist\n1952-04-02\n17c9dc8b2a6449ca2473726346e58e6c\n1362931711\n37.293339\n-84.798122\n0\n\n\n1048573\n2020-03-10 16:08:00\n4.646850e+18\nfraud_Thompson-Gleason\nhealth_fitness\n9.52\nJulia\nBell\nF\n576 House Crossroad\nWest Sayville\n...\n40.7320\n-73.1000\n4056\nFilm/video editor\n1990-06-25\n5ca650881b48a6a38754f841c23b77ab\n1362931718\n39.773077\n-72.213209\n0\n\n\n1048574\n2020-03-10 16:08:00\n2.283740e+15\nfraud_Buckridge PLC\nmisc_pos\n6.81\nShannon\nWilliams\nF\n9345 Spencer Junctions Suite 183\nAlpharetta\n...\n34.0770\n-84.3033\n165556\nPrison officer\n1997-12-27\n8d0a575fe635bbde12f1a2bffc126731\n1362931730\n33.601468\n-83.891921\n0\n\n\n\n\n1048575 rows × 22 columns\n\n\n\n- df02\n\n_df1 = fraudTrain[fraudTrain[\"is_fraud\"] == 0].sample(frac=0.20, random_state=42)\n_df2 = fraudTrain[fraudTrain[\"is_fraud\"] == 1]\ndf02 = pd.concat([_df1,_df2])\ndf02 = df02.reset_index()\n\n- df_toy\n\ndf_toy=df02[:5].copy()\ndf_toy.cc_num = pd.Series([1,1,1,2,2])\ndf_toy\n\n\n\n\n\n\n\n\nindex\ntrans_date_trans_time\ncc_num\nmerchant\ncategory\namt\nfirst\nlast\ngender\nstreet\n...\nlat\nlong\ncity_pop\njob\ndob\ntrans_num\nunix_time\nmerch_lat\nmerch_long\nis_fraud\n\n\n\n\n0\n669418\n2019-10-12 18:21:00\n1\nfraud_Haley, Jewess and Bechtelar\nshopping_pos\n7.53\nDebra\nStark\nF\n686 Linda Rest\n...\n32.3836\n-94.8653\n24536\nMultimedia programmer\n1983-10-14\nd313353fa30233e5fab5468e852d22fc\n1350066071\n32.202008\n-94.371865\n0\n\n\n1\n32567\n2019-01-20 13:06:00\n1\nfraud_Turner LLC\ntravel\n3.79\nJudith\nMoss\nF\n46297 Benjamin Plains Suite 703\n...\n39.5370\n-83.4550\n22305\nTelevision floor manager\n1939-03-09\n88c65b4e1585934d578511e627fe3589\n1327064760\n39.156673\n-82.930503\n0\n\n\n2\n156587\n2019-03-24 18:09:00\n1\nfraud_Klein Group\nentertainment\n59.07\nDebbie\nPayne\nF\n204 Ashley Neck Apt. 169\n...\n41.5224\n-71.9934\n4720\nBroadcast presenter\n1977-05-18\n3bd9ede04b5c093143d5e5292940b670\n1332612553\n41.657152\n-72.595751\n0\n\n\n3\n1020243\n2020-02-25 15:12:00\n2\nfraud_Monahan-Morar\npersonal_care\n25.58\nAlan\nParsons\nM\n0547 Russell Ford Suite 574\n...\n39.6171\n-102.4776\n207\nNetwork engineer\n1955-12-04\n19e16ee7a01d229e750359098365e321\n1361805120\n39.080346\n-103.213452\n0\n\n\n4\n116272\n2019-03-06 23:19:00\n2\nfraud_Kozey-Kuhlman\npersonal_care\n84.96\nJill\nFlores\nF\n639 Cruz Islands\n...\n41.9488\n-86.4913\n3104\nHorticulturist, commercial\n1981-03-29\na0c8641ca1f5d6e243ed5a2246e66176\n1331075954\n42.502065\n-86.732664\n0\n\n\n\n\n5 rows × 23 columns\n\n\n\n- df_toy 에서 time_difference 구함\n고객1\n\ndf_toy.iloc[0].trans_date_trans_time.value - df_toy.iloc[1].trans_date_trans_time.value\n\n22914900000000000\n\n\n\ndf_toy.iloc[0].trans_date_trans_time.value - df_toy.iloc[2].trans_date_trans_time.value\n\n17453520000000000\n\n\n\ndf_toy.iloc[1].trans_date_trans_time.value - df_toy.iloc[2].trans_date_trans_time.value\n\n-5461380000000000\n\n\n고객2\n\ndf_toy.iloc[3].trans_date_trans_time.value - df_toy.iloc[4].trans_date_trans_time.value\n\n30729180000000000\n\n\n고객1,2\n\ndef compute_time_difference(group):\n    n = len(group)\n    result = []\n    for i in range(n):\n        for j in range(n):\n            time_difference = abs(group.iloc[i].trans_date_trans_time.value - group.iloc[j].trans_date_trans_time.value)\n            result.append([group.iloc[i].name, group.iloc[j].name, time_difference])\n    return result\n\n\ngroups = df_toy.groupby('cc_num')\nedge_index_list_plus = [compute_time_difference(group) for _, group in groups]\nedge_index_list_plus_flat = [item for sublist in edge_index_list_plus for item in sublist]\nedge_index_list_plus_nparr = np.array(edge_index_list_plus_flat)\nedge_index_list_plus_nparr\n\narray([[                0,                 0,                 0],\n       [                0,                 1, 22914900000000000],\n       [                0,                 2, 17453520000000000],\n       [                1,                 0, 22914900000000000],\n       [                1,                 1,                 0],\n       [                1,                 2,  5461380000000000],\n       [                2,                 0, 17453520000000000],\n       [                2,                 1,  5461380000000000],\n       [                2,                 2,                 0],\n       [                3,                 3,                 0],\n       [                3,                 4, 30729180000000000],\n       [                4,                 3, 30729180000000000],\n       [                4,                 4,                 0]])\n\n\n- df02에서 time_difference 구함\n\nt1 = time.time()\ngroups = df02.groupby('cc_num')\nedge_index_list_plus = [compute_time_difference(group) for _, group in groups]\nedge_index_list_plus_flat = [item for sublist in edge_index_list_plus for item in sublist]\nedge_index_list_plus_nparr = np.array(edge_index_list_plus_flat)\nnp.save('edge_index_list_plus02.npy', edge_index_list_plus_nparr)\nt2 = time.time()\nt2-t1\n\n15537.573440551758\n\n\n\n(t2-t1)/3600\n\n4.3159926223754885"
  },
  {
    "objectID": "연구/보람이랑/신용카드거래 사기탐지/2024-05-23-AutoGluon.html",
    "href": "연구/보람이랑/신용카드거래 사기탐지/2024-05-23-AutoGluon.html",
    "title": "(연구&보람) AutoGluon",
    "section": "",
    "text": "import pandas as pd\nimport os \n\n\nfrom autogluon.tabular import TabularDataset, TabularPredictor\nimport sklearn\n\n\ndf_train_fnamelst = [l for l in os.listdir(\"./GCNresults/\") if \"gamma095\" in l and \"train\" in l]\ndf_train_fnamelst.sort()\ndf_train_fnamelst\n\n['df_train1_2024-06-06-07-42-19_gamma095.csv',\n 'df_train2_2024-06-06-07-57-18_gamma095.csv',\n 'df_train3_2024-06-06-08-01-55_gamma095.csv',\n 'df_train4_2024-06-06-08-05-32_gamma095.csv',\n 'df_train5_2024-06-06-08-08-44_gamma095.csv',\n 'df_train6_2024-06-06-08-11-47_gamma095.csv',\n 'df_train7_2024-06-06-08-14-46_gamma095.csv',\n 'df_train8_2024-06-06-08-17-44_gamma095.csv']\n\n\n\ndf_test_fnamelst = [l for l in os.listdir(\"./GCNresults/\") if \"gamma095\" in l and \"test\" in l]\ndf_test_fnamelst.sort()\ndf_test_fnamelst\n\n['df_test_2024-06-06-07-42-19_gamma095.csv',\n 'df_test_2024-06-06-07-57-18_gamma095.csv',\n 'df_test_2024-06-06-08-01-55_gamma095.csv',\n 'df_test_2024-06-06-08-05-32_gamma095.csv',\n 'df_test_2024-06-06-08-08-44_gamma095.csv',\n 'df_test_2024-06-06-08-11-47_gamma095.csv',\n 'df_test_2024-06-06-08-14-46_gamma095.csv',\n 'df_test_2024-06-06-08-17-44_gamma095.csv']\n\n\n\ncolumns = [\n    'category',\n    'amt',\n    'gender',\n    # 'street',\n    # 'city',\n    # 'state',\n    # 'zip',\n    # 'lat',\n    # 'long',\n    # 'city_pop',\n    'job',\n    'unix_time',\n    'is_fraud',\n#    'is_fraud_hat_prob',\n    'h0','h1','h2','h3','h4','h5','h6','h7'\n]\n\n\ndf_train_list = [pd.read_csv(f\"GCNresults/{fname}\")[Xcolumns] for fname in df_train_fnamelst]\ndf_test_list = [pd.read_csv(f\"GCNresults/{fname}\")[Xcolumns] for fname in df_test_fnamelst]\n\n\ndf_zip = zip(df_train_list,df_test_list)\n\n\ndf_train, df_test = next(df_zip)\n\n\npredictr = TabularPredictor(\n    label=\"is_fraud\", \n    verbosity=1,\n    log_to_file=False,\n)\n\nNo path specified. Models will be saved in: \"AutogluonModels/ag-20240608_021237\"\n\n\n\npredictr.fit(df_train)\n\nAutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n    If 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n\n\n&lt;autogluon.tabular.predictor.predictor.TabularPredictor at 0x7f58001ac7f0&gt;\n\n\n\nyyhat_prob = predictr.predict_proba(df_test).iloc[:,-1]\ndf_test_compact=df_test.assign(yyhat_prob = yyhat_prob).loc[:,['amt','is_fraud','yyhat_prob']]\ndf_test_compact[\n    (df_test_compact.amt&lt;80) & (df_test_compact.is_fraud==1)\n].yyhat_prob.hist()\n\n\n\n\n\n\n\n\n\ndf_test_compact\n\n\n\n\n\n\n\n\namt\nis_fraud\nyyhat_prob\n\n\n\n\n0\n7.53\n0\n2.461142e-07\n\n\n1\n3.79\n0\n9.140985e-08\n\n\n2\n59.07\n0\n8.759313e-13\n\n\n3\n25.58\n0\n1.279140e-17\n\n\n4\n84.96\n0\n1.202607e-12\n\n\n...\n...\n...\n...\n\n\n314567\n862.65\n1\n9.993129e-01\n\n\n314568\n1031.72\n1\n9.992218e-01\n\n\n314569\n778.05\n1\n9.993120e-01\n\n\n314570\n1052.39\n1\n9.465110e-01\n\n\n314571\n12.57\n1\n9.999127e-01\n\n\n\n\n314572 rows × 3 columns\n\n\n\n\nsklearn.metrics.f1_score(\n    df_test_compact[df_test_compact.amt&lt;80].is_fraud,\n    df_test_compact[df_test_compact.amt&lt;80].yyhat_prob&gt;0.5\n)\n\n0.631762652705061\n\n\n\nsklearn.metrics.recall_score(\n    df_test_compact[df_test_compact.amt&lt;80].is_fraud,\n    df_test_compact[df_test_compact.amt&lt;80].yyhat_prob&gt;0.5\n)\n\n0.4701298701298701\n\n\n\nsklearn.metrics.precision_score(\n    df_test_compact[df_test_compact.amt&lt;80].is_fraud,\n    df_test_compact[df_test_compact.amt&lt;80].yyhat_prob&gt;0.5\n)\n\n0.9627659574468085"
  },
  {
    "objectID": "연구/보람이랑/신용카드거래 사기탐지/2023-05-06-Start.html",
    "href": "연구/보람이랑/신용카드거래 사기탐지/2023-05-06-Start.html",
    "title": "(연구&보람) 신용카드거래 사기탐지 – Start",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport networkx as nx\nimport sklearn\n\n# split \nfrom sklearn.model_selection import train_test_split\n\n# embedding \nfrom node2vec import Node2Vec\nfrom node2vec.edges import HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder\n\n# models \nfrom sklearn.ensemble import RandomForestClassifier \n\n# 평가 \nfrom sklearn import metrics \n\n/home/cgb2/anaconda3/envs/py38/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n\n\ndef build_graph_bipartite(df_input, graph_type=nx.Graph()):\n    df=df_input.copy()\n    mapping={x:node_id for node_id, x in enumerate(set(df[\"cc_num\"].values.tolist()+\\\n                                                      df[\"merchant\"].values.tolist()))}\n    \n    df[\"from\"]=df[\"cc_num\"].apply(lambda x:mapping[x])  #엣지의 출발점\n    df[\"to\"]=df[\"merchant\"].apply(lambda x:mapping[x])  #엣지의 도착점\n    \n    df = df[['from', 'to', \"amt\", \"is_fraud\"]].groupby(['from','to']).agg({\"is_fraud\":\"sum\",\"amt\":\"sum\"}).reset_index()\n    df[\"is_fraud\"]=df[\"is_fraud\"].apply(lambda x:1 if x&gt;0 else 0)\n    \n    G=nx.from_edgelist(df[[\"from\",\"to\"]].values, create_using=graph_type)\n    \n    nx.set_edge_attributes(G, {(int(x[\"from\"]),int(x[\"to\"])):x[\"is_fraud\"] for idx, x in df[[\"from\",\"to\",\"is_fraud\"]].iterrows()}, \"label\")  #엣지 속성 설정,각 속성의 사기 여부부 \n    \n    nx.set_edge_attributes(G,{(int(x[\"from\"]),int(x[\"to\"])):x[\"amt\"] for idx,x in df[[\"from\",\"to\",\"amt\"]].iterrows()}, \"weight\") # 엣지 속성 설정, 각 엣지의 거래 금액\n\n    return G\n\ndef down_sample_textbook(df):\n    df_majority = df[df.is_fraud==0]\n    df_minority = df[df.is_fraud==1]\n    df_maj_dowsampled = sklearn.utils.resample(df_majority, n_samples=len(df_minority), random_state=42)\n    df_downsampled = pd.concat([df_minority, df_maj_dowsampled])\n    return df_downsampled\n\ndef split(Graph,test_size=0.20,random_state=42):\n    edg = list(range(len(Graph.edges))) \n    edg_att = list(nx.get_edge_attributes(Graph, \"label\").values())\n    return train_test_split(edg,edg_att,test_size=test_size,random_state=random_state) \n\ndef embedding(Graph):\n    _edgs = list(Graph.edges)\n    _train_edges, _test_edges, y, yy = split(Graph)\n    _train_graph = Graph.edge_subgraph([_edgs[x] for x in _train_edges]).copy()\n    _train_graph.add_nodes_from(list(set(Graph.nodes) - set(_train_graph.nodes)))\n    _embedded = AverageEmbedder(Node2Vec(_train_graph, weight_key='weight').fit(window=10).wv)\n    X = [_embedded[str(_edgs[x][0]), str(_edgs[x][1])] for x in _train_edges]\n    XX = [_embedded[str(_edgs[x][0]), str(_edgs[x][1])] for x in _test_edges]\n    return X,XX,y,yy \n\ndef evaluate(lrnr,XX,yy):\n    yyhat = lrnr.predict(XX)\n    df = pd.DataFrame({'pre':[sklearn.metrics.precision_score(yy,yyhat)], \n                  'rec':[sklearn.metrics.recall_score(yy,yyhat)],\n                  'f1':[sklearn.metrics.f1_score(yy,yyhat)]})\n    return df \n\ndef anal(df,n_estimators=10):\n    Graph = build_graph_bipartite(df)\n    X,XX,y,yy = embedding(Graph)\n    lrnr = RandomForestClassifier(n_estimators=n_estimators, random_state=42) \n    lrnr.fit(X,y)\n    return lrnr, XX,yy, evaluate(lrnr,XX,yy)\n\ndef our_sampling1(df):\n    cus_list = set(df.query('is_fraud==1').cc_num.tolist())\n    return df.query(\"cc_num in @ cus_list\")"
  },
  {
    "objectID": "연구/보람이랑/신용카드거래 사기탐지/2023-05-06-Start.html#imports",
    "href": "연구/보람이랑/신용카드거래 사기탐지/2023-05-06-Start.html#imports",
    "title": "(연구&보람) 신용카드거래 사기탐지 – Start",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport networkx as nx\nimport sklearn\n\n# split \nfrom sklearn.model_selection import train_test_split\n\n# embedding \nfrom node2vec import Node2Vec\nfrom node2vec.edges import HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder\n\n# models \nfrom sklearn.ensemble import RandomForestClassifier \n\n# 평가 \nfrom sklearn import metrics \n\n/home/cgb2/anaconda3/envs/py38/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n\n\ndef build_graph_bipartite(df_input, graph_type=nx.Graph()):\n    df=df_input.copy()\n    mapping={x:node_id for node_id, x in enumerate(set(df[\"cc_num\"].values.tolist()+\\\n                                                      df[\"merchant\"].values.tolist()))}\n    \n    df[\"from\"]=df[\"cc_num\"].apply(lambda x:mapping[x])  #엣지의 출발점\n    df[\"to\"]=df[\"merchant\"].apply(lambda x:mapping[x])  #엣지의 도착점\n    \n    df = df[['from', 'to', \"amt\", \"is_fraud\"]].groupby(['from','to']).agg({\"is_fraud\":\"sum\",\"amt\":\"sum\"}).reset_index()\n    df[\"is_fraud\"]=df[\"is_fraud\"].apply(lambda x:1 if x&gt;0 else 0)\n    \n    G=nx.from_edgelist(df[[\"from\",\"to\"]].values, create_using=graph_type)\n    \n    nx.set_edge_attributes(G, {(int(x[\"from\"]),int(x[\"to\"])):x[\"is_fraud\"] for idx, x in df[[\"from\",\"to\",\"is_fraud\"]].iterrows()}, \"label\")  #엣지 속성 설정,각 속성의 사기 여부부 \n    \n    nx.set_edge_attributes(G,{(int(x[\"from\"]),int(x[\"to\"])):x[\"amt\"] for idx,x in df[[\"from\",\"to\",\"amt\"]].iterrows()}, \"weight\") # 엣지 속성 설정, 각 엣지의 거래 금액\n\n    return G\n\ndef down_sample_textbook(df):\n    df_majority = df[df.is_fraud==0]\n    df_minority = df[df.is_fraud==1]\n    df_maj_dowsampled = sklearn.utils.resample(df_majority, n_samples=len(df_minority), random_state=42)\n    df_downsampled = pd.concat([df_minority, df_maj_dowsampled])\n    return df_downsampled\n\ndef split(Graph,test_size=0.20,random_state=42):\n    edg = list(range(len(Graph.edges))) \n    edg_att = list(nx.get_edge_attributes(Graph, \"label\").values())\n    return train_test_split(edg,edg_att,test_size=test_size,random_state=random_state) \n\ndef embedding(Graph):\n    _edgs = list(Graph.edges)\n    _train_edges, _test_edges, y, yy = split(Graph)\n    _train_graph = Graph.edge_subgraph([_edgs[x] for x in _train_edges]).copy()\n    _train_graph.add_nodes_from(list(set(Graph.nodes) - set(_train_graph.nodes)))\n    _embedded = AverageEmbedder(Node2Vec(_train_graph, weight_key='weight').fit(window=10).wv)\n    X = [_embedded[str(_edgs[x][0]), str(_edgs[x][1])] for x in _train_edges]\n    XX = [_embedded[str(_edgs[x][0]), str(_edgs[x][1])] for x in _test_edges]\n    return X,XX,y,yy \n\ndef evaluate(lrnr,XX,yy):\n    yyhat = lrnr.predict(XX)\n    df = pd.DataFrame({'pre':[sklearn.metrics.precision_score(yy,yyhat)], \n                  'rec':[sklearn.metrics.recall_score(yy,yyhat)],\n                  'f1':[sklearn.metrics.f1_score(yy,yyhat)]})\n    return df \n\ndef anal(df,n_estimators=10):\n    Graph = build_graph_bipartite(df)\n    X,XX,y,yy = embedding(Graph)\n    lrnr = RandomForestClassifier(n_estimators=n_estimators, random_state=42) \n    lrnr.fit(X,y)\n    return lrnr, XX,yy, evaluate(lrnr,XX,yy)\n\ndef our_sampling1(df):\n    cus_list = set(df.query('is_fraud==1').cc_num.tolist())\n    return df.query(\"cc_num in @ cus_list\")"
  },
  {
    "objectID": "연구/보람이랑/신용카드거래 사기탐지/2023-05-06-Start.html#read-and-define-data",
    "href": "연구/보람이랑/신용카드거래 사기탐지/2023-05-06-Start.html#read-and-define-data",
    "title": "(연구&보람) 신용카드거래 사기탐지 – Start",
    "section": "read and define data",
    "text": "read and define data\n\ndf = pd.read_csv(\"fraudTrain.csv\")\n_df1=  df[df[\"is_fraud\"]==0].sample(frac=0.20, random_state=42)\n_df2 = df[df[\"is_fraud\"] == 1]\ndf = pd.concat([_df1,_df2])\ndf.head()\n\n\n\n\n\n\n\n\nUnnamed: 0\ntrans_date_trans_time\ncc_num\nmerchant\ncategory\namt\nfirst\nlast\ngender\nstreet\n...\nlat\nlong\ncity_pop\njob\ndob\ntrans_num\nunix_time\nmerch_lat\nmerch_long\nis_fraud\n\n\n\n\n669418\n669418\n2019-10-12 18:21\n4.089100e+18\nfraud_Haley, Jewess and Bechtelar\nshopping_pos\n7.53\nDebra\nStark\nF\n686 Linda Rest\n...\n32.3836\n-94.8653\n24536\nMultimedia programmer\n1983-10-14\nd313353fa30233e5fab5468e852d22fc\n1350066071\n32.202008\n-94.371865\n0\n\n\n32567\n32567\n2019-01-20 13:06\n4.247920e+12\nfraud_Turner LLC\ntravel\n3.79\nJudith\nMoss\nF\n46297 Benjamin Plains Suite 703\n...\n39.5370\n-83.4550\n22305\nTelevision floor manager\n1939-03-09\n88c65b4e1585934d578511e627fe3589\n1327064760\n39.156673\n-82.930503\n0\n\n\n156587\n156587\n2019-03-24 18:09\n4.026220e+12\nfraud_Klein Group\nentertainment\n59.07\nDebbie\nPayne\nF\n204 Ashley Neck Apt. 169\n...\n41.5224\n-71.9934\n4720\nBroadcast presenter\n1977-05-18\n3bd9ede04b5c093143d5e5292940b670\n1332612553\n41.657152\n-72.595751\n0\n\n\n1020243\n1020243\n2020-02-25 15:12\n4.957920e+12\nfraud_Monahan-Morar\npersonal_care\n25.58\nAlan\nParsons\nM\n0547 Russell Ford Suite 574\n...\n39.6171\n-102.4776\n207\nNetwork engineer\n1955-12-04\n19e16ee7a01d229e750359098365e321\n1361805120\n39.080346\n-103.213452\n0\n\n\n116272\n116272\n2019-03-06 23:19\n4.178100e+15\nfraud_Kozey-Kuhlman\npersonal_care\n84.96\nJill\nFlores\nF\n639 Cruz Islands\n...\n41.9488\n-86.4913\n3104\nHorticulturist, commercial\n1981-03-29\na0c8641ca1f5d6e243ed5a2246e66176\n1331075954\n42.502065\n-86.732664\n0\n\n\n\n\n5 rows × 23 columns\n\n\n\n\n# df_downsampled = down_sample_textbook(df)"
  },
  {
    "objectID": "연구/보람이랑/신용카드거래 사기탐지/2023-05-06-Start.html#embedding",
    "href": "연구/보람이랑/신용카드거래 사기탐지/2023-05-06-Start.html#embedding",
    "title": "(연구&보람) 신용카드거래 사기탐지 – Start",
    "section": "embedding",
    "text": "embedding\n\n#G_down = build_graph_bipartite(df_downsampled)\n\n\n# X,XX,y,yy = embedding(G_down)"
  },
  {
    "objectID": "연구/보람이랑/신용카드거래 사기탐지/2023-05-06-Start.html#learn",
    "href": "연구/보람이랑/신용카드거래 사기탐지/2023-05-06-Start.html#learn",
    "title": "(연구&보람) 신용카드거래 사기탐지 – Start",
    "section": "learn",
    "text": "learn\n\n# lrnr = RandomForestClassifier(n_estimators=10, random_state=42) \n# lrnr.fit(X,y)"
  },
  {
    "objectID": "연구/보람이랑/신용카드거래 사기탐지/2023-05-06-Start.html#evaluate",
    "href": "연구/보람이랑/신용카드거래 사기탐지/2023-05-06-Start.html#evaluate",
    "title": "(연구&보람) 신용카드거래 사기탐지 – Start",
    "section": "evaluate",
    "text": "evaluate\n\n# evaluate(lrnr,XX,yy)"
  },
  {
    "objectID": "연구/보람이랑/신용카드거래 사기탐지/2023-05-06-Start.html#read-and-define-data-1",
    "href": "연구/보람이랑/신용카드거래 사기탐지/2023-05-06-Start.html#read-and-define-data-1",
    "title": "(연구&보람) 신용카드거래 사기탐지 – Start",
    "section": "read and define data",
    "text": "read and define data\n\nlrnr2, _,_,_ = anal(our_sampling1(df),n_estimators=100)\n\nComputing transition probabilities: 100%|██████████| 1289/1289 [00:49&lt;00:00, 26.00it/s]\nGenerating walks (CPU: 1): 100%|██████████| 10/10 [00:10&lt;00:00,  1.10s/it]"
  },
  {
    "objectID": "연구/보람이랑/신용카드거래 사기탐지/2023-05-06-Start.html#네트워크-토폴로지",
    "href": "연구/보람이랑/신용카드거래 사기탐지/2023-05-06-Start.html#네트워크-토폴로지",
    "title": "(연구&보람) 신용카드거래 사기탐지 – Start",
    "section": "네트워크 토폴로지",
    "text": "네트워크 토폴로지\n\n각 그래프별 차수 분포 살펴보기\n\n\nfor G in [G_bu, G_tu]:\n    plt.figure(figsize=(10,10))\n    degrees = pd.Series({k:v for k, v in nx.degree(G)})\n    degrees.plot.hist()\n    plt.yscale(\"log\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx축: 노드의 연결도\ny축: 로그 스케일(연결도가 큰 노드의 수가 매우 적으므로)\n\n- 각 그래프 간선 가중치 분포\n\nfor G in [G_bu, G_tu]:\n    allEdgeWeights = pd.Series({\n        (d[0],d[1]):d[2][\"weight\"]  #d[0],d[1]을 key로 d[2]를 weight로\n        #d는 G.edges(data=True)로 (u,v,data)형태의 튜플을 반복하는 반복문\n        for d in G.edges(data=True)})\n    np.quantile(allEdgeWeights.values,\n               [0.10, 0.50, 0.70, 0.9])\n    \n\n\nnp.quantile(allEdgeWeights.values,[0.10, 0.50, 0.70, 0.9])\n\narray([  4.15,  48.01,  75.75, 141.91])\n\n\n- 매게 중심성 측정 지표\n\nfor G in [G_bu, G_tu]:\n    plt.figure(figsize=(10,10))\n    bc_distr = pd.Series(nx.betweenness_centrality(G))\n    bc_distr.plot.hist()\n    plt.yscale(\"log\")\n\nKeyboardInterrupt: \n\n\n&lt;Figure size 1000x1000 with 0 Axes&gt;\n\n\n\n그래프 내에서 노드가 얼마나 중심적인 역할을 하는지 나타내는 지표\n해당 노드가 얼마나 많은 최단경로에 포함되는지 살피기\n노드가 많은 최단경로를 포함하면 해당노드의 매개중심성은 커진다.\n\n- 상관계수\n\nfor G in [G_bu, G_tu]:\n    print(nx.degree_pearson_correlation_coefficient(G))\n\n-0.12467174727090688\n-0.8051895351325623\n\n\n\n음의 동류성(서로 다른 속성을 가진 노드들끼리 연결되어 있다.)\n0~ -1 사이의 값을 가짐\n-1에 가까울수록 서로 다른 속성을 가진 노드들끼리 강한 음의 상관관계\n0에 가까울수록 노드들이 연결될 때 서로 다른 속성을 가진 노드들끼리 큰 차이가 없음 =&gt;\n연결도 높은 개인이 연골도 낮은 개인과 연관돼 있다.\n이분그래프: 낮은 차수의 고객은 들어오는 트랜잭션 수가 많은 높은 차수의 판매자와만 연결되어 상관계수가 낮다.\n삼분그래프:동류성이 훨씬 더 낮다. 트랜잭션 노드가 있기 댸문에?"
  },
  {
    "objectID": "연구/보람이랑/신용카드거래 사기탐지/2023-05-06-Start.html#커뮤니티-감지",
    "href": "연구/보람이랑/신용카드거래 사기탐지/2023-05-06-Start.html#커뮤니티-감지",
    "title": "(연구&보람) 신용카드거래 사기탐지 – Start",
    "section": "커뮤니티 감지",
    "text": "커뮤니티 감지\n\n# pip install python-louvain\n\n\nimport networkx as nx\nimport community\n\n\nimport community\nfor G in [G_bu, G_tu]:\n    parts = community.best_partition(G, random_state=42, weight='weight')\n\n\ncommunities = pd.Series(parts)\n\n\ncommunities\n\n255288    72\n204367    72\n65143     92\n10004     23\n194072     3\n          ..\n286119    78\n194740    88\n53644     57\n300283     9\n313041    66\nLength: 320413, dtype: int64\n\n\n\nprint(communities.value_counts().sort_values(ascending=False))\n\n4      9426\n94     6025\n6      5835\n42     5636\n50     5016\n       ... \n112    1341\n91     1307\n18     1104\n62     1057\n85      585\nLength: 113, dtype: int64\n\n\n\n커뮤니티 종류가 늘었따. 96&gt;&gt;113개로\n커뮤니티 감지를 통해 특정 사기 패턴 식별\n커뮤니티 추출 후 포함된 노드 수에 따라 정렬\n\n\ncommunities.value_counts().plot.hist(bins=20)\n\n\n\n\n\n\n\n\n\n9426개 이상한거 하나있고.. 약간 2000~3000사이에 집중되어 보인다.\n\n\ngraphs = [] # 부분그래프 저장\nd = {}  # 부정 거래 비율 저장 \nfor x in communities.unique():\n    tmp = nx.subgraph(G, communities[communities==x].index)\n    fraud_edges = sum(nx.get_edge_attributes(tmp, \"label\").values())\n    ratio = 0 if fraud_edges == 0 else (fraud_edges/tmp.number_of_edges())*100\n    d[x] = ratio\n    graphs += [tmp]\n\npd.Series(d).sort_values(ascending=False)\n\n56     5.281326\n59     4.709632\n111    4.399142\n77     4.149798\n15     3.975843\n         ...   \n90     0.409650\n112    0.297398\n110    0.292826\n67     0.277008\n18     0.180180\nLength: 113, dtype: float64\n\n\n\n사기 거래 비율 계산. 사기 거래가 집중된 특정 하위 그래프 식별\n특정 커뮤니티에 포함된 노드를 사용하여 노드 유도 하위 그래프 생성\n하위 그래프: 모든 간선 수에 대한 사기 거래 간선 수의 비율로 사기 거래 백분율 계싼\n\n\ngId = 10\nplt.figure(figsize=(10,10))\nspring_pos = nx.spring_layout(graphs[gId])\nplt.axis(\"off\")\nedge_colors = [\"r\" if x == 1 else \"g\" for x in nx.get_edge_attributes(graphs[gId], 'label').values()]  #r:빨간색, g:녹색\nnx.draw_networkx(graphs[gId], pos=spring_pos, node_color=default_node_color, \n                 edge_color=edge_colors, with_labels=False, node_size=15)\n\n\n\n\n\n\n\n\n\n커뮤니티 감지 알고리즘에 의해 감지된 노드 유도 하위 그래프 그리기\n특정 커뮤니티 인덱스 gId가 주어지면 해당 커뮤니티에서 사용 가능한 노드로 유도 하위 그래프 추출하고 얻는다.\n\n\ngId = 56\nplt.figure(figsize=(10,10))\nspring_pos = nx.spring_layout(graphs[gId])\nplt.axis(\"off\")\nedge_colors = [\"r\" if x == 1 else \"g\" for x in nx.get_edge_attributes(graphs[gId], 'label').values()]  #r:빨간색, g:녹색\nnx.draw_networkx(graphs[gId], pos=spring_pos, node_color=default_node_color, \n                 edge_color=edge_colors, with_labels=False, node_size=15)\n\n\n\n\n\n\n\n\n\ngId = 18\nplt.figure(figsize=(10,10))\nspring_pos = nx.spring_layout(graphs[gId])\nplt.axis(\"off\")\nedge_colors = [\"r\" if x == 1 else \"g\" for x in nx.get_edge_attributes(graphs[gId], 'label').values()]  #r:빨간색, g:녹색\nnx.draw_networkx(graphs[gId], pos=spring_pos, node_color=default_node_color, \n                 edge_color=edge_colors, with_labels=False, node_size=15)\n\n\n\n\n\n\n\n\n\npd.Series(d).plot.hist(bins=20)"
  },
  {
    "objectID": "연구/보람이랑/신용카드거래 사기탐지/2023-05-06-Start.html#사기-탐지를-위한-지도-및-비지도-임베딩",
    "href": "연구/보람이랑/신용카드거래 사기탐지/2023-05-06-Start.html#사기-탐지를-위한-지도-및-비지도-임베딩",
    "title": "(연구&보람) 신용카드거래 사기탐지 – Start",
    "section": "사기 탐지를 위한 지도 및 비지도 임베딩",
    "text": "사기 탐지를 위한 지도 및 비지도 임베딩\n\n트랜잭션 간선으로 표기\n각 간선을 올바른 클래스(사기 또는 정상)으로 분류\n\n\n지도학습\n\nfrom sklearn.utils import resample\n\ndf_majority = df[df.is_fraud==0]\ndf_minority = df[df.is_fraud==1]\n\ndf_maj_dowsampled = resample(df_majority,\n                             n_samples=len(df_minority),\n                             random_state=42)\n\ndf_downsampled = pd.concat([df_minority, df_maj_dowsampled])\n\nprint(df_downsampled.is_fraud.value_counts())\nG_down = build_graph_bipartite(df_downsampled)\n\n1    6006\n0    6006\nName: is_fraud, dtype: int64\n\n\n\ndf.shape\n\n(318777, 23)\n\n\n\ndf_minority.shape\n\n(6006, 23)\n\n\n\ndf_majority.shape\n\n(312771, 23)\n\n\n\n6006 / 312771 \n\n0.019202547550763976\n\n\n\n무작위 언더샘플링 사용\n소수 클래스(사기거래)이 샘플 수 와 일치시키려고 다수 클래스(정상거래)의 하위 샘플을 가져옴\n데이터 불균형을 처리하기 위해서\n\n\nfrom sklearn.model_selection import train_test_split\n\n\ntrain_edges, test_edges, train_labels, test_labels = train_test_split(list(range(len(G_down.edges))), \n                                                                      list(nx.get_edge_attributes(G_down, \"label\").values()), \n                                                                      test_size=0.20, \n                                                                      random_state=42)\n\n\nedgs = list(G_down.edges)\ntrain_graph = G_down.edge_subgraph([edgs[x] for x in train_edges]).copy()\ntrain_graph.add_nodes_from(list(set(G_down.nodes) - set(train_graph.nodes)))\n\n\n데이터 8:2 비율로 학습 검증\n\n\npip install node2vec\n\nCollecting node2vec\n  Downloading node2vec-0.4.6-py3-none-any.whl (7.0 kB)\nRequirement already satisfied: joblib&lt;2.0.0,&gt;=1.1.0 in /home/coco/anaconda3/envs/py38/lib/python3.8/site-packages (from node2vec) (1.2.0)\nCollecting gensim&lt;5.0.0,&gt;=4.1.2\n  Downloading gensim-4.3.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 26.5/26.5 MB 71.8 MB/s eta 0:00:0000:0100:01\nCollecting tqdm&lt;5.0.0,&gt;=4.55.1\n  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.1/77.1 kB 18.6 MB/s eta 0:00:00\nCollecting networkx&lt;3.0,&gt;=2.5\n  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 90.4 MB/s eta 0:00:00\nRequirement already satisfied: numpy&lt;2.0.0,&gt;=1.19.5 in /home/coco/anaconda3/envs/py38/lib/python3.8/site-packages (from node2vec) (1.24.2)\nRequirement already satisfied: scipy&gt;=1.7.0 in /home/coco/anaconda3/envs/py38/lib/python3.8/site-packages (from gensim&lt;5.0.0,&gt;=4.1.2-&gt;node2vec) (1.10.1)\nCollecting smart-open&gt;=1.8.1\n  Downloading smart_open-6.3.0-py3-none-any.whl (56 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.8/56.8 kB 13.6 MB/s eta 0:00:00\nInstalling collected packages: tqdm, smart-open, networkx, gensim, node2vec\n  Attempting uninstall: networkx\n    Found existing installation: networkx 3.0\n    Uninstalling networkx-3.0:\n      Successfully uninstalled networkx-3.0\nSuccessfully installed gensim-4.3.1 networkx-2.8.8 node2vec-0.4.6 smart-open-6.3.0 tqdm-4.65.0\nNote: you may need to restart the kernel to use updated packages.\n\n\n\nfrom node2vec import Node2Vec\nfrom node2vec.edges import HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder\n\nnode2vec_train = Node2Vec(train_graph, weight_key='weight')\nmodel_train = node2vec_train.fit(window=10)\n\n\n\n\nGenerating walks (CPU: 1):   0%|          | 0/10 [00:00&lt;?, ?it/s]Generating walks (CPU: 1): 100%|██████████| 10/10 [00:04&lt;00:00,  2.45it/s]\n\n\n\n\n\n\nNode2Vec 알고리즘 사용해 특징 공간 구축\n\n\nfrom sklearn.ensemble import RandomForestClassifier \nfrom sklearn import metrics \n\nclasses = [HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder]\nfor cl in classes:\n    embeddings_train = cl(keyed_vectors=model_train.wv) \n    # 벡터스페이스 상에 edge를 투영.. \n\n    train_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in train_edges]\n    test_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in test_edges]\n    \n    rf = RandomForestClassifier(n_estimators=1000, random_state=42) \n    rf.fit(train_embeddings, train_labels); \n    #\n    y_hat = rf.predict_proba(test_embeddings)\n    y_pred = np.argmax(yhat,axis=1)\n    #y_pred = rf.predict(test_embeddings)\n    print(cl)\n    print('Precision:', metrics.precision_score(test_labels, y_pred)) \n    print('Recall:', metrics.recall_score(test_labels, y_pred)) \n    print('F1-Score:', metrics.f1_score(test_labels, y_pred)) \n\n&lt;class 'node2vec.edges.HadamardEmbedder'&gt;\nPrecision: 0.7236842105263158\nRecall: 0.1407849829351536\nF1-Score: 0.2357142857142857\n\n\n\ny_pred\n\narray([1, 0, 0, ..., 0, 0, 0])\n\n\n\nyhat = rf.predict_proba(test_embeddings)\n\n\nyhat\n\narray([[0.457, 0.543],\n       [0.634, 0.366],\n       [0.609, 0.391],\n       ...,\n       [0.577, 0.423],\n       [0.59 , 0.41 ],\n       [0.557, 0.443]])\n\n\n\nNode2Vec 알고리즘 사용해 각 Edge2Vec 알고리즘으로 특징 공간 생성\nsklearn 파이썬 라이브러리의 RandomForestClassifier은 이전 단계에서 생성한 특징에 대해 학습\n검증 테스트 위해 정밀도, 재현율, F1-score 성능 지표 측정\n\n\n\n비지도학습\n\nk-means 알고리즘 사용\n지도학습과의 차이점은 특징 공간이 학습-검증 분할을 안함.\n\n\nnod2vec_unsup = Node2Vec(G_down, weight_key='weight')\nunsup_vals = nod2vec_unsup.fit(window=10)\n\n\n\n\nGenerating walks (CPU: 1): 100%|██████████| 10/10 [00:04&lt;00:00,  2.30it/s]\n\n\n\n다운샘플링 절차에 전체 그래프 알고리즘 계산\n\n\nfrom sklearn.cluster import KMeans\n\nclasses = [HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder]\ntrue_labels = [x for x in nx.get_edge_attributes(G_down, \"label\").values()]\n\nfor cl in classes:\n    embedding_edge = cl(keyed_vectors=unsup_vals.wv) \n\n    embedding = [embedding_edge[str(x[0]), str(x[1])] for x in G_down.edges()]\n    kmeans = KMeans(2, random_state=42).fit(embedding)\n    \n    \n    nmi = metrics.adjusted_mutual_info_score(true_labels, kmeans.labels_)\n    ho = metrics.homogeneity_score(true_labels, kmeans.labels_)\n    co = metrics.completeness_score(true_labels, kmeans.labels_)\n    vmeasure = metrics.v_measure_score(true_labels, kmeans.labels_)\n    \n    print(cl)\n    print('NMI:', nmi)\n    print('Homogeneity:', ho)\n    print('Completeness:', co)\n    print('V-Measure:', vmeasure)\n\n/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n\n\n&lt;class 'node2vec.edges.HadamardEmbedder'&gt;\nNMI: 0.04418691434534317\nHomogeneity: 0.0392170155918133\nCompleteness: 0.05077340984619601\nV-Measure: 0.044253187956299615\n&lt;class 'node2vec.edges.AverageEmbedder'&gt;\nNMI: 0.10945180042668563\nHomogeneity: 0.10590886334115046\nCompleteness: 0.11336117407653773\nV-Measure: 0.10950837820667877\n&lt;class 'node2vec.edges.WeightedL1Embedder'&gt;\nNMI: 0.17575054988974667\nHomogeneity: 0.1757509360433583\nCompleteness: 0.17585150874409544\nV-Measure: 0.17580120800977098\n&lt;class 'node2vec.edges.WeightedL2Embedder'&gt;\nNMI: 0.13740583375677415\nHomogeneity: 0.13628828058562012\nCompleteness: 0.1386505946822449\nV-Measure: 0.13745928896382234\n\n\n- NMI(Normalized Mutual Information)\n\n두 개의 군집 결과 비교\n0~1이며 1에 가까울수록 높은 성능\n\n- Homogeneity\n\n하나의 실제 군집 내에서 같은 군집에 속한 샘플들이 군집화 결과에서 같은 군집에 속할 비율\n1에 가까울수록 높은 성능\n\n- Completeness\n\n하나의 예측 군집 내에서 같은 실제 군집에 속한 샘플들이 군집화 결과에서 같은 군집에 속할 비율\n0~1이며 1에 가까울수록 높은 성능\n\n- V-measure\n\nHomogeneity와 Completeness의 조화 평균\n0~1이며 1에 가까울수록 높은 성능\n비지도 학습에 이상치 탐지 방법\nk-means/LOF/One-class SVM 등이 있다.. 한번 같이 해보자.\n조금씩 다 커졌넹..\n\n- 지도학습에서 정상거래에서 다운샘플링을 했는데\n만약, 사기거래에서 업샘플링을 하게되면 어떻게 될까?"
  },
  {
    "objectID": "연구/보람이랑/신용카드거래 사기탐지/2024-04-30-데이터정리.html",
    "href": "연구/보람이랑/신용카드거래 사기탐지/2024-04-30-데이터정리.html",
    "title": "(연구&보람) 데이터정리",
    "section": "",
    "text": "import torch\nimport torch_geometric\nimport pandas as pd\nimport numpy as np\nimport pickle \nimport itertools\nimport multiprocessing\nfrom functools import partial\nimport matplotlib.pyplot as plt\n\n\ndef throw(df, fraud_rate, random_state=42):\n    # Separate fraud and non-fraud transactions and make copies\n    df1 = df[df['is_fraud'] == 1].copy()  # Fraud transactions\n    df0 = df[df['is_fraud'] == 0].copy()  # Non-fraud transactions\n    \n    # Downsample non-fraud transactions\n    # Downsample the non-fraud transactions considering the fraud rate\n    df0_downsample = (len(df1) * (1 - fraud_rate)) / (len(df0) * fraud_rate)\n    df0_down = df0.sample(frac=df0_downsample, random_state=random_state)\n    \n    # Concatenate fraud transactions and downsampled non-fraud transactions\n    df_p = pd.concat([df1, df0_down])\n    \n    # Return the concatenated DataFrame\n    return df_p\n    \ndef split_dataframe(data_frame, test_fraud_rate, test_rate=0.3, random_state=42):\n    # Split the data into 70:30 ratio with test_fraud_rate as input\n    n = len(data_frame)\n\n    # Separate fraud and non-fraud transactions\n    fraud_data = data_frame[data_frame['is_fraud'] == 1]\n    normal_data = data_frame[data_frame['is_fraud'] == 0]\n\n    # Calculate the size of the test data\n    test_samples = int(test_fraud_rate * (n * test_rate))\n    remaining_test_samples = int(n * test_rate) - test_samples\n\n    # Randomly sample test data from fraud and non-fraud transactions\n    test_fraud_data = fraud_data.sample(n=test_samples, replace=False, random_state=random_state)\n    test_normal_data = normal_data.sample(n=remaining_test_samples, replace=False, random_state=random_state)\n\n    # Concatenate test data\n    test_data = pd.concat([test_normal_data, test_fraud_data])\n\n    # Create training data\n    train_data = data_frame[~data_frame.index.isin(test_data.index)]\n\n    return train_data, test_data\n\n\n# GCN에서 mask를 위한 함수 \ndef _concat(df_tr, df_tst):   \n    df = pd.concat([df_tr, df_tst])\n    train_mask = np.concatenate((np.full(len(df_tr), True), np.full(len(df_tst), False)))    # index꼬이는거 방지하기 위해서? ★ (이거,, 훔,,?(\n    test_mask =  np.concatenate((np.full(len(df_tr), False), np.full(len(df_tst), True))) \n    mask = (train_mask, test_mask)\n    return df, mask\n\n# 거래시간차이 계산 \ndef _compute_time_difference(sub_df):\n    t = sub_df.unix_time.to_numpy() \n    t_diff = abs(t.reshape(-1,1) - t.reshape(1,-1)).reshape(-1,1)\n    idx = np.array(list(itertools.product(sub_df.index,sub_df.index)))\n    result = np.concatenate([idx,t_diff],axis=1)\n    return result\n\ndef _parallel_apply(func, data_frames, num_processes=None):\n    \"\"\"\n    Apply a function to a list of DataFrames in parallel.\n    \n    :param func: The function to apply.\n    :param data_frames: The list of DataFrames to process.\n    :param num_processes: The number of processes to use.\n    :return: A list containing the processed results.\n    \"\"\"\n    if num_processes is None:\n        num_processes = multiprocessing.cpu_count()  # Number of available CPU cores\n\n    with multiprocessing.Pool(processes=num_processes) as pool:\n        results = pool.map(func, data_frames)\n\n    return results\n    \ndef df2geodata(df_train,df_test,theta,gamma):\n    df2, mask = _concat(df_train, df_test)   \n    df = df2.reset_index()\n    groups = df.groupby('cc_num')\n    data_frames = [sub_df for _,sub_df in groups]  # 여기에 데이터프레임들을 리스트로 \n    processed_results = _parallel_apply(_compute_time_difference, data_frames)\n    processed_results = np.concatenate(processed_results).astype(np.float64)\n    edge_index = processed_results[:,:2]\n    dist = processed_results[:,2]\n    weight = (dist != 0) * np.exp(-dist/theta)\n    edge_index = torch.tensor(edge_index[weight &gt; gamma]).long().t()    \n    x = torch.tensor(df['amt'].values, dtype=torch.float).reshape(-1,1)\n    y = torch.tensor(df['is_fraud'].values,dtype=torch.int64)\n    data = torch_geometric.data.Data(x=x, edge_index = edge_index, y=y, train_mask = mask[0], test_mask= mask[1])\n    return data"
  },
  {
    "objectID": "연구/보람이랑/신용카드거래 사기탐지/2024-04-30-데이터정리.html#a.-분리",
    "href": "연구/보람이랑/신용카드거래 사기탐지/2024-04-30-데이터정리.html#a.-분리",
    "title": "(연구&보람) 데이터정리",
    "section": "A. 분리",
    "text": "A. 분리\n\ndf_train1, df_test = split_dataframe(fraudTrain,test_fraud_rate=FRAUD_RATE)\n\n\ndf_train2 = throw(df_train1, fraud_rate=0.01) \ndf_train3 = throw(df_train1, fraud_rate=0.05) \ndf_train4 = throw(df_train1, fraud_rate=0.1) \ndf_train5 = throw(df_train1, fraud_rate=0.2) \ndf_train6 = throw(df_train1, fraud_rate=0.3) \ndf_train7 = throw(df_train1, fraud_rate=0.4) \ndf_train8 = throw(df_train1, fraud_rate=0.5) \n\n\nprint(f\"\"\"&lt;df1&gt;\ntraining set := {df_train1.shape}, {df_train1.is_fraud.mean():.4f}, {df_train1.is_fraud.sum()}\ntest set := {df_test.shape}, {df_test.is_fraud.mean():.4f}, {df_test.is_fraud.sum()}\n&lt;df2&gt;\ntraining set := {df_train2.shape}, {df_train2.is_fraud.mean():.4f}, {df_train1.is_fraud.sum()}\ntest set := {df_test.shape}, {df_test.is_fraud.mean():.4f}, {df_test.is_fraud.sum()}\n&lt;df3&gt;\ntraining set := {df_train3.shape}, {df_train3.is_fraud.mean():.4f}, {df_train1.is_fraud.sum()}\ntest set := {df_test.shape}, {df_test.is_fraud.mean():.4f}, {df_test.is_fraud.sum()}\n&lt;df4&gt;\ntraining set := {df_train4.shape}, {df_train4.is_fraud.mean():.4f}, {df_train1.is_fraud.sum()}\ntest set := {df_test.shape}, {df_test.is_fraud.mean():.4f}, {df_test.is_fraud.sum()}\n&lt;df5&gt;\ntraining set := {df_train5.shape}, {df_train5.is_fraud.mean():.4f}, {df_train1.is_fraud.sum()}\ntest set := {df_test.shape}, {df_test.is_fraud.mean():.4f}, {df_test.is_fraud.sum()}\n&lt;df6&gt;\ntraining set := {df_train6.shape}, {df_train6.is_fraud.mean():.4f}, {df_train1.is_fraud.sum()}\ntest set := {df_test.shape}, {df_test.is_fraud.mean():.4f}, {df_test.is_fraud.sum()}\n&lt;df2&gt;\ntraining set := {df_train7.shape}, {df_train7.is_fraud.mean():.4f}, {df_train1.is_fraud.sum()}\ntest set := {df_test.shape}, {df_test.is_fraud.mean():.4f}, {df_test.is_fraud.sum()}\n&lt;df8&gt;\ntraining set := {df_train8.shape}, {df_train8.is_fraud.mean():.4f}, {df_train1.is_fraud.sum()}\ntest set := {df_test.shape}, {df_test.is_fraud.mean():.4f}, {df_test.is_fraud.sum()}\n\"\"\")\n\n&lt;df1&gt;\ntraining set := (734003, 22), 0.0057, 4205\ntest set := (314572, 22), 0.0057, 1801\n&lt;df2&gt;\ntraining set := (420500, 22), 0.0100, 4205\ntest set := (314572, 22), 0.0057, 1801\n&lt;df3&gt;\ntraining set := (84100, 22), 0.0500, 4205\ntest set := (314572, 22), 0.0057, 1801\n&lt;df4&gt;\ntraining set := (42050, 22), 0.1000, 4205\ntest set := (314572, 22), 0.0057, 1801\n&lt;df5&gt;\ntraining set := (21025, 22), 0.2000, 4205\ntest set := (314572, 22), 0.0057, 1801\n&lt;df6&gt;\ntraining set := (14017, 22), 0.3000, 4205\ntest set := (314572, 22), 0.0057, 1801\n&lt;df2&gt;\ntraining set := (10512, 22), 0.4000, 4205\ntest set := (314572, 22), 0.0057, 1801\n&lt;df8&gt;\ntraining set := (8410, 22), 0.5000, 4205\ntest set := (314572, 22), 0.0057, 1801"
  },
  {
    "objectID": "연구/보람이랑/신용카드거래 사기탐지/2024-04-30-데이터정리.html#b.-df저장",
    "href": "연구/보람이랑/신용카드거래 사기탐지/2024-04-30-데이터정리.html#b.-df저장",
    "title": "(연구&보람) 데이터정리",
    "section": "B. DF저장",
    "text": "B. DF저장\n\ndf_train1.to_csv(\"./data/df_train1.csv\",index=False)\ndf_train2.to_csv(\"./data/df_train2.csv\",index=False)\ndf_train3.to_csv(\"./data/df_train3.csv\",index=False)\ndf_train4.to_csv(\"./data/df_train4.csv\",index=False)\ndf_train5.to_csv(\"./data/df_train5.csv\",index=False)\ndf_train6.to_csv(\"./data/df_train6.csv\",index=False)\ndf_train7.to_csv(\"./data/df_train7.csv\",index=False)\ndf_train8.to_csv(\"./data/df_train8.csv\",index=False)\ndf_test.to_csv(\"./data/df_test.csv\",index=False)"
  },
  {
    "objectID": "연구/보람이랑/신용카드거래 사기탐지/2024-04-30-데이터정리.html#c.-make_graph",
    "href": "연구/보람이랑/신용카드거래 사기탐지/2024-04-30-데이터정리.html#c.-make_graph",
    "title": "(연구&보람) 데이터정리",
    "section": "C. Make_Graph",
    "text": "C. Make_Graph\n\nTHETA = 1e7\nGAMMA = 0.95\n\n\ntorch_geometric_data1 = df2geodata(df_train1,df_test,theta=THETA,gamma=GAMMA)\ntorch_geometric_data2 = df2geodata(df_train2,df_test,theta=THETA,gamma=GAMMA)\ntorch_geometric_data3 = df2geodata(df_train3,df_test,theta=THETA,gamma=GAMMA)\ntorch_geometric_data4 = df2geodata(df_train4,df_test,theta=THETA,gamma=GAMMA)\ntorch_geometric_data5 = df2geodata(df_train5,df_test,theta=THETA,gamma=GAMMA)\ntorch_geometric_data6 = df2geodata(df_train6,df_test,theta=THETA,gamma=GAMMA)\ntorch_geometric_data7 = df2geodata(df_train7,df_test,theta=THETA,gamma=GAMMA)\ntorch_geometric_data8 = df2geodata(df_train8,df_test,theta=THETA,gamma=GAMMA)\n\n\ntorch_geometric_data_list = [\n    torch_geometric_data1,\n    torch_geometric_data2,\n    torch_geometric_data3,\n    torch_geometric_data4,\n    torch_geometric_data5,\n    torch_geometric_data6,\n    torch_geometric_data7,\n    torch_geometric_data8\n]\ndf_train_list = [\n    df_train1,\n    df_train2,\n    df_train3,\n    df_train4,\n    df_train5,\n    df_train6,\n    df_train7,\n    df_train8\n]\n\n\nfor data, df_train in zip(torch_geometric_data_list,df_train_list):\n    data._train_size = len(df_train)\n    data._train_frate = df_train.is_fraud.mean()\n    data._test_size = len(df_test)\n    data._test_frate = df_test.is_fraud.mean()\n    data._theta = THETA\n    data._gamma = GAMMA \n\n\nfor (i,data) in enumerate(torch_geometric_data_list):\n    with open(f'data/torch_geometric_data{i+1}_{THETA:.1e}_{GAMMA}.pkl', 'wb') as f:\n        pickle.dump(data, f)"
  },
  {
    "objectID": "연구/보람이랑/신용카드거래 사기탐지/2023-05-24-Try2변형.html",
    "href": "연구/보람이랑/신용카드거래 사기탐지/2023-05-24-Try2변형.html",
    "title": "(연구&보람) 신용카드거래 사기탐지 – Try2변형",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport networkx as nx\nimport sklearn\n\n# sklearn\nfrom sklearn import model_selection # split함수이용\nfrom sklearn import ensemble # RF,GBM\nfrom sklearn import metrics \n\n# embedding \nfrom node2vec import Node2Vec\nfrom node2vec.edges import HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder\n\n/home/cgb2/anaconda3/envs/py38/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n\n\ndef build_graph_bipartite(df_input, graph_type=nx.Graph()):\n    df=df_input.copy()\n    mapping={x:node_id for node_id, x in enumerate(set(df[\"cc_num\"].values.tolist()+\\\n                                                      df[\"merchant\"].values.tolist()))}\n    \n    df[\"from\"]=df[\"cc_num\"].apply(lambda x:mapping[x])  #엣지의 출발점\n    df[\"to\"]=df[\"merchant\"].apply(lambda x:mapping[x])  #엣지의 도착점\n    \n    df = df[['from', 'to', \"amt\", \"is_fraud\"]].groupby(['from','to']).agg({\"is_fraud\":\"sum\",\"amt\":\"sum\"}).reset_index()\n    df[\"is_fraud\"]=df[\"is_fraud\"].apply(lambda x:1 if x&gt;0 else 0)\n    \n    G=nx.from_edgelist(df[[\"from\",\"to\"]].values, create_using=graph_type)\n    \n    nx.set_edge_attributes(G,{(int(x[\"from\"]),int(x[\"to\"])):x[\"is_fraud\"] for idx, x in df[[\"from\",\"to\",\"is_fraud\"]].iterrows()}, \"label\")  #엣지 속성 설정,각 속성의 사기 여부부     \n    nx.set_edge_attributes(G,{(int(x[\"from\"]),int(x[\"to\"])):x[\"amt\"] for idx,x in df[[\"from\",\"to\",\"amt\"]].iterrows()}, \"weight\") # 엣지 속성 설정, 각 엣지의 거래 금액\n\n    return G\n\n\ndef build_graph_tripartite(df_input, graph_type=nx.Graph()):\n    df=df_input.copy()\n    mapping={x:node_id for node_id, x in enumerate(set(df.index.values.tolist() + \n                                                       df[\"cc_num\"].values.tolist() +\n                                                       df[\"merchant\"].values.tolist()))}\n    df[\"in_node\"]= df[\"cc_num\"].apply(lambda x: mapping[x])\n    df[\"out_node\"]=df[\"merchant\"].apply(lambda x:mapping[x])\n    \n        \n    G=nx.from_edgelist([(x[\"in_node\"], mapping[idx]) for idx, x in df.iterrows()] +\\\n                        [(x[\"out_node\"], mapping[idx]) for idx, x in df.iterrows()], create_using=graph_type)\n    \n    nx.set_edge_attributes(G,{(x[\"in_node\"], mapping[idx]):x[\"is_fraud\"] for idx, x in df.iterrows()}, \"label\")     \n    nx.set_edge_attributes(G,{(x[\"out_node\"], mapping[idx]):x[\"is_fraud\"] for idx, x in df.iterrows()}, \"label\")   \n    nx.set_edge_attributes(G,{(x[\"in_node\"], mapping[idx]):x[\"amt\"] for idx, x in df.iterrows()}, \"weight\")  \n    nx.set_edge_attributes(G,{(x[\"out_node\"], mapping[idx]):x[\"amt\"] for idx, x in df.iterrows()}, \"weight\")\n\n    return G\n    \n    \ndef down_sample_textbook(df):\n    df_majority = df[df.is_fraud==0].copy()\n    df_minority = df[df.is_fraud==1].copy()\n    df_maj_dowsampled = sklearn.utils.resample(df_majority, n_samples=len(df_minority), replace=False, random_state=42)\n    df_downsampled = pd.concat([df_minority, df_maj_dowsampled])\n    return df_downsampled\n\ndef embedding(Graph):\n    # Graph -&gt; X (feature)\n    _edgs = list(Graph.edges)\n    subGraph = Graph.edge_subgraph([_edgs[x] for x in range(len(Graph.edges))]).copy()\n    subGraph.add_nodes_from(list(set(Graph.nodes) - set(subGraph.nodes)))    \n    embedded = AverageEmbedder(Node2Vec(subGraph, weight_key='weight').fit(window=10).wv)\n    X = [embedded[str(_edgs[x][0]), str(_edgs[x][1])] for x in range(len(Graph.edges))]\n    # Graph -&gt; y (label)\n    y = np.array(list(nx.get_edge_attributes(Graph, \"label\").values()))\n    return X,y \n\ndef anal(df):\n    Graph = build_graph_bipartite(df)\n    X,XX,y,yy = embedding(Graph)\n    lrnr = RandomForestClassifier(n_estimators=100, random_state=42) \n    lrnr.fit(X,y)\n    yyhat = lrnr.predict(XX)\n    df = pd.DataFrame({\n        'acc':[sklearn.metrics.accuracy_score(yy,yyhat)], \n        'pre':[sklearn.metrics.precision_score(yy,yyhat)], \n        'rec':[sklearn.metrics.recall_score(yy,yyhat)],\n        'f1':[sklearn.metrics.f1_score(yy,yyhat)]}\n    )    \n    return df\n\ndef our_sampling1(df):\n    cus_list = set(df.query('is_fraud==1').cc_num.tolist())\n    return df.query(\"cc_num in @ cus_list\")"
  },
  {
    "objectID": "연구/보람이랑/신용카드거래 사기탐지/2023-05-24-Try2변형.html#데이터-종류",
    "href": "연구/보람이랑/신용카드거래 사기탐지/2023-05-24-Try2변형.html#데이터-종류",
    "title": "(연구&보람) 신용카드거래 사기탐지 – Try2변형",
    "section": "데이터 종류",
    "text": "데이터 종류\n\nfraudTrain.csv: (1048575, 23), 기본데이터\ndf02: (214520, 23), is_fraud==0 에서는 20퍼의 샘플만, is_fraud==1 에서는 모든 샘플을 뽑아서 정리한 새로운 자료\ndf50 = (12012, 23), df20에서 is_fraud==0 와 is_fraud==1 의 비율을 맞추어서 샘플을 뽑은 것\n\n\n\n\n\n\n\n\n\n\n데이터\nshape\n사기거래빈도\n설명\n\n\n\n\nfraudTrain\n(1048575, 22)\n0.00573\n원래자료\n\n\ndf02\n(214520, 22)\n0.028\nis_fraud==0 에서는 20퍼의 샘플만, is_fraud==1 에서는 모든 샘플을 뽑아서 정리한 새로운 자료\n\n\ndf50\n(12012, 22)\n0.5\ndf02에서 사기비율을 50퍼로 맞추어 샘플링한 자료\n\n\ndf50_tr\n(9009, 22)\n0.49828\ndf50에서 랜덤으로 train/test를 분리하여 얻은 train dataset\n\n\ndf50_test\n(3003, 22)\n0.50516\ndf50에서 랜덤으로 train/test를 분리하여 얻은 test dataset\n\n\ndf02_tr\n(211517, 22)\n0.02122\ndf02에서 df50_test에 해당하는 인덱스를 제외\n\n\nfraudTrain_tr\n(1045572, 22)\n0.00429\nfraudTrain에서 df50_test에 해당하는 인덱스를 제외\n\n\n\n- fraudTrain\n\nfraudTrain = pd.read_csv(\"fraudTrain.csv\").iloc[:,1:]\n\n\nfraudTrain.is_fraud.mean().round(5)\n\n0.00573\n\n\n- df20\n\n_df1 = fraudTrain[fraudTrain[\"is_fraud\"] == 0].sample(frac=0.20, random_state=42)\n_df2 = fraudTrain[fraudTrain[\"is_fraud\"] == 1]\ndf02 = pd.concat([_df1,_df2])\ndf02.shape\n\n(214520, 22)\n\n\n\ndf02.is_fraud.mean().round(5)\n\n0.028\n\n\n- df50\n\ndf50 = down_sample_textbook(df02)\ndf50.shape\n\n(12012, 22)\n\n\n\ndf50\n\n\n\n\n\n\n\n\ntrans_date_trans_time\ncc_num\nmerchant\ncategory\namt\nfirst\nlast\ngender\nstreet\ncity\n...\nlat\nlong\ncity_pop\njob\ndob\ntrans_num\nunix_time\nmerch_lat\nmerch_long\nis_fraud\n\n\n\n\n2449\n2019-01-02 1:06\n4.613310e+12\nfraud_Rutherford-Mertz\ngrocery_pos\n281.06\nJason\nMurphy\nM\n542 Steve Curve Suite 011\nCollettsville\n...\n35.9946\n-81.7266\n885\nSoil scientist\n1988-09-15\ne8a81877ae9a0a7f883e15cb39dc4022\n1325466397\n36.430124\n-81.179483\n1\n\n\n2472\n2019-01-02 1:47\n3.401870e+14\nfraud_Jenkins, Hauck and Friesen\ngas_transport\n11.52\nMisty\nHart\nF\n27954 Hall Mill Suite 575\nSan Antonio\n...\n29.4400\n-98.4590\n1595797\nHorticultural consultant\n1960-10-28\nbc7d41c41103877b03232f03f1f8d3f5\n1325468849\n29.819364\n-99.142791\n1\n\n\n2523\n2019-01-02 3:05\n3.401870e+14\nfraud_Goodwin-Nitzsche\ngrocery_pos\n276.31\nMisty\nHart\nF\n27954 Hall Mill Suite 575\nSan Antonio\n...\n29.4400\n-98.4590\n1595797\nHorticultural consultant\n1960-10-28\nb98f12f4168391b2203238813df5aa8c\n1325473523\n29.273085\n-98.836360\n1\n\n\n2546\n2019-01-02 3:38\n4.613310e+12\nfraud_Erdman-Kertzmann\ngas_transport\n7.03\nJason\nMurphy\nM\n542 Steve Curve Suite 011\nCollettsville\n...\n35.9946\n-81.7266\n885\nSoil scientist\n1988-09-15\n397894a5c4c02e3c61c784001f0f14e4\n1325475483\n35.909292\n-82.091010\n1\n\n\n2553\n2019-01-02 3:55\n3.401870e+14\nfraud_Koepp-Parker\ngrocery_pos\n275.73\nMisty\nHart\nF\n27954 Hall Mill Suite 575\nSan Antonio\n...\n29.4400\n-98.4590\n1595797\nHorticultural consultant\n1960-10-28\n7863235a750d73a244c07f1fb7f0185a\n1325476547\n29.786426\n-98.683410\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n363827\n2019-06-17 19:30\n2.475090e+15\nfraud_Frami Group\nentertainment\n81.13\nJohn\nMiller\nM\n153 Mccullough Springs Apt. 857\nLamberton\n...\n44.2378\n-95.2739\n1507\nLand/geomatics surveyor\n1993-10-12\nc66cb411019c7dfd4d89f42a1ba4765f\n1339961448\n44.212695\n-95.661879\n0\n\n\n140154\n2019-03-17 14:33\n2.131550e+14\nfraud_Bahringer-Streich\nfood_dining\n55.00\nChristopher\nSheppard\nM\n39218 Baker Shoals\nBristow\n...\n38.1981\n-86.6821\n965\nHorticultural therapist\n1982-02-10\n316b9d25b9fa7d08a6831b7dab6634cd\n1331994839\n38.394240\n-86.413557\n0\n\n\n860597\n2019-12-17 12:31\n2.280870e+15\nfraud_Lubowitz-Walter\nkids_pets\n8.12\nKatherine\nCooper\nF\n3854 Lauren Springs Suite 648\nOakford\n...\n40.0994\n-89.9601\n530\nTransport planner\n1967-09-23\nd92e9e63d9b24c3ccb92d05cba4cac54\n1355747517\n39.695248\n-89.853063\n0\n\n\n29341\n2019-01-18 9:20\n4.878360e+15\nfraud_Denesik and Sons\nshopping_pos\n3.52\nTina\nAlvarez\nF\n1976 Tyler Underpass\nEarly\n...\n42.4483\n-95.1726\n885\nPilot, airline\n1949-08-14\n8390ce51cfb8482b618ebc4ac370bcf7\n1326878457\n42.633204\n-95.598143\n0\n\n\n529797\n2019-08-16 13:17\n4.450830e+15\nfraud_Beier and Sons\nhome\n84.15\nDonna\nDavis\nF\n6760 Donovan Lakes\nClayton\n...\n34.5906\n-95.3800\n1760\nOccupational psychologist\n1972-01-20\n04e1be9bcb18ea8b96048659bd02177b\n1345123058\n33.885236\n-95.885110\n0\n\n\n\n\n12012 rows × 22 columns\n\n\n\n\ndf50.is_fraud.mean().round(5)\n\n0.5\n\n\n- df50_tr, df50_test\n\ndf50_tr,df50_test = sklearn.model_selection.train_test_split(df50, random_state=42)\n\n\ndf50_tr.is_fraud.mean().round(5), df50_test.is_fraud.mean().round(5)\n\n(0.49828, 0.50516)\n\n\n- df02_tr, fraudTrain_tr\n\ndf02_tr = df02.loc[[i not in df50_test.index for i in df02.index],:].copy()\nfraudTrain_tr = fraudTrain.loc[[i not in df50_test.index for i in fraudTrain.index],:].copy()\n\n\ndf02_tr.shape, fraudTrain_tr.shape\n\n((211517, 22), (1045572, 22))\n\n\n\ndf02_tr.is_fraud.mean().round(5), fraudTrain_tr.is_fraud.mean().round(5)\n\n(0.02122, 0.00429)"
  },
  {
    "objectID": "연구/나혼자/gglite/2024-07-09-내부기능.html",
    "href": "연구/나혼자/gglite/2024-07-09-내부기능.html",
    "title": "(연구) gglite – 내부기능",
    "section": "",
    "text": "Options\n\noptions(jupyter.plot_scale=4)\noptions(repr.plot.width=6,repr.plot.height=4,repr.plot.res=300)\n\n\n\nImports\n\nlibrary(devtools)\ninstall_github(\"seoyeonc/gglite\",force=TRUE)\nlibrary(gglite)\nlibrary(tidyverse)\nlibrary(patchwork)\n\nDownloading GitHub repo seoyeonc/gglite@HEAD\n\n\n\n── R CMD build ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n✔  checking for file ‘/tmp/Rtmp6JCCsE/remotesf878558db2fe0/seoyeonc-gglite-cc4f3ac/DESCRIPTION’\n─  preparing ‘gglite’:\n✔  checking DESCRIPTION meta-information\n─  checking for LF line-endings in source and make files and shell scripts\n─  checking for empty or unneeded directories\n   Omitted ‘LazyData’ from DESCRIPTION\n─  building ‘gglite_0.1.0.tar.gz’\n   \n\n\n\n\n\ngglite\n\ngglite &lt;- function(...){\n    ggplot2::ggplot(...)+\n    ggplot2::theme_bw()+\n    ggplot2::theme(panel.border=ggplot2::element_blank(),axis.line=ggplot2::element_line(colour=\"black\"))+\n    ggplot2::theme(axis.title.x=ggplot2::element_text(size=ggplot2::rel(1),lineheight=0.9,face=\"bold.italic\"))+\n    ggplot2::theme(axis.title.y=ggplot2::element_text(size=ggplot2::rel(1),lineheight=0.9,face=\"bold.italic\"))+\n    ggplot2::theme(plot.title=ggplot2::element_text(size=ggplot2::rel(1),lineheight=0.9,face=\"bold\"))+\n    ggplot2::theme(plot.margin = ggplot2::unit(c(3,3,0,0), \"mm\"))\n}\n\n\ngglite()\n\n\n\n\n\n\n\n\n\n\nmake_df\n\nmake_df &lt;- function(x, y = NULL, label = NULL) {\n  if (is.null(y)) {\n    y=x\n    if (!is.vector(y)) {\n      x = 1:dim(y)[1]\n    } else {\n      x = 1:length(y)\n    }\n  }\n  #---#\n  if (!is.vector(y)) {\n      dfx = data.frame(x)\n      dfy = data.frame(y)\n      df = cbind(dfx,dfy)\n      df = tidyr::pivot_longer(df,cols = colnames(dfy), names_to = \"group\", values_to = \"y\")\n  } else {\n      if (is.null(label)){\n          df = data.frame(x=x,y=y)\n      } else { \n      df = data.frame(x=x,y=y,group=label)\n      }\n  }\n  return(df)\n}\n\n\nmake_df(rnorm(10),label=\"A\")\n\n\nA data.frame: 10 × 3\n\n\nx\ny\ngroup\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;chr&gt;\n\n\n\n\n1\n-0.2261991\nA\n\n\n2\n-0.1408211\nA\n\n\n3\n0.6522622\nA\n\n\n4\n-1.0774237\nA\n\n\n5\n1.9254478\nA\n\n\n6\n2.1194208\nA\n\n\n7\n3.4066460\nA\n\n\n8\n0.6947182\nA\n\n\n9\n-1.0329483\nA\n\n\n10\n-0.8516010\nA\n\n\n\n\n\n\nmake_df(c('A','A','A','B','B','B'))\n\n\nA data.frame: 6 × 2\n\n\nx\ny\n\n\n&lt;int&gt;\n&lt;chr&gt;\n\n\n\n\n1\nA\n\n\n2\nA\n\n\n3\nA\n\n\n4\nB\n\n\n5\nB\n\n\n6\nB\n\n\n\n\n\n\nmake_df(c(1,2,4),rnorm(3))\n\n\nA data.frame: 3 × 2\n\n\nx\ny\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n-0.2703365\n\n\n2\n0.7374404\n\n\n4\n-1.4255919\n\n\n\n\n\n\n\n버그수정\n\ny1=rnorm(100)\ny2=rnorm(100)+3\n\n\ngglite()+line(y1,label='A',col=2,lty=2)+line(y2,label='B',col=4,lty=2)\n\n\n\n\n\n\n\n\n\nline &lt;- function(x, y = NULL, label = NULL, ...) {\n  args &lt;- list(...)\n  df &lt;- make_df(x, y, label)\n  geom_type &lt;- ggplot2::geom_line\n  if (is.null(df$group)) {\n      aes &lt;- ggplot2::aes(x = x, y = y)\n      return(make_geom(df,geom_type,aes,args))\n  } else {\n      aes &lt;- ggplot2::aes(x = x, y = y, col = group)\n      if (any(names(args) %in% c(\"col\", \"color\", \"colour\"))){\n          args[c(\"col\", \"color\", \"colour\")] &lt;- NULL\n          # col &lt;- args$col\n          # if (is.null(col)) col &lt;- args$color\n          # if (is.null(col)) col &lt;- args$colour\n          return(list(make_geom(df,geom_type,aes,args)))\n      } else {    \n          return(make_geom(df,geom_type,aes,args))\n      }\n  }\n}\n\n\ngglite()+line(y1,lty=1,label=\"A\",col=2)#+line(y2,lty=2,col=3,label=\"B\")"
  },
  {
    "objectID": "연구/나혼자/graft/2024-07-17-tutorial 2.html",
    "href": "연구/나혼자/graft/2024-07-17-tutorial 2.html",
    "title": "(연구) graft – tutorial 2",
    "section": "",
    "text": "1. Install\nconda create -n graft \nconda activate graft \nconda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\nconda install pyg -c pyg \nconda install -c conda-forge notebook \nconda install -c conda-forge graph-tool\nref: https://git.skewed.de/count0/graph-tool/-/wikis/installation-instructions\n\n!pip uninstall graft -y\n!pip install git+https://github.com/guebin/graft.git\n\nFound existing installation: graft 0.0.1\nUninstalling graft-0.0.1:\n  Successfully uninstalled graft-0.0.1\nCollecting git+https://github.com/guebin/graft.git\n  Cloning https://github.com/guebin/graft.git to /tmp/pip-req-build-h737ugcz\n  Running command git clone --filter=blob:none --quiet https://github.com/guebin/graft.git /tmp/pip-req-build-h737ugcz\n  Resolved https://github.com/guebin/graft.git to commit 04bd6f129e9758a96b4697fcf8620a5b43625a5c\n  Preparing metadata (setup.py) ... done\nRequirement already satisfied: pandas in ./anaconda3/envs/graft/lib/python3.12/site-packages (from graft==0.0.1) (2.2.2)\nRequirement already satisfied: numpy&gt;=1.26.0 in ./anaconda3/envs/graft/lib/python3.12/site-packages (from pandas-&gt;graft==0.0.1) (1.26.4)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in ./anaconda3/envs/graft/lib/python3.12/site-packages (from pandas-&gt;graft==0.0.1) (2.9.0)\nRequirement already satisfied: pytz&gt;=2020.1 in ./anaconda3/envs/graft/lib/python3.12/site-packages (from pandas-&gt;graft==0.0.1) (2024.1)\nRequirement already satisfied: tzdata&gt;=2022.7 in ./anaconda3/envs/graft/lib/python3.12/site-packages (from pandas-&gt;graft==0.0.1) (2024.1)\nRequirement already satisfied: six&gt;=1.5 in ./anaconda3/envs/graft/lib/python3.12/site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas-&gt;graft==0.0.1) (1.16.0)\nBuilding wheels for collected packages: graft\n  Building wheel for graft (setup.py) ... done\n  Created wheel for graft: filename=graft-0.0.1-py3-none-any.whl size=4816 sha256=713c4874915e24e661cee812761a46c6f19ebdf4f88858a86518e75dfed4b7a9\n  Stored in directory: /tmp/pip-ephem-wheel-cache-qu7yugck/wheels/5a/da/81/7f1de9f08d7753f35b8a3ca78aaacecedc86bc4077124d73fe\nSuccessfully built graft\nInstalling collected packages: graft\nSuccessfully installed graft-0.0.1\n\n\n\nimport numpy as np\nimport torch\nimport torch_geometric\nimport graph_tool.all as gt\nimport graft\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n\n3. 기본사용\n\nlinks = torch.tensor([[0, 1, 2, 3, 4, 3],\n                      [1, 0, 3, 2, 3, 4]], dtype=torch.long)\ng = torch_geometric.data.Data(\n    edge_index = links\n)\n\nundirected graf임\n\ngraft.plot(g)\n\n\n\n\n\n\n\n\n노드이름을 정의함\n\ngraft.plot(\n    g,\n    node_names=[0,1,2,3,4]\n)\n\n\n\n\n\n\n\n\n\ngraft.plot(\n    g,\n    node_names=[\"A\",\"B\",\"C\",\"D\",\"E\"],\n)\n\n\n\n\n\n\n\n\n이름을 쓰기 싫다면 공백을 넣을수도있음.\n\ngraft.plot(\n    g,\n    node_names=[\"\",\"\",\"\",\"A\",\"\"]\n)\n\n\n\n\n\n\n\n\n\ngraft.plot(\n    g,\n    node_names=[\"A\",\"B\",\"C\",\"D\",\"E\"],\n    node_sizes=[1,1,2,2,3],\n)\n\n\n\n\n\n\n\n\n\ngraft.plot(\n    g,\n    node_names=[\"A\",\"B\",\"C\",\"D\",\"E\"],\n    node_colors=[0,0,1,2,2],\n)\n\n\n\n\n\n\n\n\n\n# graft.plot(\n#     g,\n#     node_names=[\"A\",\"B\",\"C\",\"D\",\"E\"],\n#     node_colors=[1,1,1,2,2], # 버그.. 카테고리일 경우 node_colors는 0부터 시작해야함\n# )\n\n\ngraft.plot(\n    g,\n    node_names=[\"A\",\"B\",\"C\",\"D\",\"E\"],\n    node_colors=np.array([0,0,1,2,2])/2,\n)\n\n\n\n\n\n\n\n\n\ngraft.plot(\n    g,\n    node_names=[\"A\",\"B\",\"C\",\"D\",\"E\"],\n    node_colors=np.array([0,0,1,2,2])/2,\n    node_sizes=np.array([0,0,1,2,2])/2,\n)\n\n\n\n\n\n\n\n\n\n\n4. 옵션\n\n#graft.plot(g)\ngt_graph, draw_options = graft.setup_graph_draw(g)\ngt.graph_draw(gt_graph, **draw_options)\n\n\n\n\n\n\n\n\n\n# graft.plot(\n#     g,\n#     node_names=[0,1,2,3,4]\n# )\ngt_graph, draw_options = graft.setup_graph_draw(g)\ngt_graph, draw_options = graft.map_node_names(gt_graph,draw_options,node_names=[0,1,2,3,4])\ngt.graph_draw(gt_graph, **draw_options)\n\n\n\n\n\n\n\n\n\n# graft.plot(\n#     g,\n#     node_names=[\"A\",\"B\",\"C\",\"D\",\"E\"],\n# )\ngt_graph, draw_options = graft.setup_graph_draw(g)\ngt_graph, draw_options = graft.map_node_names(gt_graph,draw_options,node_names=[\"A\",\"B\",\"C\",\"D\",\"E\"])\ngt.graph_draw(gt_graph, **draw_options)\n\n\n\n\n\n\n\n\n\n# graft.plot(\n#     g,\n#     node_names=[\"\",\"\",\"\",\"A\",\"\"]\n# )\ngt_graph, draw_options = graft.setup_graph_draw(g)\ngt_graph, draw_options = graft.map_node_names(gt_graph,draw_options,node_names=[\"\",\"\",\"\",\"A\",\"\"])\ngt.graph_draw(gt_graph, **draw_options)\n\n\n\n\n\n\n\n\n\n# graft.plot(\n#     g,\n#     node_names=[\"A\",\"B\",\"C\",\"D\",\"E\"],\n#     node_sizes=[1,1,2,2,3],\n# )\ngt_graph, draw_options = graft.setup_graph_draw(g)\ngt_graph, draw_options = graft.map_node_names(gt_graph,draw_options,node_names=[\"\",\"\",\"\",\"A\",\"\"])\ngt_graph, draw_options = graft.map_node_sizes(gt_graph,draw_options,node_sizes=[1,1,2,2,3])\ngt.graph_draw(gt_graph, **draw_options)\n\n\n\n\n\n\n\n\n\n# graft.plot(\n#     g,\n#     node_names=[\"A\",\"B\",\"C\",\"D\",\"E\"],\n#     node_colors=[0,0,1,2,2],\n# )\ngt_graph, draw_options = graft.setup_graph_draw(g)\ngt_graph, draw_options = graft.map_node_names(gt_graph,draw_options,node_names=[\"A\",\"B\",\"C\",\"D\",\"E\"])\ngt_graph, draw_options = graft.map_node_colors(gt_graph,draw_options,node_colors=[0,0,1,2,2])\ngt.graph_draw(gt_graph, **draw_options)\n\n\n\n\n\n\n\n\n\n# graft.plot(\n#     g,\n#     node_names=[\"A\",\"B\",\"C\",\"D\",\"E\"],\n#     node_colors=np.array([0,0,1,2,2])/2,\n# )\ngt_graph, draw_options = graft.setup_graph_draw(g)\ngt_graph, draw_options = graft.map_node_names(gt_graph,draw_options,node_names=[\"A\",\"B\",\"C\",\"D\",\"E\"])\ngt_graph, draw_options = graft.map_node_colors(gt_graph,draw_options,node_colors=np.array([0,0,1,2,2])/2)\ngt.graph_draw(gt_graph, **draw_options)\n\n\n\n\n\n\n\n\n\n# graft.plot(\n#     g,\n#     node_names=[\"A\",\"B\",\"C\",\"D\",\"E\"],\n#     node_colors=np.array([0,0,1,2,2])/2,\n#     node_sizes=np.array([0,0,1,2,2])/2,\n# )\ngt_graph, draw_options = graft.setup_graph_draw(g)\ngt_graph, draw_options = graft.map_node_names(gt_graph,draw_options,node_names=[\"A\",\"B\",\"C\",\"D\",\"E\"])\ngt_graph, draw_options = graft.map_node_colors(gt_graph,draw_options,node_colors=np.array([0,0,1,2,2])/2)\ngt_graph, draw_options = graft.map_node_sizes(gt_graph,draw_options,node_sizes=np.array([0,0,1,2,2])/2)\ngt.graph_draw(gt_graph, **draw_options)"
  },
  {
    "objectID": "연구/나혼자/gglitely/2024-01-19-서브플랏.html",
    "href": "연구/나혼자/gglitely/2024-01-19-서브플랏.html",
    "title": "(연구) gglitely – 서브플랏",
    "section": "",
    "text": "Install\n\n!pip uninstall gglitely -y\n!pip install git+https://github.com/seoyeonc/gglitely.git\n\nFound existing installation: gglitely 0.0.1\nUninstalling gglitely-0.0.1:\n  Successfully uninstalled gglitely-0.0.1\nCollecting git+https://github.com/seoyeonc/gglitely.git\n  Cloning https://github.com/seoyeonc/gglitely.git to /tmp/pip-req-build-9t0e7z9w\n  Running command git clone --filter=blob:none --quiet https://github.com/seoyeonc/gglitely.git /tmp/pip-req-build-9t0e7z9w\n  Resolved https://github.com/seoyeonc/gglitely.git to commit 86f5c00a4a8e40a05e5fdaa927296f50ff290b24\n  Preparing metadata (setup.py) ... -\b \bdone\nRequirement already satisfied: pandas in /home/cgb2/anaconda3/lib/python3.11/site-packages (from gglitely==0.0.1) (2.0.3)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in /home/cgb2/anaconda3/lib/python3.11/site-packages (from pandas-&gt;gglitely==0.0.1) (2.8.2)\nRequirement already satisfied: pytz&gt;=2020.1 in /home/cgb2/anaconda3/lib/python3.11/site-packages (from pandas-&gt;gglitely==0.0.1) (2023.3.post1)\nRequirement already satisfied: tzdata&gt;=2022.1 in /home/cgb2/anaconda3/lib/python3.11/site-packages (from pandas-&gt;gglitely==0.0.1) (2023.3)\nRequirement already satisfied: numpy&gt;=1.21.0 in /home/cgb2/anaconda3/lib/python3.11/site-packages (from pandas-&gt;gglitely==0.0.1) (1.24.3)\nRequirement already satisfied: six&gt;=1.5 in /home/cgb2/anaconda3/lib/python3.11/site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas-&gt;gglitely==0.0.1) (1.16.0)\nBuilding wheels for collected packages: gglitely\n  Building wheel for gglitely (setup.py) ... -\b \b\\\b \bdone\n  Created wheel for gglitely: filename=gglitely-0.0.1-py3-none-any.whl size=2473 sha256=0a6075f842842ec871a74e18a523d82c3160de8baa0a0ab9469016da09d2adf1\n  Stored in directory: /tmp/pip-ephem-wheel-cache-zmt2m3x0/wheels/a5/b2/29/5db99646aa2b8d946b957bdf761a177612bf6709303d4ed579\nSuccessfully built gglitely\nInstalling collected packages: gglitely\nSuccessfully installed gglitely-0.0.1\n\n\n\n\nImports\n\nfrom gglitely import *\n\n\nsubplot_count = lambda fig: len({geom[key] for geom in fig.data for key in geom if 'xaxis' in key})\ndef trace_axes_adjustment(fig1, fig2):\n    x_axes_fig1 = sorted([key for key in fig1.layout if 'xaxis' in key])\n    y_axes_fig1 = sorted([key for key in fig1.layout if 'yaxis' in key])\n    x_axes_fig2 = sorted([key for key in fig2.layout if 'xaxis' in key])\n    y_axes_fig2 = sorted([key for key in fig2.layout if 'yaxis' in key])    \n    for trace in fig1.data:\n        if trace['xaxis'] is None:\n            for i, (x, y) in enumerate(zip(x_axes_fig1, y_axes_fig1), start=1):\n                trace['xaxis'] = f'x{i}'\n                trace['yaxis'] = f'y{i}'\n    for trace in fig2.data:\n        if trace['xaxis'] is None:\n            for i, (x, y) in enumerate(zip(x_axes_fig2, y_axes_fig2), start=1):\n                trace['xaxis'] = f'x{i + subplot_count(fig1)}'\n                trace['yaxis'] = f'y{i + subplot_count(fig1)}'\n        else:\n            if trace['xaxis'] == 'x':\n                trace['xaxis'] = f'x{1 + subplot_count(fig1)}'\n            else:\n                axis_num = int(trace['xaxis'][-1]) + subplot_count(fig1)\n                trace['xaxis'] = f'x{axis_num}'\n\n            if trace['yaxis'] == 'y':\n                trace['yaxis'] = f'y{1 + subplot_count(fig1)}'\n            else:\n                axis_num = int(trace['yaxis'][-1]) + subplot_count(fig1)\n                trace['yaxis'] = f'y{axis_num}'\n    return fig1, fig2\n\ndef clayout_adjustment(fig1, fig2):\n    # Loop through fig1 and fig2\n    for f in [fig1, fig2]:\n        # Extract all xaxes and yaxes\n        xaxes = [geom[key] for geom in f.data for key in geom if 'xaxis' in key]\n        yaxes = [geom[key] for geom in f.data for key in geom if 'yaxis' in key]\n        # Check if all traces in the figure share the same xaxis (i.e., there is only one subplot)\n        if len(set(xaxes)) == 1:\n            for i, (x, y) in enumerate(zip(xaxes, yaxes), start=1):\n                # Update xaxis layout\n                f.layout[x.replace('x', 'xaxis')] = {'anchor': x.replace('axis', ''), 'domain': [0.0, 1.0]}\n                # Update yaxis layout\n                f.layout[y.replace('y', 'yaxis')] = {'anchor': y.replace('axis', ''), 'domain': [0.0, 1.0]}\n        else:\n            pass  # Do nothing if xaxes are not the same\n    return fig1, fig2\n\n    \ndef cbind(fig1,fig2,column_widths=None):\n    # Update data and layout for fig1 and fig2\n    fig1 = gglitely(data=fig1.data, layout=fig1.layout)\n    fig2 = gglitely(data=fig2.data, layout=fig2.layout)\n    \n    # Calculate the number of subplots\n    n1 = subplot_count(fig1)\n    n2 = subplot_count(fig2)\n    \n    # Adjust trace axes\n    fig1, fig2 = trace_axes_adjustment(fig1, fig2)\n    \n    # Adjust layout\n    fig1, fig2 = clayout_adjustment(fig1, fig2)\n    \n    # Set column widths if not provided\n    if column_widths is None:\n        column_widths = [1] * n1 + [1] * n2\n    \n    # Create subplots\n    fig = make_subplots(rows=1, cols=n1 + n2, column_widths=column_widths)\n    fig = gglitely(layout=fig.layout)\n    \n    # Add traces from fig1 and fig2\n    fig.add_traces(fig1.data)\n    fig.add_traces(fig2.data)\n    \n    # Increment ncols\n    fig._ncols += 1\n    return fig\n\n\n\n서브플랏\n\nfig1 = gglitely() + bar(y=[1,2,3],col='red') + bar(y=[2,3,1],col='blue')\nfig2 = gglitely() + bar(y=[2,3,1],alpha=0.7,col='blue')\n\n\ncbind(cbind(cbind(fig1,fig2),fig1),fig2)\n\nAttributeError: 'gglitely' object has no attribute '_ncols'"
  },
  {
    "objectID": "연구/나혼자/gglitely/2024-01-19-튜토리얼.html",
    "href": "연구/나혼자/gglitely/2024-01-19-튜토리얼.html",
    "title": "(연구) gglitely – 튜토리얼",
    "section": "",
    "text": "Install\n\n!pip uninstall gglitely -y\n!pip install git+https://github.com/seoyeonc/gglitely.git\n\nFound existing installation: gglitely 0.0.1\nUninstalling gglitely-0.0.1:\n  Successfully uninstalled gglitely-0.0.1\nCollecting git+https://github.com/seoyeonc/gglitely.git\n  Cloning https://github.com/seoyeonc/gglitely.git to /tmp/pip-req-build-clvasx8s\n  Running command git clone --filter=blob:none --quiet https://github.com/seoyeonc/gglitely.git /tmp/pip-req-build-clvasx8s\n  Resolved https://github.com/seoyeonc/gglitely.git to commit 86f5c00a4a8e40a05e5fdaa927296f50ff290b24\n  Preparing metadata (setup.py) ... -\b \bdone\nRequirement already satisfied: pandas in /home/cgb2/anaconda3/lib/python3.11/site-packages (from gglitely==0.0.1) (2.0.3)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in /home/cgb2/anaconda3/lib/python3.11/site-packages (from pandas-&gt;gglitely==0.0.1) (2.8.2)\nRequirement already satisfied: pytz&gt;=2020.1 in /home/cgb2/anaconda3/lib/python3.11/site-packages (from pandas-&gt;gglitely==0.0.1) (2023.3.post1)\nRequirement already satisfied: tzdata&gt;=2022.1 in /home/cgb2/anaconda3/lib/python3.11/site-packages (from pandas-&gt;gglitely==0.0.1) (2023.3)\nRequirement already satisfied: numpy&gt;=1.21.0 in /home/cgb2/anaconda3/lib/python3.11/site-packages (from pandas-&gt;gglitely==0.0.1) (1.24.3)\nRequirement already satisfied: six&gt;=1.5 in /home/cgb2/anaconda3/lib/python3.11/site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas-&gt;gglitely==0.0.1) (1.16.0)\nBuilding wheels for collected packages: gglitely\n  Building wheel for gglitely (setup.py) ... -\b \bdone\n  Created wheel for gglitely: filename=gglitely-0.0.1-py3-none-any.whl size=2473 sha256=7a09b4a9a4c18cc1587130647e0a6564a45c45c030e545006cdca4e30fd706f3\n  Stored in directory: /tmp/pip-ephem-wheel-cache-hhonsjtg/wheels/a5/b2/29/5db99646aa2b8d946b957bdf761a177612bf6709303d4ed579\nSuccessfully built gglitely\nInstalling collected packages: gglitely\nSuccessfully installed gglitely-0.0.1\n\n\n\n\nImports\n\nfrom gglitely import * \n\n\n\nPoint\n\ngglitely() + point(y=[2,3,4,3],cex=[10,20,30,44],alpha=0.5,pch=0,line={'width':2,'color':'DarkSlateGray'})\n\n                                                \n\n\n\n\nLine\n\ngglitely() + line(y=[3,4,2,1],alpha=0.5,lwd=5,lty=2,col=2)\n\n                                                \n\n\n\n\nCol\n\ngglitely() + bar(y=[1,2,3]) + bar(y=[2,3,4])\n\n                                                \n\n\n\n\nBoxplot\n\nx1 = np.random.randn(100)\nx2 = np.random.randn(100) + 3 \n\n\ngglitely() + boxplot(y=x1) + boxplot(y=x2)\n\n                                                \n\n\n\n\nHist\n\nx1 = np.random.randn(100)\nx2 = np.random.randn(100) + 3 \n\n\nfig = gglitely() + histogram(x=x1) + histogram(x=x2)\nfig\n\n                                                \n\n\n\nfig.layout['barmode'] = 'overlay'\n\n\nfig"
  },
  {
    "objectID": "연구/재인이랑/2023-10-11-(연구&재인) MBTI -- 감성분석.html",
    "href": "연구/재인이랑/2023-10-11-(연구&재인) MBTI -- 감성분석.html",
    "title": "(연구&재인) MBTI – 감성분석",
    "section": "",
    "text": "from autogluon.core.utils.loaders import load_pd\ntrain_data = load_pd.load('https://autogluon-text.s3-accelerate.amazonaws.com/glue/sst/train.parquet')\ntest_data = load_pd.load('https://autogluon-text.s3-accelerate.amazonaws.com/glue/sst/dev.parquet')\nsubsample_size = 1000  # subsample data for faster demo, try setting this to larger values\ntrain_data = train_data.sample(n=subsample_size, random_state=0)\ntrain_data.head(10)\n\n\n\n\n\n\n\n\nsentence\nlabel\n\n\n\n\n43787\nvery pleasing at its best moments\n1\n\n\n16159\n, american chai is enough to make you put away...\n0\n\n\n59015\ntoo much like an infomercial for ram dass 's l...\n0\n\n\n5108\na stirring visual sequence\n1\n\n\n67052\ncool visual backmasking\n1\n\n\n35938\nhard ground\n0\n\n\n49879\nthe striking , quietly vulnerable personality ...\n1\n\n\n51591\npan nalin 's exposition is beautiful and myste...\n1\n\n\n56780\nwonderfully loopy\n1\n\n\n28518\nmost beautiful , evocative\n1\n\n\n\n\n\n\n\n\nfrom autogluon.multimodal import MultiModalPredictor\nimport uuid\nmodel_path = f\"./tmp/{uuid.uuid4().hex}-automm_sst\"\npredictor = MultiModalPredictor(label='label', eval_metric='acc', path=model_path)\npredictor.fit(train_data, time_limit=180)\n\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'libc10_cuda.so: cannot open shared object file: No such file or directory'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n  warn(\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/autogluon/core/utils/utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\nAutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n    2 unique label values:  [0, 1]\n    If 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\nGlobal seed set to 0\nAutoMM starts to create your model. ✨\n\n- AutoGluon version is 0.8.2.\n\n- Pytorch version is 2.0.0.post2.\n\n- Model will be saved to \"/home/cgb2/Dropbox/03_yechan3/tmp/ec6bab7c48a341ed99029ebb6094a01a-automm_sst\".\n\n- Validation metric is \"acc\".\n\n- To track the learning progress, you can open a terminal and launch Tensorboard:\n    ```shell\n    # Assume you have installed tensorboard\n    tensorboard --logdir /home/cgb2/Dropbox/03_yechan3/tmp/ec6bab7c48a341ed99029ebb6094a01a-automm_sst\n    ```\n\nEnjoy your coffee, and let AutoMM do the job ☕☕☕ Learn more at https://auto.gluon.ai\n\nDownloading (…)lve/main/config.json: 100%|██████████| 666/666 [00:00&lt;00:00, 1.35MB/s]\nDownloading pytorch_model.bin: 100%|██████████| 440M/440M [00:21&lt;00:00, 20.0MB/s] \nDownloading (…)okenizer_config.json: 100%|██████████| 27.0/27.0 [00:00&lt;00:00, 59.8kB/s]\nDownloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00&lt;00:00, 1.16MB/s]\nDownloading (…)/main/tokenizer.json: 100%|██████████| 466k/466k [00:00&lt;00:00, 58.6MB/s]\n0 GPUs are detected, and 0 GPUs will be used.\n\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/autogluon/multimodal/utils/environment.py:91: UserWarning: Only CPU is detected in the instance. This may result in slow speed for MultiModalPredictor. Consider using an instance with GPU support.\n  warnings.warn(\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\n\n  | Name              | Type                         | Params\n-------------------------------------------------------------------\n0 | model             | HFAutoModelForTextPrediction | 108 M \n1 | validation_metric | MulticlassAccuracy           | 0     \n2 | loss_func         | CrossEntropyLoss             | 0     \n-------------------------------------------------------------------\n108 M     Trainable params\n0         Non-trainable params\n108 M     Total params\n435.573   Total estimated model params size (MB)\nEpoch 0, global step 3: 'val_acc' reached 0.46500 (best 0.46500), saving model to '/home/cgb2/Dropbox/03_yechan3/tmp/ec6bab7c48a341ed99029ebb6094a01a-automm_sst/epoch=0-step=3.ckpt' as top 3\nEpoch 0, global step 7: 'val_acc' reached 0.57000 (best 0.57000), saving model to '/home/cgb2/Dropbox/03_yechan3/tmp/ec6bab7c48a341ed99029ebb6094a01a-automm_sst/epoch=0-step=7.ckpt' as top 3\nEpoch 1, global step 10: 'val_acc' reached 0.77500 (best 0.77500), saving model to '/home/cgb2/Dropbox/03_yechan3/tmp/ec6bab7c48a341ed99029ebb6094a01a-automm_sst/epoch=1-step=10.ckpt' as top 3\nEpoch 1, global step 14: 'val_acc' reached 0.79500 (best 0.79500), saving model to '/home/cgb2/Dropbox/03_yechan3/tmp/ec6bab7c48a341ed99029ebb6094a01a-automm_sst/epoch=1-step=14.ckpt' as top 3\nTime limit reached. Elapsed time is 0:03:01. Signaling Trainer to stop.\nStart to fuse 3 checkpoints via the greedy soup algorithm.\nAutoMM has created your model 🎉🎉🎉\n\n- To load the model, use the code below:\n    ```python\n    from autogluon.multimodal import MultiModalPredictor\n    predictor = MultiModalPredictor.load(\"/home/cgb2/Dropbox/03_yechan3/tmp/ec6bab7c48a341ed99029ebb6094a01a-automm_sst\")\n    ```\n\n- You can open a terminal and launch Tensorboard to visualize the training log:\n    ```shell\n    # Assume you have installed tensorboard\n    tensorboard --logdir /home/cgb2/Dropbox/03_yechan3/tmp/ec6bab7c48a341ed99029ebb6094a01a-automm_sst\n    ```\n\n- If you are not satisfied with the model, try to increase the training time, \nadjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\nor post issues on GitHub: https://github.com/autogluon/autogluon\n\n\n\n\nEpoch 0:  50%|█████     | 50/100 [00:38&lt;00:38,  1.29it/s]                  Epoch 0: 100%|██████████| 100/100 [01:25&lt;00:00,  1.18it/s]Epoch 1:  50%|█████     | 50/100 [00:43&lt;00:43,  1.14it/s] Epoch 1: 100%|██████████| 100/100 [01:30&lt;00:00,  1.10it/s]Epoch 2:   0%|          | 0/100 [00:00&lt;?, ?it/s]          Epoch 2:   1%|          | 1/100 [00:06&lt;10:45,  6.52s/it]\nPredicting DataLoader 0: 100%|██████████| 7/7 [00:05&lt;00:00,  1.25it/s]\nPredicting DataLoader 0: 100%|██████████| 7/7 [00:05&lt;00:00,  1.29it/s]\nPredicting DataLoader 0: 100%|██████████| 7/7 [00:05&lt;00:00,  1.25it/s]\n\n\n&lt;autogluon.multimodal.predictor.MultiModalPredictor at 0x7f8acd4349a0&gt;\n\n\n\nsentence1 = \"it's a charming and often affecting journey.\"\nsentence2 = \"It's slow, very, very, very slow.\"\npredictions = predictor.predict({'sentence': [sentence1, sentence2]})\nprint('\"Sentence\":', sentence1, '\"Predicted Sentiment\":', predictions[0])\nprint('\"Sentence\":', sentence2, '\"Predicted Sentiment\":', predictions[1])\n\n\"Sentence\": it's a charming and often affecting journey. \"Predicted Sentiment\": 1\n\"Sentence\": It's slow, very, very, very slow. \"Predicted Sentiment\": 0"
  },
  {
    "objectID": "연구/재인이랑/2023-12-23-(연구&재인) MBTI(정리) -- 실험결과 시각화.html",
    "href": "연구/재인이랑/2023-12-23-(연구&재인) MBTI(정리) -- 실험결과 시각화.html",
    "title": "(연구&재인) MBTI(정리) – 실험결과 시각화",
    "section": "",
    "text": "1. Imports\n\nimport numpy as np\nimport pandas as pd\nimport time\nimport pickle\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nimport plotly.express as px\nimport plotly.io as pio\nfrom plotly.subplots import make_subplots\npd.options.plotting.backend = \"plotly\"\npio.templates.default = \"plotly_white\"\n\n\n![ -d \"Figures\" ] || mkdir \"Figures\"\n\n\n\n2. 실험1 – 결과시각화\n\ndf1 = pd.read_csv(\"실험결과/실험1/시나리오1.csv\").rename({'Unnamed: 0':'Method','Unnamed: 1':'Metrics'},axis=1).set_index(['Method','Metrics'])\ndf2 = pd.read_csv(\"실험결과/실험1/시나리오2.csv\").rename({'Unnamed: 0':'Method','Unnamed: 1':'Metrics'},axis=1).set_index(['Method','Metrics'])\n\n\ntidydata = df1[['ESTP','ESFP','ESFJ','ESTJ']].stack().reset_index()\\\n.set_axis(['Method','Metrics','Type','Value'],axis=1)\\\n.groupby(['Metrics','Method']).agg({'Value':'mean'}).reset_index()\\\n.query('Metrics == \"F1\"').sort_values('Value',ascending=False).reset_index(drop=True)\\\n.eval('Top6 = index &lt; 6')\ntidydata\nfig = px.bar(tidydata,x='Method',y='Value',color='Top6',opacity=1.0)\nfig.layout['xaxis']['title']['text']=''\nfig.layout['yaxis']['title']['text']='F1 score'\nfig.data[1]['marker']['color']='#636efa'\nfig.data[1]['marker']['opacity']=0.2\nfig.data[0]['showlegend']=False \nfig.data[1]['showlegend']=False \nwith open('Figures/실험1모델비교F1.pkl','wb') as f:\n    pickle.dump(fig,f)\nfig\n\n                                                \n\n\n\ntidydata = df1[['ESTP','ESFP','ESFJ','ESTJ']].stack().reset_index()\\\n.set_axis(['Method','Metrics','Type','Value'],axis=1)\\\n.groupby(['Metrics','Method']).agg({'Value':'mean'}).reset_index()\\\n.query('Metrics == \"PRE\"').sort_values('Value',ascending=False).reset_index(drop=True)\\\n.eval('Top6 = index &lt; 6')\ntidydata\nfig = px.bar(tidydata,x='Method',y='Value',color='Top6')\nfig.layout['xaxis']['title']['text']=''\nfig.layout['yaxis']['title']['text']='Precision'\nfig.data[1]['marker']['color']='#636efa'\nfig.data[1]['marker']['opacity']=0.2\nfig.data[0]['showlegend']=False \nfig.data[1]['showlegend']=False \nwith open('Figures/실험1모델비교PRE.pkl','wb') as f:\n    pickle.dump(fig,f)\nfig\n\n                                                \n\n\n\ntidydata = df1[['ESTP','ESFP','ESFJ','ESTJ']].stack().reset_index()\\\n.set_axis(['Method','Metrics','Type','Value'],axis=1)\\\n.groupby(['Metrics','Method']).agg({'Value':'mean'}).reset_index()\\\n.query('Metrics == \"REC\"').sort_values('Value',ascending=False).reset_index(drop=True)\\\n.eval('Top6 = index &lt; 6')\ntidydata\nfig = px.bar(tidydata,x='Method',y='Value',color='Top6')\nfig.layout['xaxis']['title']['text']=''\nfig.layout['yaxis']['title']['text']='Recall'\nfig.data[1]['marker']['color']='#636efa'\nfig.data[1]['marker']['opacity']=0.2\nfig.data[0]['showlegend']=False \nfig.data[1]['showlegend']=False \nwith open('Figures/실험1모델비교REC.pkl','wb') as f:\n    pickle.dump(fig,f)\nfig\n\n                                                \n\n\n\ntidydata = df1[['ESTP','ESFP','ESFJ','ESTJ']].stack().reset_index()\\\n.set_axis(['Method','Metrics','Type','Value'],axis=1)\\\n.groupby(['Metrics','Method']).agg({'Value':'mean'}).reset_index()\\\n.query('Metrics == \"AUC\"').sort_values('Value',ascending=False).reset_index(drop=True)\\\n.eval('Top6 = index &lt; 6')\ntidydata\nfig = px.bar(tidydata,x='Method',y='Value',color='Top6')\nfig.layout['xaxis']['title']['text']=''\nfig.layout['yaxis']['title']['text']='Area Under the Curve'\nfig.data[1]['marker']['color']='#636efa'\nfig.data[1]['marker']['opacity']=0.2\nfig.data[0]['showlegend']=False \nfig.data[1]['showlegend']=False \nwith open('Figures/실험1모델비교AUC.pkl','wb') as f:\n    pickle.dump(fig,f)\nfig\n\n                                                \n\n\n\n_df1= df1.stack().reset_index().set_axis(['Method','Metrics','Type','Value'],axis=1).assign(시나리오='Kaggle')\n_df2= df2.stack().reset_index().set_axis(['Method','Metrics','Type','Value'],axis=1).assign(시나리오='Kaggle+GPT')\ntidydata = pd.concat([_df1,_df2],axis=0)\\\n.query(\"Type in ['ESTP','ESFP','ESFJ','ESTJ']\")\\\n.query(\"Metrics == 'AUC'\")\\\n.query(\"Method in ['LightGBMXT','LightGBMLarge','LightGBM','XGBoost','CatBoost','WeightedEnsemble_L2']\")\\\n.assign(Value = lambda df: np.round(df['Value'],3))\nfig = px.bar(\n    tidydata,\n    x='Type',y='Value',color='시나리오',\n    text='Value',\n    facet_col='Method',\n    barmode='group'\n)\nfor i in range(len(fig['layout']['annotations'])): \n    fig['layout']['annotations'][i]['text'] = fig['layout']['annotations'][i]['text'].replace('Method=','')\nfig['layout']['legend']['title']['text'] = ''\nfig['layout']['xaxis']['title']['text'] = ''\nfig['layout']['xaxis2']['title']['text'] = ''\nfig['layout']['xaxis3']['title']['text'] = ''\nfig['layout']['xaxis4']['title']['text'] = ''\nfig['layout']['xaxis5']['title']['text'] = ''\nfig['layout']['xaxis6']['title']['text'] = ''\nfig['layout']['yaxis']['title']['text'] = 'AUC'\nwith open('Figures/실험1결과요약.pkl','wb') as f:\n    pickle.dump(fig,f)\nfig\n\n                                                \n\n\n\n\n3. 실험2 – 결과시각화\n\ndf0a = pd.read_csv(\"실험결과/실험2/시나리오0a.csv\").rename({'Unnamed: 0':'Method','Unnamed: 1':'Metrics'},axis=1).set_index(['Method','Metrics'])\ndf1a = pd.read_csv(\"실험결과/실험2/시나리오1a.csv\").rename({'Unnamed: 0':'Method','Unnamed: 1':'Metrics'},axis=1).set_index(['Method','Metrics'])\ndf1b = pd.read_csv(\"실험결과/실험2/시나리오1b.csv\").rename({'Unnamed: 0':'Method','Unnamed: 1':'Metrics'},axis=1).set_index(['Method','Metrics'])\ndf1c = pd.read_csv(\"실험결과/실험2/시나리오1c.csv\").rename({'Unnamed: 0':'Method','Unnamed: 1':'Metrics'},axis=1).set_index(['Method','Metrics'])\ndf2a = pd.read_csv(\"실험결과/실험2/시나리오2a.csv\").rename({'Unnamed: 0':'Method','Unnamed: 1':'Metrics'},axis=1).set_index(['Method','Metrics'])\ndf2b = pd.read_csv(\"실험결과/실험2/시나리오2b.csv\").rename({'Unnamed: 0':'Method','Unnamed: 1':'Metrics'},axis=1).set_index(['Method','Metrics'])\ndf2c = pd.read_csv(\"실험결과/실험2/시나리오2c.csv\").rename({'Unnamed: 0':'Method','Unnamed: 1':'Metrics'},axis=1).set_index(['Method','Metrics'])\ndf3a = pd.read_csv(\"실험결과/실험2/시나리오3a.csv\").rename({'Unnamed: 0':'Method','Unnamed: 1':'Metrics'},axis=1).set_index(['Method','Metrics'])\ndf3b = pd.read_csv(\"실험결과/실험2/시나리오3b.csv\").rename({'Unnamed: 0':'Method','Unnamed: 1':'Metrics'},axis=1).set_index(['Method','Metrics'])\ndf3c = pd.read_csv(\"실험결과/실험2/시나리오3c.csv\").rename({'Unnamed: 0':'Method','Unnamed: 1':'Metrics'},axis=1).set_index(['Method','Metrics'])\nselected_model = [\"LightGBMXT\",\"LightGBM\",\"CatBoost\",\"XGBoost\",\"LightGBMLarge\",\"WeightedEnsemble_L2\"]\n_df0a = df0a['ENFJ'].reset_index().query('Metrics == \"AUC\" and Method in @selected_model').assign(자료수집='kaggle',add='+0')\n_df0b = df0a['ENFJ'].reset_index().query('Metrics == \"AUC\" and Method in @selected_model').assign(자료수집='gpt',add='+0')\n_df1a = df1a['ENFJ'].reset_index().query('Metrics == \"AUC\" and Method in @selected_model').assign(자료수집='kaggle',add='+40')\n_df1b = df1b['ENFJ'].reset_index().query('Metrics == \"AUC\" and Method in @selected_model').assign(자료수집='gpt',add='+40')\n_df2a = df2a['ENFJ'].reset_index().query('Metrics == \"AUC\" and Method in @selected_model').assign(자료수집='kaggle',add='+80')\n_df2b = df2b['ENFJ'].reset_index().query('Metrics == \"AUC\" and Method in @selected_model').assign(자료수집='gpt',add='+80')\n_df3a = df3a['ENFJ'].reset_index().query('Metrics == \"AUC\" and Method in @selected_model').assign(자료수집='kaggle',add='+120')\n_df3b = df3b['ENFJ'].reset_index().query('Metrics == \"AUC\" and Method in @selected_model').assign(자료수집='gpt',add='+120')\ntidydata = pd.concat([_df0a,_df0b,_df1a,_df1b,_df2a,_df2b,_df3a,_df3b]).reset_index(drop=True)\n\n\nfig = px.line(\n    tidydata,\n    x='add',\n    y='ENFJ',\n    facet_col='Method',\n    color='자료수집',    \n)\nfig.update_traces({'mode':'markers+lines'})\nfor i in range(len(fig['layout']['annotations'])): \n    fig['layout']['annotations'][i]['text'] = fig['layout']['annotations'][i]['text'].replace('Method=','')\nfig['layout']['legend']['title']['text'] = ''\nfig['layout']['xaxis']['title']['text'] = ''\nfig['layout']['xaxis2']['title']['text'] = ''\nfig['layout']['xaxis3']['title']['text'] = ''\nfig['layout']['xaxis4']['title']['text'] = ''\nfig['layout']['xaxis5']['title']['text'] = ''\nfig['layout']['xaxis6']['title']['text'] = ''\nfig['layout']['yaxis']['title']['text'] = 'AUC'\nfor i in range(len(fig['data'])):\n    fig['data'][i]['hovertemplate'] = fig['data'][i]['hovertemplate']\nwith open('Figures/실험2결과요약.pkl','wb') as f:\n    pickle.dump(fig,f)\nfig\n\n                                                \n\n\n\n\n3. 실험3 – 결과시각화\n\ndf0a = pd.read_csv(\"실험결과/실험3/시나리오0a.csv\").rename({'Unnamed: 0':'Method','Unnamed: 1':'Metrics'},axis=1).set_index(['Method','Metrics'])[['ENFJ']].reset_index().query(\"Method in ['LightGBMXT','LightGBM','CatBoost','XGBoost','LightGBMLarge']\")\ndf1a = pd.read_csv(\"실험결과/실험3/시나리오1a.csv\").rename({'Unnamed: 0':'Method','Unnamed: 1':'Metrics'},axis=1).set_index(['Method','Metrics'])[['ENFJ']].reset_index().query(\"Method in ['LightGBMXT','LightGBM','CatBoost','XGBoost','LightGBMLarge']\")\ndf1b = pd.read_csv(\"실험결과/실험3/시나리오1b.csv\").rename({'Unnamed: 0':'Method','Unnamed: 1':'Metrics'},axis=1).set_index(['Method','Metrics'])[['ENFJ']].reset_index().query(\"Method in ['LightGBMXT','LightGBM','CatBoost','XGBoost','LightGBMLarge']\")\ndf2a = pd.read_csv(\"실험결과/실험3/시나리오2a.csv\").rename({'Unnamed: 0':'Method','Unnamed: 1':'Metrics'},axis=1).set_index(['Method','Metrics'])[['ENFJ']].reset_index().query(\"Method in ['LightGBMXT','LightGBM','CatBoost','XGBoost','LightGBMLarge']\")\ndf2b = pd.read_csv(\"실험결과/실험3/시나리오2b.csv\").rename({'Unnamed: 0':'Method','Unnamed: 1':'Metrics'},axis=1).set_index(['Method','Metrics'])[['ENFJ']].reset_index().query(\"Method in ['LightGBMXT','LightGBM','CatBoost','XGBoost','LightGBMLarge']\")\ndf3a = pd.read_csv(\"실험결과/실험3/시나리오3a.csv\").rename({'Unnamed: 0':'Method','Unnamed: 1':'Metrics'},axis=1).set_index(['Method','Metrics'])[['ENFJ']].reset_index().query(\"Method in ['LightGBMXT','LightGBM','CatBoost','XGBoost','LightGBMLarge']\")\ndf3b = pd.read_csv(\"실험결과/실험3/시나리오3b.csv\").rename({'Unnamed: 0':'Method','Unnamed: 1':'Metrics'},axis=1).set_index(['Method','Metrics'])[['ENFJ']].reset_index().query(\"Method in ['LightGBMXT','LightGBM','CatBoost','XGBoost','LightGBMLarge']\")\ndf4a = pd.read_csv(\"실험결과/실험3/시나리오4a.csv\").rename({'Unnamed: 0':'Method','Unnamed: 1':'Metrics'},axis=1).set_index(['Method','Metrics'])[['ENFJ']].reset_index().query(\"Method in ['LightGBMXT','LightGBM','CatBoost','XGBoost','LightGBMLarge']\")\ndf4b = pd.read_csv(\"실험결과/실험3/시나리오4b.csv\").rename({'Unnamed: 0':'Method','Unnamed: 1':'Metrics'},axis=1).set_index(['Method','Metrics'])[['ENFJ']].reset_index().query(\"Method in ['LightGBMXT','LightGBM','CatBoost','XGBoost','LightGBMLarge']\")\ndf5a = pd.read_csv(\"실험결과/실험3/시나리오5a.csv\").rename({'Unnamed: 0':'Method','Unnamed: 1':'Metrics'},axis=1).set_index(['Method','Metrics'])[['ENFJ']].reset_index().query(\"Method in ['LightGBMXT','LightGBM','CatBoost','XGBoost','LightGBMLarge']\")\ndf5b = pd.read_csv(\"실험결과/실험3/시나리오5b.csv\").rename({'Unnamed: 0':'Method','Unnamed: 1':'Metrics'},axis=1).set_index(['Method','Metrics'])[['ENFJ']].reset_index().query(\"Method in ['LightGBMXT','LightGBM','CatBoost','XGBoost','LightGBMLarge']\")\ndf6a = pd.read_csv(\"실험결과/실험3/시나리오6a.csv\").rename({'Unnamed: 0':'Method','Unnamed: 1':'Metrics'},axis=1).set_index(['Method','Metrics'])[['ENFJ']].reset_index().query(\"Method in ['LightGBMXT','LightGBM','CatBoost','XGBoost','LightGBMLarge']\")\ndf6b = pd.read_csv(\"실험결과/실험3/시나리오6b.csv\").rename({'Unnamed: 0':'Method','Unnamed: 1':'Metrics'},axis=1).set_index(['Method','Metrics'])[['ENFJ']].reset_index().query(\"Method in ['LightGBMXT','LightGBM','CatBoost','XGBoost','LightGBMLarge']\")\ndf7a = pd.read_csv(\"실험결과/실험3/시나리오7a.csv\").rename({'Unnamed: 0':'Method','Unnamed: 1':'Metrics'},axis=1).set_index(['Method','Metrics'])[['ENFJ']].reset_index().query(\"Method in ['LightGBMXT','LightGBM','CatBoost','XGBoost','LightGBMLarge']\")\ndf7b = pd.read_csv(\"실험결과/실험3/시나리오7b.csv\").rename({'Unnamed: 0':'Method','Unnamed: 1':'Metrics'},axis=1).set_index(['Method','Metrics'])[['ENFJ']].reset_index().query(\"Method in ['LightGBMXT','LightGBM','CatBoost','XGBoost','LightGBMLarge']\")\n\n\n_df0a = df0a.assign(자료수집='kaggle',add='+0')\n_df0b = df0a.assign(자료수집='gpt',add='+0')\n_df1a = df1a.assign(자료수집='kaggle',add='+20')\n_df1b = df1b.assign(자료수집='gpt',add='+20')\n_df2a = df2a.assign(자료수집='kaggle',add='+40')\n_df2b = df2b.assign(자료수집='gpt',add='+40')\n_df3a = df3a.assign(자료수집='kaggle',add='+60')\n_df3b = df3b.assign(자료수집='gpt',add='+60')\n_df4a = df4a.assign(자료수집='kaggle',add='+80')\n_df4b = df4b.assign(자료수집='gpt',add='+80')\n_df5a = df5a.assign(자료수집='kaggle',add='+100')\n_df5b = df5b.assign(자료수집='gpt',add='+100')\n_df6a = df6a.assign(자료수집='kaggle',add='+120')\n_df6b = df6b.assign(자료수집='gpt',add='+120')\n_df7a = df7a.assign(자료수집='kaggle',add='+140')\n_df7b = df7b.assign(자료수집='gpt',add='+140')\ntidydata = pd.concat([_df0a,_df0b,_df1a,_df1b,_df2a,_df2b,_df3a,_df3b,_df4a,_df4b,_df5a,_df5b,_df6a,_df6b,_df7a,_df7b]).reset_index(drop=True)\n\n\nfig = px.line(\n    tidydata.query(\"Metrics == 'AUC'\"),\n    x='add',\n    y='ENFJ',\n    facet_col='Method',\n    color='자료수집',    \n)\nfig.update_traces({'mode':'markers+lines'})\nfor i in range(len(fig['layout']['annotations'])): \n    fig['layout']['annotations'][i]['text'] = fig['layout']['annotations'][i]['text'].replace('Method=','')\nfig['layout']['legend']['title']['text'] = ''\nfig['layout']['xaxis']['title']['text'] = ''\nfig['layout']['xaxis2']['title']['text'] = ''\nfig['layout']['xaxis3']['title']['text'] = ''\nfig['layout']['xaxis4']['title']['text'] = ''\nfig['layout']['xaxis5']['title']['text'] = ''\nfig['layout']['yaxis']['title']['text'] = 'AUC'\nfor i in range(len(fig['data'])):\n    fig['data'][i]['hovertemplate'] = fig['data'][i]['hovertemplate']\nwith open('Figures/실험3결과요약.pkl','wb') as f:\n    pickle.dump(fig,f)\nfig"
  },
  {
    "objectID": "연구/재인이랑/2023-12-21-(연구&재인) MBTI(정리) -- TabularPredictor 실험.html",
    "href": "연구/재인이랑/2023-12-21-(연구&재인) MBTI(정리) -- TabularPredictor 실험.html",
    "title": "(연구&재인) MBTI(정리) – TabularPredictor 실험",
    "section": "",
    "text": "라이브러리\n\nimport pandas as pd\nimport sklearn.model_selection\nimport sklearn.metrics\n#from autogluon.multimodal import MultiModalPredictor\nfrom autogluon.tabular import TabularPredictor\nimport time\nimport pickle\nimport warnings\nwarnings.filterwarnings('ignore')\n\n/root/anaconda3/envs/ag/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n\n함수들\n\ndef report(predictor,df_test):\n    model_names = [\n        'KNeighborsUnif',\n        'KNeighborsDist',\n        'NeuralNetFastAI',\n        'LightGBMXT',\n        'LightGBM',\n        'RandomForestGini',\n        'RandomForestEntr',\n        'CatBoost',\n        'ExtraTreesGini',\n        'ExtraTreesEntr',\n        'XGBoost',\n        'NeuralNetTorch',\n        'LightGBMLarge',\n        'WeightedEnsemble_L2'\n    ]\n    labels = ['ENTP', 'ESFP', 'ISFJ', 'INTJ', 'ISFP', 'ESTP', 'INTP', 'INFJ', 'ESTJ', 'ENFP', 'ISTJ', 'ENTJ', 'INFP', 'ISTP', 'ESFJ', 'ENFJ']\n    df_report = pd.concat({model_name:pd.DataFrame({label:{'PRE':0.0,'REC':0.0,'F1':0.0,'AUC':0.0} for label in labels}) for model_name in model_names})\n    yhats_dct = {model_name:predictor.predict_proba(df_test,model=model_name) for model_name in model_names}    \n    y = df_test['type']\n    for model_name in model_names:\n        yhat = yhats_dct[model_name].idxmax(axis=1)    \n        for label in labels:\n            if label in set(y):\n                _y = (y == label)*1\n                _y_pred = (yhat == label)*1\n                _y_proba = yhats_dct[model_name][label]\n                df_report[label][model_name]['PRE'] = sklearn.metrics.precision_score(_y,_y_pred)\n                df_report[label][model_name]['REC'] = sklearn.metrics.recall_score(_y,_y_pred)\n                df_report[label][model_name]['F1'] = sklearn.metrics.f1_score(_y,_y_pred)\n                df_report[label][model_name]['AUC'] = sklearn.metrics.roc_auc_score(_y,_y_proba)\n            else:\n                pass \n    return df_report\n\n\ndef fit_predict_save(path,experiments_index):\n    t1 = time.time()\n    df_train = df_trains_dct[experiments_index]\n    df_test = df_tests_dct[experiments_index]\n    predictor = TabularPredictor(label='type', eval_metric='acc', path=f\"AutogluonModels/{experiments_index}\",verbosity=False)\n    predictor.fit(\n        df_train,\n        hyperparameters = {\n            'NN_TORCH': {},\n            'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n            'CAT': {},\n            'XGB': {},\n            'FASTAI': {},\n            'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],  'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n            'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n        },\n    )\n    df_report = report(predictor,df_test)\n    df_report.to_csv(f\"{path}{experiments_index}.csv\")\n    t2 = time.time()\n    print(f\"{experiments_index} -- 완료 (걸린시간 = {(t2-t1)/60:.4f} 분)\")"
  },
  {
    "objectID": "연구/재인이랑/2023-12-21-(연구&재인) MBTI(정리) -- TabularPredictor 실험.html#a.-실험1",
    "href": "연구/재인이랑/2023-12-21-(연구&재인) MBTI(정리) -- TabularPredictor 실험.html#a.-실험1",
    "title": "(연구&재인) MBTI(정리) – TabularPredictor 실험",
    "section": "A. 실험1",
    "text": "A. 실험1\n\n# ![ -d \"실험결과/실험1\" ] || mkdir \"실험결과/실험1\"\n# fit_predict_save(path='실험결과/',experiments_index='실험1/시나리오1')\n# fit_predict_save(path='실험결과/',experiments_index='실험1/시나리오2')"
  },
  {
    "objectID": "연구/재인이랑/2023-12-21-(연구&재인) MBTI(정리) -- TabularPredictor 실험.html#b.-실험2",
    "href": "연구/재인이랑/2023-12-21-(연구&재인) MBTI(정리) -- TabularPredictor 실험.html#b.-실험2",
    "title": "(연구&재인) MBTI(정리) – TabularPredictor 실험",
    "section": "B. 실험2",
    "text": "B. 실험2\n\n![ -d \"실험셋업/실험2\" ] || mkdir \"실험셋업/실험2\"\nfit_predict_save('실험결과/','실험2/시나리오0a')\nfit_predict_save('실험결과/','실험2/시나리오1a')\nfit_predict_save('실험결과/','실험2/시나리오1b')\nfit_predict_save('실험결과/','실험2/시나리오1c')\nfit_predict_save('실험결과/','실험2/시나리오2a')\nfit_predict_save('실험결과/','실험2/시나리오2b')\nfit_predict_save('실험결과/','실험2/시나리오2c')\nfit_predict_save('실험결과/','실험2/시나리오3a')\nfit_predict_save('실험결과/','실험2/시나리오3b')\nfit_predict_save('실험결과/','실험2/시나리오3c')\nfit_predict_save('실험결과/','실험2/시나리오4a')\nfit_predict_save('실험결과/','실험2/시나리오4b')\nfit_predict_save('실험결과/','실험2/시나리오4c')\n\n실험2/시나리오0a -- 완료 (걸린시간 = 14.1333 분)\n실험2/시나리오1a -- 완료 (걸린시간 = 16.1246 분)\n실험2/시나리오1b -- 완료 (걸린시간 = 15.6699 분)\n실험2/시나리오1c -- 완료 (걸린시간 = 15.3118 분)\n실험2/시나리오2a -- 완료 (걸린시간 = 15.6923 분)\n실험2/시나리오2b -- 완료 (걸린시간 = 14.2966 분)\n실험2/시나리오2c -- 완료 (걸린시간 = 15.3765 분)\n실험2/시나리오3a -- 완료 (걸린시간 = 17.0679 분)\n실험2/시나리오3b -- 완료 (걸린시간 = 15.2641 분)\n실험2/시나리오3c -- 완료 (걸린시간 = 13.3913 분)\n실험2/시나리오4a -- 완료 (걸린시간 = 15.5517 분)"
  },
  {
    "objectID": "연구/재인이랑/2023-12-21-(연구&재인) MBTI(정리) -- TabularPredictor 실험.html#c.-실험3",
    "href": "연구/재인이랑/2023-12-21-(연구&재인) MBTI(정리) -- TabularPredictor 실험.html#c.-실험3",
    "title": "(연구&재인) MBTI(정리) – TabularPredictor 실험",
    "section": "C. 실험3",
    "text": "C. 실험3\n\n![ -d \"실험결과/실험3\" ] || mkdir \"실험결과/실험3\"\nfit_predict_save('실험결과/','실험3/시나리오0a')\nfit_predict_save('실험결과/','실험3/시나리오1a')\nfit_predict_save('실험결과/','실험3/시나리오1b')\nfit_predict_save('실험결과/','실험3/시나리오2a')\nfit_predict_save('실험결과/','실험3/시나리오2b')\nfit_predict_save('실험결과/','실험3/시나리오3a')\nfit_predict_save('실험결과/','실험3/시나리오3b')\nfit_predict_save('실험결과/','실험3/시나리오4a')\nfit_predict_save('실험결과/','실험3/시나리오4b')\nfit_predict_save('실험결과/','실험3/시나리오5a')\nfit_predict_save('실험결과/','실험3/시나리오5b')\nfit_predict_save('실험결과/','실험3/시나리오6a')\nfit_predict_save('실험결과/','실험3/시나리오6b')\nfit_predict_save('실험결과/','실험3/시나리오7a')\nfit_predict_save('실험결과/','실험3/시나리오7b')\n\n실험3/시나리오0a -- 완료 (걸린시간 = 4.0562 분)\n실험3/시나리오1a -- 완료 (걸린시간 = 4.4870 분)\n실험3/시나리오1b -- 완료 (걸린시간 = 4.6460 분)\n실험3/시나리오2a -- 완료 (걸린시간 = 4.2561 분)\n실험3/시나리오2b -- 완료 (걸린시간 = 3.9312 분)\n실험3/시나리오3a -- 완료 (걸린시간 = 4.5184 분)\n실험3/시나리오3b -- 완료 (걸린시간 = 4.0638 분)\n실험3/시나리오4a -- 완료 (걸린시간 = 4.5813 분)\n실험3/시나리오4b -- 완료 (걸린시간 = 4.0858 분)\n실험3/시나리오5a -- 완료 (걸린시간 = 4.4831 분)\n실험3/시나리오5b -- 완료 (걸린시간 = 4.2321 분)\n실험3/시나리오6a -- 완료 (걸린시간 = 4.5741 분)\n실험3/시나리오6b -- 완료 (걸린시간 = 4.3771 분)\n실험3/시나리오7a -- 완료 (걸린시간 = 4.5339 분)\n실험3/시나리오7b -- 완료 (걸린시간 = 4.1424 분)"
  },
  {
    "objectID": "연구/재인이랑/2023-12-13-(연구&재인) MBTI -- 추가자료분석(all).html",
    "href": "연구/재인이랑/2023-12-13-(연구&재인) MBTI -- 추가자료분석(all).html",
    "title": "(연구&재인) MBTI – 추가자료분석 (all)",
    "section": "",
    "text": "1. Imports\n\nimport pandas as pd\nimport sklearn.model_selection\nimport sklearn.metrics\nfrom autogluon.multimodal import MultiModalPredictor\nfrom autogluon.tabular import TabularPredictor\n\n/root/anaconda3/envs/ag/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n\n\n\n2. Data\n\ndf = pd.read_csv('mbti_1.csv')\ndf_train, df_test = sklearn.model_selection.train_test_split(df,test_size=0.5,random_state=42)\n\n\nlabels = list(set(df_train.type))\n\n\ndf_additinal = pd.read_csv('MBTI.csv')\ndf_additinal2= df_additinal.copy()[429:]\n\n\ndf_additinal2['type'].value_counts()\n\ntype\nESTJ    372\nESFJ    194\nENFJ    164\nESFP     91\nESTP     57\nISFJ     32\nENFP      3\nName: count, dtype: int64\n\n\n\nfor i,post in enumerate(df_additinal['posts']):\n    for label in labels:\n        if label in post: \n            df_additinal['posts'][i] = post.replace(label,'')\n\n\ndf_train2 = pd.concat([df_train,df_additinal],axis=0).reset_index(drop=True)\n\n\ndf_train2\n\n\n\n\n\n\n\n\ntype\nposts\n\n\n\n\n0\nINFP\nI feel trapped by what people around me think of me. On one hand the way I react and live is based off my interactions with people. And know that I have people who know me or at least feel they...|||I never get it when people tell me they would have needed to be on acid to enjoy some sort of psychedelic concert. If an experience is intense enough to give the appearance of being on drugs why...|||55317 This is me...very tired, in my favorite sweater. I have such a love for good sweaters.|||Thank you all for the responses and the honesty in them. The advice you've given is quite sound. ...\n\n\n1\nENTP\n'http://www.youtube.com/watch?v=xQ04WbgI9rg&ob=av2e http://www.youtube.com/watch?v=gGdGFtwCNBE&ob=av3e http://www.youtube.com/watch?v=gH2efAcmBQM&ob=av3e ...|||What we did is inform each other what our love languages were, and both of our primaries are physical touch. So hugs, cuddling, hand holding, all that cute-sy crap that couples do... we're big on...|||I am currently dating an INTJ. Objectively, she is the most compatible woman for me from all of my relationships heretofore. This was an observation by both of us (eventually) and all of our...|||Quite, actually. It keeps us ali...\n\n\n2\nINFP\n'No, no, and no. In my opinion. I believe the adage you have to hit your kids sometimes is really just totally wrong. There are plenty of ways to discipline children that do not involve physical...|||It does kinda sound like she's using you to an extent. Don't do anything for her that you don't want to do. That's not what friendship is about. Sounds like she tries to guilt you into doing stuff...|||Hey, I never said I was making an attempt to be wholly logical in my response. :P As for your comparison, it actually is kind of like that. I'll consider the emotional reactions to all of my pos...\n\n\n3\nINFP\n'Hey! It seems like you have a great foundation and the fact that you have passion for you what you do is HUGE! Passion will take you farther then any skill set will and you can always learn skills...|||I would say there has been 3 time frames in my life that I was pretty depressed. They are never for a long time but they were pretty low points. They could be fluctuating but I always come out of it...|||I have not been on perc in forever and my heart melted when I saw all the responses I got. I appreciate you taking the time to write back. I'm doing much better. Much love and Thanks.|||It'...\n\n\n4\nENTP\n'Hahahaha, you guys are hilarious. I suppose I should do that, I don't quite understand myself all too well anywho. As to the, 'Making stuff up as you go that happens to be correct/make sense, I...|||After taking about a dozen personality tests over the course of about two months I came to the conclusion of being an INTP, although unwillingly. A few things stood out to me that I didn't agree...|||Nothing too fancy My dream goal is pretty simple (not necessarily to achieve). I want a family, and a good earning to live comfortably. I'd like money to not be an issue, so I can treat my family....\n\n\n...\n...\n...\n\n\n5674\nESFP\nToday, I dove into the realm of art. A canvas, a palette of colors, and a surge of creativity - it was time to unleash the artist within.\\nMy morning began with a visit to a local art studio. Surrounded by fellow artists, the space buzzed with creative energy. I picked up a brush and let my imagination flow onto the canvas.\\nAs the day unfolded, I found a peaceful corner in a park to continue my artistic journey. Nature itself became my muse.\\nLunch was a quaint affair in a charming café. A warm cup of tea and a slice of homemade pie - a treat for the taste buds.\\nThe afternoon was dedicat...\n\n\n5675\nESFP\nIn the heart of nature, I found my sanctuary today. The sun-dappled forest, the chirping birds, and the rustling leaves - a world apart from the concrete jungle.\\nMy morning commenced with a hike along a forest trail. The fresh scent of pine, the soft earth beneath my feet, and the symphony of nature - it's the ultimate therapy.\\nAs the day unfolded, I discovered a serene clearing by a crystal-clear stream. I couldn't resist taking a dip in the cool water and laying on the mossy banks, staring up at the canopy of green.\\nLunch was a simple affair, a picnic of sandwiches and fresh fruit. So...\n\n\n5676\nENFP\nAs the sun sets and the evening casts its warm glow, I find solace in the simplicity of home. There's something magical about cozying up with a good book or a movie, surrounded by the familiar comforts of my space.\\nTonight, I've chosen a classic novel to accompany me on my literary journey. The characters, the plot, and the scent of the pages make it feel like I'm visiting an old friend.\\nA warm cup of herbal tea in my favorite mug completes the scene. The gentle steam, the earthy aroma, and the first sip – it's like a soothing embrace for the soul.\\nAs I lose myself in the story, I can't...\n\n\n5677\nENFP\nToday, I embarked on a book lover's dream adventure, exploring quaint and hidden bookstores in the heart of the city. Each store held its own charm, secrets waiting to be uncovered in the pages of books.\\nThe first stop was a tiny, independent bookstore tucked away in an alley. The musty scent of old books and the creaking wooden floors gave it an irresistible vintage charm.\\nI spent hours browsing through shelves, discovering rare editions and forgotten gems. There's an excitement in the hunt for the perfect book that only fellow bookworms understand.\\nEach bookstore had its own theme – f...\n\n\n5678\nENFP\nToday was a day of pure artistic indulgence. From the canvas to the camera lens, I explored the world through the eyes of an artist, capturing moments and emotions in various forms.\\nThe morning began with a blank canvas and a palette of colors. With each stroke of the brush, I lost myself in the world of abstraction, a language where emotions spoke louder than words.\\nThe afternoon took me to the heart of the city, where I explored street photography. Every corner had a story to tell, and every face had a unique expression. I was a silent observer of life's drama.\\nAs the day drew to a cl...\n\n\n\n\n5679 rows × 2 columns\n\n\n\n\n\n3. Tabular\n\npredictor = TabularPredictor(label='type', eval_metric='acc')\npredictor.fit(df_train2)\n#predictor = TabularPredictor.load(\"AutogluonModels/ag-20231214_002525\")\npredictor.leaderboard()\n\nNo path specified. Models will be saved in: \"AutogluonModels/ag-20231214_011537\"\nNo presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n    Recommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n    presets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n    presets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n    presets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n    presets='medium_quality' : Fast training time, ideal for initial prototyping.\nBeginning AutoGluon training ...\nAutoGluon will save models to \"AutogluonModels/ag-20231214_011537\"\n=================== System Info ===================\nAutoGluon Version:  1.0.0\nPython Version:     3.10.13\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #140-Ubuntu SMP Thu Aug 4 02:23:37 UTC 2022\nCPU Count:          128\nMemory Avail:       374.52 GB / 503.74 GB (74.3%)\nDisk Space Avail:   976.53 GB / 1757.88 GB (55.6%)\n===================================================\nTrain Data Rows:    5679\nTrain Data Columns: 1\nLabel Column:       type\nAutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n    First 10 (of 22) unique label values:  ['INFP', 'ENTP', 'ENFP', 'INTP', 'INTJ', 'ENFJ', 'INFJ', 'ISFP', 'ISTJ', 'ISTP']\n    If 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\nProblem Type:       multiclass\nPreprocessing data ...\nWarning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 16 out of 22 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\nFraction of data from classes with at least 10 examples that will be kept for training models: 0.9984152139461173\nTrain Data Class Count: 16\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n    Available Memory:                    383556.94 MB\n    Train Data (Original)  Memory Usage: 45.00 MB (0.0% of available memory)\n    Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n    Stage 1 Generators:\n        Fitting AsTypeFeatureGenerator...\n    Stage 2 Generators:\n        Fitting FillNaFeatureGenerator...\n    Stage 3 Generators:\n        Fitting CategoryFeatureGenerator...\n            Fitting CategoryMemoryMinimizeFeatureGenerator...\n        Fitting TextSpecialFeatureGenerator...\n            Fitting BinnedFeatureGenerator...\n            Fitting DropDuplicatesFeatureGenerator...\n        Fitting TextNgramFeatureGenerator...\n            Fitting CountVectorizer for text features: ['posts']\n            CountVectorizer fit with vocabulary size = 10000\n    Stage 4 Generators:\n        Fitting DropUniqueFeatureGenerator...\n    Stage 5 Generators:\n        Fitting DropDuplicatesFeatureGenerator...\n    Types of features in original data (raw dtype, special dtypes):\n        ('object', ['text']) : 1 | ['posts']\n    Types of features in processed data (raw dtype, special dtypes):\n        ('category', ['text_as_category'])  :    1 | ['posts']\n        ('int', ['binned', 'text_special']) :   38 | ['posts.char_count', 'posts.word_count', 'posts.capital_ratio', 'posts.lower_ratio', 'posts.digit_ratio', ...]\n        ('int', ['text_ngram'])             : 9970 | ['__nlp__.00', '__nlp__.000', '__nlp__.10', '__nlp__.10 years', '__nlp__.100', ...]\n    114.2s = Fit runtime\n    1 features in original data used to generate 10009 features in processed data.\n    Train Data (Processed) Memory Usage: 108.04 MB (0.0% of available memory)\nData preprocessing and feature engineering runtime = 116.66s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n    To change this, specify the eval_metric parameter of Predictor()\nAutomatically generating train/validation split with holdout_frac=0.1, Train Rows: 5103, Val Rows: 567\nUser-specified model hyperparameters to be fit:\n{\n    'NN_TORCH': {},\n    'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n    'CAT': {},\n    'XGB': {},\n    'FASTAI': {},\n    'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n    'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n    'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n}\nFitting 13 L1 models ...\nFitting model: KNeighborsUnif ...\n    0.2945   = Validation score   (accuracy)\n    6.51s    = Training   runtime\n    1.36s    = Validation runtime\nFitting model: KNeighborsDist ...\n    0.3298   = Validation score   (accuracy)\n    6.33s    = Training   runtime\n    1.4s     = Validation runtime\nFitting model: NeuralNetFastAI ...\n    0.2892   = Validation score   (accuracy)\n    8.62s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: LightGBMXT ...\n    0.7125   = Validation score   (accuracy)\n    169.24s  = Training   runtime\n    0.1s     = Validation runtime\nFitting model: LightGBM ...\n    0.7037   = Validation score   (accuracy)\n    143.3s   = Training   runtime\n    0.09s    = Validation runtime\nFitting model: RandomForestGini ...\n    0.5873   = Validation score   (accuracy)\n    12.44s   = Training   runtime\n    0.45s    = Validation runtime\nFitting model: RandomForestEntr ...\n    0.5714   = Validation score   (accuracy)\n    18.51s   = Training   runtime\n    0.13s    = Validation runtime\nFitting model: CatBoost ...\n    Many features detected (10009), dynamically setting 'colsample_bylevel' to 0.09991008092716555 to speed up training (Default = 1).\n    To disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n    0.7019   = Validation score   (accuracy)\n    57.55s   = Training   runtime\n    1.0s     = Validation runtime\nFitting model: ExtraTreesGini ...\n    0.515    = Validation score   (accuracy)\n    12.18s   = Training   runtime\n    0.12s    = Validation runtime\nFitting model: ExtraTreesEntr ...\n    0.4515   = Validation score   (accuracy)\n    12.01s   = Training   runtime\n    0.11s    = Validation runtime\nFitting model: XGBoost ...\n    0.7143   = Validation score   (accuracy)\n    56.77s   = Training   runtime\n    0.07s    = Validation runtime\nFitting model: NeuralNetTorch ...\n    0.3016   = Validation score   (accuracy)\n    11.84s   = Training   runtime\n    0.02s    = Validation runtime\nFitting model: LightGBMLarge ...\n    0.7055   = Validation score   (accuracy)\n    273.52s  = Training   runtime\n    0.08s    = Validation runtime\nFitting model: WeightedEnsemble_L2 ...\n    Ensemble Weights: {'CatBoost': 0.571, 'LightGBMXT': 0.143, 'XGBoost': 0.143, 'NeuralNetTorch': 0.143}\n    0.7337   = Validation score   (accuracy)\n    0.62s    = Training   runtime\n    0.0s     = Validation runtime\nAutoGluon training complete, total runtime = 925.58s ... Best model: \"WeightedEnsemble_L2\"\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231214_011537\")\n\n\n\n\n\n\n\n\n\nmodel\nscore_val\neval_metric\npred_time_val\nfit_time\npred_time_val_marginal\nfit_time_marginal\nstack_level\ncan_infer\nfit_order\n\n\n\n\n0\nWeightedEnsemble_L2\n0.733686\naccuracy\n1.190554\n296.010678\n0.000615\n0.620404\n2\nTrue\n14\n\n\n1\nXGBoost\n0.714286\naccuracy\n0.070626\n56.765352\n0.070626\n56.765352\n1\nTrue\n11\n\n\n2\nLightGBMXT\n0.712522\naccuracy\n0.102126\n169.236619\n0.102126\n169.236619\n1\nTrue\n4\n\n\n3\nLightGBMLarge\n0.705467\naccuracy\n0.077333\n273.520550\n0.077333\n273.520550\n1\nTrue\n13\n\n\n4\nLightGBM\n0.703704\naccuracy\n0.090923\n143.299396\n0.090923\n143.299396\n1\nTrue\n5\n\n\n5\nCatBoost\n0.701940\naccuracy\n1.001522\n57.553270\n1.001522\n57.553270\n1\nTrue\n8\n\n\n6\nRandomForestGini\n0.587302\naccuracy\n0.453024\n12.436017\n0.453024\n12.436017\n1\nTrue\n6\n\n\n7\nRandomForestEntr\n0.571429\naccuracy\n0.127032\n18.513521\n0.127032\n18.513521\n1\nTrue\n7\n\n\n8\nExtraTreesGini\n0.514991\naccuracy\n0.118020\n12.177610\n0.118020\n12.177610\n1\nTrue\n9\n\n\n9\nExtraTreesEntr\n0.451499\naccuracy\n0.105017\n12.011709\n0.105017\n12.011709\n1\nTrue\n10\n\n\n10\nKNeighborsDist\n0.329806\naccuracy\n1.404224\n6.326862\n1.404224\n6.326862\n1\nTrue\n2\n\n\n11\nNeuralNetTorch\n0.301587\naccuracy\n0.015665\n11.835034\n0.015665\n11.835034\n1\nTrue\n12\n\n\n12\nKNeighborsUnif\n0.294533\naccuracy\n1.363828\n6.506021\n1.363828\n6.506021\n1\nTrue\n1\n\n\n13\nNeuralNetFastAI\n0.289242\naccuracy\n0.012532\n8.623879\n0.012532\n8.623879\n1\nTrue\n3\n\n\n\n\n\n\n\n\npredictor.evaluate(df_test)\n\n{'accuracy': 0.6680497925311203,\n 'balanced_accuracy': 0.4269238301463123,\n 'mcc': 0.6136189980032133}\n\n\n\npredictor.predict(df_test)\n\n2802    INTP\n2166    INFJ\n1919    INTP\n360     ENFP\n1115    INTJ\n        ... \n1415    ENTP\n7269    INFP\n127     INFJ\n3474    INTP\n5960    INFJ\nName: type, Length: 4338, dtype: object\n\n\n\nmodel_names = predictor.model_names()\nyhats = {model_name:predictor.predict(df_test,model=model_name) for model_name in model_names}\n\n\ny = df_test['type']\n\n\nyhats['KNeighborsUnif']\n\n2802    ENFP\n2166    INFJ\n1919    INTJ\n360     INTJ\n1115    ENTP\n        ... \n1415    INTP\n7269    INTJ\n127     INFP\n3474    ENTP\n5960    ENFP\nName: type, Length: 4338, dtype: object\n\n\n\ny\n\n2802    INTP\n2166    INTJ\n1919    INTP\n360     ENFP\n1115    ENTJ\n        ... \n1415    ENFJ\n7269    ISFJ\n127     INFJ\n3474    INTP\n5960    INFP\nName: type, Length: 4338, dtype: object\n\n\n\nyhats.keys()\n\ndict_keys(['KNeighborsUnif', 'KNeighborsDist', 'NeuralNetFastAI', 'LightGBMXT', 'LightGBM', 'RandomForestGini', 'RandomForestEntr', 'CatBoost', 'ExtraTreesGini', 'ExtraTreesEntr', 'XGBoost', 'NeuralNetTorch', 'LightGBMLarge', 'WeightedEnsemble_L2'])\n\n\n\nprint(sklearn.metrics.classification_report(y,yhats['LightGBMLarge']))\n\n              precision    recall  f1-score   support\n\n        ENFJ       0.54      0.29      0.38        92\n        ENFP       0.64      0.63      0.63       327\n        ENTJ       0.69      0.35      0.46       115\n        ENTP       0.65      0.64      0.64       337\n        ESFJ       0.83      0.25      0.38        20\n        ESFP       0.25      0.04      0.07        24\n        ESTJ       0.50      0.12      0.20        24\n        ESTP       0.61      0.27      0.37        41\n        INFJ       0.69      0.70      0.70       745\n        INFP       0.66      0.80      0.72       916\n        INTJ       0.64      0.67      0.66       523\n        INTP       0.68      0.74      0.71       675\n        ISFJ       0.81      0.41      0.54        86\n        ISFP       0.57      0.50      0.53       130\n        ISTJ       0.78      0.44      0.56       113\n        ISTP       0.69      0.64      0.66       170\n\n    accuracy                           0.66      4338\n   macro avg       0.64      0.47      0.51      4338\nweighted avg       0.66      0.66      0.65      4338\n\n\n\n\n              precision    recall  f1-score   support\n\n        ENFJ       0.68      0.35      0.46        92\n        ENFP       0.63      0.63      0.63       327\n        ENTJ       0.65      0.41      0.50       115\n        ENTP       0.63      0.61      0.62       337\n        ESFJ       0.67      0.10      0.17        20\n        ESFP       0.00      0.00      0.00        24\n        ESTJ       0.50      0.08      0.14        24\n        ESTP       0.71      0.24      0.36        41\n        INFJ       0.70      0.71      0.70       745\n        INFP       0.64      0.81      0.72       916\n        INTJ       0.65      0.67      0.66       523\n        INTP       0.68      0.73      0.70       675\n        ISFJ       0.84      0.44      0.58        86\n        ISFP       0.59      0.42      0.49       130\n        ISTJ       0.71      0.43      0.54       113\n        ISTP       0.69      0.63      0.66       170\n\n    accuracy                           0.66      4338\n   macro avg       0.62      0.45      0.50      4338\nweighted avg       0.66      0.66      0.65      4338"
  },
  {
    "objectID": "연구/서연이랑/Ebayesthresh/2024-08-27-Ebayesthresh Layer.html",
    "href": "연구/서연이랑/Ebayesthresh/2024-08-27-Ebayesthresh Layer.html",
    "title": "(연구&서연) Ebayesthresh Layer",
    "section": "",
    "text": "pip install --no-deps git+https://github.com/seoyeonc/ebayesthresh_torch.git -U\n\nCollecting git+https://github.com/seoyeonc/ebayesthresh_torch.git\n  Cloning https://github.com/seoyeonc/ebayesthresh_torch.git to /tmp/pip-req-build-zyg9_r7k\n  Running command git clone --filter=blob:none --quiet https://github.com/seoyeonc/ebayesthresh_torch.git /tmp/pip-req-build-zyg9_r7k\n  Resolved https://github.com/seoyeonc/ebayesthresh_torch.git to commit da73db669a7965c26397949b7594f4ee34cfa73a\n  Preparing metadata (setup.py) ... done\nNote: you may need to restart the kernel to use updated packages.\n\n\n\nImport\n\nimport ebayesthresh_torch\n\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\n\n예제를 위해 필요한 함수 정의\n\ndef make_Psi(T):\n    W = torch.zeros((T,T))\n    for i in range(T):\n        for j in range(T):\n            if i==j :\n                W[i,j] = 0\n            elif torch.abs(torch.tensor(i - j)) &lt;= 1 : \n                W[i,j] = 1\n    d = W.sum(dim=1)\n    D = torch.diag(d)\n    L = torch.diag(1/torch.sqrt(d)) @ (D-W) @ torch.diag(1/torch.sqrt(d))\n    lamb, Psi = torch.linalg.eigh(L)\n    return Psi\n\n\n\nExample\n\nT = 100\nx = np.arange(T)/T * 10\ny_true = 3*np.sin(0.5*x) + 1.2*np.sin(1.0*x) + 0.5*np.sin(1.2*x) \ny = y_true + np.random.normal(size=T)\n\n\nplt.figure(figsize=(10,6))\nplt.plot(x,y,'o')\nplt.plot(x,y_true,'--')\n\n\n\n\n\n\n\n\n\nf = np.array(y)\nif len(f.shape)==1: f = f.reshape(-1,1)\nT,N = f.shape\nPsi = make_Psi(T)\nfbar = Psi.T @ f # apply dft \n\n\nfbar_threshed = ebayesthresh_torch.ebayesthresh(fbar[:,0])\n\n/home/cgb2/anaconda3/envs/EbayesthreshLayer/lib/python3.12/site-packages/ebayesthresh_torch/utils.py:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  if torch.isnan(torch.tensor(sdev)):\n\n\n\nplt.figure(figsize=(10,6))\nplt.plot((fbar**2)) # periodogram \nplt.plot((fbar_threshed**2)) \n\n\n\n\n\n\n\n\n\nplt.figure(figsize=(10,6))\nplt.plot((fbar**2)[20:80]) # periodogram \nplt.plot((fbar_threshed**2)[20:80]) \n\n\n\n\n\n\n\n\n\nyhat = Psi @ fbar_threshed.float() # inverse dft\nplt.figure(figsize=(10,6))\nplt.plot(x,y,'.')\nplt.plot(x,y_true,'--')\nplt.plot(x,yhat)\n\n\n\n\n\n\n\n\n\n\n사용자 함수 정의\n\nclass ebayesthresh_nn(torch.nn.Module):\n    def __init__(self, **kwargs):\n        super().__init__()\n        self.bayesfac = kwargs.get(\"bayesfac\",True)\n        self.verbose = kwargs.get('verbose', True)\n        self.threshrule = kwargs.get('threshrule', 'median')\n        self.universalthresh = kwargs.get('universalthresh', True)\n        self.stabadjustment = kwargs.get('stabadjustment', None)\n        self.prior = kwargs.get('prior', 'laplace')\n        self.bayesfac = kwargs.get('bayesfac', False) \n        #--#\n        self.a = torch.tensor(0.1,requires_grad=True); self.a.data = torch.tensor(kwargs.get('a', 0.5)).float()\n        self.sdev = torch.tensor(0.1,requires_grad=True); self.sdev.data =  torch.tensor(kwargs.get('sdev', 0.5)).float()\n        #prior=\"laplace\", a = 0.5, bayesfac = False, sdev = None, verbose = True, threshrule = \"median\", universalthresh = True, stabadjustment = None\n    def forward(self,x):\n        out = ebayesthresh_torch.ebayesthresh(\n            x,\n            self.prior, \n            a=self.a, \n            bayesfac=self.bayesfac, \n            sdev=self.sdev, \n            verbose=self.verbose, \n            threshrule=self.threshrule, \n            universalthresh=self.universalthresh, \n            stabadjustment=self.stabadjustment\n        )\n        self.muhat = out['muhat']\n        self.a = out['a']\n        self.sdev = out['sdev']\n        return self.muhat\n\n\n데이터\n\n\nnp.random.seed(111)\nT = 100\nx = np.arange(T)/T * 10\nytrue = 3*np.sin(0.5*x) + 1.2*np.sin(1.0*x) + 0.5*np.sin(1.2*x) \nnoise  = np.random.normal(size=T)*0.7\ny = ytrue + noise\n\n\n# plt.figure(figsize=(10,6))\n# plt.plot(y,'.',color='r')\n# plt.plot(ytrue,'-',color='b')\n\n\n레이어 정의\n\n\nthresh_layer = ebayesthresh_nn()\n\n\nFourier Transform\n\n\nPsi = make_Psi(T)\n\n\nybar = Psi.T @ torch.tensor(y).float()\n\n\nLearn\n\n\npower_threshed = thresh_layer(ybar).float()\n\n/home/cgb2/anaconda3/envs/EbayesthreshLayer/lib/python3.12/site-packages/ebayesthresh_torch/utils.py:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  if torch.isnan(torch.tensor(sdev)):\n\n\n\nloss = torch.mean((torch.tensor(ytrue).float() - Psi @ power_threshed)**2)\n\n\nloss.backward()\n\n\nthresh_layer.a\n\ntensor(0.500000000000000, requires_grad=True)\n\n\n\nthresh_layer.a.grad\n\ntensor(-0.089596189558506)\n\n\n\nthresh_layer.sdev # 미분꼬리표가 없음..\n\ntensor([0.500000000000000])"
  },
  {
    "objectID": "연구/서연이랑/GODE/Ex2_Kappa에따른성능시각화.html",
    "href": "연구/서연이랑/GODE/Ex2_Kappa에따른성능시각화.html",
    "title": "(연구&서연) GODE – Ex2 Kappa에 따른 성능 시각화",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nplt.rcParams['text.usetex'] = True\n\n\n#df = pd.read_csv(\"./Dropbox/03_Yechan3/연구/서연이랑/GODE/ex2_kappa_results.csv\")\ndf = pd.read_csv(\"~/Dropbox/03_Yechan3/연구/서연이랑/GODE/ex2_kappa_results.csv\")\ndf\n\n\n\n\n\n\n\n\nKappa\nAccuracy\nPrecision\nRecall\nF1\nAUC\nIteration\n\n\n\n\n0\n0.01\n0.897\n0.02\n0.018182\n0.019048\n0.527561\n0\n\n\n1\n0.02\n0.897\n0.02\n0.018182\n0.019048\n0.527561\n0\n\n\n2\n0.03\n0.903\n0.08\n0.072727\n0.076190\n0.542184\n0\n\n\n3\n0.04\n0.907\n0.12\n0.109091\n0.114286\n0.596094\n0\n\n\n4\n0.05\n0.945\n0.50\n0.454545\n0.476190\n0.764618\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n35995\n11.96\n0.943\n0.44\n0.431373\n0.435644\n0.810740\n29\n\n\n35996\n11.97\n0.943\n0.44\n0.431373\n0.435644\n0.817517\n29\n\n\n35997\n11.98\n0.943\n0.44\n0.431373\n0.435644\n0.808446\n29\n\n\n35998\n11.99\n0.947\n0.48\n0.470588\n0.475248\n0.823054\n29\n\n\n35999\n12.00\n0.945\n0.46\n0.450980\n0.455446\n0.822641\n29\n\n\n\n\n36000 rows × 7 columns\n\n\n\n\nplt.figure(figsize=(14*2/3, 10*2/3))\n\n# Adjusting the approach to find the optimal Kappa for each metric\noptimal_kappas = {}\n\n# Use full names for F1 Score and AUC\nfull_names = {\n    'Precision': 'Precision',\n    'Recall': 'Recall',\n    'F1': 'F1 Score',\n    'AUC': 'Area Under Curve (AUC)'\n}\n\nfor metric in metrics:\n    near_2_range = df[(df['Kappa'] &gt;= 0) & (df['Kappa'] &lt;= 2)]\n    mean_values = near_2_range.groupby('Kappa')[metric].mean()\n    optimal_kappa = mean_values.idxmax()\n    optimal_kappas[metric] = optimal_kappa\n\noptimal_kappas\n\nfor i, metric in enumerate(metrics):\n    means = df.groupby('Kappa')[metric].mean().to_numpy()\n    std_devs = df.groupby('Kappa')[metric].std().fillna(0).to_numpy()\n    kappa_values = df.groupby('Kappa')[metric].mean().index.to_numpy()\n\n    plt.subplot(2, 2, i + 1)\n    plt.plot(kappa_values, means, label=full_names[metric], linestyle='-', linewidth=2, color=colors[metric])\n    plt.fill_between(kappa_values, means - std_devs, means + std_devs, alpha=0.2, color=colors[metric])\n    \n    # Set y-axis limit to [0, 1]\n    plt.ylim(0, 1)\n    \n    # Add red dotted line at the optimal Kappa\n    plt.axvline(x=optimal_kappas[metric], color='red', linestyle='--', linewidth=2)\n    \n    # Annotate the optimal Kappa value, making the text more prominent\n    plt.text(optimal_kappas[metric] - 0.2, 0.65, f'$\\kappa$ = {optimal_kappas[metric]:.2f}', \n             fontsize=14, color='black', fontweight='bold', bbox=dict(facecolor='white', alpha=1.0))\n\n    plt.title(f'Kappa vs. {full_names[metric]}', fontsize=14)\n    plt.xlabel('Kappa', fontsize=12)\n    plt.ylabel(full_names[metric], fontsize=12)\n    plt.grid(True)\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "연구/서연이랑/GODE/env.html",
    "href": "연구/서연이랑/GODE/env.html",
    "title": "(연구&서연) GODE – 환경설정",
    "section": "",
    "text": "conda create -n gode python=3.10 \nconda install -c conda-forge r-essentials\nconda install r::rpy2\nconda install conda-forge::scikit-learn\nconda install conda-forge::pygsp\nconda install -c conda-forge notebook\npip install matplotlib\npip install pandas\npip install haversine\nconda install plotly::plotly\npip install tqdm \nconda install -c conda-forge pyod\npip install combo\nconda install pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch -c nvidia\ninstall.packages(\"EbayesThresh\")\npip install seaborn\nconda create -n gode37 python=3.7\nconda install -c conda-forge r-essentials\nconda install r::rpy2\nconda install conda-forge::scikit-learn\nconda install conda-forge::pygsp\nconda install -c conda-forge notebook\npip install matplotlib\npip install pandas\npip install haversine\nconda install plotly::plotly\npip install tqdm \nconda install -c conda-forge pyod\npip install combo\nconda install pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch -c nvidia\ninstall.packages(\"EbayesThresh\")\npip install seaborn"
  },
  {
    "objectID": "연구/서연이랑/GODE/CLT에대한연구.html",
    "href": "연구/서연이랑/GODE/CLT에대한연구.html",
    "title": "(연구&서연) GODE – CLT",
    "section": "",
    "text": "수정된 정리와 증명\n\nTheorem (Graph Fourier Transform and Asymptotic Normality)\n가정:\n벡터 \\(\\mathbf{y} \\in \\mathbb{R}^N\\)은 평균이 0이고 분산이 \\(\\sigma^2\\)인 독립적이고 동일한 분포(iid)를 따르는 확률 변수들로 구성된 그래프 신호이다. 즉, \\(\\mathbf{y} = [y_1, y_2, \\dots, y_N]^T \\sim \\text{iid}(0, \\sigma^2)\\)이다. 그래프 시프트 연산자(GSO) \\(\\mathbf{S}\\)는 실수 대칭 행렬로, 고유벡터들이 직교성을 가지며, 고유값 분해 \\(\\mathbf{S} = \\mathbf{U} \\Lambda \\mathbf{U}^T\\)가 성립한다. 여기서 \\(\\mathbf{U} = [\\mathbf{u}_1, \\mathbf{u}_2, \\dots, \\mathbf{u}_N]\\)는 고유벡터들로 구성된 직교행렬이고, \\(\\Lambda\\)는 고유값을 대각성분으로 가지는 대각행렬이다. \\(\\mathbf{\\tilde{y}} = \\mathbf{U}^T \\mathbf{y}\\)로 정의된 GFT(Graph Fourier Transform) 계수 벡터는 \\(\\mathbf{y}\\)의 그래프 푸리에 변환이다.\n정리:\nGSO \\(\\mathbf{S}\\)가 위 가정을 만족할 때, \\(N\\)이 충분히 클 경우, 각 GFT 계수 \\(\\tilde{y}_i\\)는 평균이 0이고 분산이 \\(\\sigma^2\\)인 정규 분포로 수렴한다. 즉,\n\\[\n\\tilde{y}_i \\sim \\text{AN}\\left(0, \\sigma^2\\right) \\quad \\text{for } i = 1, 2, \\dots, N.\n\\]\n또한, 서로 다른 \\(i\\)와 \\(j\\)에 대해 \\(\\tilde{y}_i\\)와 \\(\\tilde{y}_j\\)는 점근적으로 독립이다.\n증명:\n벡터 \\(\\mathbf{y} \\sim \\text{iid}(0, \\sigma^2)\\)이므로, \\(\\mathbf{\\tilde{y}} = \\mathbf{U}^T \\mathbf{y}\\)에서 \\(\\mathbf{U}\\)는 직교행렬이므로 \\(\\mathbf{\\tilde{y}}\\)의 각 성분 \\(\\tilde{y}_i\\)는 다음과 같이 표현된다:\n\\[\n\\tilde{y}_i = \\mathbf{u}_i^T \\mathbf{y} = \\sum_{j=1}^{N} u_{ij} y_j,\n\\]\n여기서 \\(u_{ij}\\)는 \\(\\mathbf{U}\\)의 \\(i\\)번째 고유벡터의 \\(j\\)번째 성분이다.\n\\(\\tilde{y}_i\\)는 \\(N\\)개의 독립적인 \\(y_j\\)의 선형 조합으로 이루어져 있다. 각 \\(y_j\\)는 \\(\\text{iid}(0, \\sigma^2)\\)이므로, 중심 극한 정리에 의해 \\(N\\)이 충분히 클 때, \\(\\tilde{y}_i\\)는 평균이 0이고 분산이 \\(\\sigma^2 \\sum_{j=1}^{N} u_{ij}^2\\)인 정규 분포로 수렴한다.\n\\(\\mathbf{U}\\)의 직교성에 의해 \\(\\sum_{j=1}^{N} u_{ij}^2 = 1\\)이므로, \\(\\tilde{y}_i\\)의 분산은 \\(\\sigma^2\\)이 된다.\n\\[\n\\tilde{y}_i \\sim \\text{AN}\\left(0, \\sigma^2\\right).\n\\]\nAN은 “Asymptotically Normal”의 약어로, 점근적으로 정규 분포를 따른다는 의미이다. 서로 다른 \\(\\tilde{y}_i\\)와 \\(\\tilde{y}_j\\)는 각각 서로 다른 고유벡터 \\(\\mathbf{u}_i\\)와 \\(\\mathbf{u}_j\\)에 의해 결정된다. 고유벡터들이 직교성이므로, \\(\\tilde{y}_i\\)와 \\(\\tilde{y}_j\\)는 서로 독립이다. 따라서 \\(N\\)이 충분히 클 때 \\(\\tilde{y}_i\\)와 \\(\\tilde{y}_j\\)는 점근적으로 독립인 정규 분포를 따르게 된다.\n결론:\n따라서, 위의 가정 하에서 각 GFT 계수 \\(\\tilde{y}_i\\)는 평균이 0이고 분산이 \\(\\sigma^2\\)인 정규 분포로 수렴하며, 서로 다른 GFT 계수들 간에는 점근적으로 독립성이 보장된다.\n- 각 \\(y_j\\)는 \\(\\text{iid}(0, \\sigma^2)\\)이므로, 중심 극한 정리에 의해 \\(N\\)이 충분히 클 때, \\(\\tilde{y}_i\\)는 평균이 0이고 분산이 \\(\\sigma^2 \\sum_{j=1}^{N} u_{ij}^2\\)인 정규 분포로 수렴한다.\n* 벡터 \\(\\mathbf{y}\\)의 성분인 \\(y_j\\)들은 모두 \\(\\text{iid}(0, \\sigma^2)\\)를 따르며, 이는 \\(y_j\\)가 평균이 0이고 분산이 \\(\\sigma^2\\)인 독립적이고 동일한 분포를 따른다는 것을 의미한다. 이 경우, \\(\\tilde{y}_i\\)는 여러 \\(y_j\\)들이 각기 다른 \\(u_{ij}\\) 계수로 가중되어 더해진 형태를 가지게 된다.\n\\[\n\\tilde{y}_i = \\sum_{j=1}^{N} u_{ij} y_j\n\\]\n이 식은 \\(N\\)개의 독립적인 확률 변수 \\(y_j\\)들의 가중합으로 볼 수 있다. 중심 극한 정리에 따르면, \\(y_j\\)들이 독립적이고 동일한 분포를 따르며, \\(N\\)이 충분히 클 때, 이들의 선형 조합(즉, \\(\\tilde{y}_i\\))은 정규 분포로 수렴한다. 이때 \\(\\tilde{y}_i\\)의 분포는 다음과 같은 평균과 분산을 갖는다.\n\n평균: 각 \\(y_j\\)의 평균이 0이므로, \\(\\tilde{y}_i\\)의 평균도 0이다.\n분산: \\(y_j\\)의 분산이 \\(\\sigma^2\\)이고, 각 \\(y_j\\)가 \\(u_{ij}\\)로 가중되어 합산되므로, \\(\\tilde{y}_i\\)의 분산은 \\(\\sigma^2\\)에 각 \\(u_{ij}^2\\)의 합을 곱한 값이 된다:\n\n\\[\n\\text{Var}(\\tilde{y}_i) = \\sigma^2 \\sum_{j=1}^{N} u_{ij}^2\n\\]\n\\(\\mathbf{U}\\)가 직교행렬이므로, 고유벡터 \\(\\mathbf{u}_i\\)의 성분 \\(u_{ij}\\)들에 대해 \\(\\sum_{j=1}^{N} u_{ij}^2 = 1\\)이 성립한다. 따라서 \\(\\tilde{y}_i\\)의 분산은 \\(\\sigma^2\\)이 된다.\n\\[\n\\tilde{y}_i \\sim \\text{AN}(0, \\sigma^2)\n\\]\n즉, \\(\\tilde{y}_i\\)는 평균이 0이고 분산이 \\(\\sigma^2\\)인 정규 분포로 수렴한다.\n- \\(y_j\\)들이 독립적이고 동일한 분포를 따르며, \\(N\\)이 충분히 클 때, 이들의 선형 조합(즉, \\(\\tilde{y}_i\\))은 정규 분포로 수렴하는 이유??\n* 정리 (Lindeberg-Feller 중심 극한 정리):\n서로 독립적인 확률 변수들의 수열 \\(\\{X_{n, k} : k = 1, 2, \\dots, n\\}\\)이 존재한다고 가정하자. 각 \\(X_{n,k}\\)에 대해 기대값 \\(E[X_{n,k}] = 0\\), 분산 \\(\\text{Var}(X_{n,k}) = \\sigma_{n,k}^2\\)라고 하자. 이때, 합\n\\[\nS_n = \\sum_{k=1}^{n} X_{n,k}\n\\]\n의 분산 \\(\\text{Var}(S_n) = \\sum_{k=1}^{n} \\sigma_{n,k}^2 = \\sigma_n^2\\)가 존재하고, 다음의 Lindeberg 조건이 성립한다고 가정한다:\n\\[\n\\lim_{n \\to \\infty} \\frac{1}{\\sigma_n^2} \\sum_{k=1}^{n} E\\left[ X_{n,k}^2 \\cdot \\mathbf{1}\\left(\\frac{|X_{n,k}|}{\\sigma_n} &gt; \\epsilon \\right) \\right] = 0 \\quad \\text{for all } \\epsilon &gt; 0,\n\\]\n여기서 \\(\\mathbf{1}(\\cdot)\\)은 지시 함수(indicator function)로, 조건이 참이면 1, 거짓이면 0을 반환한다.\n위 조건이 성립하면, 합 \\(S_n / \\sigma_n\\)은 표준 정규 분포 \\(N(0,1)\\)로 수렴한다:\n\\[\n\\frac{S_n}{\\sigma_n} \\xrightarrow{d} N(0,1) \\quad \\text{as } n \\to \\infty.\n\\]\n해설:\n이 정리는 서로 독립적인 확률 변수들의 가중합이 정규 분포로 수렴하는 조건을 제시한다. Lindeberg 조건은 특히, 개별 항이 정규 분포의 극한에 기여하지 않을 정도로 작아야 한다는 점을 강조한다. 즉, 분산이 매우 큰 값으로 치우치는 변수가 있으면 이 조건이 만족되지 않으며, 이 경우 정규 분포로 수렴하지 않을 수 있다.\n이 정리는 표준적인 중심 극한 정리보다 더 일반적인 상황에 적용될 수 있으며, 특히 독립적이지만 동일한 분포를 따르지 않는 경우나 가중합이 발생하는 경우에도 적용 가능하다.\n- Lindeberg 조건의 의미\n* Lindeberg 조건은 중심 극한 정리가 성립하기 위한 중요한 기준 중 하나로, 특정 확률 변수들이 정규 분포로 수렴하는 데 있어 개별 항들의 역할을 제한한다. 이 조건은 모든 개별 항들이 합의 결과에 지나치게 큰 영향을 미치지 않도록 보장하는 역할을 한다.\n조건의 구체적인 의미\nLindeberg 조건은 다음과 같다:\n\\[\n\\lim_{n \\to \\infty} \\frac{1}{\\sigma_n^2} \\sum_{k=1}^{n} E\\left[ X_{n,k}^2 \\cdot \\mathbf{1}\\left(\\frac{|X_{n,k}|}{\\sigma_n} &gt; \\epsilon \\right) \\right] = 0 \\quad \\text{for all } \\epsilon &gt; 0,\n\\]\n이 조건은 다음과 같은 의미를 갖는다:\n\n개별 항의 영향 제한: \\(\\frac{|X_{n,k}|}{\\sigma_n}\\)가 일정한 임계값 \\(\\epsilon\\)을 넘는 경우, 그에 대응하는 기댓값 \\(E[X_{n,k}^2 \\cdot \\mathbf{1}(\\cdot)]\\)이 0에 수렴해야 한다. 즉, 개별 확률 변수가 전체 합에 미치는 영향이 너무 크지 않아야 한다는 것을 의미한다.\n중앙 극한 정리 성립의 핵심: Lindeberg 조건은 각 항이 “정규 분포”로의 수렴 과정에서 지나치게 큰 역할을 하지 않도록 보장한다. 만약 일부 항이 지나치게 큰 영향을 미치면, 그 항의 기여가 합을 왜곡하여 정규 분포로의 수렴이 이루어지지 않게 된다.\n\nLindeberg 조건을 만족하지 않는 예시\nLindeberg 조건을 만족하지 않는 경우는 다음과 같이 설명할 수 있다.\n예시:\n서로 독립적인 확률 변수 \\(X_1, X_2, \\dots, X_n\\)이 있다고 하자. 이들 중 하나의 확률 변수 \\(X_n\\)이 나머지 변수들에 비해 매우 큰 분산을 가진다고 가정해보자. 이를 위해 다음과 같은 경우를 생각할 수 있다:\n\n\\(X_1, X_2, \\dots, X_{n-1}\\)은 모두 평균이 0이고 분산이 \\(\\sigma^2\\)인 동일한 분포를 따른다.\n\\(X_n\\)은 평균이 0이지만 분산이 매우 큰 값, 예를 들어 \\(n^2 \\cdot \\sigma^2\\)을 가진다고 하자.\n\n이 경우, \\(\\sigma_n^2 = \\sum_{k=1}^{n} \\text{Var}(X_{n,k})\\)이므로,\n\\[\n\\sigma_n^2 = (n-1)\\sigma^2 + n^2 \\cdot \\sigma^2 = (n-1)\\sigma^2 + n^2 \\cdot \\sigma^2\n\\]\n전체 합 \\(S_n = \\sum_{k=1}^{n} X_k\\)에서, \\(X_n\\)의 기여가 다른 모든 변수들보다 훨씬 더 크게 된다. 이는 \\(X_n\\)의 분산이 매우 크기 때문에 발생한다. 따라서 \\(X_n\\)이 Lindeberg 조건을 위반하게 되고, 전체 합 \\(S_n\\)이 정규 분포로 수렴하지 않을 가능성이 생긴다.\nLindeberg 조건을 위반함으로써 발생할 수 있는 문제는 다음과 같다:\n\n정규 분포로의 수렴 실패: 하나의 큰 변동성이 전체 합을 왜곡하여, 원래 기대했던 정규 분포가 아닌 다른 분포로 수렴할 수 있다.\n합의 극단적 왜곡: 큰 분산을 가진 변수 하나가 합의 값을 극단적으로 왜곡하여, 분포의 꼬리가 매우 두꺼워질 수 있다(예: 파레토 분포, Cauchy 분포 등으로 수렴할 수 있음).\n\n이 예시는 Lindeberg 조건의 중요성을 강조하며, 특히 일부 변수가 지나치게 큰 분산을 가지는 경우 정규 분포로의 수렴이 보장되지 않을 수 있음을 보여준다. 이 조건이 충족되지 않으면, 중심 극한 정리는 성립하지 않을 수 있다.\n- Salt-and-Pepper 노이즈 가 린드버그의 조건을 만족할까?\n* Salt-and-Pepper 노이즈는 디지털 이미지 처리에서 주로 등장하는 노이즈로, 픽셀 값이 임의로 최대값(흰색, “salt”) 또는 최소값(검정색, “pepper”)으로 설정되는 것을 의미한다. 일반적으로 이 노이즈는 이산적인 두 개의 값을 갖는 비대칭적 분포를 따른다. 이를 확률 변수로 표현하면, \\(X_i\\)가 다음과 같은 분포를 따를 수 있다:\n\\[\nX_i =\n\\begin{cases}\nM & \\text{with probability } p_s \\\\\n-m & \\text{with probability } p_p \\\\\n0 & \\text{with probability } 1 - p_s - p_p\n\\end{cases}\n\\]\n여기서 \\(M\\)과 \\(-m\\)은 각각 최대값과 최소값, \\(p_s\\)와 \\(p_p\\)는 각각 salt와 pepper 노이즈가 발생할 확률이다.\n# [Lindeberg 조건 검토]\nLindeberg 조건이 성립하기 위해서는 다음과 같은 조건을 검토해야 한다:\n\\[\n\\lim_{n \\to \\infty} \\frac{1}{\\sigma_n^2} \\sum_{k=1}^{n} E\\left[ X_k^2 \\cdot \\mathbf{1}\\left(\\frac{|X_k|}{\\sigma_n} &gt; \\epsilon \\right) \\right] = 0 \\quad \\text{for all } \\epsilon &gt; 0,\n\\]\n여기서 \\(\\sigma_n^2 = \\sum_{k=1}^{n} \\text{Var}(X_k)\\)는 전체 합의 분산이다.\n# [Salt-and-Pepper 노이즈의 분포에 따른 Lindeberg 조건 분석]\n\n확률 변수 \\(X_i\\)의 분산: 각 \\(X_i\\)의 분산 \\(\\text{Var}(X_i)\\)는 다음과 같이 계산된다:\n\\[\n\\text{Var}(X_i) = E[X_i^2] - (E[X_i])^2\n\\]\n\\[\nE[X_i] = p_s \\cdot M + p_p \\cdot (-m)\n\\]\n\\[\nE[X_i^2] = p_s \\cdot M^2 + p_p \\cdot m^2\n\\]\n따라서 분산은 다음과 같다:\n\\[\n\\text{Var}(X_i) = p_s \\cdot M^2 + p_p \\cdot m^2 - (p_s \\cdot M + p_p \\cdot (-m))^2\n\\]\n분산이 큰 값으로 유지될 수 있지만, 개별 항들이 극단적인 값을 취할 가능성이 제한되어 있으므로 중심 극한 정리에서 중요한 역할을 하는 평균과 분산의 조건이 만족될 가능성이 있다.\nLindeberg 조건에 따른 임계값 초과 확률: \\(X_i\\)가 특정 값 \\(M\\) 또는 \\(-m\\)으로 설정될 확률 \\(p_s\\) 및 \\(p_p\\)가 매우 작지 않다면, 그 값들이 \\(\\epsilon \\cdot \\sigma_n\\)를 초과할 가능성도 높아진다.\n이 경우, \\(X_i\\)가 \\(\\epsilon \\cdot \\sigma_n\\)를 초과하는 확률이 비례적으로 매우 높아지며, \\(\\sum_{k=1}^{n} E\\left[ X_k^2 \\cdot \\mathbf{1}\\left(\\frac{|X_k|}{\\sigma_n} &gt; \\epsilon \\right) \\right]\\)의 값이 0으로 수렴하지 않을 수 있다. 이는 Lindeberg 조건이 성립하지 않음을 의미할 수 있다.\n\n# [결론]\nSalt-and-Pepper 노이즈의 경우, Lindeberg 조건이 항상 만족된다고 보장할 수 없다. 특히, Salt-and-Pepper 노이즈에서 발생하는 값들이 매우 큰 편차를 가지거나 그 발생 확률이 특정 방식으로 분포할 경우, 개별 항들이 합 전체에 큰 영향을 미치게 되며, 이는 Lindeberg 조건을 위반할 가능성이 크다.\n따라서, Salt-and-Pepper 노이즈를 따르는 확률 변수 \\(X_i\\)들이 중심 극한 정리의 일반적 형태로 정규 분포에 수렴하는 것은 보장되지 않는다. 이를 위해서는 노이즈 발생 확률과 그 값들이 Lindeberg 조건을 만족하는지를 추가로 검토해야 한다."
  },
  {
    "objectID": "연구/서연이랑/ITSTGCN/2023-03-17-ITSTGCN-Tutorial.html",
    "href": "연구/서연이랑/ITSTGCN/2023-03-17-ITSTGCN-Tutorial.html",
    "title": "(연구&서연) IT-STGCN – ITSTGCN-Tutorial",
    "section": "",
    "text": "edit\n\n\nimport\n\nimport itstgcn \nimport torch\n\n\n\n예제1: vanilla STGCN\n- 데이터\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n\n\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \n\n\ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.utils.temporal_signal_split(dataset, train_ratio=0.8)\n\n- 학습\n\nlrnr = itstgcn.StgcnLearner(train_dataset,dataset_name='five_nodes')\n\n/home/csy/Dropbox/blog/posts/GCN/itstgcn/learners.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180588308/work/torch/csrc/utils/tensor_new.cpp:201.)\n  self.lags = torch.tensor(train_dataset.features).shape[-1]\n\n\n\nlrnr.learn(filters=4,epoch=5)\n\n5/5\n\n\n- 적합값\n\n#lrnr(train_dataset) \n#lrnr(test_dataset)\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) \nfig.set_figwidth(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\n\n\n\n\n예제2: padding missing values\n- 데이터\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.utils.temporal_signal_split(dataset, train_ratio=0.8)\n\n- 임의로 결측치 발생\n\nmindex = itstgcn.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex=mindex,mtype='rand')\n\n\nfig = itstgcn.plot(torch.tensor(train_dataset_miss.targets),'o')\nfig \n\n\n\n\n\n\n\n\n- 적절한 method로 결측치를 채움 (default 는 linear)\n\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n\nfig = itstgcn.plot(torch.tensor(train_dataset_miss.targets),'o')\nitstgcn.plot_add(fig,torch.tensor(train_dataset_padded.targets),'--x',color='C1',alpha=0.5)\n\n\n\n\n\n\n\n\n다른 method로 결측치를 채울수도 있음. 사용할 수 있는 방법들은 아래에 정리되어 있음\n\nref: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html\n\n\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss,interpolation_method='nearest')\n\n\nfig = itstgcn.plot(torch.tensor(train_dataset_miss.targets),'o')\nitstgcn.plot_add(fig,torch.tensor(train_dataset_padded.targets),'--x',color='C1',alpha=0.5)\n\n\n\n\n\n\n\n\n\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss,interpolation_method='quadratic')\n\n\nfig = itstgcn.plot(torch.tensor(train_dataset_miss.targets),'o')\nitstgcn.plot_add(fig,torch.tensor(train_dataset_padded.targets),'--x',color='C1',alpha=0.5)\n\n\n\n\n\n\n\n\n\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss,interpolation_method='cubic')\n\n\nfig = itstgcn.utils.plot(torch.tensor(train_dataset_miss.targets),'o')\nitstgcn.utils.plot_add(fig,torch.tensor(train_dataset_padded.targets),'--x',color='C1',alpha=0.5)\n\n\n\n\n\n\n\n\n- 블락으로 결측치 발생\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='block')\n\n\nfig = itstgcn.utils.plot(torch.tensor(train_dataset_miss.targets),'o')\nfig \n\n\n\n\n\n\n\n\n\n\n예제3: vanilla STGCN with random missing\n- data\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.utils.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = itstgcn.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr = itstgcn.learners.StgcnLearner(train_dataset_padded)\n\n\nlrnr.learn(filters=4,epoch=5)\n\n5/5\n\n\n- 적합값\n\n#lrnr(train_dataset_padded) \n#lrnr(test_dataset)\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=5,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\n\n\n\n\n예제4: vanilla STGCN with block missing\n- data\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.utils.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr = itstgcn.StgcnLearner(train_dataset_padded)\n\n\nlrnr.learn(filters=4,epoch=5)\n\n5/5\n\n\n- 적합값\n\n#lrnr(train_dataset_padded) \n#lrnr(test_dataset)\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=5,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\n\n\n\n\n예제5: threshold example (random)\n- data\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.utils.temporal_signal_split(dataset, train_ratio=0.8)\n\n- 결측치 발생 및 패딩\n\nmindex=itstgcn.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss)\n\n\nf_miss,_ = itstgcn.convert_train_dataset(train_dataset_miss)\nf_padded,_ = itstgcn.convert_train_dataset(train_dataset_padded)\n\n\nfig = itstgcn.utils.plot(f_miss,'o')\nitstgcn.utils.plot_add(fig,f_padded,'--x',alpha=0.5)\n\n\n\n\n\n\n\n\n- update by frequency thresholding\n\nfig = itstgcn.plot(f_miss,'o',alpha=0.5)\nitstgcn.plot_add(fig,f_padded,'--x',alpha=0.5)\nf_updated = itstgcn.update_from_freq_domain(f_padded,train_dataset_padded.mindex)\nitstgcn.plot_add(fig,f_updated,'-')\n\n\n\n\n\n\n\n\n\n\n예제6: threshold example (block)\n- data\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.temporal_signal_split(dataset, train_ratio=0.8)\n\n- 결측치 발생 및 패딩\n\nmindex=[list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss)\n\n\nf_miss,_ = itstgcn.convert_train_dataset(train_dataset_miss)\nf_padded,_ = itstgcn.convert_train_dataset(train_dataset_padded)\n\n\nfig = itstgcn.plot(f_miss,'o')\nitstgcn.plot_add(fig,f_padded,'--x',alpha=0.5)\n\n\n\n\n\n\n\n\n- update by frequency thresholding\n\nfig = itstgcn.plot(f_miss,'o',alpha=0.5)\nitstgcn.plot_add(fig,f_padded,'--x',alpha=0.5)\nf_updated = itstgcn.update_from_freq_domain(f_padded,train_dataset_padded.mindex)\nitstgcn.plot_add(fig,f_updated,'-')\n\n\n\n\n\n\n\n\n\n\n예제7: iterative thresholded STGCN (IT-STGCN) with random missing\n- data\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = itstgcn.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr = itstgcn.ITStgcnLearner(train_dataset_padded)\n\n\nlrnr.learn(filters=4,epoch=5)\n\n5/5\n\n\n- 적합값\n\n#lrnr(train_dataset_padded) \n#lrnr(test_dataset)['yhat'].shape\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\n\n\n\n\n예제8: iterative thresholded STGCN (IT-STGCN) with block missing\n- data\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex = [list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr = itstgcn.ITStgcnLearner(train_dataset_padded)\n\n\nlrnr.learn(filters=4,epoch=5)\n\n5/5\n\n\n- 적합값\n\n#lrnr(train_dataset_padded) \n#lrnr(test_dataset)['yhat'].shape\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\n\n\n\n\n예제9: GNAR (random missing)\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex=itstgcn.rand_mindex(train_dataset,mrate=0.5)\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='rand')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr = itstgcn.GNARLearner(train_dataset_padded)\n\n\nlrnr.learn()\n\nWARNING: diagonal entries present in original matrix, these will be removed\n\n\n- 적합값\n\n#lrnr(train_dataset_padded) \n#lrnr(test_dataset)\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.tight_layout()\nfig\n\n\n\n\n\n\n\n\n\n\n예제10: GNAR (block missing)\n\n_data = itstgcn.load_data('./data/fivenodes.pkl')\n_edges = torch.tensor(_data['edges']).nonzero().tolist()\n_FX = _data['f'].tolist()\n_node_ids = {'node1':0, 'node2':1, 'node3':2, 'node4':3, 'node5':4} \ndata_dict = {'edges':_edges, 'node_ids':_node_ids, 'FX':_FX}\n\n\nloader = itstgcn.DatasetLoader(data_dict)\n\n\nloader = itstgcn.DatasetLoader(data_dict)\ndataset = loader.get_dataset(lags=2)\ntrain_dataset, test_dataset = itstgcn.temporal_signal_split(dataset, train_ratio=0.8)\n\n\nmindex=[list(range(10,100)),[],list(range(50,80)),[],[]]\ntrain_dataset_miss = itstgcn.miss(train_dataset,mindex,mtype='block')\ntrain_dataset_padded = itstgcn.padding(train_dataset_miss) # padding(train_dataset_miss,method='linear'와 같음)\n\n- 학습\n\nlrnr = itstgcn.GNARLearner(train_dataset_padded)\n\n\nlrnr.learn()\n\nWARNING: diagonal entries present in original matrix, these will be removed\n\n\n- 적합값\n\n#lrnr(train_dataset_padded) \n#lrnr(test_dataset)\n\n\n실행하면 X,y,yhat 출력\n\n- 모형 평가 및 시각화\n\nevtor = itstgcn.Evaluator(lrnr,train_dataset_padded,test_dataset)\n\nWARNING: diagonal entries present in original matrix, these will be removed\nWARNING: diagonal entries present in original matrix, these will be removed\n\n\n\nfig = evtor.plot('--.',h=5,max_node=3,label='complete data',alpha=0.5) # max_nodes 는 1보다 커야함\nfig.set_figwidth(12)\nfig.tight_layout()\nfig"
  },
  {
    "objectID": "연구/서연이랑/ITSTGCN/2023-04-27-Toy Example Figure(Intro).html",
    "href": "연구/서연이랑/ITSTGCN/2023-04-27-Toy Example Figure(Intro).html",
    "title": "(연구&서연) IT-STGCN – Toy Example Figure(Intro)",
    "section": "",
    "text": "import itstgcn \nimport torch\nimport numpy as np\n\n\nimport matplotlib.pyplot as plt\n\n\nclass Eval_csy:\n    def __init__(self,learner,train_dataset):\n        self.learner = learner\n        # self.learner.model.eval()\n        try:self.learner.model.eval()\n        except:pass\n        self.train_dataset = train_dataset\n        self.lags = self.learner.lags\n        rslt_tr = self.learner(self.train_dataset) \n        self.X_tr = rslt_tr['X']\n        self.y_tr = rslt_tr['y']\n        self.f_tr = torch.concat([self.train_dataset[0].x.T,self.y_tr],axis=0).float()\n        self.yhat_tr = rslt_tr['yhat']\n        self.fhat_tr = torch.concat([self.train_dataset[0].x.T,self.yhat_tr],axis=0).float()\n\n\nimport pickle\nimport pandas as pd\n\n\ndef load_data(fname):\n    with open(fname, 'rb') as outfile:\n        data_dict = pickle.load(outfile)\n    return data_dict\n\ndef save_data(data_dict,fname):\n    with open(fname,'wb') as outfile:\n        pickle.dump(data_dict,outfile)\n\n\nT = 100\nt = np.arange(T)/T * 10 \n\nx = 0.3*np.sin(2*t)+0.1*np.sin(4*t)+0.1*np.sin(8*t)\neps_x  = np.random.normal(size=T)*0\ny = x.copy()\nfor i in range(2,T):\n    y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 0.5*np.cos(0.5*t[i]) \neps_y  = np.random.normal(size=T)*0\nx = x\ny = y\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n\n# _FX1 = np.stack([x,y],axis=1).tolist()\n_FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n#data_dict = itstgcn.load_data('./data/fivenodes.pkl')\n\nsave_data(data_dict1, './data/toy_example1.pkl')\n\ndata1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\nsave_data(data1, './data/toy_example_true1.csv')\n\n\n\n\n\n\n\n\n\ndata_dict1 = itstgcn.load_data('./data/toy_example1.pkl')\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\ndataset05031 = loader1.get_dataset(lags=4)\n\n\nmindex05031 = itstgcn.rand_mindex(dataset05031,mrate=0)\ndataset_miss05031 = itstgcn.miss(dataset05031,mindex05031,mtype='rand')\n\n\ndataset_miss05031.edge_index\n\narray([[0],\n       [1]])\n\n\n\ndataset_padded_cubic05031 = itstgcn.padding(dataset_miss05031,imputation_method='cubic')\n\n\ndataset_padded_cubic05031.edge_index\n\narray([[0],\n       [1]])\n\n\n- 학습\n\nlrnr05031 = itstgcn.StgcnLearner(dataset_padded_cubic05031)\n\n\nlrnr05031.train_dataset.edge_index\n\narray([[0],\n       [1]])\n\n\n\nlags4/0.3/filter16\nlags4/0.38/filter8\nlags8/0.38/filter8\n\n\nlrnr05031.learn(filters=16,epoch=50)\n\n50/50\n\n\n- 모형 평가 및 시각화\n\ndf1 = itstgcn.load_data('./data/toy_example_true1.csv')\n\n\nevtor05031 = Eval_csy(lrnr05031,dataset_padded_cubic05031)\n\n\nevtor05031.train_dataset.edge_index\n\narray([[0],\n       [1]])\n\n\n\nfig, ((ax1, ax2), (ax3, ax4), (ax5, ax6), (ax7, ax8), (ax9, ax10)) = plt.subplots(5, 2,figsize=(30,20))\n# fig.suptitle('Figure 1')\nax1.plot(df1['x'][:],'.',color='C0')\nax2.plot(df1['y'][:],'.',color='C0')\nax3.plot(df1['xer'][:],'.',color='C1')\nax4.plot(df1['yer'][:],'.',color='C1')\nax5.plot(evtor05031.f_tr[:,0],'.',color='C2')\nax6.plot(evtor05031.f_tr[:,1],'.',color='C2')\nax7.plot(df1['x'][:],'.',color='C0')\nax7.plot(evtor05031.fhat_tr[:,0],color='C3')\nax8.plot(df1['y'][:],'.',color='C0')\nax8.plot(evtor05031.fhat_tr[:,1],color='C3')\nax9.plot(df1['x'][:],'.',color='C0')\nax9.plot(df1['xer'][:],'.',color='C1')\nax9.plot(evtor05031.f_tr[:,0],'.',color='C2')\nax9.plot(evtor05031.fhat_tr[:,0],color='C3')\nax10.plot(df1['y'][:],'.',color='C0')\nax10.plot(df1['yer'][:],'.',color='C1')\nax10.plot(evtor05031.f_tr[:,1],'.',color='C2')\nax10.plot(evtor05031.fhat_tr[:,1],color='C3')\n\nfor ax in fig.get_axes():\n    ax.label_outer()"
  },
  {
    "objectID": "연구/서연이랑/ITSTGCN/2023-04-27-Toy Example Figure(Intro).html#import",
    "href": "연구/서연이랑/ITSTGCN/2023-04-27-Toy Example Figure(Intro).html#import",
    "title": "(연구&서연) IT-STGCN – Toy Example Figure(Intro)",
    "section": "",
    "text": "import itstgcn \nimport torch\nimport numpy as np\n\n\nimport matplotlib.pyplot as plt\n\n\nclass Eval_csy:\n    def __init__(self,learner,train_dataset):\n        self.learner = learner\n        # self.learner.model.eval()\n        try:self.learner.model.eval()\n        except:pass\n        self.train_dataset = train_dataset\n        self.lags = self.learner.lags\n        rslt_tr = self.learner(self.train_dataset) \n        self.X_tr = rslt_tr['X']\n        self.y_tr = rslt_tr['y']\n        self.f_tr = torch.concat([self.train_dataset[0].x.T,self.y_tr],axis=0).float()\n        self.yhat_tr = rslt_tr['yhat']\n        self.fhat_tr = torch.concat([self.train_dataset[0].x.T,self.yhat_tr],axis=0).float()\n\n\nimport pickle\nimport pandas as pd\n\n\ndef load_data(fname):\n    with open(fname, 'rb') as outfile:\n        data_dict = pickle.load(outfile)\n    return data_dict\n\ndef save_data(data_dict,fname):\n    with open(fname,'wb') as outfile:\n        pickle.dump(data_dict,outfile)\n\n\nT = 100\nt = np.arange(T)/T * 10 \n\nx = 0.3*np.sin(2*t)+0.1*np.sin(4*t)+0.1*np.sin(8*t)\neps_x  = np.random.normal(size=T)*0\ny = x.copy()\nfor i in range(2,T):\n    y[i] = 0.35*x[i-1] - 0.15*x[i-2] + 0.5*np.cos(0.5*t[i]) \neps_y  = np.random.normal(size=T)*0\nx = x\ny = y\nplt.plot(t,x,color='C0',lw=5)\nplt.plot(t,x+eps_x,alpha=0.5,color='C0')\nplt.plot(t,y,color='C1',lw=5)\nplt.plot(t,y+eps_y,alpha=0.5,color='C1')\n_node_ids = {'node1':0, 'node2':1}\n\n# _FX1 = np.stack([x,y],axis=1).tolist()\n_FX1 = np.stack([x+eps_x,y+eps_y],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n#data_dict = itstgcn.load_data('./data/fivenodes.pkl')\n\nsave_data(data_dict1, './data/toy_example1.pkl')\n\ndata1 = pd.DataFrame({'x':x,'y':y,'xer':x,'yer':y})\n\nsave_data(data1, './data/toy_example_true1.csv')\n\n\n\n\n\n\n\n\n\ndata_dict1 = itstgcn.load_data('./data/toy_example1.pkl')\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\ndataset05031 = loader1.get_dataset(lags=4)\n\n\nmindex05031 = itstgcn.rand_mindex(dataset05031,mrate=0)\ndataset_miss05031 = itstgcn.miss(dataset05031,mindex05031,mtype='rand')\n\n\ndataset_miss05031.edge_index\n\narray([[0],\n       [1]])\n\n\n\ndataset_padded_cubic05031 = itstgcn.padding(dataset_miss05031,imputation_method='cubic')\n\n\ndataset_padded_cubic05031.edge_index\n\narray([[0],\n       [1]])\n\n\n- 학습\n\nlrnr05031 = itstgcn.StgcnLearner(dataset_padded_cubic05031)\n\n\nlrnr05031.train_dataset.edge_index\n\narray([[0],\n       [1]])\n\n\n\nlags4/0.3/filter16\nlags4/0.38/filter8\nlags8/0.38/filter8\n\n\nlrnr05031.learn(filters=16,epoch=50)\n\n50/50\n\n\n- 모형 평가 및 시각화\n\ndf1 = itstgcn.load_data('./data/toy_example_true1.csv')\n\n\nevtor05031 = Eval_csy(lrnr05031,dataset_padded_cubic05031)\n\n\nevtor05031.train_dataset.edge_index\n\narray([[0],\n       [1]])\n\n\n\nfig, ((ax1, ax2), (ax3, ax4), (ax5, ax6), (ax7, ax8), (ax9, ax10)) = plt.subplots(5, 2,figsize=(30,20))\n# fig.suptitle('Figure 1')\nax1.plot(df1['x'][:],'.',color='C0')\nax2.plot(df1['y'][:],'.',color='C0')\nax3.plot(df1['xer'][:],'.',color='C1')\nax4.plot(df1['yer'][:],'.',color='C1')\nax5.plot(evtor05031.f_tr[:,0],'.',color='C2')\nax6.plot(evtor05031.f_tr[:,1],'.',color='C2')\nax7.plot(df1['x'][:],'.',color='C0')\nax7.plot(evtor05031.fhat_tr[:,0],color='C3')\nax8.plot(df1['y'][:],'.',color='C0')\nax8.plot(evtor05031.fhat_tr[:,1],color='C3')\nax9.plot(df1['x'][:],'.',color='C0')\nax9.plot(df1['xer'][:],'.',color='C1')\nax9.plot(evtor05031.f_tr[:,0],'.',color='C2')\nax9.plot(evtor05031.fhat_tr[:,0],color='C3')\nax10.plot(df1['y'][:],'.',color='C0')\nax10.plot(df1['yer'][:],'.',color='C1')\nax10.plot(evtor05031.f_tr[:,1],'.',color='C2')\nax10.plot(evtor05031.fhat_tr[:,1],color='C3')\n\nfor ax in fig.get_axes():\n    ax.label_outer()"
  },
  {
    "objectID": "연구/서연이랑/ITSTGCN/2024-01-19-실험결과정리.html",
    "href": "연구/서연이랑/ITSTGCN/2024-01-19-실험결과정리.html",
    "title": "(연구&서연) IT-STGCN – 실험결과시각화",
    "section": "",
    "text": "Import\n\nimport pandas as pd\nimport numpy as np\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport pickle\n\nimport plotly.io as pio\n\n\npd.options.plotting.backend = \"plotly\"\npio.templates.default = \"plotly_white\"\n\n\n\nConditions\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nFiveVTS\nChickenpox\nPedalme\nWikimath\nWindmillsmall\nMontevideoBus\n\n\n\n\nMax iter.\n30\n30\n30\n30\n30\n30\n\n\nEpochs\n50\n50\n50\n50\n50\n50\n\n\nLags\n2\n4\n4\n8\n8\n4\n\n\nInterpolation\nlinear\nlinear\nnearest\nlinear\nlinear\nnearest\n\n\nFilters\n\n\n\n\n\n\n\n\nGConvGRU\n12\n16\n12\n12\n12\n12\n\n\nGConvLSTM\n12\n32\n2\n64\n16\n12\n\n\nGCLSTM\n4\n16\n4\n64\n16\n12\n\n\nLRGCN\n4\n8\n8\n32\n12\n2\n\n\nDyGrEncoder\n12\n12\n12\n12\n12\n12\n\n\nEvolveGCNH\nNo need\nNo need\nNo need\nNo need\nNo need\nNo need\n\n\nEvolveGCNO\nNo need\nNo need\nNo need\nNo need\nNo need\nNo need\n\n\nTGCN\n12\n12\n12\n12\n12\n8\n\n\nDCRNN\n2\n16\n8\n12\n4\n12\n\n\n\n\n\nData & 사용자정의함수\n\ndf_dataset = pd.DataFrame({\n    'dataset':['fivenodes','chickenpox','pedalme','wikimath','windmillsmall','monte'],\n    'node':[5,20,15,1068,11,675],\n    'time':[200,522,36,731,17472,744]\n})\ndf = pd.read_csv('./Body_Results.csv').iloc[:,1:]\\\n.merge(df_dataset)\\\n.assign(method = lambda df: df['method'].map({'STGCN':'STGNN','IT-STGCN':'IT-STGNN','GNAR':'GNAR'}))\n\n\ndf.head()\n\n\n\n\n\n\n\n\ndataset\nmethod\nmrate\nmtype\nlags\nnof_filters\ninter_method\nepoch\nmse\ncalculation_time\nmodel\nnode\ntime\n\n\n\n\n0\nfivenodes\nSTGNN\n0.0\nNaN\n2\n12.0\nNaN\n50.0\n0.729374\n80.985221\nGConvGRU\n5\n200\n\n\n1\nfivenodes\nSTGNN\n0.0\nNaN\n2\n12.0\nNaN\n50.0\n0.729082\n80.891788\nGConvGRU\n5\n200\n\n\n2\nfivenodes\nIT-STGNN\n0.0\nNaN\n2\n12.0\nNaN\n50.0\n0.731600\n114.492592\nGConvGRU\n5\n200\n\n\n3\nfivenodes\nIT-STGNN\n0.0\nNaN\n2\n12.0\nNaN\n50.0\n0.735026\n115.544274\nGConvGRU\n5\n200\n\n\n4\nfivenodes\nSTGNN\n0.0\nNaN\n2\n12.0\nNaN\n50.0\n0.727182\n102.783140\nGConvGRU\n5\n200\n\n\n\n\n\n\n\n\ndf2 = df.assign(model = lambda df: df.model.apply(lambda x: '' if x == \"GNAR\" else x))\\\n.eval('model = method+model')\\\n.assign(model = lambda df: df.model.str.replace(\"STGNN\",\"\"))\ndf2.head()\n\nRecursionError: maximum recursion depth exceeded\n\n\n\nset(df.method)\n\n{'GNAR', 'IT-STGNN', 'STGNN'}\n\n\n\ndef show_experiment_spec(df):\n    df_cols = ['method','mrate','mtype','lags','nof_filters','inter_method','epoch','model']\n    for dataset in df.dataset.unique():\n        print(f'dataset: {dataset}')\n        for col in df_cols: \n            df_query = df[df['dataset'] == dataset]\n            print(f'{col}: {df_query[col].unique().tolist()}')\n        print('---')\n\n- 데이터세트별 실험셋팅\n\nshow_experiment_spec(df)\n\ndataset: fivenodes\nmethod: ['STGNN', 'IT-STGNN', 'GNAR']\nmrate: [0.0, 0.7, 0.8, 0.3, 0.5, 0.6, 0.125]\nmtype: [nan, 'rand', 'block']\nlags: [2]\nnof_filters: [12.0, 4.0, 2.0, nan]\ninter_method: [nan, 'linear']\nepoch: [50.0, nan]\nmodel: ['GConvGRU', 'GConvLSTM', 'GCLSTM', 'DCRNN', 'LRGCN', 'TGCN', 'EvolveGCNO', 'DyGrEncoder', 'EvolveGCNH', 'GNAR']\n---\ndataset: chickenpox\nmethod: ['STGNN', 'IT-STGNN', 'GNAR']\nmrate: [0.0, 0.3, 0.8, 0.5, 0.6, 0.2877697841726618]\nmtype: [nan, 'rand', 'block']\nlags: [4]\nnof_filters: [16.0, 32.0, 8.0, 12.0, nan]\ninter_method: [nan, 'linear']\nepoch: [50.0, nan]\nmodel: ['GConvGRU', 'GConvLSTM', 'GCLSTM', 'DCRNN', 'LRGCN', 'TGCN', 'EvolveGCNO', 'DyGrEncoder', 'EvolveGCNH', 'GNAR']\n---\ndataset: pedalme\nmethod: ['STGNN', 'IT-STGNN', 'GNAR']\nmrate: [0.0, 0.3, 0.6, 0.5, 0.8, 0.2857142857142857]\nmtype: [nan, 'rand', 'block']\nlags: [4]\nnof_filters: [12.0, 2.0, 4.0, 8.0, nan]\ninter_method: [nan, 'nearest', 'linear']\nepoch: [50.0, nan]\nmodel: ['GConvGRU', 'GConvLSTM', 'GCLSTM', 'DCRNN', 'LRGCN', 'TGCN', 'EvolveGCNO', 'DyGrEncoder', 'EvolveGCNH', 'GNAR']\n---\ndataset: wikimath\nmethod: ['STGNN', 'IT-STGNN', 'GNAR']\nmrate: [0.3, 0.8, 0.0, 0.0958699236875407, 0.0038347969475016, 0.5, 0.1198374046094259, 0.6]\nmtype: ['rand', nan, 'block']\nlags: [8]\nnof_filters: [12.0, 64.0, 32.0, nan]\ninter_method: ['linear', nan]\nepoch: [50.0, nan]\nmodel: ['GConvGRU', 'GConvLSTM', 'GCLSTM', 'DCRNN', 'LRGCN', 'TGCN', 'EvolveGCNO', 'DyGrEncoder', 'EvolveGCNH', 'GNAR']\n---\ndataset: windmillsmall\nmethod: ['STGNN', 'IT-STGNN']\nmrate: [0.0, 0.7, 0.0812907673198108]\nmtype: [nan, 'rand', 'block']\nlags: [8]\nnof_filters: [12.0, 16.0, 4.0]\ninter_method: [nan, 'linear']\nepoch: [50.0]\nmodel: ['GConvGRU', 'GConvLSTM', 'GCLSTM', 'DCRNN', 'LRGCN', 'TGCN', 'EvolveGCNO', 'DyGrEncoder', 'EvolveGCNH']\n---\ndataset: monte\nmethod: ['STGNN', 'IT-STGNN', 'GNAR']\nmrate: [0.8, 0.0, 0.1491424310216256, 0.3, 0.5, 0.7]\nmtype: ['rand', nan, 'block']\nlags: [4]\nnof_filters: [12.0, 2.0, 8.0, nan]\ninter_method: ['nearest', nan, 'cubic', 'linear']\nepoch: [50.0, nan]\nmodel: ['GConvGRU', 'GConvLSTM', 'GCLSTM', 'DCRNN', 'LRGCN', 'TGCN', 'EvolveGCNO', 'DyGrEncoder', 'EvolveGCNH', 'GNAR']\n---\n\n\n- 요약\n\ndf_summary = df2.groupby([\"method\",\"dataset\",\"mrate\",\"model\"]).agg({'mse':'mean'}).reset_index()\\\n.pivot_table(index=['model'],columns=['dataset'],values='mse')\ndf_summary\n\nNameError: name 'df2' is not defined\n\n\n\n\n시각화1: MissingRate (본문)\n\nbig = df.query(\"mtype=='rand' or mtype.isna()\").query(\"dataset == 'chickenpox'\").query(\"model == 'GConvLSTM'\")\\\n.sort_values(by='mrate')\\\n.assign(mrate_jittered = lambda df: np.array(df['mrate'])+np.random.randn(len(df['mrate']))*0.01)\nsmall = big.groupby([\"dataset\",\"mrate\",\"method\"]).agg({'mse':np.median}).reset_index().rename({'mse':'mse_median'},axis=1)\ntidydata = big.merge(small)\n#---#\nfig = px.scatter(\n    tidydata,\n    y='mse_median',\n    x='mrate',\n    opacity=0.3,\n    color='method',\n    width=425,\n    height=425,\n    hover_data='mrate',\n)\nfig.data[0]['mode']='markers+lines'\nfig.data[0]['marker']['size'] = 6\nfig.data[0]['line']['width'] = 1.5\nfig.data[0]['line']['dash'] = 'dashdot'\nfig.data[1]['mode']='markers+lines'\nfig.data[1]['marker']['size'] = 6\nfig.data[1]['line']['width'] =1.5\nfig.data[1]['line']['dash'] = 'dashdot'\nbox1 = px.box(\n    tidydata.query(\"method=='STGNN'\"),\n    y='mse',\n    x='mrate',\n)\nbox1.data[0]['opacity']=0.5\nbox1.data[0]['marker']['color']='#636efa'\nbox2 = px.box(\n    tidydata.query(\"method=='IT-STGNN'\"),\n    y='mse',\n    x='mrate',\n)\nbox2.data[0]['opacity']=0.5\nbox2.data[0]['marker']['color']='#EF553B'\nfig.add_traces(box1.data)\nfig.add_traces(box2.data)\nfig.data[0]['showlegend'] =False\nfig.data[1]['showlegend'] =False\nfig.layout['xaxis']['title']['text']='Missign Rate'\nfig.layout['yaxis']['title']['text']='MSE'\nfig.layout['legend']['title']['text']=\"\"\nfig.layout['title']['text']='Chickenpox/GConvLSTM'\nfig\n\nValueError: Value of 'hover_data_0' is not the name of a column in 'data_frame'. Expected one of ['dataset', 'method', 'mrate', 'mtype', 'lags', 'nof_filters', 'inter_method', 'epoch', 'mse', 'calculation_time', 'model', 'node', 'time', 'mrate_jittered', 'mse_median'] but received: m\n\n\n\n\n시각화2: MissingRate (부록)\n\ntidydata = df.query(\"mtype!='block'\").query(\"method!='GNAR'\").query(\"dataset != 'fivenodes'\")\\\n.groupby([\"method\",\"dataset\",\"mrate\",\"model\"]).agg({'mse':'mean'}).reset_index()\n#---#\nfig = px.line(\n    tidydata,\n    x='mrate',\n    y='mse',\n    color='method',\n    facet_row='model',\n    facet_col='dataset',\n    width=850,\n    height=1000,\n    \n)\nfor scatter in fig.data:\n    scatter['mode'] = 'lines+markers'\n    scatter['line']['dash'] = 'dashdot'\nfor annotation in fig.layout['annotations']:\n    annotation['text'] = annotation['text'].replace('dataset=','')\n    annotation['text'] = annotation['text'].replace('model=','')\nfor k in [k for k in fig.layout if 'xaxis' in k]:\n    fig.layout[k]['title']['text'] = None \nfor k in [k for k in fig.layout if 'yaxis' in k]:\n    fig.layout[k]['title']['text'] = None \nfig.update_yaxes(showticklabels=True,matches=None)\nfig.update_xaxes(showticklabels=True,matches=None)\n\n                                                \n\n\n\n\n시각화3\n\ndef func(x):\n    if 'IT' in x:\n        return 'IT-STGNN'\n    elif 'GNAR' in x:\n        return 'GNAR'\n    else: \n        return 'STGNN'\n\n\ntidydata = df2.query('mtype != \"block\"').query('method!=\"GNAR\"').groupby([\"method\",\"dataset\",\"mrate\",\"model\"]).agg({'mse':'mean'}).reset_index()\\\n.pivot_table(index=['model'],columns=['dataset'],values='mse').stack().reset_index().rename({0:'mse'},axis=1).assign(\n    method = lambda df: df['model'].apply(func)\n)\ntidydata = pd.concat([df.sort_values('mse').reset_index(drop=True).reset_index() for _,df in tidydata.groupby(\"dataset\")])\n#---#\nfig = px.bar(\n    tidydata,\n    x='index',\n    y='mse',\n    color='method',\n    facet_col='dataset',\n    facet_col_wrap=2,\n    text='model',\n    height=800\n)\nfig\n\nNameError: name 'df2' is not defined\n\n\n\n\n시각화4\n\ntidydata = df.query('mtype != \"block\"').query('dataset != \"fivenodes\"')\\\n.groupby([\"method\",\"dataset\",\"node\",\"time\"]).agg({'mse':'mean'}).reset_index()\\\n.assign(ratio = lambda df: df['time']/df['node'])\\\n.pivot_table(index=['dataset','ratio'] ,columns=['method'],values='mse')\\\n.assign(mse_diff = lambda df: df['STGNN']- df['IT-STGNN']).loc[:,'mse_diff']\\\n.reset_index()\ntidydata\nfig = px.scatter(\n    tidydata,\n    x='ratio',\n    log_x=True,\n    y='mse_diff',\n    text='dataset',\n    width=625,\n    height=425,\n)\nfig.data[0]['textposition'] = ['top right']*3 + ['bottom right'] + ['top left']\nfig.data[0]['marker']['size'] = 8\nfig\n\n                                                \n\n\n\n\n시각화5\n\ntidydata = df.assign(mtype = df['mtype'].fillna(\"rand\"))\\\n.query('method != \"GNAR\"').query('dataset != \"windmillsmall\"').query('dataset != \"wikimath\"')\\\n.groupby([\"method\",\"dataset\",\"mtype\",\"mrate\"]).agg({'mse':'mean'}).reset_index()\\\n.sort_values('mrate')\\\n.assign(mrate = lambda df: df['mrate'].apply(lambda x: f'{x:.3f}'))\n#---#\nfig = px.bar(\n    tidydata,\n    x='mrate',\n    y='mse',\n    color='method',\n    facet_col='dataset',\n    facet_col_wrap=2,    \n    width=850,\n    height=650,\n    barmode='group',\n    hover_data='mtype',\n    opacity=0.2\n)\nfig.update_yaxes(showticklabels=True,matches=None)\nfig.update_xaxes(showticklabels=True,matches=None)\nfor trace in fig.data:\n    trace['marker']['opacity']=[0.2, 1, 0.2, 0.2, 0.2, 0.2, 0.2]\nfig\n\nValueError: Value of 'hover_data_0' is not the name of a column in 'data_frame'. Expected one of ['method', 'dataset', 'mtype', 'mrate', 'mse'] but received: m"
  },
  {
    "objectID": "연구/서연이랑/ITSTGCN/2022-12-29-Tutorial.html",
    "href": "연구/서연이랑/ITSTGCN/2022-12-29-Tutorial.html",
    "title": "(연구&서연) IT-STGCN – Tutorial",
    "section": "",
    "text": "- 이 문서는 공식홈페이지의 예제와 최서연학생의 블로그 내용을 재구성하여 만듬\n- 이 문서의 목표는 아래와 같다.\n\nSTGCN을 사용할 수 있는 데이터의 형태를 탐구한다.\nSTGCN을 실습할 코드를 확보한다.\n\n- 코랩에서 실습하기 위해서는 아래를 설치해야한다.\n\n!pip install torch-geometric\n!pip install torch-geometric-temporal"
  },
  {
    "objectID": "연구/서연이랑/ITSTGCN/2022-12-29-Tutorial.html#pyg-의-data-자료형",
    "href": "연구/서연이랑/ITSTGCN/2022-12-29-Tutorial.html#pyg-의-data-자료형",
    "title": "(연구&서연) IT-STGCN – Tutorial",
    "section": "PyG 의 Data 자료형",
    "text": "PyG 의 Data 자료형\n\nref: https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html#data-handling-of-graphs\n\n- 자료는 PyG의 Data 오브젝트를 기반으로 한다.\n(예제) 아래와 같은 그래프자료를 고려하자.\n\n이러한 자료형은 아래와 같은 형식으로 저장한다.\n\nedge_index = torch.tensor([[0, 1, 1, 2],\n                           [1, 0, 2, 1]], dtype=torch.long)\nx = torch.tensor([[-1], [0], [1]], dtype=torch.float)\ndata = Data(x=x, edge_index=edge_index) # Data는 그래프자료형을 만드는 클래스\n\n\ntype(data)\n\ntorch_geometric.data.data.Data\n\n\n\ndata.x\n\ntensor([[-1.],\n        [ 0.],\n        [ 1.]])\n\n\n\ndata.edge_index\n\ntensor([[0, 1, 1, 2],\n        [1, 0, 2, 1]])"
  },
  {
    "objectID": "연구/서연이랑/ITSTGCN/2022-12-29-Tutorial.html#pytorch-geometric-temporal-의-자료형",
    "href": "연구/서연이랑/ITSTGCN/2022-12-29-Tutorial.html#pytorch-geometric-temporal-의-자료형",
    "title": "(연구&서연) IT-STGCN – Tutorial",
    "section": "PyTorch Geometric Temporal 의 자료형",
    "text": "PyTorch Geometric Temporal 의 자료형\n\nref: PyTorch Geometric Temporal Signal\n\n아래의 클래스들중 하나를 이용하여 만든다.\n## Temporal Signal Iterators\ntorch_geometric_temporal.signal.StaticGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphStaticSignal\n## Heterogeneous Temporal Signal Iterators\ntorch_geometric_temporal.signal.StaticHeteroGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicHeteroGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicHeteroGraphStaticSignal\n이중 “Heterogeneous Temporal Signal” 은 우리가 관심이 있는 신호가 아니므로 사실상 아래의 3개만 고려하면 된다.\n\ntorch_geometric_temporal.signal.StaticGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphStaticSignal\n\n여기에서 StaticGraphTemporalSignal 는 시간에 따라서 그래프 구조가 일정한 경우, 즉 \\({\\cal G}_t=\\{{\\cal V},{\\cal E}\\}\\)와 같은 구조를 의미한다.\n(예제1) StaticGraphTemporalSignal 를 이용하여 데이터 셋 만들기\n- json data \\(\\to\\) dict\n\nimport json\nimport urllib\n\n\nurl = \"https://raw.githubusercontent.com/benedekrozemberczki/pytorch_geometric_temporal/master/dataset/chickenpox.json\"\ndata_dict = json.loads(urllib.request.urlopen(url).read())\n# data_dict 출력이 김\n\n\ndata_dict.keys()\n\ndict_keys(['edges', 'node_ids', 'FX'])\n\n\n- 살펴보기\n\nnp.array(data_dict['edges']).T\n\narray([[ 0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  2,  2,  2,  2,  3,\n         3,  3,  3,  3,  3,  4,  4,  5,  5,  5,  5,  6,  6,  6,  6,  6,\n         6,  6,  7,  7,  7,  7,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,\n        10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 12, 12, 12,\n        12, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 15,\n        15, 15, 16, 16, 16, 16, 16, 17, 17, 17, 17, 18, 18, 18, 18, 18,\n        18, 18, 19, 19, 19, 19],\n       [10,  6, 13,  1,  0,  5, 16,  0, 16,  1, 14, 10,  8,  2,  5,  8,\n        15, 12,  9, 10,  3,  4, 13,  0, 10,  2,  5,  0, 16,  6, 14, 13,\n        11, 18,  7, 17, 11, 18,  3,  2, 15,  8, 10,  9, 13,  3, 12, 10,\n         5,  9,  8,  3, 10,  2, 13,  0,  6, 11,  7, 13, 18,  3,  9, 13,\n        12, 13,  9,  6,  4, 12,  0, 11, 10, 18, 19,  1, 14,  6, 16,  3,\n        15,  8, 16, 14,  1,  0,  6,  7, 19, 17, 18, 14, 18, 17,  7,  6,\n        19, 11, 18, 14, 19, 17]])\n\n\n\n\\({\\cal E} = \\{(0,10),(0,6), \\dots, (19,17)\\}\\)\n혹은 \\({\\cal E} = \\{(\\tt{BACS},\\tt{JASZ}), ({\\tt BACS},{\\tt FEJER}), \\dots, (\\tt{ZALA},\\tt{VAS})\\}\\)\n\n\ndata_dict['node_ids']\n\n{'BACS': 0,\n 'BARANYA': 1,\n 'BEKES': 2,\n 'BORSOD': 3,\n 'BUDAPEST': 4,\n 'CSONGRAD': 5,\n 'FEJER': 6,\n 'GYOR': 7,\n 'HAJDU': 8,\n 'HEVES': 9,\n 'JASZ': 10,\n 'KOMAROM': 11,\n 'NOGRAD': 12,\n 'PEST': 13,\n 'SOMOGY': 14,\n 'SZABOLCS': 15,\n 'TOLNA': 16,\n 'VAS': 17,\n 'VESZPREM': 18,\n 'ZALA': 19}\n\n\n\n\\({\\cal V}=\\{\\tt{BACS},\\tt{BARANYA} \\dots, \\tt{ZALA}\\}\\)\n\n\nnp.array(data_dict['FX']), np.array(data_dict['FX']).shape\n\n(array([[-1.08135724e-03, -7.11136085e-01, -3.22808515e+00, ...,\n          1.09445310e+00, -7.08747750e-01, -1.82280792e+00],\n        [ 2.85705967e-02, -5.98430173e-01, -2.29097341e-01, ...,\n         -1.59220988e+00, -2.24597623e-01,  7.86330575e-01],\n        [ 3.54742090e-01,  1.90511208e-01,  1.61028185e+00, ...,\n          1.38183225e-01, -7.08747750e-01, -5.61724314e-01],\n        ...,\n        [-4.75512620e-01, -1.19952837e+00, -3.89043358e-01, ...,\n         -1.00023329e+00, -1.71429032e+00,  4.70746677e-02],\n        [-2.08645035e-01,  6.03766218e-01,  1.08216835e-02, ...,\n          4.71099041e-02,  2.45684924e+00, -3.44296107e-01],\n        [ 1.21464875e+00,  7.16472130e-01,  1.29038982e+00, ...,\n          4.56939849e-01,  7.43702632e-01,  1.00375878e+00]]),\n (521, 20))\n\n\n\n\\({\\bf f}=\\begin{bmatrix} {\\bf f}_1\\\\ {\\bf f}_2\\\\ \\dots \\\\ {\\bf f}_{521} \\end{bmatrix}=\\begin{bmatrix} f(t=1,v=\\tt{BACS}) & \\dots & f(t=1,v=\\tt{ZALA}) \\\\ f(t=2,v=\\tt{BACS}) & \\dots & f(t=2,v=\\tt{ZALA}) \\\\ \\dots & \\dots & \\dots \\\\ f(t=521,v=\\tt{BACS}) & \\dots & f(t=521,v=\\tt{ZALA}) \\end{bmatrix}\\)\n\n즉 data_dict는 아래와 같이 구성되어 있음\n\n\n\n\n\n\n\n\n\n\n수학 기호\n코드에 저장된 변수\n자료형\n차원\n설명\n\n\n\n\n\\({\\cal V}\\)\ndata_dict['node_ids']\ndict\n20\n20개의 노드에 대한 설명이 있음\n\n\n\\({\\cal E}\\)\ndata_dict['edges']\nlist (double list)\n(102,2)\n노드들에 대한 102개의 연결을 정의함\n\n\n\\({\\bf f}\\)\ndata_dict['node_ids']\ndict\n(521,20)\n\\(f(t,v)\\) for \\(v \\in {\\cal V}\\) and \\(t = 1,\\dots, T\\)\n\n\n\n- 주어진 자료를 정리하여 그래프신호 \\(\\big(\\{{\\cal V},{\\cal E},{\\bf W}\\},{\\bf f}\\big)\\)를 만들면 아래와 같다.\n\nedges = np.array(data_dict[\"edges\"]).T\nedge_weight = np.ones(edges.shape[1])\nf = np.array(data_dict[\"FX\"])\n\n\n여기에서 edges는 \\({\\cal E}\\)에 대한 정보를\nedges_weight는 \\({\\bf W}\\)에 대한 정보를\nf는 \\({\\bf f}\\)에 대한 정보를 저장한다.\n\n\nNote: 이때 \\({\\bf W}={\\bf E}\\) 로 정의한다. (하지만 꼭 이래야 하는건 아니야)\n\n- data_dict \\(\\to\\) dl\n\nlags = 4\nfeatures = [f[i : i + lags, :].T for i in range(f.shape[0] - lags)]\ntargets = [f[i + lags, :].T for i in range(f.shape[0] - lags)]\n\n\nnp.array(features).shape, np.array(targets).shape\n\n((517, 20, 4), (517, 20))\n\n\n\n\n\n\n\n\n\n설명변수\n반응변수\n\n\n\n\n\\({\\bf X} = {\\tt features} = \\begin{bmatrix} {\\bf f}_1 & {\\bf f}_2 & {\\bf f}_3 & {\\bf f}_4 \\\\ {\\bf f}_2 & {\\bf f}_3 & {\\bf f}_4 & {\\bf f}_5 \\\\ \\dots & \\dots & \\dots & \\dots \\\\ {\\bf f}_{517} & {\\bf f}_{518} & {\\bf f}_{519} & {\\bf f}_{520} \\end{bmatrix}\\)\n\\({\\bf y}= {\\tt targets} = \\begin{bmatrix} {\\bf f}_5 \\\\ {\\bf f}_6 \\\\ \\dots \\\\ {\\bf f}_{521} \\end{bmatrix}\\)\n\n\n\n\nAR 느낌으로 표현하면 AR(4) 임\n\n\ndataset = torch_geometric_temporal.signal.StaticGraphTemporalSignal(\n    edge_index= edges,\n    edge_weight = edge_weight,\n    features = features,\n    targets = targets\n)\n\n\ndataset\n\n&lt;torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal at 0x7faad2716a60&gt;\n\n\n- 그런데 이 과정을 아래와 같이 할 수도 있음\n# PyTorch Geometric Temporal 공식홈페이지에 소개된 코드\nloader = torch_geometric_temporal.dataset.ChickenpoxDatasetLoader()\ndataset=loader.get_dataset(lags=4)\n- dataset은 dataset[0], \\(\\dots\\) , dataset[516]과 같은 방식으로 각 시점별 자료에 접근가능\n\ndataset[0]\n\nData(x=[20, 4], edge_index=[2, 102], edge_attr=[102], y=[20])\n\n\n각 시점에 대한 자료형은 아까 살펴보았던 PyG의 Data 자료형과 같음\n\ntype(dataset[0])\n\ntorch_geometric.data.data.Data\n\n\n\ndataset[0].x \n\ntensor([[-1.0814e-03,  2.8571e-02,  3.5474e-01,  2.9544e-01],\n        [-7.1114e-01, -5.9843e-01,  1.9051e-01,  1.0922e+00],\n        [-3.2281e+00, -2.2910e-01,  1.6103e+00, -1.5487e+00],\n        [ 6.4750e-01, -2.2117e+00, -9.6858e-01,  1.1862e+00],\n        [-1.7302e-01, -9.4717e-01,  1.0347e+00, -6.3751e-01],\n        [ 3.6345e-01, -7.5468e-01,  2.9768e-01, -1.6273e-01],\n        [-3.4174e+00,  1.7031e+00, -1.6434e+00,  1.7434e+00],\n        [-1.9641e+00,  5.5208e-01,  1.1811e+00,  6.7002e-01],\n        [-2.2133e+00,  3.0492e+00, -2.3839e+00,  1.8545e+00],\n        [-3.3141e-01,  9.5218e-01, -3.7281e-01, -8.2971e-02],\n        [-1.8380e+00, -5.8728e-01, -3.5514e-02, -7.2298e-02],\n        [-3.4669e-01, -1.9827e-01,  3.9540e-01, -2.4774e-01],\n        [ 1.4219e+00, -1.3266e+00,  5.2338e-01, -1.6374e-01],\n        [-7.7044e-01,  3.2872e-01, -1.0400e+00,  3.4945e-01],\n        [-7.8061e-01, -6.5022e-01,  1.4361e+00, -1.2864e-01],\n        [-1.0993e+00,  1.2732e-01,  5.3621e-01,  1.9023e-01],\n        [ 2.4583e+00, -1.7811e+00,  5.0732e-02, -9.4371e-01],\n        [ 1.0945e+00, -1.5922e+00,  1.3818e-01,  1.1855e+00],\n        [-7.0875e-01, -2.2460e-01, -7.0875e-01,  1.5630e+00],\n        [-1.8228e+00,  7.8633e-01, -5.6172e-01,  1.2647e+00]])\n\n\n\n이 값들은 features[0]의 값들과 같음. 즉 \\([{\\bf f}_1~ {\\bf f}_2~ {\\bf f}_3~ {\\bf f}_4]\\)를 의미함\n\n\ndataset[0].y\n\ntensor([ 0.7106, -0.0725,  2.6099,  1.7870,  0.8024, -0.2614, -0.8370,  1.9674,\n        -0.4212,  0.1655,  1.2519,  2.3743,  0.7877,  0.4531, -0.1721, -0.0614,\n         1.0452,  0.3203, -1.3791,  0.0036])\n\n\n\n이 값들은 targets[0]의 값들과 같음. 즉 \\({\\bf f}_5\\)를 의미함"
  },
  {
    "objectID": "연구/서연이랑/ITSTGCN/2022-12-29-Tutorial.html#summary-of-data",
    "href": "연구/서연이랑/ITSTGCN/2022-12-29-Tutorial.html#summary-of-data",
    "title": "(연구&서연) IT-STGCN – Tutorial",
    "section": "summary of data",
    "text": "summary of data\n\n\\(T\\) = 519\n\\(N\\) = 20 # number of nodes\n\\(|{\\cal E}|\\) = 102 # edges\n\\(f(t,v)\\)의 차원? (1,)\n시간에 따라서 Number of nodes가 변하는지? False\n시간에 따라서 Number of nodes가 변하는지? False\n\\({\\bf X}\\): (20,4)\n\\({\\bf y}\\): (20,)\n예제코드적용가능여부: Yes\n\n- Nodes : 20\n\nvertices are counties\n\n-Edges : 102\n\nedges are neighbourhoods\n\n- Time : 519\n\nbetween 2004 and 2014\nper weeks\n\n\nloader = torch_geometric_temporal.dataset.ChickenpoxDatasetLoader()\ndataset = loader.get_dataset(lags=4)\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)"
  },
  {
    "objectID": "연구/서연이랑/ITSTGCN/2022-12-29-Tutorial.html#learn",
    "href": "연구/서연이랑/ITSTGCN/2022-12-29-Tutorial.html#learn",
    "title": "(연구&서연) IT-STGCN – Tutorial",
    "section": "learn",
    "text": "learn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for t, snapshot in enumerate(train_dataset):\n        yt_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((yt_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [01:16&lt;00:00,  1.52s/it]\n\n\n\ndataset.features[0].shape\n\n(20, 4)"
  },
  {
    "objectID": "연구/서연이랑/ITSTGCN/2022-12-29-Tutorial.html#visualization",
    "href": "연구/서연이랑/ITSTGCN/2022-12-29-Tutorial.html#visualization",
    "title": "(연구&서연) IT-STGCN – Tutorial",
    "section": "visualization",
    "text": "visualization\n\nmodel.eval()\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)\n\n\n\nyhat_train = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in train_dataset]).detach().numpy()\nyhat_test = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in test_dataset]).detach().numpy()\n\n\nV = list(data_dict['node_ids'].keys())\n\n\nfig,ax = plt.subplots(20,1,figsize=(10,50))\nfor k in range(20):\n    ax[k].plot(f[:,k],'--',alpha=0.5,label='observed')\n    ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_train[:,k],label='predicted (tr)')\n    ax[k].plot(range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0]),yhat_test[:,k],label='predicted (test)')\n    ax[k].legend()\nfig.tight_layout()"
  },
  {
    "objectID": "연구/지윤이랑/SOLAR/2023-04-04-(연구&지윤) 태양광자료분석 -- EPT.html",
    "href": "연구/지윤이랑/SOLAR/2023-04-04-(연구&지윤) 태양광자료분석 -- EPT.html",
    "title": "(연구&지윤) 태양광자료분석",
    "section": "",
    "text": "ref: https://www.sciencedirect.com/science/article/pii/S2352711021000492\n\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(EPT)\n\n\nurl = 'https://raw.githubusercontent.com/miruetoto/yechan3/main/posts/3_Researches/SOLAR/solar_radiation.csv'\ndf = read_csv(url)\n\nRows: 803000 Columns: 3\n── Column specification ────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): region, date\ndbl (1): solar_radiation\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\ndf = df |&gt; filter(region == '북춘천') |&gt; mutate(date=ymd_hm(date))\ndf\n\n\nA tibble: 18250 × 3\n\n\nregion\nsolar_radiation\ndate\n\n\n&lt;chr&gt;\n&lt;dbl&gt;\n&lt;dttm&gt;\n\n\n\n\n북춘천\n0.00\n2021-01-01 00:00:00\n\n\n북춘천\n0.00\n2021-01-01 01:00:00\n\n\n북춘천\n0.00\n2021-01-01 02:00:00\n\n\n북춘천\n0.00\n2021-01-01 03:00:00\n\n\n북춘천\n0.00\n2021-01-01 04:00:00\n\n\n북춘천\n0.00\n2021-01-01 05:00:00\n\n\n북춘천\n0.00\n2021-01-01 06:00:00\n\n\n북춘천\n0.00\n2021-01-01 07:00:00\n\n\n북춘천\n0.00\n2021-01-01 08:00:00\n\n\n북춘천\n0.37\n2021-01-01 09:00:00\n\n\n북춘천\n0.96\n2021-01-01 10:00:00\n\n\n북춘천\n1.40\n2021-01-01 11:00:00\n\n\n북춘천\n1.72\n2021-01-01 12:00:00\n\n\n북춘천\n1.84\n2021-01-01 13:00:00\n\n\n북춘천\n1.74\n2021-01-01 14:00:00\n\n\n북춘천\n1.30\n2021-01-01 15:00:00\n\n\n북춘천\n0.93\n2021-01-01 16:00:00\n\n\n북춘천\n0.29\n2021-01-01 17:00:00\n\n\n북춘천\n0.01\n2021-01-01 18:00:00\n\n\n북춘천\n0.00\n2021-01-01 19:00:00\n\n\n북춘천\n0.00\n2021-01-01 07:00:00\n\n\n북춘천\n0.00\n2021-01-01 20:00:00\n\n\n북춘천\n0.00\n2021-01-01 06:00:00\n\n\n북춘천\n0.00\n2021-01-01 21:00:00\n\n\n북춘천\n0.00\n2021-01-01 05:00:00\n\n\n북춘천\n0.00\n2021-01-02 00:00:00\n\n\n북춘천\n0.00\n2021-01-02 01:00:00\n\n\n북춘천\n0.00\n2021-01-02 02:00:00\n\n\n북춘천\n0.00\n2021-01-02 03:00:00\n\n\n북춘천\n0.00\n2021-01-02 04:00:00\n\n\n⋮\n⋮\n⋮\n\n\n북춘천\n0.00\n2022-12-30 07:00:00\n\n\n북춘천\n0.00\n2022-12-30 20:00:00\n\n\n북춘천\n0.00\n2022-12-30 06:00:00\n\n\n북춘천\n0.00\n2022-12-30 21:00:00\n\n\n북춘천\n0.00\n2022-12-30 05:00:00\n\n\n북춘천\n0.00\n2022-12-31 00:00:00\n\n\n북춘천\n0.00\n2022-12-31 01:00:00\n\n\n북춘천\n0.00\n2022-12-31 02:00:00\n\n\n북춘천\n0.00\n2022-12-31 03:00:00\n\n\n북춘천\n0.00\n2022-12-31 04:00:00\n\n\n북춘천\n0.00\n2022-12-31 05:00:00\n\n\n북춘천\n0.00\n2022-12-31 06:00:00\n\n\n북춘천\n0.00\n2022-12-31 07:00:00\n\n\n북춘천\n0.00\n2022-12-31 08:00:00\n\n\n북춘천\n0.22\n2022-12-31 09:00:00\n\n\n북춘천\n0.50\n2022-12-31 10:00:00\n\n\n북춘천\n0.80\n2022-12-31 11:00:00\n\n\n북춘천\n2.13\n2022-12-31 12:00:00\n\n\n북춘천\n1.78\n2022-12-31 13:00:00\n\n\n북춘천\n1.45\n2022-12-31 14:00:00\n\n\n북춘천\n0.78\n2022-12-31 15:00:00\n\n\n북춘천\n0.38\n2022-12-31 16:00:00\n\n\n북춘천\n0.15\n2022-12-31 17:00:00\n\n\n북춘천\n0.00\n2022-12-31 18:00:00\n\n\n북춘천\n0.00\n2022-12-31 19:00:00\n\n\n북춘천\n0.00\n2022-12-31 07:00:00\n\n\n북춘천\n0.00\n2022-12-31 20:00:00\n\n\n북춘천\n0.00\n2022-12-31 06:00:00\n\n\n북춘천\n0.00\n2022-12-31 21:00:00\n\n\n북춘천\n0.00\n2022-12-31 05:00:00\n\n\n\n\n\n- 지역을 북춘천으로 고정\n\ndf2 = df |&gt; filter(region =='북춘천') \ndf2 = df2[order(df2$date),]\n\n\ny = df2$solar_radiation\ny\n\n\n0000000000000.370.961.41.721.841.741.30.930.290.010000000000000000.320.951.461.791.911.821.50.970.370.010000000000000000.290.891.41.751.761.350.820.520.30.010000000000000000.330.931.321.531.671.5110.790.1900000000000000000.190.791.411.761.931.851.561.050.450.020000000000000000.511.381.811.881.931.851.5210.410.020000000000000000.110.741.441.811.981.911.611.090.450.020000000000000000.360.971.491.8521.911.611.10.480.03000⋯000000000000.010.471.31.711.871.881.721.380.880.3200000000000000000.190.681.351.712.191.891.380.820.2600000000000000000.150.420.931.071.181.051.160.830.300000000000000000.080.280.430.741.41.841.530.850.2700000000000000000.411.021.841.921.851.721.420.930.340.010000000000000000.471.281.681.81.851.741.40.890.30.010000000000000000.150.641.11.732.121.741.290.860.310.010000000000000000.220.50.82.131.781.450.780.380.150000\n\n\n\nplot(y[1:500])\nlines(y[1:500],lty=2)\n\n\n\n\n\n\n\n\n- EPT 수행\n\nept = function(y){\n    EpM = eptransf(signal=y,tau=24,process=c(\"envelope\",\"average\"))$EpM\n    EpM*2\n}\n\n\nyU = ept(y)\n\n\nplot(y[1:500])\nlines(yU[1:500],col=2,lty=2)\n\n\n\n\n\n\n\n\n- todo: 모든 지역에대하여 yU를 구하여 저장"
  },
  {
    "objectID": "연구/지윤이랑/SOLAR/2023-07-20-(연구&지윤) 태양광자료분석 -- EPT + RGCN (시뮬레이션).html",
    "href": "연구/지윤이랑/SOLAR/2023-07-20-(연구&지윤) 태양광자료분석 -- EPT + RGCN (시뮬레이션).html",
    "title": "(연구&지윤) 태양광자료분석 – EPT + RGCN (시뮬레이션)",
    "section": "",
    "text": "%run 0807.py\n\n\nimport os\n\n\ns=Simulator()\n\n\nclass GConv_GRU(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(GConv_GRU, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n        \ns.simulate(\n    n_iteration = 1,\n    lags = [1],\n    filters = [4,6],\n    epoch = [1],\n    Model = GConv_GRU\n)\n\nmethod:classic lag:1 filters:4 epoch:1 is done\nmethod:classic lag:1 filters:6 epoch:1 is done\nmethod:proposed lag:1 filters:4 epoch:1 is done\nmethod:proposed lag:1 filters:6 epoch:1 is done\nsave results\n\n\n\nfnames = ['./results/'+l for l in os.listdir('./results/') if l[0] != '.']\nfnames \n\n['./results/SOLAR_2023-08-07 16:12:29.037623.csv',\n './results/SOLAR_2023-08-07 15:48:50.109743.csv',\n './results/SOLAR_2023-08-07 16:08:41.687843.csv',\n './results/SOLAR_2023-08-07 15:48:25.728993.csv',\n './results/SOLAR_2023-08-07 16:28:55.929269.csv']\n\n\n\npd.concat([pd.read_csv(fname) for fname in fnames]).reset_index(drop=True)\n\n\n\n\n\n\n\n\nindex_time\nmse_mean\nmodel\nmethod\nlags\nnof_filters\nepoch\ncalculation_time\nnode\nmse\n\n\n\n\n0\n2023-08-07 16:11:11.072667\n0.419854\nRecurrentGCN\nclassic\n1\n4\n1\n15.519606\nBukchoncheon\n0.491867\n\n\n1\n2023-08-07 16:11:11.072667\n0.419854\nRecurrentGCN\nclassic\n1\n4\n1\n15.519606\nCheorwon\n0.474034\n\n\n2\n2023-08-07 16:11:11.072667\n0.419854\nRecurrentGCN\nclassic\n1\n4\n1\n15.519606\nDaegwallyeong\n0.468020\n\n\n3\n2023-08-07 16:11:11.072667\n0.419854\nRecurrentGCN\nclassic\n1\n4\n1\n15.519606\nChuncheon\n0.433953\n\n\n4\n2023-08-07 16:11:11.072667\n0.419854\nRecurrentGCN\nclassic\n1\n4\n1\n15.519606\nBaengnyeongdo\n0.620410\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n875\n2023-08-07 16:28:55.924567\n0.139105\nGConvGRU\nproposed\n1\n6\n1\n30.982189\nUiryeong-gun\n0.140765\n\n\n876\n2023-08-07 16:28:55.924567\n0.139105\nGConvGRU\nproposed\n1\n6\n1\n30.982189\nHamyang-gun\n0.122213\n\n\n877\n2023-08-07 16:28:55.924567\n0.139105\nGConvGRU\nproposed\n1\n6\n1\n30.982189\nGwangyang-si\n0.144140\n\n\n878\n2023-08-07 16:28:55.924567\n0.139105\nGConvGRU\nproposed\n1\n6\n1\n30.982189\nCheongsong-gun\n0.143174\n\n\n879\n2023-08-07 16:28:55.924567\n0.139105\nGConvGRU\nproposed\n1\n6\n1\n30.982189\nGyeongju-si\n0.109372\n\n\n\n\n880 rows × 10 columns"
  },
  {
    "objectID": "연구/지윤이랑/SOLAR/2023-04-03-(연구&지윤) 태양광자료분석 -- 일사량자료정리.html",
    "href": "연구/지윤이랑/SOLAR/2023-04-03-(연구&지윤) 태양광자료분석 -- 일사량자료정리.html",
    "title": "(연구&지윤) 태양광자료분석 – 일사량자료정리",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport itertools\n\n\ndf0 = pd.read_csv('https://raw.githubusercontent.com/pinkocto/noteda/main/posts/data/OBS_ASOS_TIM_data0.csv', encoding='cp949') # 2021-01-01 ~ 2021-12-31\ndf1 = pd.read_csv('https://raw.githubusercontent.com/pinkocto/noteda/main/posts/data/OBS_ASOS_TIM_data1.csv') # 2022-01-01 ~ 2023-12-31\ndf2 = pd.read_csv('https://raw.githubusercontent.com/pinkocto/noteda/main/posts/data/test_raw.csv', encoding='cp949') # 2023-01-01 ~ 2023-01-15\n\n- df_raw\n\ndf_raw = pd.concat([df0, df1])\ndf_raw\n\n\n\n\n\n\n\n\n지점\n지점명\n일시\n일사(MJ/m2)\n\n\n\n\n0\n93\n북춘천\n2021-01-01 08:00\n0.00\n\n\n1\n93\n북춘천\n2021-01-01 09:00\n0.37\n\n\n2\n93\n북춘천\n2021-01-01 10:00\n0.96\n\n\n3\n93\n북춘천\n2021-01-01 11:00\n1.40\n\n\n4\n93\n북춘천\n2021-01-01 12:00\n1.72\n\n\n...\n...\n...\n...\n...\n\n\n229672\n283\n경주시\n2022-12-31 14:00:00\n1.82\n\n\n229673\n283\n경주시\n2022-12-31 15:00:00\n1.52\n\n\n229674\n283\n경주시\n2022-12-31 16:00:00\n0.96\n\n\n229675\n283\n경주시\n2022-12-31 17:00:00\n0.35\n\n\n229676\n283\n경주시\n2022-12-31 18:00:00\n0.01\n\n\n\n\n444720 rows × 4 columns\n\n\n\n- 지점칼럼 삭제 // 일시 \\(\\to\\) 날짜,시간 으로 분리\n\ndf_temp = df_raw.assign(날짜= list(map(lambda x: x[:10],df_raw['일시'])))\\\n.assign(시간= list(map(lambda x: x[11:16],df_raw['일시'])))\\\n.drop(['일시','지점'],axis=1).rename({'일사(MJ/m2)':'일사'},axis=1).reset_index(drop=True)\ndf_temp\n\n\n\n\n\n\n\n\n지점명\n일사\n날짜\n시간\n\n\n\n\n0\n북춘천\n0.00\n2021-01-01\n08:00\n\n\n1\n북춘천\n0.37\n2021-01-01\n09:00\n\n\n2\n북춘천\n0.96\n2021-01-01\n10:00\n\n\n3\n북춘천\n1.40\n2021-01-01\n11:00\n\n\n4\n북춘천\n1.72\n2021-01-01\n12:00\n\n\n...\n...\n...\n...\n...\n\n\n444715\n경주시\n1.82\n2022-12-31\n14:00\n\n\n444716\n경주시\n1.52\n2022-12-31\n15:00\n\n\n444717\n경주시\n0.96\n2022-12-31\n16:00\n\n\n444718\n경주시\n0.35\n2022-12-31\n17:00\n\n\n444719\n경주시\n0.01\n2022-12-31\n18:00\n\n\n\n\n444720 rows × 4 columns\n\n\n\n- 파주,상주,동두천,충주,제천은 삭제\n\ndf_temp = df_temp.query(\"지점명 not in ['파주','상주','동두천','충주','제천']\").reset_index(drop=True)\ndf_temp\n\n\n\n\n\n\n\n\n지점명\n일사\n날짜\n시간\n\n\n\n\n0\n북춘천\n0.00\n2021-01-01\n08:00\n\n\n1\n북춘천\n0.37\n2021-01-01\n09:00\n\n\n2\n북춘천\n0.96\n2021-01-01\n10:00\n\n\n3\n북춘천\n1.40\n2021-01-01\n11:00\n\n\n4\n북춘천\n1.72\n2021-01-01\n12:00\n\n\n...\n...\n...\n...\n...\n\n\n420955\n경주시\n1.82\n2022-12-31\n14:00\n\n\n420956\n경주시\n1.52\n2022-12-31\n15:00\n\n\n420957\n경주시\n0.96\n2022-12-31\n16:00\n\n\n420958\n경주시\n0.35\n2022-12-31\n17:00\n\n\n420959\n경주시\n0.01\n2022-12-31\n18:00\n\n\n\n\n420960 rows × 4 columns\n\n\n\n- 시간이 비어있지 않도록..\n\nreg = df_temp['지점명'].unique().tolist() \nday = df_temp['날짜'].unique().tolist() \ntime = list(df_temp['시간'].unique())\ntime = ['0{}:00'.format(i) for i in range(0,8)] + time\n\n\ndf_temp2 = pd.DataFrame(itertools.product(reg,day,time)).rename({0:'지점명',1:'날짜',2:'시간'},axis=1).merge(df_temp,how='left').fillna(0)\ndf_temp2\n\n\n\n\n\n\n\n\n지점명\n날짜\n시간\n일사\n\n\n\n\n0\n북춘천\n2021-01-01\n00:00\n0.0\n\n\n1\n북춘천\n2021-01-01\n01:00\n0.0\n\n\n2\n북춘천\n2021-01-01\n02:00\n0.0\n\n\n3\n북춘천\n2021-01-01\n03:00\n0.0\n\n\n4\n북춘천\n2021-01-01\n04:00\n0.0\n\n\n...\n...\n...\n...\n...\n\n\n802995\n경주시\n2022-12-31\n07:00\n0.0\n\n\n802996\n경주시\n2022-12-31\n20:00\n0.0\n\n\n802997\n경주시\n2022-12-31\n06:00\n0.0\n\n\n802998\n경주시\n2022-12-31\n21:00\n0.0\n\n\n802999\n경주시\n2022-12-31\n05:00\n0.0\n\n\n\n\n803000 rows × 4 columns\n\n\n\n\ndf_temp2[:20]\n\n\n\n\n\n\n\n\n지점명\n날짜\n시간\n일사\n\n\n\n\n0\n북춘천\n2021-01-01\n00:00\n0.00\n\n\n1\n북춘천\n2021-01-01\n01:00\n0.00\n\n\n2\n북춘천\n2021-01-01\n02:00\n0.00\n\n\n3\n북춘천\n2021-01-01\n03:00\n0.00\n\n\n4\n북춘천\n2021-01-01\n04:00\n0.00\n\n\n5\n북춘천\n2021-01-01\n05:00\n0.00\n\n\n6\n북춘천\n2021-01-01\n06:00\n0.00\n\n\n7\n북춘천\n2021-01-01\n07:00\n0.00\n\n\n8\n북춘천\n2021-01-01\n08:00\n0.00\n\n\n9\n북춘천\n2021-01-01\n09:00\n0.37\n\n\n10\n북춘천\n2021-01-01\n10:00\n0.96\n\n\n11\n북춘천\n2021-01-01\n11:00\n1.40\n\n\n12\n북춘천\n2021-01-01\n12:00\n1.72\n\n\n13\n북춘천\n2021-01-01\n13:00\n1.84\n\n\n14\n북춘천\n2021-01-01\n14:00\n1.74\n\n\n15\n북춘천\n2021-01-01\n15:00\n1.30\n\n\n16\n북춘천\n2021-01-01\n16:00\n0.93\n\n\n17\n북춘천\n2021-01-01\n17:00\n0.29\n\n\n18\n북춘천\n2021-01-01\n18:00\n0.01\n\n\n19\n북춘천\n2021-01-01\n19:00\n0.00\n\n\n\n\n\n\n\n\ndf_temp2[-20:]\n\n\n\n\n\n\n\n\n지점명\n날짜\n시간\n일사\n\n\n\n\n802980\n경주시\n2022-12-31\n05:00\n0.00\n\n\n802981\n경주시\n2022-12-31\n06:00\n0.00\n\n\n802982\n경주시\n2022-12-31\n07:00\n0.00\n\n\n802983\n경주시\n2022-12-31\n08:00\n0.02\n\n\n802984\n경주시\n2022-12-31\n09:00\n0.41\n\n\n802985\n경주시\n2022-12-31\n10:00\n1.05\n\n\n802986\n경주시\n2022-12-31\n11:00\n1.52\n\n\n802987\n경주시\n2022-12-31\n12:00\n1.86\n\n\n802988\n경주시\n2022-12-31\n13:00\n1.93\n\n\n802989\n경주시\n2022-12-31\n14:00\n1.82\n\n\n802990\n경주시\n2022-12-31\n15:00\n1.52\n\n\n802991\n경주시\n2022-12-31\n16:00\n0.96\n\n\n802992\n경주시\n2022-12-31\n17:00\n0.35\n\n\n802993\n경주시\n2022-12-31\n18:00\n0.01\n\n\n802994\n경주시\n2022-12-31\n19:00\n0.00\n\n\n802995\n경주시\n2022-12-31\n07:00\n0.00\n\n\n802996\n경주시\n2022-12-31\n20:00\n0.00\n\n\n802997\n경주시\n2022-12-31\n06:00\n0.00\n\n\n802998\n경주시\n2022-12-31\n21:00\n0.00\n\n\n802999\n경주시\n2022-12-31\n05:00\n0.00\n\n\n\n\n\n\n\n\ndf_temp2\n\n\n\n\n\n\n\n\n지점명\n날짜\n시간\n일사\n\n\n\n\n0\n북춘천\n2021-01-01\n00:00\n0.0\n\n\n1\n북춘천\n2021-01-01\n01:00\n0.0\n\n\n2\n북춘천\n2021-01-01\n02:00\n0.0\n\n\n3\n북춘천\n2021-01-01\n03:00\n0.0\n\n\n4\n북춘천\n2021-01-01\n04:00\n0.0\n\n\n...\n...\n...\n...\n...\n\n\n802995\n경주시\n2022-12-31\n07:00\n0.0\n\n\n802996\n경주시\n2022-12-31\n20:00\n0.0\n\n\n802997\n경주시\n2022-12-31\n06:00\n0.0\n\n\n802998\n경주시\n2022-12-31\n21:00\n0.0\n\n\n802999\n경주시\n2022-12-31\n05:00\n0.0\n\n\n\n\n803000 rows × 4 columns\n\n\n\n- 시간,날짜 \\(\\to\\) 일시\n\ndf_temp3=df_temp2.assign(일시 = list(map(lambda x,y: x+'-'+y,df_temp2['날짜'],df_temp2['시간'])))\\\n.drop(['날짜','시간'],axis=1)\ndf_temp3\n\n\n\n\n\n\n\n\n지점명\n일사\n일시\n\n\n\n\n0\n북춘천\n0.0\n2021-01-01-00:00\n\n\n1\n북춘천\n0.0\n2021-01-01-01:00\n\n\n2\n북춘천\n0.0\n2021-01-01-02:00\n\n\n3\n북춘천\n0.0\n2021-01-01-03:00\n\n\n4\n북춘천\n0.0\n2021-01-01-04:00\n\n\n...\n...\n...\n...\n\n\n802995\n경주시\n0.0\n2022-12-31-07:00\n\n\n802996\n경주시\n0.0\n2022-12-31-20:00\n\n\n802997\n경주시\n0.0\n2022-12-31-06:00\n\n\n802998\n경주시\n0.0\n2022-12-31-21:00\n\n\n802999\n경주시\n0.0\n2022-12-31-05:00\n\n\n\n\n803000 rows × 3 columns\n\n\n\n- 저장\n\ndf_temp3.rename({'지점명':'region','일사':'solar_radiation','일시':'date'},axis=1)\n\n\n\n\n\n\n\n\nregion\nsolar_radiation\ndate\n\n\n\n\n0\n북춘천\n0.0\n2021-01-01-00:00\n\n\n1\n북춘천\n0.0\n2021-01-01-01:00\n\n\n2\n북춘천\n0.0\n2021-01-01-02:00\n\n\n3\n북춘천\n0.0\n2021-01-01-03:00\n\n\n4\n북춘천\n0.0\n2021-01-01-04:00\n\n\n...\n...\n...\n...\n\n\n802995\n경주시\n0.0\n2022-12-31-07:00\n\n\n802996\n경주시\n0.0\n2022-12-31-20:00\n\n\n802997\n경주시\n0.0\n2022-12-31-06:00\n\n\n802998\n경주시\n0.0\n2022-12-31-21:00\n\n\n802999\n경주시\n0.0\n2022-12-31-05:00\n\n\n\n\n803000 rows × 3 columns\n\n\n\n\ndf = df_temp3.rename({'지점명':'region','일사':'solar_radiation','일시':'date'},axis=1)\ndf.to_csv(\"solar_radiation.csv\",index=False)\n!git add .\n!git commit -m .\n!git push \n\n[main 299d058] .\n 3 files changed, 806273 insertions(+)\n create mode 100644 \"posts/3_Researches/SOLAR/.ipynb_checkpoints/2023-04-03-\\354\\235\\274\\354\\202\\254\\353\\237\\211-checkpoint.ipynb\"\n create mode 100644 \"posts/3_Researches/SOLAR/2023-04-03-\\354\\235\\274\\354\\202\\254\\353\\237\\211.ipynb\"\n create mode 100644 posts/3_Researches/SOLAR/solar_radiation.csv\nEnumerating objects: 10, done.\nCounting objects: 100% (10/10), done.\nDelta compression using up to 16 threads\nCompressing objects: 100% (7/7), done.\nWriting objects: 100% (7/7), 8.74 KiB | 8.74 MiB/s, done.\nTotal 7 (delta 2), reused 0 (delta 0)\nremote: Resolving deltas: 100% (2/2), completed with 2 local objects.\nTo https://github.com/miruetoto/yechan3.git\n   495d9ce..299d058  main -&gt; main\n\n\n- 불러오기\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/miruetoto/yechan3/main/posts/3_Researches/SOLAR/solar_radiation.csv\")\ndf\n\n\n\n\n\n\n\n\nregion\nsolar_radiation\ndate\n\n\n\n\n0\n북춘천\n0.0\n2021-01-01-00:00\n\n\n1\n북춘천\n0.0\n2021-01-01-01:00\n\n\n2\n북춘천\n0.0\n2021-01-01-02:00\n\n\n3\n북춘천\n0.0\n2021-01-01-03:00\n\n\n4\n북춘천\n0.0\n2021-01-01-04:00\n\n\n...\n...\n...\n...\n\n\n802995\n경주시\n0.0\n2022-12-31-07:00\n\n\n802996\n경주시\n0.0\n2022-12-31-20:00\n\n\n802997\n경주시\n0.0\n2022-12-31-06:00\n\n\n802998\n경주시\n0.0\n2022-12-31-21:00\n\n\n802999\n경주시\n0.0\n2022-12-31-05:00\n\n\n\n\n803000 rows × 3 columns\n\n\n\n- 다운로드\n!wget https://raw.githubusercontent.com/miruetoto/yechan3/main/posts/3_Researches/SOLAR/solar_radiation.csv"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-08-09-HST example 2 (1).html",
    "href": "연구/교수님이랑/HST/2021-08-09-HST example 2 (1).html",
    "title": "(연구&교수님) HST example 2 (1)",
    "section": "",
    "text": "import heavysnow as hs \nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt \nfrom sklearn.decomposition import PCA \nimport rpy2 \n%load_ext rpy2.ipython\n%run pybase\n\n\n### Example 2\nnp.random.seed(777)\nimport math\npi=math.pi\nn=60\nang=np.linspace(-pi,pi-2*pi/n,n)\nV=np.arange(n)+1\nr=1\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=vx*0\n\nf2=vx*0\nf2[vy&lt;0]=3+np.random.normal(size=sum(vy&lt;0),scale=0.1)\nf2[vy&gt;=0]= -3+np.random.normal(size=sum(vy&gt;=0),scale=0.1)\n\n\n# Edg setting\nΣ=l2distance(np.matrix([vx,vy]).T)\nθ=0.2\nW=np.exp(-Σ**2/(2*θ**2))-np.eye(n,n)\nE=W&gt;0\nplt.plot(W[0,:].T)\n# color\nimport matplotlib.cm as cm\ncol=list(np.array(cm.rainbow((ang+pi)/2/pi)))\n\n\n\n\n\n\n\n\n\ngs1=hs.GraphSignal(V,W,f1)\ngs2=hs.GraphSignal(V,W,f2)\n\n\nDiffusion distance\n\nP=W/W.round(3).sum(axis=0)[0]\nprint(P)\nplt.imshow(P)\n\n[[0.         0.1200121  0.11735654 ... 0.10662519 0.11735654 0.1200121 ]\n [0.1200121  0.         0.1200121  ... 0.08271274 0.10662519 0.11735654]\n [0.11735654 0.1200121  0.         ... 0.04899084 0.08271274 0.10662519]\n ...\n [0.10662519 0.08271274 0.04899084 ... 0.         0.1200121  0.11735654]\n [0.11735654 0.10662519 0.08271274 ... 0.1200121  0.         0.1200121 ]\n [0.1200121  0.11735654 0.10662519 ... 0.11735654 0.1200121  0.        ]]\n\n\n\n\n\n\n\n\n\n\nplt.imshow(P@P@P@P)\n\n\n\n\n\n\n\n\n\nP4=P@P@P@P\ndiffusion_distance=l2distance(P4)\nplt.imshow(diffusion_distance)\n\n\n\n\n\n\n\n\n\n\nSnow distance\n\nhs1=hs.HeavySnowTransform(gs1)\nhs2=hs.HeavySnowTransform(gs2)\n\n\nhs1.snow(tau=100000,b=0.05)\nhs2.snow(tau=100000,b=0.05)\n\nHST (tau= 100000, b=0.05)\n100000/100000\nHST completed and all history is recorded.\nHST (tau= 100000, b=0.05)\n100000/100000\nHST completed and all history is recorded.\n\n\n\nfrom sklearn.decomposition import PCA \np1=PCA(n_components=3)\np2=PCA(n_components=3)\np3=PCA(n_components=3)\np4=PCA(n_components=3)\np5=PCA(n_components=3)\np6=PCA(n_components=3)\n\n\np1.fit(hs1.eucliddistance)\np2.fit(diffusion_distance)\np3.fit(hs1.snowdistance)\np4.fit(hs2.eucliddistance)\np5.fit(diffusion_distance)\np6.fit(hs2.snowdistance)\n\nr1=p1.transform(hs1.eucliddistance)\nr2=p2.transform(diffusion_distance)\nr3=p3.transform(hs1.snowdistance)\nr4=p4.transform(hs2.eucliddistance)\nr5=p5.transform(diffusion_distance)\nr6=p6.transform(hs2.snowdistance)\n\n/home/cgb4/anaconda3/envs/py38r40/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:470: RuntimeWarning: invalid value encountered in true_divide\n  explained_variance_ratio_ = explained_variance_ / total_var\n\n\n\n# 1. \np=plt.figure(figsize=(12,4), dpi=70)  # Make figure object \n\n# 2. \nax1=p.add_subplot(2,4,1, projection='3d')\nax2=p.add_subplot(2,4,2, projection='3d')\nax3=p.add_subplot(2,4,3, projection='3d')\nax4=p.add_subplot(2,4,4, projection='3d')\nax5=p.add_subplot(2,4,5, projection='3d')\nax6=p.add_subplot(2,4,6, projection='3d')\nax7=p.add_subplot(2,4,7, projection='3d')\nax8=p.add_subplot(2,4,8, projection='3d')\n\n# 3. \nax1.grid(False)\nax1.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax1.scatter3D(vx, vy, f1, c=col,alpha=1)\nax1.set_xlim(-1,1)\nax1.set_ylim(-1,1)\nax1.set_zlim(-5,5)\n\nax2.grid(False)\nax2.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax2.scatter3D(r1[:,0],r1[:,1],r1[:,2],s=10,c=col,alpha=1)\n\nax3.grid(False)\nax3.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax3.scatter3D(r2[:,0],r2[:,1],r2[:,2],s=10,c=col,alpha=1)\n\nax4.grid(False)\nax4.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax4.scatter3D(r3[:,0],r3[:,1],r3[:,2],s=10,c=col,alpha=1)\n\n\nax5.grid(False)\nax5.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\ntop = -f2\nbottom = np.zeros_like(top)\nwidth=depth=0.05\nax5.bar3d(vx, vy, bottom, width, depth, top, shade=False,color=col)\nax5.set_xlim(-1,1)\nax5.set_ylim(-1,1)\nax5.set_zlim(-5,5)\n\nax6.grid(False)\nax6.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax6.scatter3D(r4[:,0],r4[:,1],r4[:,2],s=10,c=col,alpha=1)\n\nax7.grid(False)\nax7.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax7.scatter3D(r5[:,0],r5[:,1],r5[:,2],s=10,c=col,alpha=1)\n\nax8.grid(False)\nax8.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax8.scatter3D(r6[:,0],r6[:,1],r6[:,2],s=10,c=col,alpha=1)\np.tight_layout(h_pad=2.6) #rect : tuple (left, bottom, right, top), optional"
  },
  {
    "objectID": "연구/교수님이랑/HST/2023-07-12-링형태의자료만들기.html",
    "href": "연구/교수님이랑/HST/2023-07-12-링형태의자료만들기.html",
    "title": "(연구&교수님) 링형태의자료만들기",
    "section": "",
    "text": "import hsnowtrans as hst \n\n\nimport numpy as np\nimport matplotlib.pyplot as plt \nfrom scipy.spatial.distance import cdist\nimport torch\nimport torch_geometric\nimport time"
  },
  {
    "objectID": "연구/교수님이랑/HST/2023-07-12-링형태의자료만들기.html#cal-vv_1dotsv_nx_1y_1dotsx_ny_n",
    "href": "연구/교수님이랑/HST/2023-07-12-링형태의자료만들기.html#cal-vv_1dotsv_nx_1y_1dotsx_ny_n",
    "title": "(연구&교수님) 링형태의자료만들기",
    "section": "\\({\\cal V}=\\{v_1,\\dots,v_N\\}=\\{(x_1,y_1),\\dots,(x_N,y_N)\\}\\)",
    "text": "\\({\\cal V}=\\{v_1,\\dots,v_N\\}=\\{(x_1,y_1),\\dots,(x_N,y_N)\\}\\)\n\nnp.random.seed(777)\nN=1000\nangle=np.linspace(-np.pi,np.pi-2*np.pi/N,N)\nradius=1\nVx,Vy = radius*np.cos(angle),radius*np.sin(angle)\nV = np.stack([Vx,Vy],axis=1)"
  },
  {
    "objectID": "연구/교수님이랑/HST/2023-07-12-링형태의자료만들기.html#boldsymbolf-cal-v-to-mathbbr",
    "href": "연구/교수님이랑/HST/2023-07-12-링형태의자료만들기.html#boldsymbolf-cal-v-to-mathbbr",
    "title": "(연구&교수님) 링형태의자료만들기",
    "section": "\\(\\boldsymbol{f}: {\\cal V} \\to \\mathbb{R}\\)",
    "text": "\\(\\boldsymbol{f}: {\\cal V} \\to \\mathbb{R}\\)\n\nf = np.zeros(N)\nf[Vy&lt;0] = -3+np.random.normal(size=sum(Vy&lt;0),scale=0.5)\nf[Vy&gt;=0] = 3+np.random.normal(size=sum(Vy&gt;=0),scale=0.5)"
  },
  {
    "objectID": "연구/교수님이랑/HST/2023-07-12-링형태의자료만들기.html#visualization",
    "href": "연구/교수님이랑/HST/2023-07-12-링형태의자료만들기.html#visualization",
    "title": "(연구&교수님) 링형태의자료만들기",
    "section": "Visualization",
    "text": "Visualization\n\ndef plot_ring(V,f,angle):\n    fig = plt.Figure()\n    ax = fig.add_subplot(projection='3d')\n    ax.grid(False)\n    ax.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\n    ax.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\n    ax.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\n    top = f\n    bottom = np.zeros_like(top)\n    width=0.05\n    ax.bar3d(\n        x=Vx, \n        y=Vy, \n        z=0, \n        dx=0.001, \n        dy=0.001, \n        dz=f, \n        shade=False,\n        color=cm.rainbow((angle+np.pi)/2/np.pi)\n    )\n    ax.set_xlim(-1,1)\n    ax.set_ylim(-1,1)\n    ax.set_zlim(-5,5)\n    return fig    \n\n\nplot_ring(V,f,angle)"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-07-22-HST example 1.html",
    "href": "연구/교수님이랑/HST/2021-07-22-HST example 1.html",
    "title": "(연구&교수님) HST example 1",
    "section": "",
    "text": "Import\n\nimport heavysnow as hs\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport rpy2 \n%load_ext rpy2.ipython\n%run pybase\n\nThe rpy2.ipython extension is already loaded. To reload it, use:\n  %reload_ext rpy2.ipython\n\n\n\n\nData\n\nf=np.array([-1,-1,-1,1,-1,-1,-1,1,1,1,-1,1,1,1])*1.0\nn=len(f)\nV=list(range(n))\nW=np.zeros([n,n])\nfor i in range(n):\n    for j in range(n):\n        if abs(i-j)==1: W[i,j]=1\nW[0,0]=0.5\nW[n-1,n-1]=0.5\n\n\ngs=hs.GraphSignal(V,W,f)\n\n\ngs.initdist=np.array([1/n]*n)\n\n\n\nHST\n\nhst=hs.HeavySnowTransform(gsobj)\nhst.snow(tau=80000,b=0.005)\n\nHST (tau= 80000, b=0.005)\n80000/80000\nHST completed and all history is recorded.\n\n\n\nplt.imshow(hst.snowweight)\n\n\n\n\n\n\n\n\n\n\n시각화를 위해서 R로 자료를 옮김\n\nmaxtau=hst.tau\nW_Graph=hst.graphweight\nW_Euclid=hst.euclidweight\nW_HST=hst.snowweight\nV=np.array(hst.V)\nf=hst.f\nn=hst.n\n%R -i maxtau,W_Graph,W_Euclid,W_HST,V,f,n\n\n\n\nR을 활용한 시각화 (1): 원래자료\n\n%%R -w 2000 -h 800 -r 100\nlibrary(tidyverse)\nlibrary(latex2exp)\nlibrary(gridExtra)\nsource('rbase.R')\nVtext=str_c('node ',V+1)\nfig0&lt;-ggplot(data=tibble(V=V,f=f,Vtext=Vtext),aes(x=V,y=f,label=Vtext))+\ngeom_col(aes(fill=(f&gt;0)),width=0.1)+geom_hline(aes(yintercept=0),col=\"gray60\",lty=2)+\ngeom_text(fontface = 4,size=8)+\nxlab(\"\")+ylab(\"\")+guides(fill=FALSE)+theme(plot.title=element_text(face=\"bold.italic\"))+theme_bw()+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 15, color = \"black\", face = \"bold.italic\"))+\nylim(-1.2,1.2)+\ntheme(plot.title=element_text(face=\"bold.italic\"))\n#ggsave(plot=p0,\"./fig/2021-0217_fig0.pdf\",width=20,height=6)\nfig0\n\n\n\n\n\n\n\n\n\n\nR을 활용한 시각화 (2): Weight matrix 와 Eigen plot\n- ggplot에서 geom_tile을 사용하기 위해서 매트릭스 형태인 W_Graph, W_Euclid, W_HST를 길게 펼친다. 결과를 각각 W_Graph_long, W_Euclid_long, W_HST_long에 저장한다.\n\n%%R\ngrid&lt;-expand.grid(x=1:n,y=1:n)\nW_Graph_long&lt;-as_tibble(cbind(grid,as.vector(W_Graph)));names(W_Graph_long)&lt;-c(\"x\",\"y\",\"W\")\nW_Euclid_long&lt;-as_tibble(cbind(grid,as.vector(W_Euclid)));names(W_Euclid_long)&lt;-c(\"x\",\"y\",\"W\")\nW_HST_long&lt;-as_tibble(cbind(grid,as.vector(W_HST)));names(W_HST_long)&lt;-c(\"x\",\"y\",\"W\")\n\n- 그래프퓨리에 변환: \\((\\bf{f},\\bf{W})\\)에 그래프 퓨리에 변환을 수행함.\n\n%%R\nsource('heavysnow.R')\ngfftrslt_Euclid&lt;-gfft(f,W_Euclid)\ngfftrslt_Graph&lt;-gfft(f,W_Graph)\ngfftrslt_HST&lt;-gfft(f,W_HST)\n\n- 그래프 퓨리에 변환의 결과 고유치, 고유벡터, \\(\\bf{\\bar{f}}\\)가 반환됨.\n\n%%R\nhead(gfftrslt_HST)\n\n$λ\n [1] 2.000000e+00 1.998065e+00 1.973146e+00 1.904274e+00 1.026854e+00\n [6] 1.001935e+00 9.572661e-02 7.354423e-10 3.613526e-17 2.448950e-17\n[11] 1.417075e-23 1.752496e-24 9.860761e-32 1.867904e-40\n\n$Ψ\n               [,1]          [,2]           [,3]          [,4]           [,5]\n [1,] -9.071768e-51  1.720543e-96 -1.005578e-106 -7.141429e-05  5.188853e-107\n [2,] -9.736659e-54  1.846654e-99 -1.079284e-109  7.071068e-01  5.569184e-110\n [3,] -8.824039e-54  1.672315e-99 -9.773907e-110 -7.071068e-01  5.043406e-110\n [4,]  2.570198e-48  1.336382e-51  -4.078315e-56  0.000000e+00  -2.039158e-56\n [5,] -2.570182e-48 -3.036427e-99  1.774651e-109  9.860357e-10 -9.157328e-110\n [6,] -7.071068e-01  8.270257e-36   2.800625e-40 -1.144252e-91  -1.445143e-40\n [7,]  7.071068e-01  8.270257e-36   2.800625e-40  8.033315e-92  -1.445143e-40\n [8,]  0.000000e+00  4.189199e-44  -5.736707e-01  0.000000e+00  -5.843557e-01\n [9,]  0.000000e+00  4.819483e-45   7.118721e-01  0.000000e+00  -9.098010e-03\n[10,]  0.000000e+00 -3.687915e-44  -4.051420e-01  0.000000e+00   8.114466e-01\n[11,] -8.873316e-41  8.902806e-33  -5.203278e-43 -4.552864e-71   2.684929e-43\n[12,]  0.000000e+00 -3.670984e-01  -5.168880e-45  0.000000e+00  -2.237545e-44\n[13,]  0.000000e+00  7.074488e-01   3.510106e-45  0.000000e+00   3.854087e-44\n[14,]  0.000000e+00 -6.039495e-01  -2.118307e-45  0.000000e+00  -3.140900e-44\n               [,6]          [,7]          [,8]          [,9]         [,10]\n [1,]  1.072799e-80 -1.441122e-03 -9.999927e-01  7.013316e-65 -3.032449e-55\n [2,]  1.151433e-83  7.071060e-01 -1.069518e-03  7.527375e-68 -3.254704e-58\n [3,]  1.042728e-83  7.071061e-01 -9.685234e-04  6.816728e-68 -2.949640e-58\n [4,] -6.018531e-36  0.000000e+00  0.000000e+00  5.421011e-20  2.653689e-41\n [5,] -1.893284e-83 -1.978819e-08  3.529603e-03 -1.237715e-67 -8.591427e-53\n [6,]  5.156701e-20  4.832789e-87 -1.528581e-65  3.371141e-04 -2.778154e-04\n [7,]  5.156701e-20 -4.833468e-87  1.528581e-65  3.371141e-04 -2.778154e-04\n [8,]  3.112827e-31  0.000000e+00  0.000000e+00 -5.299286e-01 -1.396810e-01\n [9,]  3.808597e-31  0.000000e+00  0.000000e+00 -6.483767e-01 -1.709021e-01\n[10,]  2.284375e-31  0.000000e+00  0.000000e+00 -3.888928e-01 -1.025062e-01\n[11,]  5.551110e-17 -9.853888e-70  1.932563e-64  3.628982e-01 -2.990640e-01\n[12,] -8.540064e-01  0.000000e+00  0.000000e+00 -4.641406e-02  3.401566e-01\n[13,]  9.998842e-04  0.000000e+00  0.000000e+00 -8.898056e-02  6.521155e-01\n[14,]  5.202616e-01  0.000000e+00  0.000000e+00 -7.601740e-02  5.571118e-01\n              [,11]         [,12]          [,13]         [,14]\n [1,]  1.705569e-64  3.529599e-03  -1.374121e-88  1.332083e-57\n [2,]  1.830583e-67  3.788292e-06  -1.474841e-91  1.429715e-60\n [3,]  1.657761e-67  3.433214e-06  -1.335603e-91  1.295707e-60\n [4,]  1.084202e-19  0.000000e+00   1.000000e+00 -1.165716e-43\n [5,] -3.010002e-67  9.999938e-01   2.425059e-91  3.774011e-55\n [6,]  8.198283e-04 -1.817404e-48  -1.110223e-16 -7.071062e-01\n [7,]  8.198283e-04  1.817404e-48   1.110223e-16 -7.071062e-01\n [8,]  1.705733e-01  0.000000e+00   2.440335e-62 -1.077857e-40\n [9,]  2.086994e-01  0.000000e+00  -6.425625e-62  2.838095e-40\n[10,]  1.251768e-01  0.000000e+00   7.387698e-62 -3.263028e-40\n[11,]  8.825327e-01 -2.872718e-52  -7.110274e-25  1.313732e-03\n[12,]  1.343544e-01  0.000000e+00  1.718592e-106 -7.590746e-85\n[13,]  2.575714e-01  0.000000e+00  1.320093e-108 -5.830637e-87\n[14,]  2.200470e-01  0.000000e+00  5.531522e-111 -2.443184e-89\n\n$fbar\n [1]  8.873316e-41 -2.635991e-01 -2.669406e-01  7.140560e-05  2.179929e-01\n [6] -3.327449e-01 -1.412771e+00  9.985012e-01 -2.142182e+00  1.435914e+00\n[11]  2.322500e-01 -1.003531e+00  1.000000e+00  1.412899e+00\n\n\n\n- 시각화코드\n\n%%R -w 1000 -h 800 -r 100\nlibrary(gridExtra)\n\nfig1_1&lt;-ggplot()+geom_tile(data=W_Euclid_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"red\",high=\"blue\",mid=\"purple\",midpoint=0.25,breaks=c(0,0.5,0.99))+\nlabs(fill=TeX('$W$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(a) Euclid\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_2&lt;-ggplot()+geom_tile(data=W_Graph_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"red\",high=\"blue\",mid=\"purple\",midpoint=0.5,breaks=c(0,0.5,0.99))+\nlabs(fill=TeX('$\\\\hat{W}$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(b) Graph\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_3&lt;-ggplot()+geom_tile(data=W_HST_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"red\",high=\"blue\",mid=\"purple\",midpoint=0.5,breaks=c(0,0.5,0.99))+\nlabs(fill=TeX('$\\\\hat{W}(\\\\tau)$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(c) HST\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_4&lt;-eigenplot(gfftrslt_Euclid)+ylim(0,2)+theme_light()\nfig1_5&lt;-eigenplot(gfftrslt_Graph)+ylim(0,2)+theme_light()\nfig1_6&lt;-eigenplot(gfftrslt_HST)+ylim(0,2)+theme_light()\nfig1=grid.arrange(fig1_1,fig1_2,fig1_3,fig1_4,fig1_5,fig1_6,ncol=3,nrow=2)\nfig1\n#ggsave(plot=grid.arrange(p1_a,p1_b,p1_c,ncol=3),\"2021-07-22_fig1.png\",width=20,height=4)\n\nTableGrob (2 x 3) \"arrange\": 6 grobs\n  z     cells    name           grob\n1 1 (1-1,1-1) arrange gtable[layout]\n2 2 (1-1,2-2) arrange gtable[layout]\n3 3 (1-1,3-3) arrange gtable[layout]\n4 4 (2-2,1-1) arrange gtable[layout]\n5 5 (2-2,2-2) arrange gtable[layout]\n6 6 (2-2,3-3) arrange gtable[layout]\n\n\n\n\n\n\n\n\n\n\n\nR을 활용한 시각화 (3): Decomposition\n- 디콤포지션을 수행하고 결과를 저장: \\((\\bf{f},\\bf{W})\\)에 decomposition을 수행하고 그 결과를 각각 decomprslt_Euclid, decomprslt_Graph, decomprslt_HST에 저장한다.\n\n%%R \ndecomprslt_Euclid&lt;-decompose(f,W_Euclid,V=1:n) # 0, 35000, 60000, 80000\ndecomprslt_Graph&lt;-decompose(f,W_Graph,V=1:n) # 0, 35000, 60000, 80000\ndecomprslt_HST&lt;-decompose(f,W_HST,V=1:n) # 0, 35000, 60000, 80000\n\n- 디콤포지션 결과는 아래와 같은 형태임\n\n%%R\nhead(decomprslt_Euclid)\n\n# A tibble: 6 x 5\n      V Vindex eigenvectorindex      fhat eigenvalue\n  &lt;int&gt;  &lt;int&gt;            &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1     1      1                1  1.45e-32   3.28e-18\n2     2      2                1  2.48e-17   3.28e-18\n3     3      3                1 -2.02e-16   3.28e-18\n4     4      4                1  1   e+ 0   3.28e-18\n5     5      5                1  8.73e-17   3.28e-18\n6     6      6                1 -6.32e-17   3.28e-18\n\n\n\n%%R \ndecomprslt_Euclid$method=\"Euclid\"\ndecomprslt_Graph$method=\"Graph\"\ndecomprslt_HST$method=\"HST\"\ndecomprslt&lt;-rbind(decomprslt_Euclid,decomprslt_Graph,decomprslt_HST)\n\n- 디콤포지션결과를 시각화한다. geom_col과 facet_grid를 이용.\n\n%%R -w 2000 -h 500 -r 100\nfig2&lt;-ggplot(data=decomprslt,aes(x=V,y=fhat))+\ngeom_col(aes(fill=fhat&gt;0),width=0.7)+facet_grid(method~eigenvectorindex)+geom_hline(aes(yintercept=0),col=\"gray60\",lty=2)+\nxlab(\"\")+ylab(\"\")+guides(fill=FALSE)+theme(plot.title=element_text(face=\"bold.italic\"))+theme_bw()+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 15, color = \"black\", face = \"bold.italic\"))+\nylim(-1.5,1.5)+\ntheme(plot.title=element_text(face=\"bold.italic\"))\nfig2\n#ggsave(plot=fig2,\"./fig/2021-0514_fig2.pdf\",width=20,height=6)"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-08-03-HST example 2 (8).html",
    "href": "연구/교수님이랑/HST/2021-08-03-HST example 2 (8).html",
    "title": "(연구&교수님) HST example 2 (8)",
    "section": "",
    "text": "import heavysnow as hs \nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt \nfrom sklearn.decomposition import PCA \nimport rpy2 \n%load_ext rpy2.ipython\n%run pybase\n\n\n### Example 2\nnp.random.seed(777)\nimport math\npi=math.pi\nn=60\nang=np.linspace(-pi,pi-2*pi/n,n)\nV=np.arange(n)+1\nr=1\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=vx*0\n\nf2=vx*0\nf2[vy&lt;0]=3+np.random.normal(size=sum(vy&lt;0),scale=0.1)\nf2[vy&gt;0]= -3+np.random.normal(size=sum(vy&gt;0),scale=0.1)\n\n\n# Edg setting\nΣ=l2distance(np.matrix([vx,vy]).T)\nθ=0.05\nW=np.exp(-Σ**2/(2*θ**2))\nE=W&gt;0\nplt.plot(W[0,:].T)\n# color\nimport matplotlib.cm as cm\ncol=list(np.array(cm.rainbow((ang+pi)/2/pi)))\n\n\n\n\n\n\n\n\n\n%R -i ang,vx,vy,n\n\n\n%%R\nlibrary(latex2exp)\nlibrary(gridExtra)\nlibrary(tidyverse)\n\nR[write to console]: ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\nR[write to console]: ✔ ggplot2 3.3.5     ✔ purrr   0.3.4\n✔ tibble  3.1.2     ✔ dplyr   1.0.7\n✔ tidyr   1.1.3     ✔ stringr 1.4.0\n✔ readr   1.4.0     ✔ forcats 0.5.1\n\nR[write to console]: ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::combine() masks gridExtra::combine()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n\n\n\n\n%%R -w 450 -h 300 -r 100\nex2df&lt;-data.frame(cbind(ang,vx,vy))\nnames(ex2df)&lt;-c(\"ang\",\"vx\",\"vy\")\nex2plt &lt;- ggplot(data=ex2df,aes(x=vx,y=vy))+\n            geom_point(col=\"gray60\",cex=1.5,alpha=0.7)+\n            geom_point(data=ex2df[1:n,],aes(x=vx,y=vy,col=ang),cex=1.5,alpha=0.7)+\n            xlab(\"\")+ylab(\"\")+scale_colour_gradientn(colours=rainbow(7))+labs(col=TeX(\"$\\\\phi$\"))+theme_classic()+\n            theme(legend.key.width = unit(2,\"mm\"))\nshow(ex2plt)\n\n\n\n\n\n\n\n\n\ngs1=hs.GraphSignal(V,W,f1)\ngs2=hs.GraphSignal(V,W,f2)\n\n\nplt.imshow(W)\n\n\n\n\n\n\n\n\n\nDiffusion distance\n\nP=W/W.round(3).sum(axis=0)[0]\nprint(P)\nplt.imshow(P)\n\n[[2.20167327e-01 2.14586355e-01 1.46335569e-01 ... 2.83862880e-02\n  1.46335569e-01 2.14586355e-01]\n [2.14586355e-01 2.20167327e-01 2.14586355e-01 ... 3.69898283e-04\n  2.83862880e-02 1.46335569e-01]\n [1.46335569e-01 2.14586355e-01 2.20167327e-01 ... 4.82347874e-08\n  3.69898283e-04 2.83862880e-02]\n ...\n [2.83862880e-02 3.69898283e-04 4.82347874e-08 ... 2.20167327e-01\n  2.14586355e-01 1.46335569e-01]\n [1.46335569e-01 2.83862880e-02 3.69898283e-04 ... 2.14586355e-01\n  2.20167327e-01 2.14586355e-01]\n [2.14586355e-01 1.46335569e-01 2.83862880e-02 ... 1.46335569e-01\n  2.14586355e-01 2.20167327e-01]]\n\n\n\n\n\n\n\n\n\n\nplt.imshow(P@P@P@P)\n\n\n\n\n\n\n\n\n\nP4=P@P@P@P\ndiffusion_distance=l2distance(P4)\nplt.imshow(diffusion_distance)\n\n\n\n\n\n\n\n\n\n\nSnow distance\n\nhs1=hs.HeavySnowTransform(gs1)\nhs2=hs.HeavySnowTransform(gs2)\n\n\nhs1.snow(tau=90000,b=0.1)\nhs2.snow(tau=90000,b=0.1)\n\nHST (tau= 90000, b=0.1)\n90000/90000\nHST completed and all history is recorded.\nHST (tau= 90000, b=0.1)\n90000/90000\nHST completed and all history is recorded.\n\n\n\nfrom sklearn.decomposition import PCA \np1=PCA(n_components=3)\np2=PCA(n_components=3)\np3=PCA(n_components=3)\np4=PCA(n_components=3)\np5=PCA(n_components=3)\np6=PCA(n_components=3)\n\n\np1.fit(hs1.eucliddistance)\np2.fit(diffusion_distance)\np3.fit(hs1.snowdistance)\np4.fit(hs2.eucliddistance)\np5.fit(diffusion_distance)\np6.fit(hs2.snowdistance)\n\nr1=p1.transform(hs1.eucliddistance)\nr2=p2.transform(diffusion_distance)\nr3=p3.transform(hs1.snowdistance)\nr4=p4.transform(hs2.eucliddistance)\nr5=p5.transform(diffusion_distance)\nr6=p6.transform(hs2.snowdistance)\n\n/home/cgb4/anaconda3/envs/py38r40/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:470: RuntimeWarning: invalid value encountered in true_divide\n  explained_variance_ratio_ = explained_variance_ / total_var\n\n\n\n# 1. \np=plt.figure(figsize=(12,4), dpi=70)  # Make figure object \n\n# 2. \nax1=p.add_subplot(2,4,1, projection='3d')\nax2=p.add_subplot(2,4,2, projection='3d')\nax3=p.add_subplot(2,4,3, projection='3d')\nax4=p.add_subplot(2,4,4, projection='3d')\nax5=p.add_subplot(2,4,5, projection='3d')\nax6=p.add_subplot(2,4,6, projection='3d')\nax7=p.add_subplot(2,4,7, projection='3d')\nax8=p.add_subplot(2,4,8, projection='3d')\n\n# 3. \nax1.grid(False)\nax1.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax1.scatter3D(vx, vy, f1, c=col,alpha=1)\nax1.set_xlim(-1,1)\nax1.set_ylim(-1,1)\nax1.set_zlim(-5,5)\n\nax2.grid(False)\nax2.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax2.scatter3D(r1[:,0],r1[:,1],r1[:,2],s=20,c=col,alpha=1)\n\nax3.grid(False)\nax3.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax3.scatter3D(r2[:,0],r2[:,1],r2[:,2],s=20,c=col,alpha=1)\n\nax4.grid(False)\nax4.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax4.scatter3D(r3[:,0],r3[:,1],r3[:,2],s=20,c=col,alpha=1)\n\n\nax5.grid(False)\nax5.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\ntop = -f2\nbottom = np.zeros_like(top)\nwidth=depth=0.05\nax5.bar3d(vx, vy, bottom, width, depth, top, shade=False,color=col)\nax5.set_xlim(-1,1)\nax5.set_ylim(-1,1)\nax5.set_zlim(-5,5)\n\nax6.grid(False)\nax6.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax6.scatter3D(r4[:,0],r4[:,1],r4[:,2],s=20,c=col,alpha=1)\n\nax7.grid(False)\nax7.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax7.scatter3D(r5[:,0],r5[:,1],r5[:,2],s=20,c=col,alpha=1)\n\nax8.grid(False)\nax8.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax8.scatter3D(r6[:,0],r6[:,1],r6[:,2],s=20,c=col,alpha=1)\np.tight_layout(h_pad=2.6) #rect : tuple (left, bottom, right, top), optional"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-08-09-HST example 2 (7).html",
    "href": "연구/교수님이랑/HST/2021-08-09-HST example 2 (7).html",
    "title": "(연구&교수님) HST example 2 (7)",
    "section": "",
    "text": "import heavysnow as hs \nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt \nfrom sklearn.decomposition import PCA \nimport rpy2 \n%load_ext rpy2.ipython\n%run pybase\n\n\n### Example 2\nnp.random.seed(777)\nimport math\npi=math.pi\nn=60\nang=np.linspace(-pi,pi-2*pi/n,n)\nV=np.arange(n)+1\nr=1\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=vx*0\n\nf2=vx*0\nf2[vy&lt;0]=3+np.random.normal(size=sum(vy&lt;0),scale=0.1)\nf2[vy&gt;=0]= -3+np.random.normal(size=sum(vy&gt;=0),scale=0.1)\n\n\n# Edg setting\nΣ=l2distance(np.matrix([vx,vy]).T)\nθ=0.3\nW=np.exp(-Σ**2/(2*θ**2))-np.eye(n,n)\nE=W&gt;0\nplt.plot(W[0,:].T)\n# color\nimport matplotlib.cm as cm\ncol=list(np.array(cm.rainbow((ang+pi)/2/pi)))\n\n\n\n\n\n\n\n\n\ngs1=hs.GraphSignal(V,W,f1)\ngs2=hs.GraphSignal(V,W,f2)\n\n\nDiffusion distance\n\nP=W/W.round(3).sum(axis=0)[0]\nprint(P)\nplt.imshow(P)\n\n[[0.         0.09526533 0.09432263 ... 0.09038699 0.09432263 0.09526533]\n [0.09526533 0.         0.09526533 ... 0.0807401  0.09038699 0.09432263]\n [0.09432263 0.09526533 0.         ... 0.06397305 0.0807401  0.09038699]\n ...\n [0.09038699 0.0807401  0.06397305 ... 0.         0.09526533 0.09432263]\n [0.09432263 0.09038699 0.0807401  ... 0.09526533 0.         0.09526533]\n [0.09526533 0.09432263 0.09038699 ... 0.09432263 0.09526533 0.        ]]\n\n\n\n\n\n\n\n\n\n\nplt.imshow(P@P@P@P)\n\n\n\n\n\n\n\n\n\nP4=P@P@P@P\ndiffusion_distance=l2distance(P4)\nplt.imshow(diffusion_distance)\n\n\n\n\n\n\n\n\n\n\nSnow distance\n\nhs1=hs.HeavySnowTransform(gs1)\nhs2=hs.HeavySnowTransform(gs2)\n\n\nhs1.snow(tau=100000,b=0.05)\nhs2.snow(tau=100000,b=0.05)\n\nHST (tau= 100000, b=0.05)\n100000/100000\nHST completed and all history is recorded.\nHST (tau= 100000, b=0.05)\n100000/100000\nHST completed and all history is recorded.\n\n\n\nfrom sklearn.decomposition import PCA \np1=PCA(n_components=3)\np2=PCA(n_components=3)\np3=PCA(n_components=3)\np4=PCA(n_components=3)\np5=PCA(n_components=3)\np6=PCA(n_components=3)\n\n\np1.fit(hs1.eucliddistance)\np2.fit(diffusion_distance)\np3.fit(hs1.snowdistance)\np4.fit(hs2.eucliddistance)\np5.fit(diffusion_distance)\np6.fit(hs2.snowdistance)\n\nr1=p1.transform(hs1.eucliddistance)\nr2=p2.transform(diffusion_distance)\nr3=p3.transform(hs1.snowdistance)\nr4=p4.transform(hs2.eucliddistance)\nr5=p5.transform(diffusion_distance)\nr6=p6.transform(hs2.snowdistance)\n\n/home/cgb4/anaconda3/envs/py38r40/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:470: RuntimeWarning: invalid value encountered in true_divide\n  explained_variance_ratio_ = explained_variance_ / total_var\n\n\n\n# 1. \np=plt.figure(figsize=(12,4), dpi=70)  # Make figure object \n\n# 2. \nax1=p.add_subplot(2,4,1, projection='3d')\nax2=p.add_subplot(2,4,2, projection='3d')\nax3=p.add_subplot(2,4,3, projection='3d')\nax4=p.add_subplot(2,4,4, projection='3d')\nax5=p.add_subplot(2,4,5, projection='3d')\nax6=p.add_subplot(2,4,6, projection='3d')\nax7=p.add_subplot(2,4,7, projection='3d')\nax8=p.add_subplot(2,4,8, projection='3d')\n\n# 3. \nax1.grid(False)\nax1.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax1.scatter3D(vx, vy, f1, c=col,alpha=1)\nax1.set_xlim(-1,1)\nax1.set_ylim(-1,1)\nax1.set_zlim(-5,5)\n\nax2.grid(False)\nax2.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax2.scatter3D(r1[:,0],r1[:,1],r1[:,2],s=20,c=col,alpha=1)\n\nax3.grid(False)\nax3.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax3.scatter3D(r2[:,0],r2[:,1],r2[:,2],s=20,c=col,alpha=1)\n\nax4.grid(False)\nax4.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax4.scatter3D(r3[:,0],r3[:,1],r3[:,2],s=20,c=col,alpha=1)\n\n\nax5.grid(False)\nax5.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\ntop = -f2\nbottom = np.zeros_like(top)\nwidth=depth=0.05\nax5.bar3d(vx, vy, bottom, width, depth, top, shade=False,color=col)\nax5.set_xlim(-1,1)\nax5.set_ylim(-1,1)\nax5.set_zlim(-5,5)\n\nax6.grid(False)\nax6.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax6.scatter3D(r4[:,0],r4[:,1],r4[:,2],s=20,c=col,alpha=1)\n\nax7.grid(False)\nax7.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax7.scatter3D(r5[:,0],r5[:,1],r5[:,2],s=20,c=col,alpha=1)\n\nax8.grid(False)\nax8.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax8.scatter3D(r6[:,0],r6[:,1],r6[:,2],s=20,c=col,alpha=1)\np.tight_layout(h_pad=2.6) #rect : tuple (left, bottom, right, top), optional"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-08-05-HST example 1, Appendix 추가.html",
    "href": "연구/교수님이랑/HST/2021-08-05-HST example 1, Appendix 추가.html",
    "title": "(연구&교수님) HST example 1, Appendix 추가",
    "section": "",
    "text": "Import\n\nimport heavysnow as hs\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib\nmatplotlib.rc('image', cmap='Greys')\nimport rpy2 \n%load_ext rpy2.ipython\n%run pybase\n\nThe rpy2.ipython extension is already loaded. To reload it, use:\n  %reload_ext rpy2.ipython\n\n\n\n\nData\n\nf=np.array([-1,-1,-1,1,-1,-1,-1,1,1,1,-1,1,1,1])*1.0\nn=len(f)\nV=list(range(n))\nW=np.zeros([n,n])\nfor i in range(n):\n    for j in range(n):\n        if abs(i-j)==1: W[i,j]=1\nW[0,0]=0.5\nW[n-1,n-1]=0.5\n\n\ngs=hs.GraphSignal(V,W,f)\n\n\ngs.initdist=np.array([1/n]*n)\n\n\n\nHST\n\nhst=hs.HeavySnowTransform(gs)\nhst.snow(tau=80000,b=0.03)\n\nHST (tau= 80000, b=0.03)\n80000/80000\nHST completed and all history is recorded.\n\n\n\n\n시각화를 위해서 R로 자료를 옮김\n\nmaxtau=hst.tau\nW_Graph=hst.graphweight\nW_Euclid=hst.euclidweight\nW_HST=hst.snowweight\nV=np.array(hst.V)\nf=hst.f\nn=hst.n\n%R -i maxtau,W_Graph,W_Euclid,W_HST,V,f,n\n\n\n\nR을 활용한 시각화 (1): 원래자료\n\n%%R -w 2000 -h 800 -r 100\nlibrary(tidyverse)\nlibrary(latex2exp)\nlibrary(gridExtra)\nsource('rbase.R')\nVtext=str_c('node ',V+1)\nfig0&lt;-ggplot(data=tibble(V=V,f=f,Vtext=Vtext),aes(x=V,y=f,label=Vtext))+\ngeom_col(aes(fill=(f&gt;0)),width=0.1)+geom_hline(aes(yintercept=0),col=\"gray60\",lty=2)+\ngeom_text(fontface = 4,size=8)+\nxlab(\"\")+ylab(\"\")+guides(fill=FALSE)+theme(plot.title=element_text(face=\"bold.italic\"))+theme_bw()+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 15, color = \"black\", face = \"bold.italic\"))+\nylim(-1.2,1.2)+\ntheme(plot.title=element_text(face=\"bold.italic\"))\n#ggsave(plot=p0,\"./fig/2021-0217_fig0.pdf\",width=20,height=6)\nfig0\n\nR[write to console]: ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\nR[write to console]: ✔ ggplot2 3.3.5     ✔ purrr   0.3.4\n✔ tibble  3.1.2     ✔ dplyr   1.0.7\n✔ tidyr   1.1.3     ✔ stringr 1.4.0\n✔ readr   1.4.0     ✔ forcats 0.5.1\n\nR[write to console]: ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nR[write to console]: \nAttaching package: ‘gridExtra’\n\n\nR[write to console]: The following object is masked from ‘package:dplyr’:\n\n    combine\n\n\nR[write to console]: \nAttaching package: ‘lubridate’\n\n\nR[write to console]: The following objects are masked from ‘package:base’:\n\n    date, intersect, setdiff, union\n\n\n\n\n\n\n\n\n\n\n\n\n\nR을 활용한 시각화 (2): Weight matrix 와 Eigen plot\n- ggplot에서 geom_tile을 사용하기 위해서 매트릭스 형태인 W_Graph, W_Euclid, W_HST를 길게 펼친다. 결과를 각각 W_Graph_long, W_Euclid_long, W_HST_long에 저장한다.\n\n%%R\ngrid&lt;-expand.grid(x=1:n,y=1:n)\nW_Graph_long&lt;-as_tibble(cbind(grid,as.vector(W_Graph)));names(W_Graph_long)&lt;-c(\"x\",\"y\",\"W\")\nW_Euclid_long&lt;-as_tibble(cbind(grid,as.vector(W_Euclid)));names(W_Euclid_long)&lt;-c(\"x\",\"y\",\"W\")\nW_HST_long&lt;-as_tibble(cbind(grid,as.vector(W_HST)));names(W_HST_long)&lt;-c(\"x\",\"y\",\"W\")\n\n- 그래프퓨리에 변환: \\((\\bf{f},\\bf{W})\\)에 그래프 퓨리에 변환을 수행함.\n\n%%R\nsource('heavysnow.R')\ngfftrslt_Euclid&lt;-gfft(f,W_Euclid)\ngfftrslt_Graph&lt;-gfft(f,W_Graph)\ngfftrslt_HST&lt;-gfft(f,W_HST)\n\nR[write to console]: \nAttaching package: ‘kohonen’\n\n\nR[write to console]: The following object is masked from ‘package:purrr’:\n\n    map\n\n\n\n\n- 그래프 퓨리에 변환의 결과 고유치, 고유벡터, \\(\\bf{\\bar{f}}\\)가 반환됨.\n\n%%R\nhead(gfftrslt_HST)\n\n$λ\n [1] 1.967491e+00 1.960435e+00 1.874019e+00 1.871890e+00 1.159678e+00\n [6] 1.151570e+00 8.915846e-01 8.728308e-01 1.280887e-01 1.222847e-01\n[11] 1.071484e-04 2.131002e-05 5.756344e-15 6.036393e-19\n\n$Ψ\n               [,1]          [,2]          [,3]          [,4]          [,5]\n [1,] -2.858227e-01  1.138863e-05 -5.098557e-05  4.344260e-01 -4.599248e-01\n [2,]  4.135539e-01 -1.635579e-05  6.652553e-05 -5.654310e-01  1.057088e-01\n [3,] -3.533504e-01  1.366271e-05 -3.958104e-05  3.329696e-01  4.976276e-01\n [4,] -1.707615e-11  1.998879e-09 -2.163173e-09 -4.765451e-11  5.596891e-11\n [5,]  4.041036e-01 -1.428137e-05 -2.163381e-05  1.995871e-01 -5.616120e-01\n [6,] -5.447738e-01  1.855108e-05  5.033676e-05 -4.497566e-01 -8.071018e-02\n [7,]  4.029191e-01 -1.304356e-05 -4.244800e-05  3.722594e-01  4.557844e-01\n [8,] -1.387502e-05 -3.440114e-01  3.549120e-01  4.146910e-05 -3.198499e-05\n [9,]  1.981451e-05  5.167084e-01 -4.810186e-01 -5.716976e-05  4.892180e-06\n[10,] -1.559414e-05 -4.200088e-01  2.794907e-01  3.379273e-05  3.208705e-05\n[11,] -2.633792e-11 -4.024678e-16  1.517318e-15 -2.562123e-11 -5.221953e-11\n[12,]  1.173649e-05  3.489334e-01  2.684266e-01  3.004189e-05 -3.146080e-05\n[13,] -1.473984e-05 -4.506913e-01 -5.415890e-01 -6.149420e-05 -4.971508e-06\n[14,]  1.092911e-05  3.367255e-01  4.462869e-01  5.080173e-05  2.456768e-05\n               [,6]          [,7]          [,8]          [,9]         [,10]\n [1,] -2.865275e-05  1.298443e-05  4.956209e-01  4.529668e-01  2.331568e-05\n [2,]  6.239008e-06  2.191830e-06  9.743766e-02  5.847088e-01  3.029407e-05\n [3,]  3.115235e-05 -1.403329e-05 -5.290485e-01  3.460194e-01  1.836386e-05\n [4,] -5.214592e-09  6.478037e-09  2.521623e-10 -1.422034e-11  3.324695e-08\n [5,] -3.319838e-05 -1.176742e-05 -5.178739e-01 -1.827846e-01 -7.618540e-06\n [6,] -5.981749e-06  3.359795e-06  9.363241e-02 -4.165960e-01 -1.912904e-05\n [7,]  2.695560e-05  1.016150e-05  4.336048e-01 -3.553096e-01 -1.700827e-05\n [8,]  5.137955e-01 -4.900340e-01  1.302336e-05  1.715042e-05 -3.362552e-01\n [9,] -9.571231e-02 -1.020091e-01  1.647328e-06  2.326800e-05 -4.348310e-01\n[10,] -5.131227e-01  4.698602e-01 -1.266312e-05  1.405366e-05 -2.512318e-01\n[11,] -6.596993e-15 -7.540311e-15 -6.748416e-11  4.095386e-10  3.007263e-15\n[12,]  5.337581e-01  5.683377e-01 -1.323774e-05 -1.350500e-05  2.888008e-01\n[13,]  7.933760e-02 -7.494852e-02  2.035797e-06 -2.758562e-05  5.707285e-01\n[14,] -4.151703e-01 -4.472888e-01  1.053459e-05 -2.310459e-05  4.749738e-01\n              [,11]         [,12]         [,13]        [,14]\n [1,] -1.169248e-03  2.592842e-01  2.442310e-06 1.039862e-06\n [2,] -1.727097e-03  3.830211e-01  3.607916e-06 1.536142e-06\n [3,] -1.542148e-03  3.420782e-01  3.222415e-06 1.372009e-06\n [4,] -4.216089e-05 -9.988802e-06  9.941179e-01 1.083029e-01\n [5,] -1.910542e-03  4.240873e-01  3.995008e-06 1.701154e-06\n [6,] -2.516088e-03  5.586598e-01  5.262448e-06 2.241053e-06\n [7,] -1.894599e-03  4.208064e-01  3.963842e-06 1.688159e-06\n [8,]  3.721615e-01  1.678359e-03  1.563298e-05 1.707141e-06\n [9,]  5.412789e-01  2.439769e-03  2.272263e-05 2.481341e-06\n[10,]  4.453007e-01  2.006620e-03  1.868730e-05 2.040677e-06\n[11,]  2.624676e-09 -2.967421e-06 -1.083029e-01 9.941179e-01\n[12,]  3.389381e-01  1.526153e-03  1.421008e-05 1.551759e-06\n[13,]  4.073237e-01  1.833598e-03  1.707161e-05 1.864242e-06\n[14,]  2.990123e-01  1.345915e-03  1.253081e-05 1.368380e-06\n\n$fbar\n [1] -0.03663149 -0.01234409  0.32654631 -0.32401709  0.04311921  0.10288939\n [7] -0.07608552 -0.07337208 -0.42901444  0.31215687  2.41473272 -2.37711349\n[13]  1.10249916 -0.88581366\n\n\n\n- 시각화코드\n\n%%R -w 1000 -h 800 -r 100\nlibrary(gridExtra)\n\nfig1_1&lt;-ggplot()+geom_tile(data=W_Euclid_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"white\",high=\"black\")+\nlabs(fill=TeX('$W$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(a) Euclid\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_2&lt;-ggplot()+geom_tile(data=W_Graph_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"white\",high=\"black\")+\nlabs(fill=TeX('$\\\\hat{W}$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(b) Graph\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_3&lt;-ggplot()+geom_tile(data=W_HST_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"white\",high=\"black\")+\nlabs(fill=TeX('$\\\\hat{W}(\\\\tau)$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(c) HST\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_4&lt;-eigenplot(gfftrslt_Euclid)+ylim(0,2)+theme_light()\nfig1_5&lt;-eigenplot(gfftrslt_Graph)+ylim(0,2)+theme_light()\nfig1_6&lt;-eigenplot(gfftrslt_HST)+ylim(0,2)+theme_light()\nfig1=grid.arrange(fig1_1,fig1_2,fig1_3,fig1_4,fig1_5,fig1_6,ncol=3,nrow=2)\nfig1\n#ggsave(plot=fig1,\"asdf2.pdf\",width=15,height=10)\n\nTableGrob (2 x 3) \"arrange\": 6 grobs\n  z     cells    name           grob\n1 1 (1-1,1-1) arrange gtable[layout]\n2 2 (1-1,2-2) arrange gtable[layout]\n3 3 (1-1,3-3) arrange gtable[layout]\n4 4 (2-2,1-1) arrange gtable[layout]\n5 5 (2-2,2-2) arrange gtable[layout]\n6 6 (2-2,3-3) arrange gtable[layout]\n\n\n\n\n\n\n\n\n\n\n%%R -w 200 -h 600 -r 120\nfig_= grid.arrange(fig1_4,fig1_5,fig1_6,nrow=3)\nggsave(plot=fig_,\"spectrum.pdf\",width=2,height=6)\n\n\n\n\n\n\n\n\n\n\nR을 활용한 시각화 (3): Decomposition\n- 디콤포지션을 수행하고 결과를 저장: \\((\\bf{f},\\bf{W})\\)에 decomposition을 수행하고 그 결과를 각각 decomprslt_Euclid, decomprslt_Graph, decomprslt_HST에 저장한다.\n\n%%R \ndecomprslt_Euclid&lt;-decompose(f,W_Euclid,V=1:n) # 0, 35000, 60000, 80000\ndecomprslt_Graph&lt;-decompose(f,W_Graph,V=1:n) # 0, 35000, 60000, 80000\ndecomprslt_HST&lt;-decompose(f,W_HST,V=1:n) # 0, 35000, 60000, 80000\n\nNote: Using an external vector in selections is ambiguous.\nℹ Use `all_of(n)` instead of `n` to silence this message.\nℹ See &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;.\nThis message is displayed once per session.\n\n\n- 디콤포지션 결과는 아래와 같은 형태임\n\n%%R\nhead(decomprslt_Euclid)\n\n# A tibble: 6 x 5\n      V Vindex eigenvectorindex      fhat eigenvalue\n  &lt;int&gt;  &lt;int&gt;            &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1     1      1                1  8.02e-18   4.04e-18\n2     2      2                1  2.04e-16   4.04e-18\n3     3      3                1 -1.94e-16   4.04e-18\n4     4      4                1  1.00e+ 0   4.04e-18\n5     5      5                1 -3.67e-17   4.04e-18\n6     6      6                1  1.20e-16   4.04e-18\n\n\n\n%%R \ndecomprslt_Euclid$method=\"Euclid\"\ndecomprslt_Graph$method=\"Graph\"\ndecomprslt_HST$method=\"HST\"\ndecomprslt&lt;-rbind(decomprslt_Euclid,decomprslt_Graph,decomprslt_HST)\n\n- 디콤포지션결과를 시각화한다. geom_col과 facet_grid를 이용.\n\n%%R -w 2000 -h 500 -r 100\nfig2&lt;-ggplot(data=decomprslt,aes(x=V,y=fhat))+\ngeom_col(aes(fill=fhat&gt;0),width=0.7)+facet_grid(method~eigenvectorindex)+geom_hline(aes(yintercept=0),col=\"gray60\",lty=2)+\nxlab(\"\")+ylab(\"\")+guides(fill=FALSE)+theme(plot.title=element_text(face=\"bold.italic\"))+theme_bw()+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 15, color = \"black\", face = \"bold.italic\"))+\nylim(-1.5,1.5)+\ntheme(plot.title=element_text(face=\"bold.italic\"))\nfig2\n#ggsave(plot=fig2,\"asdf.pdf\",width=20,height=6)\n\n\n\n\n\n\n\n\n\n\nAppendix\n\n_, (ax1,ax2) = plt.subplots(1,2)\nax1.imshow(hst.eucliddistance[:7,:7],origin='lower')\nax2.imshow(hst.snowdistance[:7,:7],origin='lower')\nplt.show()\n\n\n\n\n\n\n\n\n\nbrk=5000\n_, (ax1,ax2,ax3) = plt.subplots(1,3) \nax1.imshow(l2distance(hst.snowygrounds.iloc[:,0:brk]),origin='lower')\nax2.imshow(l2distance(hst.snowygrounds.iloc[:,brk:]),origin='lower')\nax3.imshow(hst.snowdistance,origin='lower')\n#ax4.imshow(diffusion_distance)\nplt.show()\n\n\n\n\n\n\n\n\n\n_, (ax1,ax2,ax3) = plt.subplots(1,3) \nax1.imshow(hst.snowdistance1[:3,:3],origin='lower')\nax2.imshow(hst.snowdistance2[:3,:3],origin='lower')\nax3.imshow(hst.snowdistance3[:3,:3],origin='lower')\n#ax4.imshow(diffusion_distance)\nplt.show()\n\n\n\n\n\n\n\n\n\nhst.snowdistance1[:3,:3]\n\narray([[0., 0., 0.],\n       [0., 0., 0.],\n       [0., 0., 0.]])\n\n\n\nhst.snowdistance2[:3,:3]\n\narray([[0., 0., 0.],\n       [0., 0., 0.],\n       [0., 0., 0.]])\n\n\n\nhst.snowdistance3[:3,:3]\n\narray([[  0.    , 260.0478, 625.2048],\n       [260.0478,   0.    , 248.562 ],\n       [625.2048, 248.562 ,   0.    ]])\n\n\n\nhst.snowdistance1[2:5,2:5]\n\narray([[     0., 320004.,      0.],\n       [320004.,      0., 320004.],\n       [     0., 320004.,      0.]])\n\n\n\nhst.snowdistance2[2:5,2:5]\n\narray([[      0.       , -635244.4800001,       0.       ],\n       [-635244.4800001,       0.       , -638790.3600001],\n       [      0.       , -638790.3600001,       0.       ]])\n\n\n\nhst.snowdistance3[2:5,2:5]\n\narray([[0.00000000e+00, 3.16268692e+05, 3.04125300e+02],\n       [3.16268692e+05, 0.00000000e+00, 3.19767008e+05],\n       [3.04125300e+02, 3.19767008e+05, 0.00000000e+00]])\n\n\n\nhst.snowdistance1[1:6,1:6]+hst.snowdistance2[1:6,1:6]+hst.snowdistance3[1:6,1:6]\n\narray([[   0.        ,  248.562     , 1222.13219978,  535.0581    ,\n         747.8532    ],\n       [ 248.562     ,    0.        , 1028.21219997,  304.1253    ,\n         516.9042    ],\n       [1222.13219978, 1028.21219997,    0.        ,  980.64749998,\n        1109.91119971],\n       [ 535.0581    ,  304.1253    ,  980.64749998,    0.        ,\n         207.9441    ],\n       [ 747.8532    ,  516.9042    , 1109.91119971,  207.9441    ,\n           0.        ]])\n\n\n\nplt.plot((hst.snowdistance1[:,:])[0],'--o')\n\n\n\n\n\n\n\n\n\nplt.plot((hst.snowdistance2[:,:])[0],'--o')\n\n\n\n\n\n\n\n\n\nplt.plot((hst.snowdistance3[:,:])[0],'--o')\n\n\n\n\n\n\n\n\n\ny[[1,2]]\n\narray([260.0478, 625.2048])\n\n\n\ny=hst.snowdistance[0]\nplt.plot(y,'o--')\nplt.plot([0,1,2,4,5,6,10],y[[0,1,2,4,5,6,10]],'o')\nplt.plot([3,7,8,9,11,12,13],y[[3,7,8,9,11,12,13]],'o')\n\n\n\n\n\n\n\n\n\np, (ax1,ax2,ax3) = plt.subplots(1,3) \nax1.imshow(hst.euclidweight,origin='lower')\nax2.imshow(hst.snowweight,origin='lower')\nax3.imshow(hst.graphweight,origin='lower')\n#ax4.imshow(diffusion_distance)\n#p.show()\np.savefig('temp.pdf', transparent=True)\n\n\n\n\n\n\n\n\n\nprint(np.max(l2distance(hst.snowygrounds_sumxi.iloc[:,0:100])/(100*hst.b**2)))\nprint(np.max(l2distance(hst.snowygrounds_sumxi.iloc[:,0:1000])/(1000*hst.b**2)))\nprint(np.max(l2distance(hst.snowygrounds_sumxi.iloc[:,0:10000])/(10000*hst.b**2)))\nprint(np.max(l2distance(hst.snowygrounds_sumxi.iloc[:,0:15000])/(15000*hst.b**2)))\nprint(np.max(l2distance(hst.snowygrounds_sumxi.iloc[:,0:20000])/(20000*hst.b**2)))\nprint(np.max(l2distance(hst.snowygrounds_sumxi.iloc[:,0:25000])/(25000*hst.b**2)))\nprint(np.max(l2distance(hst.snowygrounds_sumxi.iloc[:,0:30000])/(30000*hst.b**2)))\nprint(np.max(l2distance(hst.snowygrounds_sumxi.iloc[:,0:35000])/(35000*hst.b**2)))\nprint(np.max(l2distance(hst.snowygrounds_sumxi.iloc[:,0:40000])/(40000*hst.b**2)))\nprint(np.max(l2distance(hst.snowygrounds_sumxi.iloc[:,0:45000])/(45000*hst.b**2)))\nprint(np.max(l2distance(hst.snowygrounds_sumxi.iloc[:,0:50000])/(50000*hst.b**2)))\n\n51.44000000000009\n3054.51\n4508.643399999829\n4503.149666666355\n4528.726600000274\n4561.012840000717\n4577.699633334383\n4562.227885715406\n4572.30602500118\n4596.212111112275\n4587.6461600011835"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-08-02-HST example 1 (6).html",
    "href": "연구/교수님이랑/HST/2021-08-02-HST example 1 (6).html",
    "title": "(연구&교수님) HST example 1 (6)",
    "section": "",
    "text": "Import\n\nimport heavysnow as hs\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport rpy2 \n%load_ext rpy2.ipython\n%run pybase\n\n\n\nData\n\nf=np.array([-1,-1,-1,1,-1,-1,-1,1,1,1,-1,1,1,1])*1.0\nn=len(f)\nV=list(range(n))\nW=np.zeros([n,n])\nfor i in range(n):\n    for j in range(n):\n        if abs(i-j)==1: W[i,j]=1\nW[0,0]=1\nW[n-1,n-1]=1\n\n\ngs=hs.GraphSignal(V,W,f)\n\n\ngs.initdist=np.array([1/n]*n)\n\n\n\nHST\n\nhst=hs.HeavySnowTransform(gs)\nhst.snow(tau=80000,b=0.03)\n\nHST (tau= 80000, b=0.03)\n80000/80000\nHST completed and all history is recorded.\n\n\n\nplt.imshow(hst.snowweight)\n\n\n\n\n\n\n\n\n\n\n시각화를 위해서 R로 자료를 옮김\n\nmaxtau=hst.tau\nW_Graph=hst.graphweight\nW_Euclid=hst.euclidweight\nW_HST=hst.snowweight\nV=np.array(hst.V)\nf=hst.f\nn=hst.n\n%R -i maxtau,W_Graph,W_Euclid,W_HST,V,f,n\n\n\n\nR을 활용한 시각화 (1): 원래자료\n\n%%R -w 2000 -h 800 -r 100\nlibrary(tidyverse)\nlibrary(latex2exp)\nlibrary(gridExtra)\nsource('rbase.R')\nVtext=str_c('node ',V+1)\nfig0&lt;-ggplot(data=tibble(V=V,f=f,Vtext=Vtext),aes(x=V,y=f,label=Vtext))+\ngeom_col(aes(fill=(f&gt;0)),width=0.1)+geom_hline(aes(yintercept=0),col=\"gray60\",lty=2)+\ngeom_text(fontface = 4,size=8)+\nxlab(\"\")+ylab(\"\")+guides(fill=FALSE)+theme(plot.title=element_text(face=\"bold.italic\"))+theme_bw()+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 15, color = \"black\", face = \"bold.italic\"))+\nylim(-1.2,1.2)+\ntheme(plot.title=element_text(face=\"bold.italic\"))\n#ggsave(plot=p0,\"./fig/2021-0217_fig0.pdf\",width=20,height=6)\nfig0\n\nR[write to console]: ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\nR[write to console]: ✔ ggplot2 3.3.5     ✔ purrr   0.3.4\n✔ tibble  3.1.3     ✔ dplyr   1.0.7\n✔ tidyr   1.1.3     ✔ stringr 1.4.0\n✔ readr   2.0.1     ✔ forcats 0.5.1\n\nR[write to console]: ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nR[write to console]: \nAttaching package: ‘gridExtra’\n\n\nR[write to console]: The following object is masked from ‘package:dplyr’:\n\n    combine\n\n\nR[write to console]: \nAttaching package: ‘lubridate’\n\n\nR[write to console]: The following objects are masked from ‘package:base’:\n\n    date, intersect, setdiff, union\n\n\n\n\n\n\n\n\n\n\n\n\n\nR을 활용한 시각화 (2): Weight matrix 와 Eigen plot\n- ggplot에서 geom_tile을 사용하기 위해서 매트릭스 형태인 W_Graph, W_Euclid, W_HST를 길게 펼친다. 결과를 각각 W_Graph_long, W_Euclid_long, W_HST_long에 저장한다.\n\n%%R\ngrid&lt;-expand.grid(x=1:n,y=1:n)\nW_Graph_long&lt;-as_tibble(cbind(grid,as.vector(W_Graph)));names(W_Graph_long)&lt;-c(\"x\",\"y\",\"W\")\nW_Euclid_long&lt;-as_tibble(cbind(grid,as.vector(W_Euclid)));names(W_Euclid_long)&lt;-c(\"x\",\"y\",\"W\")\nW_HST_long&lt;-as_tibble(cbind(grid,as.vector(W_HST)));names(W_HST_long)&lt;-c(\"x\",\"y\",\"W\")\n\n- 그래프퓨리에 변환: \\((\\bf{f},\\bf{W})\\)에 그래프 퓨리에 변환을 수행함.\n\n%%R\nsource('heavysnow.R')\ngfftrslt_Euclid&lt;-gfft(f,W_Euclid)\ngfftrslt_Graph&lt;-gfft(f,W_Graph)\ngfftrslt_HST&lt;-gfft(f,W_HST)\n\nR[write to console]: \nAttaching package: ‘kohonen’\n\n\nR[write to console]: The following object is masked from ‘package:purrr’:\n\n    map\n\n\nR[write to console]: \nAttaching package: ‘igraph’\n\n\nR[write to console]: The following objects are masked from ‘package:lubridate’:\n\n    %--%, union\n\n\nR[write to console]: The following objects are masked from ‘package:dplyr’:\n\n    as_data_frame, groups, union\n\n\nR[write to console]: The following objects are masked from ‘package:purrr’:\n\n    compose, simplify\n\n\nR[write to console]: The following object is masked from ‘package:tidyr’:\n\n    crossing\n\n\nR[write to console]: The following object is masked from ‘package:tibble’:\n\n    as_data_frame\n\n\nR[write to console]: The following objects are masked from ‘package:stats’:\n\n    decompose, spectrum\n\n\nR[write to console]: The following object is masked from ‘package:base’:\n\n    union\n\n\n\n\n- 그래프 퓨리에 변환의 결과 고유치, 고유벡터, \\(\\bf{\\bar{f}}\\)가 반환됨.\n\n%%R\nhead(gfftrslt_HST)\n\n$λ\n [1] 1.999761e+00 1.000000e+00 2.394143e-04 2.490505e-07 7.763995e-08\n [6] 3.897684e-10 3.862066e-11 4.759240e-12 1.338101e-14 8.565422e-18\n[11] 7.262993e-21 2.984554e-23 1.699135e-25 2.186514e-33\n\n$Ψ\n               [,1]          [,2]          [,3]          [,4]          [,5]\n [1,] -7.071068e-01  3.399790e-20  7.071068e-01  4.714158e-17  2.187466e-23\n [2,]  7.071068e-01  3.388904e-20  7.071068e-01  4.715285e-17  2.187989e-23\n [3,] -1.055615e-10 -4.440892e-16 -8.818865e-07  8.187692e-11  3.508290e-17\n [4,] -6.343903e-28  4.798396e-22 -5.298713e-24  1.998401e-15  1.188037e-16\n [5,] -7.953475e-22  5.260171e-04 -6.559183e-18 -8.428319e-01  3.294244e-19\n [6,] -7.836455e-23 -9.999998e-01 -9.264757e-21 -3.279650e-04  1.441352e-22\n [7,]  7.824325e-27  2.143886e-04  3.028994e-21  5.381768e-01 -1.359700e-19\n [8,] -5.511857e-42  2.582706e-21 -2.203172e-37 -3.546299e-14 -2.029920e-16\n [9,] -2.074409e-45  6.152347e-27 -1.934975e-41  6.369274e-18 -2.392213e-17\n[10,] -1.334284e-50  1.693165e-34 -1.024350e-46 -3.247787e-21  5.363326e-17\n[11,] -9.501223e-57  1.068480e-43 -7.939094e-53 -3.071872e-35  1.303965e-26\n[12,] -4.146264e-69 -1.777885e-55  9.867995e-65 -6.154673e-37  2.126462e-08\n[13,] -1.558172e-74 -2.927346e-64 -1.314831e-70 -3.373967e-45 -7.072368e-01\n[14,] -5.571384e-80 -2.941127e-72  2.083306e-74 -1.710405e-47  7.069767e-01\n               [,6]          [,7]          [,8]          [,9]         [,10]\n [1,]  1.280611e-22 -2.171164e-22  4.165500e-22  6.039770e-10 -7.952977e-13\n [2,]  1.280918e-22 -2.171684e-22  4.166497e-22  6.041216e-10 -7.954881e-13\n [3,]  2.053864e-16 -3.482153e-16  6.680691e-16  9.686674e-04 -1.275510e-06\n [4,]  3.149384e-17  1.548678e-16 -3.684978e-13  1.752008e-08  5.991793e-07\n [5,] -2.227570e-12  1.098780e-10 -2.534759e-19 -5.381764e-01  4.522589e-07\n [6,] -1.918002e-15  9.468134e-14 -3.272566e-22 -4.637835e-04  3.897425e-10\n [7,] -3.480886e-12  1.720410e-10 -9.045363e-19 -8.428315e-01  7.082772e-07\n [8,]  1.164463e-01 -5.697213e-01  3.785104e-13  6.845551e-07  8.135465e-01\n [9,] -9.178945e-01  2.511331e-01  1.418959e-13  2.586324e-07  3.072489e-01\n[10,]  3.793547e-01  7.825279e-01  2.268687e-13  4.156512e-07  4.937005e-01\n[11,] -1.828483e-14 -3.806576e-13 -4.970924e-17 -5.835723e-16 -1.082853e-06\n[12,] -3.011466e-13 -6.269305e-12 -3.467768e-04 -9.611235e-15 -1.783449e-05\n[13,]  2.259863e-18  3.332198e-16  7.069767e-01 -4.012326e-18 -4.372955e-09\n[14,] -4.353335e-19  9.890725e-17  7.072368e-01 -3.623546e-18 -4.374028e-09\n              [,11]         [,12]         [,13]         [,14]\n [1,]  6.235130e-07 -1.623268e-14 -2.775098e-11 -1.078127e-15\n [2,]  6.236623e-07 -1.623657e-14 -2.775762e-11 -1.078385e-15\n [3,]  9.999995e-01 -2.603422e-08 -4.450743e-05 -1.729116e-09\n [4,] -4.450747e-05  2.355265e-05 -1.000000e+00 -1.889325e-06\n [5,]  5.213142e-04 -2.142230e-11 -3.263100e-08 -1.411610e-12\n [6,]  4.492522e-07 -1.846107e-14 -2.812037e-11 -1.216482e-15\n [7,]  8.164238e-04 -3.354920e-11 -5.110301e-08 -2.210706e-12\n [8,]  1.037046e-06 -1.450895e-05  4.870740e-07 -8.849903e-07\n [9,]  3.916568e-07 -5.479539e-06  1.839513e-07 -3.342309e-07\n[10,]  6.293307e-07 -8.804759e-06  2.955808e-07 -5.370566e-07\n[11,] -1.638867e-09  2.784688e-04  1.895883e-06 -1.000000e+00\n[12,] -2.710570e-08 -9.999999e-01 -2.355213e-05 -2.784688e-04\n[13,] -6.646211e-12 -2.451781e-04 -5.774730e-09 -6.827447e-08\n[14,] -6.647841e-12 -2.452383e-04 -5.776146e-09 -6.829122e-08\n\n$fbar\n [1]  1.055614e-10  9.992594e-01 -1.414213e+00  3.049831e-01 -2.600770e-04\n [6] -4.220936e-01  4.639397e-01  1.413867e+00  1.380504e+00  1.614480e+00\n[11] -1.001381e+00 -1.000774e+00 -9.999799e-01  9.997177e-01\n\n\n\n- 시각화코드\n\n%%R -w 1000 -h 800 -r 100\nlibrary(gridExtra)\n\nfig1_1&lt;-ggplot()+geom_tile(data=W_Euclid_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"red\",high=\"blue\",mid=\"purple\",midpoint=0.25,breaks=c(0,0.5,0.99))+\nlabs(fill=TeX('$W$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(a) Euclid\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_2&lt;-ggplot()+geom_tile(data=W_Graph_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"red\",high=\"blue\",mid=\"purple\",midpoint=0.5,breaks=c(0,0.5,0.99))+\nlabs(fill=TeX('$\\\\hat{W}$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(b) Graph\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_3&lt;-ggplot()+geom_tile(data=W_HST_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"red\",high=\"blue\",mid=\"purple\",midpoint=0.5,breaks=c(0,0.5,0.99))+\nlabs(fill=TeX('$\\\\hat{W}(\\\\tau)$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(c) HST\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_4&lt;-eigenplot(gfftrslt_Euclid)+ylim(0,2)+theme_light()\nfig1_5&lt;-eigenplot(gfftrslt_Graph)+ylim(0,2)+theme_light()\nfig1_6&lt;-eigenplot(gfftrslt_HST)+ylim(0,2)+theme_light()\nfig1=grid.arrange(fig1_1,fig1_2,fig1_3,fig1_4,fig1_5,fig1_6,ncol=3,nrow=2)\nfig1\n#ggsave(plot=grid.arrange(p1_a,p1_b,p1_c,ncol=3),\"2021-07-22_fig1.png\",width=20,height=4)\n\nTableGrob (2 x 3) \"arrange\": 6 grobs\n  z     cells    name           grob\n1 1 (1-1,1-1) arrange gtable[layout]\n2 2 (1-1,2-2) arrange gtable[layout]\n3 3 (1-1,3-3) arrange gtable[layout]\n4 4 (2-2,1-1) arrange gtable[layout]\n5 5 (2-2,2-2) arrange gtable[layout]\n6 6 (2-2,3-3) arrange gtable[layout]\n\n\n\n\n\n\n\n\n\n\n\nR을 활용한 시각화 (3): Decomposition\n- 디콤포지션을 수행하고 결과를 저장: \\((\\bf{f},\\bf{W})\\)에 decomposition을 수행하고 그 결과를 각각 decomprslt_Euclid, decomprslt_Graph, decomprslt_HST에 저장한다.\n\n%%R \ndecomprslt_Euclid&lt;-decompose(f,W_Euclid,V=1:n) # 0, 35000, 60000, 80000\ndecomprslt_Graph&lt;-decompose(f,W_Graph,V=1:n) # 0, 35000, 60000, 80000\ndecomprslt_HST&lt;-decompose(f,W_HST,V=1:n) # 0, 35000, 60000, 80000\n\nNote: Using an external vector in selections is ambiguous.\nℹ Use `all_of(n)` instead of `n` to silence this message.\nℹ See &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;.\nThis message is displayed once per session.\n\n\n- 디콤포지션 결과는 아래와 같은 형태임\n\n%%R\nhead(decomprslt_Euclid)\n\n# A tibble: 6 × 5\n      V Vindex eigenvectorindex      fhat eigenvalue\n  &lt;int&gt;  &lt;int&gt;            &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1     1      1                1  1.45e-32   3.28e-18\n2     2      2                1  2.48e-17   3.28e-18\n3     3      3                1 -2.02e-16   3.28e-18\n4     4      4                1  1   e+ 0   3.28e-18\n5     5      5                1  8.73e-17   3.28e-18\n6     6      6                1 -6.32e-17   3.28e-18\n\n\n\n%%R \ndecomprslt_Euclid$method=\"Euclid\"\ndecomprslt_Graph$method=\"Graph\"\ndecomprslt_HST$method=\"HST\"\ndecomprslt&lt;-rbind(decomprslt_Euclid,decomprslt_Graph,decomprslt_HST)\n\n- 디콤포지션결과를 시각화한다. geom_col과 facet_grid를 이용.\n\n%%R -w 2000 -h 500 -r 100\nfig2&lt;-ggplot(data=decomprslt,aes(x=V,y=fhat))+\ngeom_col(aes(fill=fhat&gt;0),width=0.7)+facet_grid(method~eigenvectorindex)+geom_hline(aes(yintercept=0),col=\"gray60\",lty=2)+\nxlab(\"\")+ylab(\"\")+guides(fill=FALSE)+theme(plot.title=element_text(face=\"bold.italic\"))+theme_bw()+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 15, color = \"black\", face = \"bold.italic\"))+\nylim(-1.5,1.5)+\ntheme(plot.title=element_text(face=\"bold.italic\"))\nfig2\n#ggsave(plot=fig2,\"./fig/2021-0514_fig2.pdf\",width=20,height=6)"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-08-05-HST 이론개발.html",
    "href": "연구/교수님이랑/HST/2021-08-05-HST 이론개발.html",
    "title": "(연구&교수님) HST 이론개발",
    "section": "",
    "text": "snow distance 의 분해\n- 제안하는 snow-distance의 분해결과를 \\(\\tau\\)로 나누면 아래와 같다.\n\\(\\frac{1}{\\tau}\\Sigma_{ij}^{(\\tau)}=[f(v_i)-f(v_j)]^2+\\frac{1}{\\tau}\\sum_{\\ell=1}^{\\tau}\\left\\{\\sum_{k=1}^{\\ell}\\xi(v_i,k)-\\sum_{k=1}^{\\ell}\\xi(v_j,k) \\right\\}^2+\\frac{2}{\\tau}(f(v_i)-f(v_j))\\sum_{\\ell=1}^{\\tau}\\left\\{\\sum_{k=1}^{\\ell}\\xi(v_i,k)-\\sum_{k=1}^{\\ell}\\xi(v_j,k) \\right\\}\\)\n- 따라서 \\(\\frac{1}{\\tau}\\sum_{ij}^{(\\tau)}\\)는 아래와 같은 3가지의 term으로 구분할 수 있다.\n\n(유클리드 차이)\\(^2\\)\n(\\(1\\sim \\tau\\)의 적재량 차이)\\(^2\\)의 합 \\(\\times\\) \\(\\frac{1}{\\tau}\\)\n(\\(1\\sim \\tau\\)의 적재량 차이)의 합 \\(\\times\\) 유클리드 차이 \\(\\times\\) \\(\\frac{2}{\\tau}\\)\n\n- 편의상 유클리드텀, 그래프텀, 크로스텀이라고 부르자.\n\n그래프텀\n\\(graphterm(i,j):=\\sum_{\\ell=1}^{\\tau}\\Delta(\\ell,i,j)\\) where \\(\\Delta(\\ell,i,j)\\)는\n\\(\\Delta(\\ell,i,j)=\\left(\\sum_{k=1}^{\\ell}\\xi(v_i,k)-\\sum_{k=1}^{\\ell}\\xi(v_j,k)\\right)^2\\approx |f(v_i)-f(v_j)|^2\\)\n\\(=\\left(h(v_i,\\ell)-f(v_i)-h(v_j,\\ell)+f(v_j)\\right)^2\\)\n\\(=\\left(h(v_i,\\ell)-h(v_j,\\ell)\\right)^2+\\left(f(v_i)-f(v_j)\\right)^2+2\\left(f(v_j)-f(v_i)\\right)\\left(h(v_i,\\ell)-h(v_j,\\ell)\\right)\\)\n\\(=\\big(\\sum_{k=1}^{\\ell}\\big[\\xi(v_i,k)-\\xi(v_j,k)\\big]\\big)^2\\)\n\\(=\\big(\\xi(v_i,1)-\\xi(v_j,1)\\big)^2+\\dots+\\big(\\xi(v_i,\\ell)-\\xi(v_j,\\ell)\\big)^2+gd\\)\n\\(=\\big(\\xi(v_i,1)+\\xi(v_j,1)\\big)+\\dots+\\big(\\xi(v_i,\\ell)+\\xi(v_j,\\ell)\\big)+gd\\)\n\\(=\\sum_{k=1}^{\\ell}\\xi(v_i,k)+\\sum_{k=1}^{\\ell}\\xi(v_j,k)+gd\\)\n- gd 아래와 같이 쓸 수 있다.\n\\(gd=2\\big(\\xi(v_i,1)-\\xi(v_j,1)\\big)\\big(\\xi(v_i,2)-\\xi(v_j,2)\\big)+\\dots+2\\big(\\xi(v_i,\\ell-1)-\\xi(v_j,\\ell-1)\\big)\\big(\\xi(v_i,\\ell)-\\xi(v_j,\\ell)\\big)\\)\n\\(:=d(1,2)+d(1,3)+\\dots+d(1,\\ell)+d(2,3)+\\dots+d(2,\\ell)+\\dots+2d(\\ell-1,\\ell)\\)\n여기에서 \\(d(1,2)\\)의 값을 해석하여 보자.\n\n\\(d(1,2)=0\\): 시점1에서의 차이=0 OR 시점2에서의 차이=0\n\\(d(1,2)=2\\): 시점1에서 \\(i\\)에 눈이 내림 & 시점2에서도 \\(i\\)에 눈이 내림\n\n- regular graph + ergodicity를 이용하면 예제2의 CASE-A와 CASE-B의 그래프텀이 같은 극한값을 가짐을 보일 수 있다.\n\n\n크로스텀\n- 크로스텀을 계산하자.\n\\(\\frac{2}{\\tau}(f(v_i)-f(v_j))\\sum_{\\ell=1}^{\\tau}\\left\\{\\sum_{k=1}^{\\ell}\\xi(v_i,k)-\\sum_{k=1}^{\\ell}\\xi(v_j,k) \\right\\}\\)\n- (직관) \\(\\xi(v_i,k)-\\xi(v_j,k)\\)가 1 혹은 -1을 가질 확률은 같다.\n이제 \\(\\Delta_{ij}(\\ell):=\\sum_{k=1}^{\\ell}\\xi(v_i,k)-\\xi(v_j,k)\\) 을 정의하자.\n분명히 \\(\\Delta_{ij}(\\ell)\\)는 평균이 0인 확률변수이다. (분산은??)\n\\(\\sum_{k=1}^{\\ell}\\Delta_{ij}(k)=\\#\\big(A_i(\\ell)\\big) - \\#\\big(A_j(\\ell)\\big)\\), where \\(A_i(\\ell)=\\{\\}\\)\n\n\n\nSnow distance의 order\n– \\(\\frac{1}{\\tau b^2}\\Sigma_{ij}^{(\\tau)}=O_p(1)\\) 임을 보이자.\n- \\(\\Sigma_{ij}^{(\\tau)}=\\big[f(v_i,0)-f(v_j,0)\\big]^2+\\big[f(v_i,0)+\\xi(v_i,1)-f(v_j)-\\xi(v_j,1)\\big]^2+\\dots+\\big[f(v_i,0)+\\xi(v_i,1)+\\dots+\\xi(v_i,\\tau)-f(v_j)-\\xi(v_j,1)-\\dots-\\xi(v_j,\\tau)\\big]^2\\)\n- 편의성 아래와 같이 정의하자.\n\n\\(\\Delta_{ij}^{(0)}=\\big[f(v_i,0)-f(v_j,0)\\big]^2\\)\n\\(\\dots\\)\n\\(\\Delta_{ij}^{(\\tau)}=\\big[f(v_i,0)+\\xi(v_i,1)+\\dots+\\xi(v_i,\\tau)-f(v_j)-\\xi(v_j,1)-\\dots-\\xi(v_j,\\tau)\\big]^2\\)\n\n- 그러면 \\(\\Sigma_{ij}^{(\\tau)}=\\sum_{\\ell=0}^{\\tau}\\Delta_{ij}^{(\\ell)}\\)\n– WLOG, \\(b=1\\) then, \\(\\xi(v_i,1)=0~ or~ 1\\)\n– 아래를 살펴보자. - \\(\\frac{1}{\\tau^2}\\Delta_{ij}^{(0)}=O(\\frac{1}{\\tau^2})\\) - \\(\\frac{1}{\\tau^2}\\Delta_{ij}^{(1)}=\\frac{1}{\\tau^2}o_p(1)+(p_i-p_j)\\) - \\(\\frac{1}{\\tau^2}\\Delta_{ij}^{(2)}=\\frac{2^2}{\\tau^2}o_p(1)+(p_i-p_j)\\) - \\(\\dots\\) - \\(\\frac{1}{\\tau^2}\\Delta_{ij}^{(\\tau-1)}=\\frac{(\\tau-1)^2}{\\tau^2}o_p(1)+(p_i-p_j)\\) - \\(\\frac{1}{\\tau^2}\\Delta_{ij}^{(\\tau)}=\\frac{\\tau^2}{\\tau^2}o_p(1)+(p_i-p_j)\\)\n- 따라서 $_{ij}^{()}=(o_p(1)+(p_i-p_j)) $\n- \\(p_i=p_j\\)라고 하면 \\(\\frac{1}{\\tau^2}\\sum_{ij}^{(\\tau)}=o_p(\\tau)\\)\n\n단순한예제\n- 2개의 노드가 있고 \\(i\\),\\(j\\)에서 반복된다고 하자.\n- \\(\\Sigma^{(\\tau)}_{ij}=\\Delta_{ij}^{(0)}=0\\)"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-08-09-HST example 2 (4).html",
    "href": "연구/교수님이랑/HST/2021-08-09-HST example 2 (4).html",
    "title": "(연구&교수님) HST example 2 (4)",
    "section": "",
    "text": "import heavysnow as hs \nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt \nfrom sklearn.decomposition import PCA \nimport rpy2 \n%load_ext rpy2.ipython\n%run pybase\n\n\n### Example 2\nnp.random.seed(777)\nimport math\npi=math.pi\nn=60\nang=np.linspace(-pi,pi-2*pi/n,n)\nV=np.arange(n)+1\nr=1\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=vx*0\n\nf2=vx*0\nf2[vy&lt;0]=3+np.random.normal(size=sum(vy&lt;0),scale=0.1)\nf2[vy&gt;=0]= -3+np.random.normal(size=sum(vy&gt;=0),scale=0.1)\n\n\n# Edg setting\nΣ=l2distance(np.matrix([vx,vy]).T)\nθ=0.15\nW=np.exp(-Σ**2/(2*θ**2))-np.eye(n,n)\nE=W&gt;0\nplt.plot(W[0,:].T)\n# color\nimport matplotlib.cm as cm\ncol=list(np.array(cm.rainbow((ang+pi)/2/pi)))\n\n\n\n\n\n\n\n\n\ngs1=hs.GraphSignal(V,W,f1)\ngs2=hs.GraphSignal(V,W,f2)\n\n\nDiffusion distance\n\nP=W/W.round(3).sum(axis=0)[0]\nprint(P)\nplt.imshow(P)\n\n[[0.         0.14154641 0.13602631 ... 0.11470516 0.13602631 0.14154641]\n [0.14154641 0.         0.14154641 ... 0.07303255 0.11470516 0.13602631]\n [0.13602631 0.14154641 0.         ... 0.02878376 0.07303255 0.11470516]\n ...\n [0.11470516 0.07303255 0.02878376 ... 0.         0.14154641 0.13602631]\n [0.13602631 0.11470516 0.07303255 ... 0.14154641 0.         0.14154641]\n [0.14154641 0.13602631 0.11470516 ... 0.13602631 0.14154641 0.        ]]\n\n\n\n\n\n\n\n\n\n\nplt.imshow(P@P@P@P)\n\n\n\n\n\n\n\n\n\nP4=P@P@P@P\ndiffusion_distance=l2distance(P4)\nplt.imshow(diffusion_distance)\n\n\n\n\n\n\n\n\n\n\nSnow distance\n\nhs1=hs.HeavySnowTransform(gs1)\nhs2=hs.HeavySnowTransform(gs2)\n\n\nhs1.snow(tau=100000,b=0.05)\nhs2.snow(tau=100000,b=0.05)\n\nHST (tau= 100000, b=0.05)\n100000/100000\nHST completed and all history is recorded.\nHST (tau= 100000, b=0.05)\n100000/100000\nHST completed and all history is recorded.\n\n\n\nfrom sklearn.decomposition import PCA \np1=PCA(n_components=3)\np2=PCA(n_components=3)\np3=PCA(n_components=3)\np4=PCA(n_components=3)\np5=PCA(n_components=3)\np6=PCA(n_components=3)\n\n\np1.fit(hs1.eucliddistance)\np2.fit(diffusion_distance)\np3.fit(hs1.snowdistance)\np4.fit(hs2.eucliddistance)\np5.fit(diffusion_distance)\np6.fit(hs2.snowdistance)\n\nr1=p1.transform(hs1.eucliddistance)\nr2=p2.transform(diffusion_distance)\nr3=p3.transform(hs1.snowdistance)\nr4=p4.transform(hs2.eucliddistance)\nr5=p5.transform(diffusion_distance)\nr6=p6.transform(hs2.snowdistance)\n\n/home/cgb4/anaconda3/envs/py38r40/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:470: RuntimeWarning: invalid value encountered in true_divide\n  explained_variance_ratio_ = explained_variance_ / total_var\n\n\n\n# 1. \np=plt.figure(figsize=(12,4), dpi=70)  # Make figure object \n\n# 2. \nax1=p.add_subplot(2,4,1, projection='3d')\nax2=p.add_subplot(2,4,2, projection='3d')\nax3=p.add_subplot(2,4,3, projection='3d')\nax4=p.add_subplot(2,4,4, projection='3d')\nax5=p.add_subplot(2,4,5, projection='3d')\nax6=p.add_subplot(2,4,6, projection='3d')\nax7=p.add_subplot(2,4,7, projection='3d')\nax8=p.add_subplot(2,4,8, projection='3d')\n\n# 3. \nax1.grid(False)\nax1.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax1.scatter3D(vx, vy, f1, c=col,alpha=1)\nax1.set_xlim(-1,1)\nax1.set_ylim(-1,1)\nax1.set_zlim(-5,5)\n\nax2.grid(False)\nax2.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax2.scatter3D(r1[:,0],r1[:,1],r1[:,2],s=20,c=col,alpha=1)\n\nax3.grid(False)\nax3.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax3.scatter3D(r2[:,0],r2[:,1],r2[:,2],s=20,c=col,alpha=1)\n\nax4.grid(False)\nax4.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax4.scatter3D(r3[:,0],r3[:,1],r3[:,2],s=20,c=col,alpha=1)\n\n\nax5.grid(False)\nax5.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\ntop = -f2\nbottom = np.zeros_like(top)\nwidth=depth=0.05\nax5.bar3d(vx, vy, bottom, width, depth, top, shade=False,color=col)\nax5.set_xlim(-1,1)\nax5.set_ylim(-1,1)\nax5.set_zlim(-5,5)\n\nax6.grid(False)\nax6.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax6.scatter3D(r4[:,0],r4[:,1],r4[:,2],s=20,c=col,alpha=1)\n\nax7.grid(False)\nax7.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax7.scatter3D(r5[:,0],r5[:,1],r5[:,2],s=20,c=col,alpha=1)\n\nax8.grid(False)\nax8.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax8.scatter3D(r6[:,0],r6[:,1],r6[:,2],s=20,c=col,alpha=1)\np.tight_layout(h_pad=2.6) #rect : tuple (left, bottom, right, top), optional"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-08-03-HST example 2 (2).html",
    "href": "연구/교수님이랑/HST/2021-08-03-HST example 2 (2).html",
    "title": "(연구&교수님) HST example 2 (2)",
    "section": "",
    "text": "import heavysnow as hs \nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt \nfrom sklearn.decomposition import PCA \nimport rpy2 \n%load_ext rpy2.ipython\n%run pybase\n\n\n### Example 2\nnp.random.seed(777)\nimport math\npi=math.pi\nn=59\nang=np.linspace(-pi,pi-2*pi/n,n)\nV=np.arange(n)+1\nr=1\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=vx*0\n\nf2=vx*0\nf2[vy&lt;0]=3+np.random.normal(size=sum(vy&lt;0),scale=0.1)\nf2[vy&gt;0]= -3+np.random.normal(size=sum(vy&gt;0),scale=0.1)\n\n\n# Edg setting\nΣ=l2distance(np.matrix([vx,vy]).T)\nθ=0.05\nW=np.exp(-Σ**2/(2*θ**2))\nE=W&gt;0\nplt.plot(W[0,:].T)\n# color\nimport matplotlib.cm as cm\ncol=list(np.array(cm.rainbow((ang+pi)/2/pi)))\n\n\n\n\n\n\n\n\n\n%R -i ang,vx,vy,n\n\n\n%%R\nlibrary(latex2exp)\nlibrary(gridExtra)\nlibrary(tidyverse)\n\nR[write to console]: ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\nR[write to console]: ✔ ggplot2 3.3.5     ✔ purrr   0.3.4\n✔ tibble  3.1.2     ✔ dplyr   1.0.7\n✔ tidyr   1.1.3     ✔ stringr 1.4.0\n✔ readr   1.4.0     ✔ forcats 0.5.1\n\nR[write to console]: ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::combine() masks gridExtra::combine()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n\n\n\n\n%%R -w 450 -h 300 -r 100\nex2df&lt;-data.frame(cbind(ang,vx,vy))\nnames(ex2df)&lt;-c(\"ang\",\"vx\",\"vy\")\nex2plt &lt;- ggplot(data=ex2df,aes(x=vx,y=vy))+\n            geom_point(col=\"gray60\",cex=1.5,alpha=0.7)+\n            geom_point(data=ex2df[1:n,],aes(x=vx,y=vy,col=ang),cex=1.5,alpha=0.7)+\n            xlab(\"\")+ylab(\"\")+scale_colour_gradientn(colours=rainbow(7))+labs(col=TeX(\"$\\\\phi$\"))+theme_classic()+\n            theme(legend.key.width = unit(2,\"mm\"))\nshow(ex2plt)\n\n\n\n\n\n\n\n\n\ngs1=hs.GraphSignal(V,W,f1)\ngs2=hs.GraphSignal(V,W,f2)\n\n\nplt.imshow(W)\n\n\n\n\n\n\n\n\n\nDiffusion distance\n\nP=W/W.round(3).sum(axis=0)[0]\nprint(P)\nplt.imshow(P)\n\n[[2.20167327e-01 2.14586355e-01 1.46335569e-01 ... 2.83862880e-02\n  1.46335569e-01 2.14586355e-01]\n [2.14586355e-01 2.20167327e-01 2.14586355e-01 ... 3.69898283e-04\n  2.83862880e-02 1.46335569e-01]\n [1.46335569e-01 2.14586355e-01 2.20167327e-01 ... 4.82347874e-08\n  3.69898283e-04 2.83862880e-02]\n ...\n [2.83862880e-02 3.69898283e-04 4.82347874e-08 ... 2.20167327e-01\n  2.14586355e-01 1.46335569e-01]\n [1.46335569e-01 2.83862880e-02 3.69898283e-04 ... 2.14586355e-01\n  2.20167327e-01 2.14586355e-01]\n [2.14586355e-01 1.46335569e-01 2.83862880e-02 ... 1.46335569e-01\n  2.14586355e-01 2.20167327e-01]]\n\n\n\n\n\n\n\n\n\n\nplt.imshow(P@P@P@P)\n\n\n\n\n\n\n\n\n\nP4=P@P@P@P\ndiffusion_distance=l2distance(P4)\nplt.imshow(diffusion_distance)\n\n\n\n\n\n\n\n\n\n\nSnow distance\n\nhs1=hs.HeavySnowTransform(gs1)\nhs2=hs.HeavySnowTransform(gs2)\n\n\nhs1.snow(tau=30000,b=0.1)\nhs2.snow(tau=30000,b=0.1)\n\nHST (tau= 30000, b=0.1)\n30000/30000\nHST completed and all history is recorded.\nHST (tau= 30000, b=0.1)\n30000/30000\nHST completed and all history is recorded.\n\n\n\nfrom sklearn.decomposition import PCA \np1=PCA(n_components=3)\np2=PCA(n_components=3)\np3=PCA(n_components=3)\np4=PCA(n_components=3)\np5=PCA(n_components=3)\np6=PCA(n_components=3)\n\n\np1.fit(hs1.eucliddistance)\np2.fit(diffusion_distance)\np3.fit(hs1.snowdistance)\np4.fit(hs2.eucliddistance)\np5.fit(diffusion_distance)\np6.fit(hs2.snowdistance)\n\nr1=p1.transform(hs1.eucliddistance)\nr2=p2.transform(diffusion_distance)\nr3=p3.transform(hs1.snowdistance)\nr4=p4.transform(hs2.eucliddistance)\nr5=p5.transform(diffusion_distance)\nr6=p6.transform(hs2.snowdistance)\n\n/home/cgb4/anaconda3/envs/py38r40/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:470: RuntimeWarning: invalid value encountered in true_divide\n  explained_variance_ratio_ = explained_variance_ / total_var\n\n\n\n# 1. \np=plt.figure(figsize=(12,4), dpi=70)  # Make figure object \n\n# 2. \nax1=p.add_subplot(2,4,1, projection='3d')\nax2=p.add_subplot(2,4,2, projection='3d')\nax3=p.add_subplot(2,4,3, projection='3d')\nax4=p.add_subplot(2,4,4, projection='3d')\nax5=p.add_subplot(2,4,5, projection='3d')\nax6=p.add_subplot(2,4,6, projection='3d')\nax7=p.add_subplot(2,4,7, projection='3d')\nax8=p.add_subplot(2,4,8, projection='3d')\n\n# 3. \nax1.grid(False)\nax1.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax1.scatter3D(vx, vy, f1, c=col,alpha=1)\nax1.set_xlim(-1,1)\nax1.set_ylim(-1,1)\nax1.set_zlim(-5,5)\n\nax2.grid(False)\nax2.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax2.scatter3D(r1[:,0],r1[:,1],r1[:,2],s=20,c=col,alpha=1)\n\nax3.grid(False)\nax3.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax3.scatter3D(r2[:,0],r2[:,1],r2[:,2],s=20,c=col,alpha=1)\n\nax4.grid(False)\nax4.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax4.scatter3D(r3[:,0],r3[:,1],r3[:,2],s=20,c=col,alpha=1)\n\n\nax5.grid(False)\nax5.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\ntop = -f2\nbottom = np.zeros_like(top)\nwidth=depth=0.05\nax5.bar3d(vx, vy, bottom, width, depth, top, shade=False,color=col)\nax5.set_xlim(-1,1)\nax5.set_ylim(-1,1)\nax5.set_zlim(-5,5)\n\nax6.grid(False)\nax6.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax6.scatter3D(r4[:,0],r4[:,1],r4[:,2],s=20,c=col,alpha=1)\n\nax7.grid(False)\nax7.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax7.scatter3D(r5[:,0],r5[:,1],r5[:,2],s=20,c=col,alpha=1)\n\nax8.grid(False)\nax8.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax8.scatter3D(r6[:,0],r6[:,1],r6[:,2],s=20,c=col,alpha=1)\np.tight_layout(h_pad=2.6) #rect : tuple (left, bottom, right, top), optional"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-08-09-HST example 2 (5).html",
    "href": "연구/교수님이랑/HST/2021-08-09-HST example 2 (5).html",
    "title": "(연구&교수님) HST example 2 (5)",
    "section": "",
    "text": "import heavysnow as hs \nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt \nfrom sklearn.decomposition import PCA \nimport rpy2 \n%load_ext rpy2.ipython\n%run pybase\n\n\n### Example 2\nnp.random.seed(777)\nimport math\npi=math.pi\nn=60\nang=np.linspace(-pi,pi-2*pi/n,n)\nV=np.arange(n)+1\nr=1\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=vx*0\n\nf2=vx*0\nf2[vy&lt;0]=3+np.random.normal(size=sum(vy&lt;0),scale=0.1)\nf2[vy&gt;=0]= -3+np.random.normal(size=sum(vy&gt;=0),scale=0.1)\n\n\n# Edg setting\nΣ=l2distance(np.matrix([vx,vy]).T)\nθ=0.2\nW=np.exp(-Σ**2/(2*θ**2))-np.eye(n,n)\nE=W&gt;0\nplt.plot(W[0,:].T)\n# color\nimport matplotlib.cm as cm\ncol=list(np.array(cm.rainbow((ang+pi)/2/pi)))\n\n\n\n\n\n\n\n\n\ngs1=hs.GraphSignal(V,W,f1)\ngs2=hs.GraphSignal(V,W,f2)\n\n\nDiffusion distance\n\nP=W/W.round(3).sum(axis=0)[0]\nprint(P)\nplt.imshow(P)\n\n[[0.         0.1200121  0.11735654 ... 0.10662519 0.11735654 0.1200121 ]\n [0.1200121  0.         0.1200121  ... 0.08271274 0.10662519 0.11735654]\n [0.11735654 0.1200121  0.         ... 0.04899084 0.08271274 0.10662519]\n ...\n [0.10662519 0.08271274 0.04899084 ... 0.         0.1200121  0.11735654]\n [0.11735654 0.10662519 0.08271274 ... 0.1200121  0.         0.1200121 ]\n [0.1200121  0.11735654 0.10662519 ... 0.11735654 0.1200121  0.        ]]\n\n\n\n\n\n\n\n\n\n\nplt.imshow(P@P@P@P)\n\n\n\n\n\n\n\n\n\nP4=P@P@P@P\ndiffusion_distance=l2distance(P4)\nplt.imshow(diffusion_distance)\n\n\n\n\n\n\n\n\n\n\nSnow distance\n\nhs1=hs.HeavySnowTransform(gs1)\nhs2=hs.HeavySnowTransform(gs2)\n\n\nhs1.snow(tau=100000,b=0.05)\nhs2.snow(tau=100000,b=0.05)\n\nHST (tau= 100000, b=0.05)\n100000/100000\nHST completed and all history is recorded.\nHST (tau= 100000, b=0.05)\n100000/100000\nHST completed and all history is recorded.\n\n\n\nfrom sklearn.decomposition import PCA \np1=PCA(n_components=3)\np2=PCA(n_components=3)\np3=PCA(n_components=3)\np4=PCA(n_components=3)\np5=PCA(n_components=3)\np6=PCA(n_components=3)\n\n\np1.fit(hs1.eucliddistance)\np2.fit(diffusion_distance)\np3.fit(hs1.snowdistance)\np4.fit(hs2.eucliddistance)\np5.fit(diffusion_distance)\np6.fit(hs2.snowdistance)\n\nr1=p1.transform(hs1.eucliddistance)\nr2=p2.transform(diffusion_distance)\nr3=p3.transform(hs1.snowdistance)\nr4=p4.transform(hs2.eucliddistance)\nr5=p5.transform(diffusion_distance)\nr6=p6.transform(hs2.snowdistance)\n\n/home/cgb4/anaconda3/envs/py38r40/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:470: RuntimeWarning: invalid value encountered in true_divide\n  explained_variance_ratio_ = explained_variance_ / total_var\n\n\n\n# 1. \np=plt.figure(figsize=(12,4), dpi=70)  # Make figure object \n\n# 2. \nax1=p.add_subplot(2,4,1, projection='3d')\nax2=p.add_subplot(2,4,2, projection='3d')\nax3=p.add_subplot(2,4,3, projection='3d')\nax4=p.add_subplot(2,4,4, projection='3d')\nax5=p.add_subplot(2,4,5, projection='3d')\nax6=p.add_subplot(2,4,6, projection='3d')\nax7=p.add_subplot(2,4,7, projection='3d')\nax8=p.add_subplot(2,4,8, projection='3d')\n\n# 3. \nax1.grid(False)\nax1.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax1.scatter3D(vx, vy, f1, c=col,alpha=1)\nax1.set_xlim(-1,1)\nax1.set_ylim(-1,1)\nax1.set_zlim(-5,5)\n\nax2.grid(False)\nax2.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax2.scatter3D(r1[:,0],r1[:,1],r1[:,2],s=20,c=col,alpha=1)\n\nax3.grid(False)\nax3.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax3.scatter3D(r2[:,0],r2[:,1],r2[:,2],s=20,c=col,alpha=1)\n\nax4.grid(False)\nax4.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax4.scatter3D(r3[:,0],r3[:,1],r3[:,2],s=20,c=col,alpha=1)\n\n\nax5.grid(False)\nax5.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\ntop = -f2\nbottom = np.zeros_like(top)\nwidth=depth=0.05\nax5.bar3d(vx, vy, bottom, width, depth, top, shade=False,color=col)\nax5.set_xlim(-1,1)\nax5.set_ylim(-1,1)\nax5.set_zlim(-5,5)\n\nax6.grid(False)\nax6.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax6.scatter3D(r4[:,0],r4[:,1],r4[:,2],s=20,c=col,alpha=1)\n\nax7.grid(False)\nax7.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax7.scatter3D(r5[:,0],r5[:,1],r5[:,2],s=20,c=col,alpha=1)\n\nax8.grid(False)\nax8.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax8.scatter3D(r6[:,0],r6[:,1],r6[:,2],s=20,c=col,alpha=1)\np.tight_layout(h_pad=2.6) #rect : tuple (left, bottom, right, top), optional"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-08-03-HST example 2 (7).html",
    "href": "연구/교수님이랑/HST/2021-08-03-HST example 2 (7).html",
    "title": "(연구&교수님) HST example 2 (7)",
    "section": "",
    "text": "import heavysnow as hs \nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt \nfrom sklearn.decomposition import PCA \nimport rpy2 \n%load_ext rpy2.ipython\n%run pybase\n\n\n### Example 2\nnp.random.seed(777)\nimport math\npi=math.pi\nn=59\nang=np.linspace(-pi,pi-2*pi/n,n)\nV=np.arange(n)+1\nr=1\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=vx*0\n\nf2=vx*0\nf2[vy&lt;0]=3+np.random.normal(size=sum(vy&lt;0),scale=0.1)\nf2[vy&gt;0]= -3+np.random.normal(size=sum(vy&gt;0),scale=0.1)\n\n\n# Edg setting\nΣ=l2distance(np.matrix([vx,vy]).T)\nθ=0.05\nW=np.exp(-Σ**2/(2*θ**2))\nE=W&gt;0\nplt.plot(W[0,:].T)\n# color\nimport matplotlib.cm as cm\ncol=list(np.array(cm.rainbow((ang+pi)/2/pi)))\n\n\n\n\n\n\n\n\n\n%R -i ang,vx,vy,n\n\n\n%%R\nlibrary(latex2exp)\nlibrary(gridExtra)\nlibrary(tidyverse)\n\nR[write to console]: ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\nR[write to console]: ✔ ggplot2 3.3.5     ✔ purrr   0.3.4\n✔ tibble  3.1.2     ✔ dplyr   1.0.7\n✔ tidyr   1.1.3     ✔ stringr 1.4.0\n✔ readr   1.4.0     ✔ forcats 0.5.1\n\nR[write to console]: ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::combine() masks gridExtra::combine()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n\n\n\n\n%%R -w 450 -h 300 -r 100\nex2df&lt;-data.frame(cbind(ang,vx,vy))\nnames(ex2df)&lt;-c(\"ang\",\"vx\",\"vy\")\nex2plt &lt;- ggplot(data=ex2df,aes(x=vx,y=vy))+\n            geom_point(col=\"gray60\",cex=1.5,alpha=0.7)+\n            geom_point(data=ex2df[1:n,],aes(x=vx,y=vy,col=ang),cex=1.5,alpha=0.7)+\n            xlab(\"\")+ylab(\"\")+scale_colour_gradientn(colours=rainbow(7))+labs(col=TeX(\"$\\\\phi$\"))+theme_classic()+\n            theme(legend.key.width = unit(2,\"mm\"))\nshow(ex2plt)\n\n\n\n\n\n\n\n\n\ngs1=hs.GraphSignal(V,W,f1)\ngs2=hs.GraphSignal(V,W,f2)\n\n\nplt.imshow(W)\n\n\n\n\n\n\n\n\n\nDiffusion distance\n\nP=W/W.round(3).sum(axis=0)[0]\nprint(P)\nplt.imshow(P)\n\n[[2.20167327e-01 2.14586355e-01 1.46335569e-01 ... 2.83862880e-02\n  1.46335569e-01 2.14586355e-01]\n [2.14586355e-01 2.20167327e-01 2.14586355e-01 ... 3.69898283e-04\n  2.83862880e-02 1.46335569e-01]\n [1.46335569e-01 2.14586355e-01 2.20167327e-01 ... 4.82347874e-08\n  3.69898283e-04 2.83862880e-02]\n ...\n [2.83862880e-02 3.69898283e-04 4.82347874e-08 ... 2.20167327e-01\n  2.14586355e-01 1.46335569e-01]\n [1.46335569e-01 2.83862880e-02 3.69898283e-04 ... 2.14586355e-01\n  2.20167327e-01 2.14586355e-01]\n [2.14586355e-01 1.46335569e-01 2.83862880e-02 ... 1.46335569e-01\n  2.14586355e-01 2.20167327e-01]]\n\n\n\n\n\n\n\n\n\n\nplt.imshow(P@P@P@P)\n\n\n\n\n\n\n\n\n\nP4=P@P@P@P\ndiffusion_distance=l2distance(P4)\nplt.imshow(diffusion_distance)\n\n\n\n\n\n\n\n\n\n\nSnow distance\n\nhs1=hs.HeavySnowTransform(gs1)\nhs2=hs.HeavySnowTransform(gs2)\n\n\nhs1.snow(tau=80000,b=0.1)\nhs2.snow(tau=80000,b=0.1)\n\nHST (tau= 80000, b=0.1)\n80000/80000\nHST completed and all history is recorded.\nHST (tau= 80000, b=0.1)\n80000/80000\nHST completed and all history is recorded.\n\n\n\nfrom sklearn.decomposition import PCA \np1=PCA(n_components=3)\np2=PCA(n_components=3)\np3=PCA(n_components=3)\np4=PCA(n_components=3)\np5=PCA(n_components=3)\np6=PCA(n_components=3)\n\n\np1.fit(hs1.eucliddistance)\np2.fit(diffusion_distance)\np3.fit(hs1.snowdistance)\np4.fit(hs2.eucliddistance)\np5.fit(diffusion_distance)\np6.fit(hs2.snowdistance)\n\nr1=p1.transform(hs1.eucliddistance)\nr2=p2.transform(diffusion_distance)\nr3=p3.transform(hs1.snowdistance)\nr4=p4.transform(hs2.eucliddistance)\nr5=p5.transform(diffusion_distance)\nr6=p6.transform(hs2.snowdistance)\n\n/home/cgb4/anaconda3/envs/py38r40/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:470: RuntimeWarning: invalid value encountered in true_divide\n  explained_variance_ratio_ = explained_variance_ / total_var\n\n\n\n# 1. \np=plt.figure(figsize=(12,4), dpi=70)  # Make figure object \n\n# 2. \nax1=p.add_subplot(2,4,1, projection='3d')\nax2=p.add_subplot(2,4,2, projection='3d')\nax3=p.add_subplot(2,4,3, projection='3d')\nax4=p.add_subplot(2,4,4, projection='3d')\nax5=p.add_subplot(2,4,5, projection='3d')\nax6=p.add_subplot(2,4,6, projection='3d')\nax7=p.add_subplot(2,4,7, projection='3d')\nax8=p.add_subplot(2,4,8, projection='3d')\n\n# 3. \nax1.grid(False)\nax1.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax1.scatter3D(vx, vy, f1, c=col,alpha=1)\nax1.set_xlim(-1,1)\nax1.set_ylim(-1,1)\nax1.set_zlim(-5,5)\n\nax2.grid(False)\nax2.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax2.scatter3D(r1[:,0],r1[:,1],r1[:,2],s=20,c=col,alpha=1)\n\nax3.grid(False)\nax3.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax3.scatter3D(r2[:,0],r2[:,1],r2[:,2],s=20,c=col,alpha=1)\n\nax4.grid(False)\nax4.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax4.scatter3D(r3[:,0],r3[:,1],r3[:,2],s=20,c=col,alpha=1)\n\n\nax5.grid(False)\nax5.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\ntop = -f2\nbottom = np.zeros_like(top)\nwidth=depth=0.05\nax5.bar3d(vx, vy, bottom, width, depth, top, shade=False,color=col)\nax5.set_xlim(-1,1)\nax5.set_ylim(-1,1)\nax5.set_zlim(-5,5)\n\nax6.grid(False)\nax6.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax6.scatter3D(r4[:,0],r4[:,1],r4[:,2],s=20,c=col,alpha=1)\n\nax7.grid(False)\nax7.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax7.scatter3D(r5[:,0],r5[:,1],r5[:,2],s=20,c=col,alpha=1)\n\nax8.grid(False)\nax8.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax8.scatter3D(r6[:,0],r6[:,1],r6[:,2],s=20,c=col,alpha=1)\np.tight_layout(h_pad=2.6) #rect : tuple (left, bottom, right, top), optional"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-09-18-hst plots.html",
    "href": "연구/교수님이랑/HST/2021-09-18-hst plots.html",
    "title": "(연구&교수님) hst plots",
    "section": "",
    "text": "Import\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib\nmatplotlib.rc('image', cmap='Greys')\nimport rpy2 \n%load_ext rpy2.ipython\n%run pybase\n%run heavysnow \n\n\n\nData\n\nf=np.array([-1,-1,-1,1,-1,-1,-1,1,1,1,-1,1,1,1])*1.0\nn=len(f)\nV=list(range(n))\nW=np.zeros([n,n])\nfor i in range(n):\n    for j in range(n):\n        if abs(i-j)==1: W[i,j]=1\nW[0,0]=0\nW[n-1,n-1]=0\n\n\ngs=GraphSignal(V,W,f)\n\n\ngs.initdist=np.array([1/n]*n)\n\n\n\nHST\n\n%run heavysnow \nhst=HeavySnowTransform(gs)\nhst.snow(tau=100000,b=0.01,maxflow=3)\n\nHST (tau= 100000, b=0.01)\n100000/100000\nHST completed and all history is recorded.\n\n\n\nplt.imshow(hst.snowdistance)\n\n\n\n\n\n\n\n\n\ntheta=100\nhst.snowweight=np.exp(-hst.snowdistance/(theta*hst.tau*hst.b**2))-np.eye(n,n)\nplt.imshow(hst.snowweight)\n\n\n\n\n\n\n\n\n- \\(\\theta=10, \\theta=100\\) 에서의 결과가 우수하다.\n\n\n시각화를 위해서 R로 자료를 옮김\n\nmaxtau=hst.tau\nW_Graph=hst.graphweight\nW_Euclid=hst.euclidweight\nW_HST=hst.snowweight\nV=np.array(hst.V)\nf=hst.f\nn=hst.n\n%R -i maxtau,W_Graph,W_Euclid,W_HST,V,f,n\n\n\n\nR을 활용한 시각화 (1): 원래자료\n\n%%R -w 2000 -h 800 -r 100\nlibrary(tidyverse)\nlibrary(latex2exp)\nlibrary(gridExtra)\nsource('rbase.R')\nVtext=str_c('node ',V+1)\nfig0&lt;-ggplot(data=tibble(V=V,f=f,Vtext=Vtext),aes(x=V,y=f,label=Vtext))+\ngeom_col(aes(fill=(f&gt;0)),width=0.1)+geom_hline(aes(yintercept=0),col=\"gray60\",lty=2)+\ngeom_text(fontface = 4,size=8)+\nxlab(\"\")+ylab(\"\")+guides(fill=FALSE)+theme(plot.title=element_text(face=\"bold.italic\"))+theme_bw()+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 15, color = \"black\", face = \"bold.italic\"))+\nylim(-1.2,1.2)+\ntheme(plot.title=element_text(face=\"bold.italic\"))\n#ggsave(plot=p0,\"./fig/2021-0217_fig0.pdf\",width=20,height=6)\nfig0\n\n\n\n\n\n\n\n\n\n\nR을 활용한 시각화 (2): Weight matrix 와 Eigen plot\n- ggplot에서 geom_tile을 사용하기 위해서 매트릭스 형태인 W_Graph, W_Euclid, W_HST를 길게 펼친다. 결과를 각각 W_Graph_long, W_Euclid_long, W_HST_long에 저장한다.\n\n%%R\ngrid&lt;-expand.grid(x=1:n,y=1:n)\nW_Graph_long&lt;-as_tibble(cbind(grid,as.vector(W_Graph)));names(W_Graph_long)&lt;-c(\"x\",\"y\",\"W\")\nW_Euclid_long&lt;-as_tibble(cbind(grid,as.vector(W_Euclid)));names(W_Euclid_long)&lt;-c(\"x\",\"y\",\"W\")\nW_HST_long&lt;-as_tibble(cbind(grid,as.vector(W_HST)));names(W_HST_long)&lt;-c(\"x\",\"y\",\"W\")\n\n- 그래프퓨리에 변환: \\((\\bf{f},\\bf{W})\\)에 그래프 퓨리에 변환을 수행함.\n\n%%R\nsource('heavysnow.R')\ngfftrslt_Euclid&lt;-gfft(f,W_Euclid)\ngfftrslt_Graph&lt;-gfft(f,W_Graph)\ngfftrslt_HST&lt;-gfft(f,W_HST)\n\n- 그래프 퓨리에 변환의 결과 고유치, 고유벡터, \\(\\bf{\\bar{f}}\\)가 반환됨.\n\n%%R\nhead(gfftrslt_HST)\n\n$λ\n [1] 1.281581e+00 1.280062e+00 1.277538e+00 1.276594e+00 1.246469e+00\n [6] 1.246289e+00 1.226622e+00 1.223498e+00 1.040855e+00 1.012083e+00\n[11] 9.567342e-01 9.183002e-01 1.337453e-02 1.628144e-17\n\n$Ψ\n               [,1]         [,2]         [,3]          [,4]        [,5]\n [1,] -1.101322e-02  0.623405435 -0.091622721  0.0017456559  0.24806543\n [2,]  1.205878e-02 -0.755269196  0.101832475 -0.0018036764  0.09749994\n [3,] -2.573593e-03  0.151302392  0.013830158 -0.0006387095 -0.55300723\n [4,] -3.533479e-02  0.001934776 -0.002380270  0.0010829689 -0.01418293\n [5,]  5.657077e-03  0.020641957  0.146149059 -0.0047285571  0.42944573\n [6,] -4.457739e-05 -0.100557489 -0.758698999  0.0208523679 -0.06840576\n [7,] -1.383726e-05  0.084966266  0.618622425 -0.0161356769 -0.14706653\n [8,]  6.379135e-01  0.009833070 -0.003446524 -0.0341177590  0.07952772\n [9,] -7.573498e-01 -0.012587447  0.004061202  0.0444005100  0.04376935\n[10,]  1.154586e-01  0.003127545  0.005845689 -0.0075676043 -0.30295320\n[11,] -4.609255e-04 -0.003317048 -0.024308993 -0.0035332301  0.02583902\n[12,]  4.730960e-02  0.001047695  0.004598465  0.2254533731  0.48704881\n[13,] -3.047283e-02 -0.001452908 -0.021027461 -0.7829094180 -0.05509983\n[14,]  3.789495e-02  0.001287373  0.015629783  0.5764486262 -0.26695761\n              [,6]        [,7]         [,8]        [,9]        [,10]\n [1,] -0.212232549  0.09881472 -0.329397556 -0.13067797  0.063725698\n [2,] -0.084101745  0.05674655 -0.190831764 -0.12127549  0.054889359\n [3,]  0.470671293 -0.13442332  0.421298057 -0.05974113  0.024188103\n [4,]  0.002765557  0.06280393 -0.009895878 -0.63041398 -0.633874206\n [5,] -0.348970037 -0.17458199  0.630033245  0.10992323 -0.052910827\n [6,]  0.048584324  0.05625359 -0.188006658  0.17769490 -0.028871736\n [7,]  0.119347649  0.10986267 -0.407133854  0.16776649  0.002820665\n [8,]  0.089444425 -0.38001485 -0.116950543  0.23074930  0.003055157\n [9,]  0.043414503 -0.20792297 -0.058773593  0.23821823  0.036484538\n[10,] -0.345030868  0.70637068  0.211023700  0.13128564  0.066544116\n[11,]  0.010336186 -0.05708445  0.031196235 -0.56567341  0.747888280\n[12,]  0.589920338  0.30490632  0.076863167 -0.06735025 -0.057838094\n[13,] -0.068030869 -0.15894641 -0.047726561 -0.13334698 -0.093017561\n[14,] -0.326018829 -0.33345933 -0.092856858 -0.16089617 -0.098997802\n             [,11]       [,12]       [,13]      [,14]\n [1,] -0.408422219 -0.18530534 -0.28175180 0.27628218\n [2,] -0.382397860 -0.17397805 -0.29307694 0.28761516\n [3,] -0.241322800 -0.11713506 -0.30076063 0.29568698\n [4,] -0.009187363  0.43375706 -0.01686117 0.08220472\n [5,]  0.217900271  0.07652214 -0.29810032 0.29572434\n [6,]  0.385963701  0.13946811 -0.28977255 0.28893239\n [7,]  0.437641440  0.16717721 -0.27181805 0.27314760\n [8,] -0.253652135  0.40038366  0.26429363 0.26763390\n [9,] -0.216705167  0.31947800  0.28793316 0.28944113\n[10,] -0.105041138  0.14508110  0.29867982 0.29882229\n[11,]  0.171365092  0.26759456  0.06408804 0.09987810\n[12,]  0.122167373 -0.25125645  0.29861358 0.29615188\n[13,]  0.182730793 -0.34935928  0.29175718 0.28892148\n[14,]  0.201613365 -0.37424884  0.27730440 0.27451198\n\n$fbar\n [1]  0.011809548 -0.017982211 -0.002522520  0.027032523 -0.061218282\n [6] -0.017170862  0.038149625 -0.005474273  0.030229173 -1.589373396\n[11] -0.258801898  0.149491686  3.372912843 -0.019579358\n\n\n\n- 시각화코드\n\n%%R -w 1000 -h 800 -r 100\nlibrary(gridExtra)\n\nfig1_1&lt;-ggplot()+geom_tile(data=W_Euclid_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"white\",high=\"black\")+\nlabs(fill=TeX('$W$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(a) Euclid\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_2&lt;-ggplot()+geom_tile(data=W_Graph_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"white\",high=\"black\")+\nlabs(fill=TeX('$\\\\hat{W}$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(b) Graph\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_3&lt;-ggplot()+geom_tile(data=W_HST_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"white\",high=\"black\")+\nlabs(fill=TeX('$\\\\hat{W}(\\\\tau)$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(c) HST\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_4&lt;-eigenplot(gfftrslt_Euclid)+ylim(0,2)+theme_light()\nfig1_5&lt;-eigenplot(gfftrslt_Graph)+ylim(0,2)+theme_light()\nfig1_6&lt;-eigenplot(gfftrslt_HST)+ylim(0,2)+theme_light()\nfig1=grid.arrange(fig1_1,fig1_2,fig1_3,fig1_4,fig1_5,fig1_6,ncol=3,nrow=2)\nfig1\nggsave(plot=fig1,\"2021-08-14-EX1(0).pdf\",width=15,height=10)\n\n\n\n\n\n\n\n\n\n%%R -w 200 -h 600 -r 120\nfig_= grid.arrange(fig1_4,fig1_5,fig1_6,nrow=3)\nggsave(plot=fig_,\"2021-08-14-EX1(1).pdf\",width=2,height=6)\n\n\n\n\n\n\n\n\n\n\nR을 활용한 시각화 (3): Decomposition\n- 디콤포지션을 수행하고 결과를 저장: \\((\\bf{f},\\bf{W})\\)에 decomposition을 수행하고 그 결과를 각각 decomprslt_Euclid, decomprslt_Graph, decomprslt_HST에 저장한다.\n\n%%R \ndecomprslt_Euclid&lt;-decompose(f,W_Euclid,V=1:n) # 0, 35000, 60000, 80000\ndecomprslt_Graph&lt;-decompose(f,W_Graph,V=1:n) # 0, 35000, 60000, 80000\ndecomprslt_HST&lt;-decompose(f,W_HST,V=1:n) # 0, 35000, 60000, 80000\n\n- 디콤포지션 결과는 아래와 같은 형태임\n\n%%R\nhead(decomprslt_Euclid)\n\n# A tibble: 6 × 5\n      V Vindex eigenvectorindex      fhat eigenvalue\n  &lt;int&gt;  &lt;int&gt;            &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1     1      1                1  1.45e-32   3.28e-18\n2     2      2                1  2.48e-17   3.28e-18\n3     3      3                1 -2.02e-16   3.28e-18\n4     4      4                1  1   e+ 0   3.28e-18\n5     5      5                1  8.73e-17   3.28e-18\n6     6      6                1 -6.32e-17   3.28e-18\n\n\n\n%%R \ndecomprslt_Euclid$method=\"Euclid\"\ndecomprslt_Graph$method=\"Graph\"\ndecomprslt_HST$method=\"HST\"\ndecomprslt&lt;-rbind(decomprslt_Euclid,decomprslt_Graph,decomprslt_HST)\n\n- 디콤포지션결과를 시각화한다. geom_col과 facet_grid를 이용.\n\n%%R -w 2000 -h 500 -r 100\nfig2&lt;-ggplot(data=decomprslt,aes(x=V,y=fhat))+\ngeom_col(aes(fill=fhat&gt;0),width=0.7)+facet_grid(method~eigenvectorindex)+geom_hline(aes(yintercept=0),col=\"gray60\",lty=2)+\nxlab(\"\")+ylab(\"\")+guides(fill=FALSE)+theme(plot.title=element_text(face=\"bold.italic\"))+theme_bw()+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 15, color = \"black\", face = \"bold.italic\"))+\nylim(-1.2,1.2)+\ntheme(plot.title=element_text(face=\"bold.italic\"))\nfig2\nggsave(plot=fig2,\"2021-08-14-EX1(2).pdf\",width=20,height=6)\n\n\n\nAppendix\n\n_, (ax1,ax2) = plt.subplots(1,2)\nax1.imshow(hst.eucliddistance[:7,:7],origin='lower')\nax2.imshow(hst.snowdistance[:7,:7],origin='lower')\nplt.show()\n\n\n\n\n\n\n\n\n\nbrk=10000\np, (ax1,ax2,ax3) = plt.subplots(1,3) \nax1.imshow(l2distance(hst.snowygrounds[:,0:brk]),origin='lower')\nax2.imshow(l2distance(hst.snowygrounds[:,brk:]),origin='lower')\nax3.imshow(hst.snowdistance,origin='lower')\n#ax4.imshow(diffusion_distance)\n#plt.show()\np.savefig('temp.pdf',transparent=True)\n\n\n\n\n\n\n\n\n\ny=hst.snowdistance[0]\nplt.plot(y,'o--')\nplt.plot([0,1,2,4,5,6,10],y[[0,1,2,4,5,6,10]],'o')\nplt.plot([3,7,8,9,11,12,13],y[[3,7,8,9,11,12,13]],'o')\n\n\n\n\n\n\n\n\n\np, (ax1,ax2,ax3) = plt.subplots(1,3) \nax1.imshow(hst.euclidweight,origin='lower')\nax2.imshow(hst.snowweight,origin='lower')\nax3.imshow(hst.graphweight,origin='lower')\n#ax4.imshow(diffusion_distance)\n#p.show()\np.savefig('temp.pdf', transparent=True)"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-08-02-HST example 1 (2).html",
    "href": "연구/교수님이랑/HST/2021-08-02-HST example 1 (2).html",
    "title": "(연구&교수님) HST example 1 (2)",
    "section": "",
    "text": "Import\n\nimport heavysnow as hs\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport rpy2 \n%load_ext rpy2.ipython\n%run pybase\n\n\n\nData\n\nf=np.array([-1,-1,-1,1,-1,-1,-1,1,1,1,-1,1,1,1])*1.0\nn=len(f)\nV=list(range(n))\nW=np.zeros([n,n])\nfor i in range(n):\n    for j in range(n):\n        if abs(i-j)==1: W[i,j]=1\nW[0,0]=1\nW[n-1,n-1]=1\n\n\ngs=hs.GraphSignal(V,W,f)\n\n\ngs.initdist=np.array([1/n]*n)\n\n\n\nHST\n\nhst=hs.HeavySnowTransform(gs)\nhst.snow(tau=80000,b=0.03)\n\nHST (tau= 80000, b=0.03)\n80000/80000\nHST completed and all history is recorded.\n\n\n\nplt.imshow(hst.snowweight)\n\n\n\n\n\n\n\n\n\n\n시각화를 위해서 R로 자료를 옮김\n\nmaxtau=hst.tau\nW_Graph=hst.graphweight\nW_Euclid=hst.euclidweight\nW_HST=hst.snowweight\nV=np.array(hst.V)\nf=hst.f\nn=hst.n\n%R -i maxtau,W_Graph,W_Euclid,W_HST,V,f,n\n\n\n\nR을 활용한 시각화 (1): 원래자료\n\n%%R -w 2000 -h 800 -r 100\nlibrary(tidyverse)\nlibrary(latex2exp)\nlibrary(gridExtra)\nsource('rbase.R')\nVtext=str_c('node ',V+1)\nfig0&lt;-ggplot(data=tibble(V=V,f=f,Vtext=Vtext),aes(x=V,y=f,label=Vtext))+\ngeom_col(aes(fill=(f&gt;0)),width=0.1)+geom_hline(aes(yintercept=0),col=\"gray60\",lty=2)+\ngeom_text(fontface = 4,size=8)+\nxlab(\"\")+ylab(\"\")+guides(fill=FALSE)+theme(plot.title=element_text(face=\"bold.italic\"))+theme_bw()+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 15, color = \"black\", face = \"bold.italic\"))+\nylim(-1.2,1.2)+\ntheme(plot.title=element_text(face=\"bold.italic\"))\n#ggsave(plot=p0,\"./fig/2021-0217_fig0.pdf\",width=20,height=6)\nfig0\n\nR[write to console]: ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\nR[write to console]: ✔ ggplot2 3.3.5     ✔ purrr   0.3.4\n✔ tibble  3.1.3     ✔ dplyr   1.0.7\n✔ tidyr   1.1.3     ✔ stringr 1.4.0\n✔ readr   2.0.1     ✔ forcats 0.5.1\n\nR[write to console]: ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nR[write to console]: \nAttaching package: ‘gridExtra’\n\n\nR[write to console]: The following object is masked from ‘package:dplyr’:\n\n    combine\n\n\nR[write to console]: \nAttaching package: ‘lubridate’\n\n\nR[write to console]: The following objects are masked from ‘package:base’:\n\n    date, intersect, setdiff, union\n\n\n\n\n\n\n\n\n\n\n\n\n\nR을 활용한 시각화 (2): Weight matrix 와 Eigen plot\n- ggplot에서 geom_tile을 사용하기 위해서 매트릭스 형태인 W_Graph, W_Euclid, W_HST를 길게 펼친다. 결과를 각각 W_Graph_long, W_Euclid_long, W_HST_long에 저장한다.\n\n%%R\ngrid&lt;-expand.grid(x=1:n,y=1:n)\nW_Graph_long&lt;-as_tibble(cbind(grid,as.vector(W_Graph)));names(W_Graph_long)&lt;-c(\"x\",\"y\",\"W\")\nW_Euclid_long&lt;-as_tibble(cbind(grid,as.vector(W_Euclid)));names(W_Euclid_long)&lt;-c(\"x\",\"y\",\"W\")\nW_HST_long&lt;-as_tibble(cbind(grid,as.vector(W_HST)));names(W_HST_long)&lt;-c(\"x\",\"y\",\"W\")\n\n- 그래프퓨리에 변환: \\((\\bf{f},\\bf{W})\\)에 그래프 퓨리에 변환을 수행함.\n\n%%R\nsource('heavysnow.R')\ngfftrslt_Euclid&lt;-gfft(f,W_Euclid)\ngfftrslt_Graph&lt;-gfft(f,W_Graph)\ngfftrslt_HST&lt;-gfft(f,W_HST)\n\nR[write to console]: \nAttaching package: ‘kohonen’\n\n\nR[write to console]: The following object is masked from ‘package:purrr’:\n\n    map\n\n\nR[write to console]: \nAttaching package: ‘igraph’\n\n\nR[write to console]: The following objects are masked from ‘package:lubridate’:\n\n    %--%, union\n\n\nR[write to console]: The following objects are masked from ‘package:dplyr’:\n\n    as_data_frame, groups, union\n\n\nR[write to console]: The following objects are masked from ‘package:purrr’:\n\n    compose, simplify\n\n\nR[write to console]: The following object is masked from ‘package:tidyr’:\n\n    crossing\n\n\nR[write to console]: The following object is masked from ‘package:tibble’:\n\n    as_data_frame\n\n\nR[write to console]: The following objects are masked from ‘package:stats’:\n\n    decompose, spectrum\n\n\nR[write to console]: The following object is masked from ‘package:base’:\n\n    union\n\n\n\n\n- 그래프 퓨리에 변환의 결과 고유치, 고유벡터, \\(\\bf{\\bar{f}}\\)가 반환됨.\n\n%%R\nhead(gfftrslt_HST)\n\n$λ\n [1] 1.000000e+00 1.748909e-07 1.248978e-07 9.982953e-08 1.180269e-08\n [6] 9.249661e-10 6.508030e-12 8.123462e-13 1.916909e-14 1.071529e-14\n[11] 4.857968e-18 5.283643e-26 3.722524e-29 4.830679e-33\n\n$Ψ\n               [,1]          [,2]          [,3]          [,4]          [,5]\n [1,]  7.005723e-20  3.729395e-18 -1.469697e-23  7.069685e-01  1.786276e-17\n [2,] -8.327039e-20  3.785475e-18 -1.469314e-23 -7.072451e-01  1.785560e-17\n [3,] -2.529741e-17  1.589505e-13 -5.635188e-20  2.405103e-08  1.182894e-18\n [4,]  2.251861e-21  3.075318e-14  1.378141e-16 -6.352581e-28 -6.216104e-17\n [5,]  9.561935e-05 -3.651936e-01 -4.255448e-21 -2.869805e-20  1.026081e-11\n [6,] -9.999998e-01  5.436463e-04 -1.475276e-24  5.679467e-20  2.216905e-15\n [7,]  6.214913e-04  9.309315e-01 -1.719046e-21  2.823516e-20  1.988807e-12\n [8,]  5.269063e-19 -3.744835e-12 -7.596066e-20 -7.007619e-32 -4.816496e-01\n [9,]  3.391557e-23  1.052189e-13 -5.359558e-20 -6.631717e-35  8.745009e-01\n[10,]  2.027237e-28 -4.552571e-16 -1.800477e-19 -1.075604e-39 -5.711270e-02\n[11,]  1.123853e-30 -4.200738e-25 -6.213816e-21 -8.046281e-45  3.960782e-12\n[12,] -4.766959e-58  6.088889e-39  2.393049e-10 -6.949691e-66  1.132032e-23\n[13,] -3.323294e-72 -2.189008e-48 -7.071206e-01 -6.845625e-79 -8.282761e-28\n[14,]  3.125900e-80  7.202257e-49  7.070930e-01 -3.136336e-83  8.282033e-28\n               [,6]          [,7]          [,8]          [,9]         [,10]\n [1,] -1.455507e-18 -7.072450e-01 -7.324367e-22  9.407628e-10  1.808390e-14\n [2,] -1.454307e-18 -7.069684e-01 -7.322457e-22  9.405173e-10  1.807918e-14\n [3,] -1.414896e-18  3.687888e-04 -2.808338e-18  3.601453e-06  6.927739e-11\n [4,]  2.587258e-16 -2.468864e-19 -5.151717e-15  7.164045e-07  1.843432e-11\n [5,]  2.035470e-10 -1.945681e-12 -3.428740e-20 -9.309316e-01 -1.001220e-05\n [6,]  6.712061e-14 -6.604440e-16 -1.282538e-23 -3.159797e-04 -3.398372e-09\n [7,]  7.668328e-11 -7.633239e-13 -1.536118e-20 -3.651934e-01 -3.927668e-06\n [8,] -7.985893e-01 -3.591407e-17 -3.167965e-16  3.881610e-06 -3.609277e-01\n [9,] -4.111315e-01  8.288213e-17 -2.258664e-16  2.767518e-06 -2.573306e-01\n[10,]  4.395747e-01 -9.271388e-18 -7.867859e-16  9.640781e-06 -8.963884e-01\n[11,] -3.890376e-10  6.905949e-28 -2.217508e-16 -4.117182e-10  6.848286e-05\n[12,] -1.111767e-21  1.931337e-39  3.679268e-05 -1.176006e-21  1.952327e-16\n[13,]  2.500402e-21  1.252402e-31 -7.070930e-01 -8.986560e-21  6.146342e-16\n[14,] -2.500304e-21 -1.252353e-31 -7.071206e-01  5.033057e-21  6.147426e-16\n              [,11]         [,12]         [,13]         [,14]\n [1,]  2.608071e-04 -1.652406e-12  5.162787e-16  1.633612e-15\n [2,]  2.607391e-04 -1.651975e-12  5.161441e-16  1.633186e-15\n [3,]  9.999999e-01 -6.335744e-09  1.979544e-12  6.263684e-12\n [4,] -6.338327e-09 -9.999995e-01 -7.462122e-05  9.886606e-04\n [5,]  3.352707e-06 -6.669233e-07  2.526160e-10  6.593340e-10\n [6,]  1.137986e-09 -2.263691e-10  8.574375e-14  2.237932e-13\n [7,]  1.315227e-06 -2.616261e-07  9.909835e-11  2.586489e-10\n [8,]  1.102464e-11 -1.850481e-09  2.471705e-05 -2.215486e-09\n [9,]  7.860068e-12 -1.319341e-09  1.762257e-05 -1.579580e-09\n[10,]  2.737851e-11 -4.595864e-09  6.138742e-05 -5.502394e-09\n[11,] -2.455587e-12 -7.470987e-05  1.000000e+00 -8.963406e-05\n[12,]  1.200893e-19 -9.886539e-04 -8.970788e-05 -9.999995e-01\n[13,] -6.699708e-18 -2.572083e-08 -2.333842e-09 -2.601600e-05\n[14,] -6.589052e-18 -2.572150e-08 -2.333902e-09 -2.601668e-05\n\n$fbar\n [1]  9.992827e-01 -5.662815e-01 -2.759379e-05  2.765932e-04  3.357386e-01\n [6] -7.701461e-01  1.413845e+00 -1.414177e+00  1.296454e+00 -1.514701e+00\n[11] -1.000526e+00 -1.000913e+00 -1.000061e+00 -9.989733e-01\n\n\n\n- 시각화코드\n\n%%R -w 1000 -h 800 -r 100\nlibrary(gridExtra)\n\nfig1_1&lt;-ggplot()+geom_tile(data=W_Euclid_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"red\",high=\"blue\",mid=\"purple\",midpoint=0.25,breaks=c(0,0.5,0.99))+\nlabs(fill=TeX('$W$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(a) Euclid\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_2&lt;-ggplot()+geom_tile(data=W_Graph_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"red\",high=\"blue\",mid=\"purple\",midpoint=0.5,breaks=c(0,0.5,0.99))+\nlabs(fill=TeX('$\\\\hat{W}$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(b) Graph\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_3&lt;-ggplot()+geom_tile(data=W_HST_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"red\",high=\"blue\",mid=\"purple\",midpoint=0.5,breaks=c(0,0.5,0.99))+\nlabs(fill=TeX('$\\\\hat{W}(\\\\tau)$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(c) HST\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_4&lt;-eigenplot(gfftrslt_Euclid)+ylim(0,2)+theme_light()\nfig1_5&lt;-eigenplot(gfftrslt_Graph)+ylim(0,2)+theme_light()\nfig1_6&lt;-eigenplot(gfftrslt_HST)+ylim(0,2)+theme_light()\nfig1=grid.arrange(fig1_1,fig1_2,fig1_3,fig1_4,fig1_5,fig1_6,ncol=3,nrow=2)\nfig1\n#ggsave(plot=grid.arrange(p1_a,p1_b,p1_c,ncol=3),\"2021-07-22_fig1.png\",width=20,height=4)\n\nTableGrob (2 x 3) \"arrange\": 6 grobs\n  z     cells    name           grob\n1 1 (1-1,1-1) arrange gtable[layout]\n2 2 (1-1,2-2) arrange gtable[layout]\n3 3 (1-1,3-3) arrange gtable[layout]\n4 4 (2-2,1-1) arrange gtable[layout]\n5 5 (2-2,2-2) arrange gtable[layout]\n6 6 (2-2,3-3) arrange gtable[layout]\n\n\n\n\n\n\n\n\n\n\n\nR을 활용한 시각화 (3): Decomposition\n- 디콤포지션을 수행하고 결과를 저장: \\((\\bf{f},\\bf{W})\\)에 decomposition을 수행하고 그 결과를 각각 decomprslt_Euclid, decomprslt_Graph, decomprslt_HST에 저장한다.\n\n%%R \ndecomprslt_Euclid&lt;-decompose(f,W_Euclid,V=1:n) # 0, 35000, 60000, 80000\ndecomprslt_Graph&lt;-decompose(f,W_Graph,V=1:n) # 0, 35000, 60000, 80000\ndecomprslt_HST&lt;-decompose(f,W_HST,V=1:n) # 0, 35000, 60000, 80000\n\nNote: Using an external vector in selections is ambiguous.\nℹ Use `all_of(n)` instead of `n` to silence this message.\nℹ See &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;.\nThis message is displayed once per session.\n\n\n- 디콤포지션 결과는 아래와 같은 형태임\n\n%%R\nhead(decomprslt_Euclid)\n\n# A tibble: 6 × 5\n      V Vindex eigenvectorindex      fhat eigenvalue\n  &lt;int&gt;  &lt;int&gt;            &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1     1      1                1  1.45e-32   3.28e-18\n2     2      2                1  2.48e-17   3.28e-18\n3     3      3                1 -2.02e-16   3.28e-18\n4     4      4                1  1   e+ 0   3.28e-18\n5     5      5                1  8.73e-17   3.28e-18\n6     6      6                1 -6.32e-17   3.28e-18\n\n\n\n%%R \ndecomprslt_Euclid$method=\"Euclid\"\ndecomprslt_Graph$method=\"Graph\"\ndecomprslt_HST$method=\"HST\"\ndecomprslt&lt;-rbind(decomprslt_Euclid,decomprslt_Graph,decomprslt_HST)\n\n- 디콤포지션결과를 시각화한다. geom_col과 facet_grid를 이용.\n\n%%R -w 2000 -h 500 -r 100\nfig2&lt;-ggplot(data=decomprslt,aes(x=V,y=fhat))+\ngeom_col(aes(fill=fhat&gt;0),width=0.7)+facet_grid(method~eigenvectorindex)+geom_hline(aes(yintercept=0),col=\"gray60\",lty=2)+\nxlab(\"\")+ylab(\"\")+guides(fill=FALSE)+theme(plot.title=element_text(face=\"bold.italic\"))+theme_bw()+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 15, color = \"black\", face = \"bold.italic\"))+\nylim(-1.5,1.5)+\ntheme(plot.title=element_text(face=\"bold.italic\"))\nfig2\n#ggsave(plot=fig2,\"./fig/2021-0514_fig2.pdf\",width=20,height=6)"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-07-14-HST old example (Python).html",
    "href": "연구/교수님이랑/HST/2021-07-14-HST old example (Python).html",
    "title": "(연구&교수님) HST old exam (Python)",
    "section": "",
    "text": "About this doc\n- 앞선 R예제보다 좀더 노이지한 자료\n\n\ndata\n\nimport pandas as pd\n\n\ntestdata=pd.read_csv('~/Dropbox/03_Yechan3/연구/교수님이랑/HST/2021-07-14-hstex.csv') # data is in https://github.com/miruetoto/yechan/tree/master/_notebooks\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nsns.relplot(data=testdata,x=testdata.index,y='f')\n\n\n\n\n\n\n\n\n\nLocal view\n- local view에서의 structure가 뚜렷하게 구별되는것은 아님\n\nsns.relplot(data=testdata,x=testdata.index,y='f',hue='localstr')\n\n\n\n\n\n\n\n\n\n\nglobal view\n\nsns.relplot(data=testdata,x=testdata.index,y='f',hue='globalstr')\n\n\n\n\n\n\n\n\n\n\n\nhst\n\nclass GraphSignal: \n    def __init__(self,V,W,f):\n        self.f=np.array(f) \n        self.V=V \n        self.W=np.array(W)\n        self.n=len(self.f)\n        self.degree=np.sum(np.array(self.W),0)\n        self.initdist=self.degree/np.sum(self.degree) \n        \nclass HeavySnowTransform:  #hst(f,W,V,τ=τ,b=0.03,γ=1)\n    def __init__(self,graphsignal):\n        self.n=graphsignal.n\n        self.f=graphsignal.f\n        self.V=graphsignal.V\n        self.graphweight=graphsignal.W\n        #self.degree=graphsignal.degree\n        self.initdist=graphsignal.initdist\n        self._initialize()\n    \n    def _initialize(self):\n        self.tau=0\n        self.b=0\n        self.trajectory=[0]\n        self.flowcount=[0]\n        self.snowygrounds=pd.DataFrame(data={'h0':self.f})                    \n        self.eucliddistance=(np.array(self.f)[:,np.newaxis]-np.array(self.f)[np.newaxis,:])**2\n        self.snowdistance=np.zeros((self.n,self.n))\n        self.euclidweight=np.zeros((self.n,self.n))\n        self.snowweight=np.zeros((self.n,self.n))\n        \n    def _snowonce(self,ell,b,maxflow):\n        W=self.graphweight&gt;np.asmatrix(np.random.random((self.n,self.n)))\n        hnext=np.array(self.snowygrounds.iloc[:,-1])\n        currentnode=self.trajectory[-1]\n        flowcount=self.flowcount[-1]\n        # 1. h(u) &lt;- h(u)+b : update current node when flowcound &gt; 0 \n        hnext[currentnode]=hnext[currentnode]+b\n        # 2. check that: are there any nodes to which snow can flow from u. \n        neighbor=np.where(W[currentnode,:]&gt;0)[1] ## Nu is np.array\n        if len(neighbor)==0: downstream=np.array([])\n        else: downstream=neighbor[list((np.where(hnext[neighbor]&lt;=hnext[currentnode]))[0])]\n        # 3. check flowable \n        flowable = len(downstream)&gt;0 and flowcount &lt; maxflow \n        # 4. determine flow or block\n        if flowable==0: # block!\n            node0=np.random.choice(self.n,1,p=self.initdist).item()\n            neighbor=np.where(W[node0,:]&gt;0)[1] \n            downstream=neighbor[list((np.where(hnext[neighbor]&lt;=hnext[node0]))[0])]\n            if len(downstream)==0: \n                nextnode=node0\n            else: \n                nextnode=np.random.choice(list(downstream),1).item()\n            flowcount=0\n        else: #flow\n            nextnode=np.random.choice(list(downstream),1).item()\n            flowcount=flowcount+1\n        self.snowygrounds['h%s' % ell]=hnext\n        self.flowcount=self.flowcount+[flowcount]\n        self.trajectory=self.trajectory+[nextnode]    \n        \n        self.snowygrounds_f['h%s' % ell]=self.f\n        self.snowygrounds_sumxi['h%s' % ell]=hnext-self.f\n\n    def _getdegreematrix(self,matrix):\n        return np.diag(np.sum(matrix,1))\n    \n    def _normalize(self,matrix): \n        return np.sqrt(self._getdegreematrix(matrix))@matrix@np.sqrt(self._getdegreematrix(matrix))\n    \n    def _updateeuclidweight(self):\n        self.euclidweight=np.exp(-self.eucliddistance/(self.b**2))-np.eye(self.n)\n        \n    def _updatesnowdistance(self):\n        self.snowdistance=np.sum((np.array(self.snowygrounds)[:,np.newaxis,:]-np.array(self.snowygrounds)[np.newaxis,:,:])**2,axis=-1)\n        \n    def _updatesnowweight(self):\n        self.snowweight=np.exp(-self.snowdistance/(self.tau*self.b**2))-np.eye(self.n)\n        \n    def snow(self,tau,b=1,maxflow=100):\n        self._initialize()\n        self.b=b\n        self.tau=tau\n        print('HST (τ= %s, b=%s)' % (tau,b))\n        for ell in np.arange(1,tau+1): \n            print('\\r'+str(ell)+'/'+str(tau),sep='',end='')\n            self._snowonce(ell,b,maxflow)\n        print('\\n'+'HST completed and all history is recorded.')\n        self._updatesnowdistance()\n        self._updatesnowweight()\n        self._updateeuclidweight()\n\n- define graph signal\n\n#f=np.array([-1,-1,-1,1,-1,-1,-1,1,1,1,-1,1,1,1])*1.0\nimport numpy as np\nf=testdata.f\nn=len(f)\nV=list(range(n))\nW=np.zeros([n,n])\nfor i in range(n):\n    for j in range(n):\n        if abs(i-j)&lt;=1: W[i,j]=1\nW[0,0]=1\nW[n-1,n-1]=1\ngs1=GraphSignal(V,W,f)\n\n- hst with \\(\\tau=10000\\)\n\nhst1=HeavySnowTransform(gs1)\nhst1.snow(tau=10000,b=0.005,maxflow=1)\nplt.imshow(hst1.snowdistance)\n\nHST (τ= 10000, b=0.005)\n1/10000\n\n\nAttributeError: 'HeavySnowTransform' object has no attribute 'snowygrounds_f'\n\n\n- hst with \\(\\tau=50000\\)\n\nhst2=HeavySnowTransform(gs1)\nhst2.snow(tau=50000,b=0.003,maxflow=1)\nplt.imshow(hst2.snowdistance)\n\nHST (τ= 50000, b=0.003)\n50000/50000\nHST completed and all history is recorded.\n\n\n\n\n\n\n\n\n\n- hst with \\(\\tau=100000\\)\n\nhst3=HeavySnowTransform(gs1)\nhst3.snow(tau=100000,b=0.003,maxflow=1)\nplt.imshow(hst3.snowdistance)\n\nHST (τ= 100000, b=0.003)\n100000/100000\nHST completed and all history is recorded.\n\n\n\n\n\n\n\n\n\n\n\nPCA\n\nfrom sklearn.decomposition import PCA \np1=PCA(n_components=3)\np2=PCA(n_components=3)\np3=PCA(n_components=3)\n\np1.fit(hst1.snowygrounds)\np2.fit(hst2.snowygrounds)\np3.fit(hst3.snowygrounds)\n\nr1=p1.transform(hst1.snowygrounds)\nr2=p2.transform(hst2.snowygrounds)\nr3=p3.transform(hst3.snowygrounds)\n\n\n\nPlot\n- \\(\\tau=10000\\): local view를 반영\n\nsns.relplot(x=r1[:,0],y=r1[:,1],hue=testdata.localstr)\n\n\n\n\n\n\n\n\n- \\(\\tau=100000\\): global view를 반영\n\nsns.relplot(x=r3[:,0],y=r3[:,1],hue=testdata.globalstr)"
  },
  {
    "objectID": "연구/교수님이랑/HST/2023-07-12-old_hst.html",
    "href": "연구/교수님이랑/HST/2023-07-12-old_hst.html",
    "title": "(연구&교수님) old_hst",
    "section": "",
    "text": "test\n\nimport heavysnow as hs \nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt \nfrom sklearn.decomposition import PCA \nimport rpy2 \n%load_ext rpy2.ipython\n%run pybase\n\nModuleNotFoundError: No module named 'heavysnow'\n\n\n\n1+1\n\n2\n\n\n\n\nDataset\n\n\nHst\n\n### Example 2\nnp.random.seed(777)\nimport math\npi=math.pi\nn=60\nang=np.linspace(-pi,pi-2*pi/n,n)\nV=np.arange(n)+1\nr=1\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=vx*0\n\nf2=vx*0\nf2[vy&lt;0]=3+np.random.normal(size=sum(vy&lt;0),scale=0.1)\nf2[vy&gt;=0]= -3+np.random.normal(size=sum(vy&gt;=0),scale=0.1)\n\nNameError: name 'np' is not defined\n\n\n\n# Edg setting\nΣ=l2distance(np.matrix([vx,vy]).T)\nθ=0.05\nW=np.exp(-Σ**2/(2*θ**2))-np.eye(n,n)\nE=W&gt;0\nplt.plot(W[0,:].T)\n# color\nimport matplotlib.cm as cm\ncol=list(np.array(cm.rainbow((ang+pi)/2/pi)))\n\n\n\n\n\n\n\n\n\ngs1=hs.GraphSignal(V,W,f1)\ngs2=hs.GraphSignal(V,W,f2)\n\n\nhs1=hs.HeavysnowTransform(gs1)\nhs2=hs.HeavysnowTransform(gs2)\n\n\nhs1.snow(tau=300000,b=0.05)\nhs2.snow(tau=300000,b=0.05)\n\nHST (tau= 300000, b=0.05)\nCalculate distance and weights\nHST completed and all history is recorded.\nHST (tau= 300000, b=0.05)\nCalculate distance and weights\nHST completed and all history is recorded.\n\n\n100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300000/300000 [02:20&lt;00:00, 2140.91it/s]\n100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300000/300000 [02:09&lt;00:00, 2312.81it/s]\n\n\n\nfrom sklearn.decomposition import PCA \np1=PCA(n_components=3)\np2=PCA(n_components=3)\np3=PCA(n_components=3)\np4=PCA(n_components=3)\np5=PCA(n_components=3)\np6=PCA(n_components=3)\n\n\np1.fit(hs1.eucliddistance)\np2.fit(diffusion_distance)\np3.fit(hs1.snowdistance)\np4.fit(hs2.eucliddistance)\np5.fit(diffusion_distance)\np6.fit(hs2.snowdistance)\n\nr1=p1.transform(hs1.eucliddistance)\nr2=p2.transform(diffusion_distance)\nr3=p3.transform(hs1.snowdistance)\nr4=p4.transform(hs2.eucliddistance)\nr5=p5.transform(diffusion_distance)\nr6=p6.transform(hs2.snowdistance)\n\n/home/cgb2/anaconda3/envs/r/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:543: RuntimeWarning: invalid value encountered in divide\n\n\n\n# 1. \np=plt.figure(figsize=(12,4), dpi=70)  # Make figure object \n\n# 2. \nax1=p.add_subplot(2,4,1, projection='3d')\nax2=p.add_subplot(2,4,2, projection='3d')\nax3=p.add_subplot(2,4,3, projection='3d')\nax4=p.add_subplot(2,4,4, projection='3d')\nax5=p.add_subplot(2,4,5, projection='3d')\nax6=p.add_subplot(2,4,6, projection='3d')\nax7=p.add_subplot(2,4,7, projection='3d')\nax8=p.add_subplot(2,4,8, projection='3d')\n\n# 3. \nax1.grid(False)\nax1.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax1.scatter3D(vx, vy, f1, c=col,alpha=1)\nax1.set_xlim(-1,1)\nax1.set_ylim(-1,1)\nax1.set_zlim(-5,5)\n\nax2.grid(False)\nax2.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax2.scatter3D(r1[:,0],r1[:,1],r1[:,2],s=20,c=col,alpha=1)\n\nax3.grid(False)\nax3.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax3.scatter3D(r2[:,0],r2[:,1],r2[:,2],s=20,c=col,alpha=1)\n\nax4.grid(False)\nax4.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax4.scatter3D(r3[:,0],r3[:,1],r3[:,2],s=20,c=col,alpha=1)\n\n\nax5.grid(False)\nax5.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\ntop = -f2\nbottom = np.zeros_like(top)\nwidth=depth=0.05\nax5.bar3d(vx, vy, bottom, width, depth, top, shade=False,color=col)\nax5.set_xlim(-1,1)\nax5.set_ylim(-1,1)\nax5.set_zlim(-5,5)\n\nax6.grid(False)\nax6.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax6.scatter3D(r4[:,0],r4[:,1],r4[:,2],s=20,c=col,alpha=1)\n\nax7.grid(False)\nax7.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax7.scatter3D(r5[:,0],r5[:,1],r5[:,2],s=20,c=col,alpha=1)\n\nax8.grid(False)\nax8.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax8.scatter3D(r6[:,0],r6[:,1],r6[:,2],s=20,c=col,alpha=1)\np.tight_layout(h_pad=2.6) #rect : tuple (left, bottom, right, top), optional"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-08-02-HST example 1 (5), 이것도 좋아.html",
    "href": "연구/교수님이랑/HST/2021-08-02-HST example 1 (5), 이것도 좋아.html",
    "title": "(연구&교수님) HST example 1 (5), 이것도 좋아",
    "section": "",
    "text": "Import\n\nimport heavysnow as hs\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport rpy2 \n%load_ext rpy2.ipython\n%run pybase\n\n\n\nData\n\nf=np.array([-1,-1,-1,1,-1,-1,-1,1,1,1,-1,1,1,1])*1.0\nn=len(f)\nV=list(range(n))\nW=np.zeros([n,n])\nfor i in range(n):\n    for j in range(n):\n        if abs(i-j)==1: W[i,j]=1\nW[0,0]=1\nW[n-1,n-1]=1\n\n\ngs=hs.GraphSignal(V,W,f)\n\n\ngs.initdist=np.array([1/n]*n)\n\n\n\nHST\n\nhst=hs.HeavySnowTransform(gs)\nhst.snow(tau=80000,b=0.03)\n\nHST (tau= 80000, b=0.03)\n80000/80000\nHST completed and all history is recorded.\n\n\n\nplt.imshow(hst.snowweight)\n\n\n\n\n\n\n\n\n\n\n시각화를 위해서 R로 자료를 옮김\n\nmaxtau=hst.tau\nW_Graph=hst.graphweight\nW_Euclid=hst.euclidweight\nW_HST=hst.snowweight\nV=np.array(hst.V)\nf=hst.f\nn=hst.n\n%R -i maxtau,W_Graph,W_Euclid,W_HST,V,f,n\n\n\n\nR을 활용한 시각화 (1): 원래자료\n\n%%R -w 2000 -h 800 -r 100\nlibrary(tidyverse)\nlibrary(latex2exp)\nlibrary(gridExtra)\nsource('rbase.R')\nVtext=str_c('node ',V+1)\nfig0&lt;-ggplot(data=tibble(V=V,f=f,Vtext=Vtext),aes(x=V,y=f,label=Vtext))+\ngeom_col(aes(fill=(f&gt;0)),width=0.1)+geom_hline(aes(yintercept=0),col=\"gray60\",lty=2)+\ngeom_text(fontface = 4,size=8)+\nxlab(\"\")+ylab(\"\")+guides(fill=FALSE)+theme(plot.title=element_text(face=\"bold.italic\"))+theme_bw()+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 15, color = \"black\", face = \"bold.italic\"))+\nylim(-1.2,1.2)+\ntheme(plot.title=element_text(face=\"bold.italic\"))\n#ggsave(plot=p0,\"./fig/2021-0217_fig0.pdf\",width=20,height=6)\nfig0\n\nR[write to console]: ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\nR[write to console]: ✔ ggplot2 3.3.5     ✔ purrr   0.3.4\n✔ tibble  3.1.3     ✔ dplyr   1.0.7\n✔ tidyr   1.1.3     ✔ stringr 1.4.0\n✔ readr   2.0.1     ✔ forcats 0.5.1\n\nR[write to console]: ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nR[write to console]: \nAttaching package: ‘gridExtra’\n\n\nR[write to console]: The following object is masked from ‘package:dplyr’:\n\n    combine\n\n\nR[write to console]: \nAttaching package: ‘lubridate’\n\n\nR[write to console]: The following objects are masked from ‘package:base’:\n\n    date, intersect, setdiff, union\n\n\n\n\n\n\n\n\n\n\n\n\n\nR을 활용한 시각화 (2): Weight matrix 와 Eigen plot\n- ggplot에서 geom_tile을 사용하기 위해서 매트릭스 형태인 W_Graph, W_Euclid, W_HST를 길게 펼친다. 결과를 각각 W_Graph_long, W_Euclid_long, W_HST_long에 저장한다.\n\n%%R\ngrid&lt;-expand.grid(x=1:n,y=1:n)\nW_Graph_long&lt;-as_tibble(cbind(grid,as.vector(W_Graph)));names(W_Graph_long)&lt;-c(\"x\",\"y\",\"W\")\nW_Euclid_long&lt;-as_tibble(cbind(grid,as.vector(W_Euclid)));names(W_Euclid_long)&lt;-c(\"x\",\"y\",\"W\")\nW_HST_long&lt;-as_tibble(cbind(grid,as.vector(W_HST)));names(W_HST_long)&lt;-c(\"x\",\"y\",\"W\")\n\n- 그래프퓨리에 변환: \\((\\bf{f},\\bf{W})\\)에 그래프 퓨리에 변환을 수행함.\n\n%%R\nsource('heavysnow.R')\ngfftrslt_Euclid&lt;-gfft(f,W_Euclid)\ngfftrslt_Graph&lt;-gfft(f,W_Graph)\ngfftrslt_HST&lt;-gfft(f,W_HST)\n\nR[write to console]: \nAttaching package: ‘kohonen’\n\n\nR[write to console]: The following object is masked from ‘package:purrr’:\n\n    map\n\n\nR[write to console]: \nAttaching package: ‘igraph’\n\n\nR[write to console]: The following objects are masked from ‘package:lubridate’:\n\n    %--%, union\n\n\nR[write to console]: The following objects are masked from ‘package:dplyr’:\n\n    as_data_frame, groups, union\n\n\nR[write to console]: The following objects are masked from ‘package:purrr’:\n\n    compose, simplify\n\n\nR[write to console]: The following object is masked from ‘package:tidyr’:\n\n    crossing\n\n\nR[write to console]: The following object is masked from ‘package:tibble’:\n\n    as_data_frame\n\n\nR[write to console]: The following objects are masked from ‘package:stats’:\n\n    decompose, spectrum\n\n\nR[write to console]: The following object is masked from ‘package:base’:\n\n    union\n\n\n\n\n- 그래프 퓨리에 변환의 결과 고유치, 고유벡터, \\(\\bf{\\bar{f}}\\)가 반환됨.\n\n%%R\nhead(gfftrslt_HST)\n\n$λ\n [1] 1.000000e+00 1.000000e+00 1.464949e-06 8.895530e-07 2.262007e-07\n [6] 1.598314e-07 3.665785e-11 2.563940e-11 2.593852e-13 2.827377e-15\n[11] 2.360321e-20 1.349273e-20 3.095710e-24 3.148489e-31\n\n$Ψ\n               [,1]          [,2]          [,3]          [,4]          [,5]\n [1,]  1.647932e-20  3.137845e-19  4.670955e-17  7.070194e-01 -2.110975e-17\n [2,] -1.640639e-20 -2.995340e-19  4.669956e-17 -7.071942e-01 -2.176539e-17\n [3,] -4.315376e-20  4.378573e-17 -8.617348e-21  9.612956e-09  1.565717e-11\n [4,] -8.909868e-36  9.812867e-19 -6.559834e-18  1.267163e-24  1.193625e-10\n [5,] -1.110259e-16  4.010600e-04  9.818989e-19  7.188842e-19 -7.695629e-01\n [6,]  7.209903e-17 -9.999999e-01  7.204954e-22  1.292970e-19 -1.323671e-04\n [7,] -2.506421e-21  2.760443e-04  1.183488e-18 -1.001968e-19  6.385710e-01\n [8,] -6.284982e-04  3.823373e-17  1.220879e-19  1.461574e-23 -9.348682e-10\n [9,]  9.999998e-01  7.216759e-17  2.397844e-22 -2.325499e-20 -5.690448e-13\n[10,] -8.067624e-05 -5.453771e-21  3.406269e-19  1.876125e-24  2.280197e-10\n[11,] -7.887563e-23  3.532282e-29  2.224878e-29  8.074159e-42 -6.851679e-23\n[12,] -3.112061e-22 -2.104480e-38  1.732937e-09  7.249261e-42 -1.467225e-23\n[13,] -1.636686e-32 -1.110983e-48 -7.071439e-01  3.623240e-52  1.371193e-22\n[14,]  1.135212e-38  7.156130e-55  7.070697e-01 -7.610043e-54 -1.371049e-22\n               [,6]          [,7]          [,8]          [,9]         [,10]\n [1,] -7.676414e-18  7.071942e-01 -1.380086e-18  1.882027e-09 -1.866699e-11\n [2,] -7.674412e-18  7.070193e-01 -1.379858e-18  1.881715e-09 -1.866391e-11\n [3,] -1.642364e-16 -2.332220e-04 -8.367883e-15  1.133051e-05 -1.131751e-07\n [4,] -8.637074e-14 -4.408770e-17  8.525762e-13  8.637512e-05 -2.719773e-06\n [5,] -1.042256e-09  1.202972e-11  4.370350e-17 -6.385709e-01  6.823261e-05\n [6,] -3.510080e-13  8.828157e-15  3.206654e-20 -4.685387e-04  5.006437e-08\n [7,]  2.425813e-10  1.450316e-11  5.266838e-17 -7.695629e-01  8.222954e-05\n [8,]  9.413752e-01  4.176500e-18  1.875379e-15  3.604738e-05  3.373609e-01\n [9,]  5.644357e-04  1.075991e-17  1.600136e-18  3.077081e-08  2.879774e-04\n[10,] -3.373611e-01 -1.652459e-17  5.224063e-15  1.005884e-04  9.413753e-01\n[11,]  8.227223e-16  1.316464e-28  9.611076e-17 -1.512357e-13 -1.298295e-07\n[12,]  3.070801e-14 -1.094309e-25 -9.900698e-05 -5.645508e-12 -4.844137e-06\n[13,] -2.914076e-22  4.680526e-17  7.070696e-01 -3.983731e-16 -3.391229e-10\n[14,] -3.727726e-22 -4.680034e-17  7.071439e-01 -4.003261e-16 -3.391466e-10\n              [,11]         [,12]         [,13]         [,14]\n [1,] -1.649079e-04  2.474159e-06  8.676449e-12  2.888636e-13\n [2,] -1.648807e-04  2.473751e-06  8.675019e-12  2.888160e-13\n [3,] -9.998874e-01  1.500158e-02  5.260798e-08  1.751469e-09\n [4,] -1.500158e-02 -9.998875e-01  1.062026e-06 -3.904474e-10\n [5,] -8.061979e-06 -5.504216e-05 -2.679600e-10 -8.959269e-12\n [6,] -5.915310e-09 -4.038604e-08 -1.966107e-13 -6.573692e-15\n [7,] -9.715731e-06 -6.633294e-05 -3.229285e-10 -1.079713e-11\n [8,] -5.148622e-08 -9.137639e-07 -1.634196e-06 -4.474095e-08\n [9,] -4.394957e-11 -7.800053e-10 -1.394980e-09 -3.819168e-11\n[10,] -1.436676e-07 -2.549775e-06 -4.560078e-06 -1.248456e-07\n[11,] -1.705909e-09  1.028381e-09  5.761379e-04 -9.999998e-01\n[12,] -6.853438e-08 -1.061103e-06 -9.999998e-01 -5.761379e-04\n[13,] -4.794693e-12 -7.368076e-11 -7.000604e-05 -4.033314e-08\n[14,] -4.795030e-12 -7.368608e-11 -7.001094e-05 -4.033596e-08\n\n$fbar\n [1]  9.992906e-01  9.993228e-01 -7.425277e-05  1.748349e-04  1.311243e-01\n [6]  6.045785e-01 -1.413980e+00  1.414115e+00  1.408814e+00  1.278866e+00\n[11]  9.852332e-01 -1.014777e+00 -1.000721e+00  9.994234e-01\n\n\n\n- 시각화코드\n\n%%R -w 1000 -h 800 -r 100\nlibrary(gridExtra)\n\nfig1_1&lt;-ggplot()+geom_tile(data=W_Euclid_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"red\",high=\"blue\",mid=\"purple\",midpoint=0.25,breaks=c(0,0.5,0.99))+\nlabs(fill=TeX('$W$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(a) Euclid\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_2&lt;-ggplot()+geom_tile(data=W_Graph_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"red\",high=\"blue\",mid=\"purple\",midpoint=0.5,breaks=c(0,0.5,0.99))+\nlabs(fill=TeX('$\\\\hat{W}$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(b) Graph\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_3&lt;-ggplot()+geom_tile(data=W_HST_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"red\",high=\"blue\",mid=\"purple\",midpoint=0.5,breaks=c(0,0.5,0.99))+\nlabs(fill=TeX('$\\\\hat{W}(\\\\tau)$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(c) HST\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_4&lt;-eigenplot(gfftrslt_Euclid)+ylim(0,2)+theme_light()\nfig1_5&lt;-eigenplot(gfftrslt_Graph)+ylim(0,2)+theme_light()\nfig1_6&lt;-eigenplot(gfftrslt_HST)+ylim(0,2)+theme_light()\nfig1=grid.arrange(fig1_1,fig1_2,fig1_3,fig1_4,fig1_5,fig1_6,ncol=3,nrow=2)\nfig1\n#ggsave(plot=grid.arrange(p1_a,p1_b,p1_c,ncol=3),\"2021-07-22_fig1.png\",width=20,height=4)\n\nTableGrob (2 x 3) \"arrange\": 6 grobs\n  z     cells    name           grob\n1 1 (1-1,1-1) arrange gtable[layout]\n2 2 (1-1,2-2) arrange gtable[layout]\n3 3 (1-1,3-3) arrange gtable[layout]\n4 4 (2-2,1-1) arrange gtable[layout]\n5 5 (2-2,2-2) arrange gtable[layout]\n6 6 (2-2,3-3) arrange gtable[layout]\n\n\n\n\n\n\n\n\n\n\n\nR을 활용한 시각화 (3): Decomposition\n- 디콤포지션을 수행하고 결과를 저장: \\((\\bf{f},\\bf{W})\\)에 decomposition을 수행하고 그 결과를 각각 decomprslt_Euclid, decomprslt_Graph, decomprslt_HST에 저장한다.\n\n%%R \ndecomprslt_Euclid&lt;-decompose(f,W_Euclid,V=1:n) # 0, 35000, 60000, 80000\ndecomprslt_Graph&lt;-decompose(f,W_Graph,V=1:n) # 0, 35000, 60000, 80000\ndecomprslt_HST&lt;-decompose(f,W_HST,V=1:n) # 0, 35000, 60000, 80000\n\nNote: Using an external vector in selections is ambiguous.\nℹ Use `all_of(n)` instead of `n` to silence this message.\nℹ See &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;.\nThis message is displayed once per session.\n\n\n- 디콤포지션 결과는 아래와 같은 형태임\n\n%%R\nhead(decomprslt_Euclid)\n\n# A tibble: 6 × 5\n      V Vindex eigenvectorindex      fhat eigenvalue\n  &lt;int&gt;  &lt;int&gt;            &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1     1      1                1  1.45e-32   3.28e-18\n2     2      2                1  2.48e-17   3.28e-18\n3     3      3                1 -2.02e-16   3.28e-18\n4     4      4                1  1   e+ 0   3.28e-18\n5     5      5                1  8.73e-17   3.28e-18\n6     6      6                1 -6.32e-17   3.28e-18\n\n\n\n%%R \ndecomprslt_Euclid$method=\"Euclid\"\ndecomprslt_Graph$method=\"Graph\"\ndecomprslt_HST$method=\"HST\"\ndecomprslt&lt;-rbind(decomprslt_Euclid,decomprslt_Graph,decomprslt_HST)\n\n- 디콤포지션결과를 시각화한다. geom_col과 facet_grid를 이용.\n\n%%R -w 2000 -h 500 -r 100\nfig2&lt;-ggplot(data=decomprslt,aes(x=V,y=fhat))+\ngeom_col(aes(fill=fhat&gt;0),width=0.7)+facet_grid(method~eigenvectorindex)+geom_hline(aes(yintercept=0),col=\"gray60\",lty=2)+\nxlab(\"\")+ylab(\"\")+guides(fill=FALSE)+theme(plot.title=element_text(face=\"bold.italic\"))+theme_bw()+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 15, color = \"black\", face = \"bold.italic\"))+\nylim(-1.5,1.5)+\ntheme(plot.title=element_text(face=\"bold.italic\"))\nfig2\n#ggsave(plot=fig2,\"./fig/2021-0514_fig2.pdf\",width=20,height=6)"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-08-05-HST example 2, Appendix 추가.html",
    "href": "연구/교수님이랑/HST/2021-08-05-HST example 2, Appendix 추가.html",
    "title": "(연구&교수님) HST example 2, Appendix 추가",
    "section": "",
    "text": "import heavysnow as hs \nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport matplotlib\nmatplotlib.rc('image', cmap='Greys')\nfrom sklearn.decomposition import PCA \nimport rpy2 \n%load_ext rpy2.ipython\n%run pybase\n\nThe rpy2.ipython extension is already loaded. To reload it, use:\n  %reload_ext rpy2.ipython\n\n\n\n### Example 2\nnp.random.seed(777)\nimport math\npi=math.pi\nn=60\nang=np.linspace(-pi,pi-2*pi/n,n)\nV=np.arange(n)+1\nr=1\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=vx*0\n\nf2=vx*0\nf2[vy&lt;0]=3+np.random.normal(size=sum(vy&lt;0),scale=0.1)\nf2[vy&gt;0]= -3+np.random.normal(size=sum(vy&gt;0),scale=0.1)\n\n\n# Edg setting\nΣ=l2distance(np.matrix([vx,vy]).T)\nθ=0.05\nW=np.exp(-Σ**2/(2*θ**2))\nE=W&gt;0\nplt.plot(W[0,:].T)\n# color\nimport matplotlib.cm as cm\ncol=list(np.array(cm.rainbow((ang+pi)/2/pi)))\n\n\n\n\n\n\n\n\n\n%R -i ang,vx,vy,n\n\n\n%%R\nlibrary(latex2exp)\nlibrary(gridExtra)\nlibrary(tidyverse)\n\n\n%%R -w 450 -h 300 -r 100\nex2df&lt;-data.frame(cbind(ang,vx,vy))\nnames(ex2df)&lt;-c(\"ang\",\"vx\",\"vy\")\nex2plt &lt;- ggplot(data=ex2df,aes(x=vx,y=vy))+\n            geom_point(col=\"gray60\",cex=1.5,alpha=0.7)+\n            geom_point(data=ex2df[1:n,],aes(x=vx,y=vy,col=ang),cex=1.5,alpha=0.7)+\n            xlab(\"\")+ylab(\"\")+scale_colour_gradientn(colours=rainbow(7))+labs(col=TeX(\"$\\\\phi$\"))+theme_classic()+\n            theme(legend.key.width = unit(2,\"mm\"))\nshow(ex2plt)\n\n\n\n\n\n\n\n\n\ngs1=hs.GraphSignal(V,W,f1)\ngs2=hs.GraphSignal(V,W,f2)\n\n\nplt.imshow(W)\n\n\n\n\n\n\n\n\n\nDiffusion distance\n\nP=W/W.round(3).sum(axis=0)[0]\nprint(P)\nplt.imshow(P)\n\n[[2.20167327e-01 2.14586355e-01 1.46335569e-01 ... 2.83862880e-02\n  1.46335569e-01 2.14586355e-01]\n [2.14586355e-01 2.20167327e-01 2.14586355e-01 ... 3.69898283e-04\n  2.83862880e-02 1.46335569e-01]\n [1.46335569e-01 2.14586355e-01 2.20167327e-01 ... 4.82347874e-08\n  3.69898283e-04 2.83862880e-02]\n ...\n [2.83862880e-02 3.69898283e-04 4.82347874e-08 ... 2.20167327e-01\n  2.14586355e-01 1.46335569e-01]\n [1.46335569e-01 2.83862880e-02 3.69898283e-04 ... 2.14586355e-01\n  2.20167327e-01 2.14586355e-01]\n [2.14586355e-01 1.46335569e-01 2.83862880e-02 ... 1.46335569e-01\n  2.14586355e-01 2.20167327e-01]]\n\n\n\n\n\n\n\n\n\n\nplt.imshow(P@P@P@P)\n\n\n\n\n\n\n\n\n\nP4=P@P@P@P\ndiffusion_distance=l2distance(P4)\nplt.imshow(diffusion_distance)\n\n\n\n\n\n\n\n\n\n\nSnow distance\n\nhs1=hs.HeavySnowTransform(gs1)\nhs2=hs.HeavySnowTransform(gs2)\n\n\nhs1.snow(tau=50000,b=0.1)\nhs2.snow(tau=50000,b=0.1)\n\nHST (tau= 50000, b=0.1)\n50000/50000\nHST completed and all history is recorded.\nHST (tau= 50000, b=0.1)\n50000/50000\nHST completed and all history is recorded.\n\n\n\nfrom sklearn.decomposition import PCA \np1=PCA(n_components=3)\np2=PCA(n_components=3)\np3=PCA(n_components=3)\np4=PCA(n_components=3)\np5=PCA(n_components=3)\np6=PCA(n_components=3)\n\n\np1.fit(hs1.eucliddistance)\np2.fit(diffusion_distance)\np3.fit(hs1.snowdistance)\np4.fit(hs2.eucliddistance)\np5.fit(diffusion_distance)\np6.fit(hs2.snowdistance)\n\nr1=p1.transform(hs1.eucliddistance)\nr2=p2.transform(diffusion_distance)\nr3=p3.transform(hs1.snowdistance)\nr4=p4.transform(hs2.eucliddistance)\nr5=p5.transform(diffusion_distance)\nr6=p6.transform(hs2.snowdistance)\n\n/home/cgb4/anaconda3/envs/py38r40/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:470: RuntimeWarning: invalid value encountered in true_divide\n  explained_variance_ratio_ = explained_variance_ / total_var\n\n\n\n# 1. \np=plt.figure(figsize=(12,4), dpi=70)  # Make figure object \n\n# 2. \nax1=p.add_subplot(2,4,1, projection='3d')\nax2=p.add_subplot(2,4,2, projection='3d')\nax3=p.add_subplot(2,4,3, projection='3d')\nax4=p.add_subplot(2,4,4, projection='3d')\nax5=p.add_subplot(2,4,5, projection='3d')\nax6=p.add_subplot(2,4,6, projection='3d')\nax7=p.add_subplot(2,4,7, projection='3d')\nax8=p.add_subplot(2,4,8, projection='3d')\n\n# 3. \nax1.grid(False)\nax1.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax1.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax1.scatter3D(vx, vy, f1, c=col,alpha=1)\nax1.set_xlim(-1,1)\nax1.set_ylim(-1,1)\nax1.set_zlim(-5,5)\n\nax2.grid(False)\nax2.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax2.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax2.scatter3D(r1[:,0],r1[:,1],r1[:,2],s=20,c=col,alpha=1)\n\nax3.grid(False)\nax3.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax3.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax3.scatter3D(r2[:,0],r2[:,1],r2[:,2],s=20,c=col,alpha=1)\n\nax4.grid(False)\nax4.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax4.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax4.scatter3D(r3[:,0],r3[:,1],r3[:,2],s=20,c=col,alpha=1)\n\n\nax5.grid(False)\nax5.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax5.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\ntop = -f2\nbottom = np.zeros_like(top)\nwidth=depth=0.05\nax5.bar3d(vx, vy, bottom, width, depth, top, shade=False,color=col)\nax5.set_xlim(-1,1)\nax5.set_ylim(-1,1)\nax5.set_zlim(-5,5)\n\nax6.grid(False)\nax6.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax6.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax6.scatter3D(r4[:,0],r4[:,1],r4[:,2],s=20,c=col,alpha=1)\n\nax7.grid(False)\nax7.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax7.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax7.scatter3D(r5[:,0],r5[:,1],r5[:,2],s=20,c=col,alpha=1)\n\nax8.grid(False)\nax8.ticklabel_format(style='sci', axis='x',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='y',scilimits=(0,0))\nax8.ticklabel_format(style='sci', axis='z',scilimits=(0,0))\nax8.scatter3D(r6[:,0],r6[:,1],r6[:,2],s=20,c=col,alpha=1)\n#p.tight_layout(h_pad=2.6) #rect : tuple (left, bottom, right, top), optional\np.savefig('temp.pdf', transparent=True)\n\n\n\n\n\n\n\n\n\n\nAppendix\n\nex2, case A:\n\n_, (ax1,ax2,ax3) = plt.subplots(1,3)\nax1.imshow(hs1.eucliddistance)\nax2.imshow(hs1.snowdistance)\nax3.imshow(diffusion_distance)\nplt.show()\n\n\n\n\n\n\n\n\n그림1: 유클리드거리, snow distance, diffusion distance의 비교 - left: 유클리드 distance - middle: snow distance - right: diffusion distance.\n\n_, (ax1,ax2,ax3,ax4) = plt.subplots(1,4) \nax1.imshow(hs1.snowdistance1)\nax2.imshow(hs1.snowdistance3)\nax3.imshow(hs1.snowdistance2)\nax4.imshow(hs1.snowdistance)\nplt.show()#### ex2, case B: \n\n\n\n\n\n\n\n\n\n\nex2, case B:\n\n_, (ax1,ax2,ax3) = plt.subplots(1,3) \nax1.imshow(hs2.eucliddistance)\nax2.imshow(hs2.snowdistance)\nax3.imshow(diffusion_distance)\nplt.show()\n\n\n\n\n\n\n\n\n\n_, (ax1,ax2,ax3,ax4) = plt.subplots(1,4) \nax1.imshow(hs2.snowdistance1)\nax2.imshow(hs2.snowdistance3)\nax3.imshow(hs2.snowdistance2)\nax4.imshow(hs2.snowdistance)\nplt.show()\n\n\n\n\n\n\n\n\n\n_, (ax1,ax2,ax3,ax4) = plt.subplots(1,4) \nax1.imshow(hs2.snowdistance1[30:,30:])\nax2.imshow(hs2.snowdistance3[30:,30:])\nax3.imshow(hs2.snowdistance2[30:,30:])\nax4.imshow(hs2.snowdistance[30:,30:])\nplt.show()\n\n\n\n\n\n\n\n\n\nbrk=5000\n_, (ax1,ax2,ax3,ax4) = plt.subplots(1,4) \nax1.imshow(l2distance(hs2.snowygrounds.iloc[:,0:brk]))\nax2.imshow(l2distance(hs2.snowygrounds.iloc[:,brk:]))\nax3.imshow(hs2.eucliddistance)\nax4.imshow(diffusion_distance)\nplt.show()\n\n\n\n\n\n\n\n\n\n_, ((ax1,ax2,ax3,ax4),(ax5,ax6,ax7,ax8)) = plt.subplots(2,4) \n_d1=l2distance(hs2.snowygrounds.iloc[:,:brk])\n_d2=l2distance(hs2.snowygrounds_f.iloc[:,:brk])\n_d3=l2distance(hs2.snowygrounds_sumxi.iloc[:,:brk])\n_d4=_d1-_d2-_d3\n_d5=l2distance(hs2.snowygrounds.iloc[:,brk:])\n_d6=l2distance(np.matrix(hs2.snowygrounds.iloc[:,brk]).T)\n_d7=l2distance(hs2.snowygrounds_sumxi.iloc[:,brk:]-np.matrix(hs2.snowygrounds_sumxi.iloc[:,brk]).T)\n_d8=_d5-_d6-_d7\nax1.imshow(_d1)\nax2.imshow(_d2)\nax3.imshow(_d3)\nax4.imshow(_d4)\nax5.imshow(_d5)\nax6.imshow(_d6)\nax7.imshow(_d7)\nax8.imshow(_d8)\nplt.show()"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-08-02-HST example 1 (8), 결과좋음.html",
    "href": "연구/교수님이랑/HST/2021-08-02-HST example 1 (8), 결과좋음.html",
    "title": "(연구&교수님) HST example 1 (8), 결과좋음",
    "section": "",
    "text": "Import\n\nimport heavysnow as hs\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport rpy2 \n%load_ext rpy2.ipython\n%run pybase\n\n\n\nData\n\nf=np.array([-1,-1,-1,1,-1,-1,-1,1,1,1,-1,1,1,1])*1.0\nn=len(f)\nV=list(range(n))\nW=np.zeros([n,n])\nfor i in range(n):\n    for j in range(n):\n        if abs(i-j)==1: W[i,j]=1\nW[0,0]=1\nW[n-1,n-1]=1\n\n\ngs=hs.GraphSignal(V,W,f)\n\n\ngs.initdist=np.array([1/n]*n)\n\n\n\nHST\n\nhst=hs.HeavySnowTransform(gs)\nhst.snow(tau=80000,b=0.03)\n\nHST (tau= 80000, b=0.03)\n80000/80000\nHST completed and all history is recorded.\n\n\n\nplt.imshow(hst.snowweight)\n\n\n\n\n\n\n\n\n\n\n시각화를 위해서 R로 자료를 옮김\n\nmaxtau=hst.tau\nW_Graph=hst.graphweight\nW_Euclid=hst.euclidweight\nW_HST=hst.snowweight\nV=np.array(hst.V)\nf=hst.f\nn=hst.n\n%R -i maxtau,W_Graph,W_Euclid,W_HST,V,f,n\n\n\n\nR을 활용한 시각화 (1): 원래자료\n\n%%R -w 2000 -h 800 -r 100\nlibrary(tidyverse)\nlibrary(latex2exp)\nlibrary(gridExtra)\nsource('rbase.R')\nVtext=str_c('node ',V+1)\nfig0&lt;-ggplot(data=tibble(V=V,f=f,Vtext=Vtext),aes(x=V,y=f,label=Vtext))+\ngeom_col(aes(fill=(f&gt;0)),width=0.1)+geom_hline(aes(yintercept=0),col=\"gray60\",lty=2)+\ngeom_text(fontface = 4,size=8)+\nxlab(\"\")+ylab(\"\")+guides(fill=FALSE)+theme(plot.title=element_text(face=\"bold.italic\"))+theme_bw()+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 15, color = \"black\", face = \"bold.italic\"))+\nylim(-1.2,1.2)+\ntheme(plot.title=element_text(face=\"bold.italic\"))\n#ggsave(plot=p0,\"./fig/2021-0217_fig0.pdf\",width=20,height=6)\nfig0\n\nR[write to console]: ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\nR[write to console]: ✔ ggplot2 3.3.5     ✔ purrr   0.3.4\n✔ tibble  3.1.3     ✔ dplyr   1.0.7\n✔ tidyr   1.1.3     ✔ stringr 1.4.0\n✔ readr   2.0.1     ✔ forcats 0.5.1\n\nR[write to console]: ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nR[write to console]: \nAttaching package: ‘gridExtra’\n\n\nR[write to console]: The following object is masked from ‘package:dplyr’:\n\n    combine\n\n\nR[write to console]: \nAttaching package: ‘lubridate’\n\n\nR[write to console]: The following objects are masked from ‘package:base’:\n\n    date, intersect, setdiff, union\n\n\n\n\n\n\n\n\n\n\n\n\n\nR을 활용한 시각화 (2): Weight matrix 와 Eigen plot\n- ggplot에서 geom_tile을 사용하기 위해서 매트릭스 형태인 W_Graph, W_Euclid, W_HST를 길게 펼친다. 결과를 각각 W_Graph_long, W_Euclid_long, W_HST_long에 저장한다.\n\n%%R\ngrid&lt;-expand.grid(x=1:n,y=1:n)\nW_Graph_long&lt;-as_tibble(cbind(grid,as.vector(W_Graph)));names(W_Graph_long)&lt;-c(\"x\",\"y\",\"W\")\nW_Euclid_long&lt;-as_tibble(cbind(grid,as.vector(W_Euclid)));names(W_Euclid_long)&lt;-c(\"x\",\"y\",\"W\")\nW_HST_long&lt;-as_tibble(cbind(grid,as.vector(W_HST)));names(W_HST_long)&lt;-c(\"x\",\"y\",\"W\")\n\n- 그래프퓨리에 변환: \\((\\bf{f},\\bf{W})\\)에 그래프 퓨리에 변환을 수행함.\n\n%%R\nsource('heavysnow.R')\ngfftrslt_Euclid&lt;-gfft(f,W_Euclid)\ngfftrslt_Graph&lt;-gfft(f,W_Graph)\ngfftrslt_HST&lt;-gfft(f,W_HST)\n\nR[write to console]: \nAttaching package: ‘kohonen’\n\n\nR[write to console]: The following object is masked from ‘package:purrr’:\n\n    map\n\n\nR[write to console]: \nAttaching package: ‘igraph’\n\n\nR[write to console]: The following objects are masked from ‘package:lubridate’:\n\n    %--%, union\n\n\nR[write to console]: The following objects are masked from ‘package:dplyr’:\n\n    as_data_frame, groups, union\n\n\nR[write to console]: The following objects are masked from ‘package:purrr’:\n\n    compose, simplify\n\n\nR[write to console]: The following object is masked from ‘package:tidyr’:\n\n    crossing\n\n\nR[write to console]: The following object is masked from ‘package:tibble’:\n\n    as_data_frame\n\n\nR[write to console]: The following objects are masked from ‘package:stats’:\n\n    decompose, spectrum\n\n\nR[write to console]: The following object is masked from ‘package:base’:\n\n    union\n\n\n\n\n- 그래프 퓨리에 변환의 결과 고유치, 고유벡터, \\(\\bf{\\bar{f}}\\)가 반환됨.\n\n%%R\nhead(gfftrslt_HST)\n\n$λ\n [1] 1.976572e+00 1.000000e+00 2.342780e-02 1.432865e-07 1.026724e-07\n [6] 3.694392e-08 3.448249e-12 9.558971e-14 2.384023e-14 2.397474e-15\n[11] 3.126664e-19 9.910616e-21 6.612328e-22 1.402843e-28\n\n$Ψ\n               [,1]          [,2]          [,3]          [,4]          [,5]\n [1,] -8.288239e-17 -8.760573e-21 -1.704367e-17 -4.579204e-20  1.294809e-21\n [2,]  4.363068e-17  8.769455e-21  1.704252e-17 -4.404141e-20  1.294790e-21\n [3,]  4.064626e-22  4.206794e-19 -6.073661e-17 -1.009986e-14  2.790055e-17\n [4,]  2.220446e-16  2.812850e-23 -2.164935e-15 -1.194558e-11 -9.066508e-17\n [5,]  5.409523e-22  3.450918e-04  2.778478e-18  7.957005e-01  1.865129e-17\n [6,] -4.684363e-18 -9.999999e-01 -4.564765e-18  1.534924e-04  1.133523e-20\n [7,] -7.362288e-18  1.999328e-04  6.165919e-16 -6.056903e-01  2.450236e-17\n [8,] -1.310175e-06  7.603181e-17  1.108020e-04  4.378767e-10  8.003580e-17\n [9,]  7.071068e-01  1.034760e-20 -7.071068e-01  3.439075e-14  2.677548e-20\n[10,] -7.071068e-01  6.632814e-18 -7.071068e-01  3.358573e-14  2.711664e-20\n[11,]  1.532237e-17  1.108475e-24  1.298609e-15  8.012394e-18 -3.187528e-24\n[12,]  8.741002e-14 -1.624184e-30  7.406868e-12 -5.759162e-20 -7.046696e-09\n[13,]  1.360404e-21 -2.526427e-38  1.151522e-19 -9.884008e-28  7.071780e-01\n[14,]  1.603078e-28 -2.339964e-45 -2.357279e-25  5.052233e-28 -7.070355e-01\n               [,6]          [,7]          [,8]          [,9]         [,10]\n [1,]  7.071013e-01  6.063217e-21 -7.071123e-01  4.767118e-15  3.774676e-12\n [2,] -7.071123e-01  6.063154e-21 -7.071013e-01  4.767048e-15  3.774632e-12\n [3,]  3.789325e-11  5.734372e-16  1.464501e-05  6.953212e-11  2.702643e-07\n [4,]  2.743167e-27 -1.938665e-15 -1.129610e-15  4.452632e-07  5.433880e-04\n [5,] -7.868839e-18 -1.648851e-14 -8.359464e-13 -2.329466e-03 -6.056856e-01\n [6,] -1.352821e-20 -1.002064e-17 -5.080425e-16 -1.415722e-06 -3.681026e-04\n [7,]  5.989800e-18 -2.166025e-14 -1.098190e-12 -3.060238e-03 -7.956945e-01\n [8,]  3.536443e-21  1.163908e-09  4.153456e-16  9.999923e-01 -3.845945e-03\n [9,]  3.961819e-17  9.118353e-14 -7.090095e-18  7.927470e-05 -3.048885e-07\n[10,] -8.624363e-17  8.900103e-14  7.155285e-18  7.742184e-05 -2.977624e-07\n[11,]  4.409508e-32 -1.412408e-16 -4.012165e-23 -1.397337e-07  5.973322e-09\n[12,]  2.519775e-28 -2.097766e-04 -2.406708e-19 -7.969978e-04  3.048049e-05\n[13,]  3.917546e-36  7.070355e-01  1.094801e-21 -1.190372e-07  4.524148e-09\n[14,] -7.757457e-42  7.071780e-01 -9.169239e-22 -1.190532e-07  4.524756e-09\n              [,11]         [,12]         [,13]         [,14]\n [1,] -3.476553e-10 -1.035564e-05  2.597141e-10 -1.085114e-12\n [2,] -3.476517e-10 -1.035553e-05  2.597115e-10 -1.085103e-12\n [3,] -3.357172e-05 -1.000000e+00  2.507949e-05 -1.047848e-07\n [4,] -9.999999e-01  3.357179e-05 -2.887349e-06  1.308209e-08\n [5,] -3.291235e-04 -1.522297e-07  1.660393e-05 -6.999686e-08\n [6,] -2.000232e-07 -9.251733e-11  1.009096e-08 -4.254026e-11\n [7,] -4.323724e-04 -1.999855e-07  2.181273e-05 -9.195548e-08\n [8,] -1.646882e-06  1.907666e-08  7.971021e-04 -3.342045e-06\n [9,] -1.305556e-10  1.511987e-12  6.319569e-08 -2.649634e-10\n[10,] -1.275041e-10  1.476644e-12  6.171889e-08 -2.587715e-10\n[11,] -1.479083e-09  4.030197e-09 -4.017381e-03 -9.999919e-01\n[12,] -2.870328e-06  2.507980e-05  9.999916e-01 -4.017379e-03\n[13,] -4.257394e-10  3.719949e-09  1.483232e-04 -5.958757e-07\n[14,] -4.257975e-10  3.720449e-09  1.483431e-04 -5.959557e-07\n\n$fbar\n [1] -1.310173e-06  9.994549e-01 -1.414103e+00 -1.901637e-01  1.424902e-04\n [6]  1.097747e-05  1.414004e+00  1.414199e+00  1.004743e+00  1.398475e+00\n[11] -9.992091e-01  1.000080e+00  1.005036e+00  9.959703e-01\n\n\n\n- 시각화코드\n\n%%R -w 1000 -h 800 -r 100\nlibrary(gridExtra)\n\nfig1_1&lt;-ggplot()+geom_tile(data=W_Euclid_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"red\",high=\"blue\",mid=\"purple\",midpoint=0.25,breaks=c(0,0.5,0.99))+\nlabs(fill=TeX('$W$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(a) Euclid\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_2&lt;-ggplot()+geom_tile(data=W_Graph_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"red\",high=\"blue\",mid=\"purple\",midpoint=0.5,breaks=c(0,0.5,0.99))+\nlabs(fill=TeX('$\\\\hat{W}$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(b) Graph\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_3&lt;-ggplot()+geom_tile(data=W_HST_long,aes(x=x,y=y,fill=W))+theme_bw()+xlab(\"\")+ylab(\"\")+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\nscale_fill_gradient2(low=\"red\",high=\"blue\",mid=\"purple\",midpoint=0.5,breaks=c(0,0.5,0.99))+\nlabs(fill=TeX('$\\\\hat{W}(\\\\tau)$'))+\ntheme(legend.position=\"none\")+theme(legend.key=element_blank())+\nggtitle(\"(c) HST\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(3)))\n\nfig1_4&lt;-eigenplot(gfftrslt_Euclid)+ylim(0,2)+theme_light()\nfig1_5&lt;-eigenplot(gfftrslt_Graph)+ylim(0,2)+theme_light()\nfig1_6&lt;-eigenplot(gfftrslt_HST)+ylim(0,2)+theme_light()\nfig1=grid.arrange(fig1_1,fig1_2,fig1_3,fig1_4,fig1_5,fig1_6,ncol=3,nrow=2)\nfig1\n#ggsave(plot=grid.arrange(p1_a,p1_b,p1_c,ncol=3),\"2021-07-22_fig1.png\",width=20,height=4)\n\nTableGrob (2 x 3) \"arrange\": 6 grobs\n  z     cells    name           grob\n1 1 (1-1,1-1) arrange gtable[layout]\n2 2 (1-1,2-2) arrange gtable[layout]\n3 3 (1-1,3-3) arrange gtable[layout]\n4 4 (2-2,1-1) arrange gtable[layout]\n5 5 (2-2,2-2) arrange gtable[layout]\n6 6 (2-2,3-3) arrange gtable[layout]\n\n\n\n\n\n\n\n\n\n\n\nR을 활용한 시각화 (3): Decomposition\n- 디콤포지션을 수행하고 결과를 저장: \\((\\bf{f},\\bf{W})\\)에 decomposition을 수행하고 그 결과를 각각 decomprslt_Euclid, decomprslt_Graph, decomprslt_HST에 저장한다.\n\n%%R \ndecomprslt_Euclid&lt;-decompose(f,W_Euclid,V=1:n) # 0, 35000, 60000, 80000\ndecomprslt_Graph&lt;-decompose(f,W_Graph,V=1:n) # 0, 35000, 60000, 80000\ndecomprslt_HST&lt;-decompose(f,W_HST,V=1:n) # 0, 35000, 60000, 80000\n\nNote: Using an external vector in selections is ambiguous.\nℹ Use `all_of(n)` instead of `n` to silence this message.\nℹ See &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;.\nThis message is displayed once per session.\n\n\n- 디콤포지션 결과는 아래와 같은 형태임\n\n%%R\nhead(decomprslt_Euclid)\n\n# A tibble: 6 × 5\n      V Vindex eigenvectorindex      fhat eigenvalue\n  &lt;int&gt;  &lt;int&gt;            &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1     1      1                1  1.45e-32   3.28e-18\n2     2      2                1  2.48e-17   3.28e-18\n3     3      3                1 -2.02e-16   3.28e-18\n4     4      4                1  1   e+ 0   3.28e-18\n5     5      5                1  8.73e-17   3.28e-18\n6     6      6                1 -6.32e-17   3.28e-18\n\n\n\n%%R \ndecomprslt_Euclid$method=\"Euclid\"\ndecomprslt_Graph$method=\"Graph\"\ndecomprslt_HST$method=\"HST\"\ndecomprslt&lt;-rbind(decomprslt_Euclid,decomprslt_Graph,decomprslt_HST)\n\n- 디콤포지션결과를 시각화한다. geom_col과 facet_grid를 이용.\n\n%%R -w 2000 -h 500 -r 100\nfig2&lt;-ggplot(data=decomprslt,aes(x=V,y=fhat))+\ngeom_col(aes(fill=fhat&gt;0),width=0.7)+facet_grid(method~eigenvectorindex)+geom_hline(aes(yintercept=0),col=\"gray60\",lty=2)+\nxlab(\"\")+ylab(\"\")+guides(fill=FALSE)+theme(plot.title=element_text(face=\"bold.italic\"))+theme_bw()+\ntheme(strip.text.x = element_text(size = 20, color = \"black\", face = \"bold.italic\"))+\ntheme(strip.text.y = element_text(size = 15, color = \"black\", face = \"bold.italic\"))+\nylim(-1.5,1.5)+\ntheme(plot.title=element_text(face=\"bold.italic\"))\nfig2\n#ggsave(plot=fig2,\"asdf.pdf\",width=20,height=6)"
  },
  {
    "objectID": "연구/교수님이랑/HST/2021-12-10-HST example 3.html",
    "href": "연구/교수님이랑/HST/2021-12-10-HST example 3.html",
    "title": "(연구&교수님) HST example 3",
    "section": "",
    "text": "실험환경\n\n!conda env list\n\n# conda environments:\n#\nbase                     /home/cgb3/anaconda3\ndv2021                   /home/cgb3/anaconda3/envs/dv2021\npy38r40               *  /home/cgb3/anaconda3/envs/py38r40\n\n\n\n\n\nimport\n\n## 1. remove trash\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib\nmatplotlib.rc('image', cmap='Greys')\nimport rpy2 \n%load_ext rpy2.ipython\n%run pybase\n%run heavysnow \nplt.style.use('ggplot')\n\n\n\nload data\n\nn=23\nf=np.array(pd.read_csv(\"2021-08-15-MCU-ticket.csv\").Worldwide)/1000000\nV=np.array(pd.read_csv(\"2021-08-15-MCU-ticket.csv\").Film)\nW=np.array(pd.read_csv(\"2021-08-15-MCU-weights.csv\",index_col=0))-np.eye(n,n)\n\n\n\nHST\n\ngs=GraphSignal(V,W,f)\nhst=HeavysnowTransform(gs)\nhst.snow(tau=800000,b=0.1)\n\nHST (tau= 800000, b=0.1)\n800000/800000\nHST completed and all history is recorded.\n\n\n\ndef choose_theta(maxtheta=200):\n    y=[]\n    x=np.arange(start=0.01,stop=maxtheta,step=0.1)\n    for i in range(len(x)):\n        hst.adjustingtheta(x[i]) \n        gs=GraphSignal(V,hst.snowweight,f)\n        spa=SpectralAnalysis(gs)\n        spa.graphFouriertransform()\n        spa.decompose()        \n        y.append(sum(abs(spa.lamb)&lt;0.001))\n    plt.plot(x,y)\nchoose_theta()   \n\n/home/cgb3/Dropbox/01_yechan/_notebooks/heavysnow.py:11: RuntimeWarning: invalid value encountered in true_divide\n\n\n\n\n\n\n\n\n\n\nhst.adjustingtheta(100)\n\n\nplt.imshow(hst.snowweight)\n\n\n\n\n\n\n\n\n\n\nR 환경으로..\n\nimport rpy2 \n%load_ext rpy2.ipython\n\nThe rpy2.ipython extension is already loaded. To reload it, use:\n  %reload_ext rpy2.ipython\n\n\n\nn=hst.n \nV=hst.V\nf=hst.f \nWEuclid= hst.euclidweight\nWgraph= (hst.graphweight+hst.graphweight.T)/2\nWhst= hst.snowweight\nW= hst.graphweight\n\n\n%R -i n\n%R -i V\n%R -i f\n%R -i WEuclid\n%R -i Wgraph\n%R -i Whst\n%R -i W\n\n\n\n유클리드와 그래프도메인의 정보를 플랏.\n\n%%R \nsource('heavysnow.R')\ndf&lt;-tibble(V)\ndf$f&lt;-as.vector(f)\ndf$divlink&lt;-0\ndf$conlink&lt;-0\ndf$link&lt;-0\nfor(i in 1:23){\n    df$divlink[i]&lt;-sum(W[i,])\n    df$conlink[i]&lt;-sum(W[,i])\n    df$link[i]&lt;-(sum(W[i,])+sum(W[,i]))/2\n}\ndf$movietype&lt;-rep('singlehero',23)\ndf[V %in% c(\"The Avengers\" ,\"Avengers: Age of Ultron\",\"Captain America: Civil War\",\"Avengers: Infinity War\",\"Avengers: Endgame\"),'movietype']='multihero'\ndf\n\nR[write to console]: Error in library(ggforce) : there is no package called ‘ggforce’\n\n\n\n\nError in library(ggforce) : there is no package called ‘ggforce’\n\n\nRInterpreterError: Failed to parse and evaluate line 'source(\\'heavysnow.R\\')\\ndf&lt;-tibble(V)\\ndf$f&lt;-as.vector(f)\\ndf$divlink&lt;-0\\ndf$conlink&lt;-0\\ndf$link&lt;-0\\nfor(i in 1:23){\\n    df$divlink[i]&lt;-sum(W[i,])\\n    df$conlink[i]&lt;-sum(W[,i])\\n    df$link[i]&lt;-(sum(W[i,])+sum(W[,i]))/2\\n}\\ndf$movietype&lt;-rep(\\'singlehero\\',23)\\ndf[V %in% c(\"The Avengers\" ,\"Avengers: Age of Ultron\",\"Captain America: Civil War\",\"Avengers: Infinity War\",\"Avengers: Endgame\"),\\'movietype\\']=\\'multihero\\'\\ndf\\n'.\nR error message: 'Error in library(ggforce) : there is no package called ‘ggforce’'\n\n\n\n%%R \nregular_grid=function(df,xyz){\n    i=xyz[1]\n    j=xyz[2]\n    k=xyz[3]\n    \n    library(akima)\n    library(reshape)\n    fld &lt;- with(df, interp(x = df[[i]], y = df[[j]], z = df[[k]]))\n    # prepare data in long format\n    df2 &lt;- melt(fld$z, na.rm = TRUE)\n    names(df2) &lt;-c(\"x\", \"y\", \"z\")\n    df2$x &lt;- fld$x[df2$x]\n    df2$y &lt;- fld$y[df2$y]\n    names(df2) &lt;- names(df)[c(i,j,k)]\n    as_tibble(df2)\n}\nregular_grid(df,xyz=c(4,3,2))\n\nR[write to console]: Error in library(akima) : there is no package called ‘akima’\n\n\n\n\nError in library(akima) : there is no package called ‘akima’\n\n\nRInterpreterError: Failed to parse and evaluate line 'regular_grid=function(df,xyz){\\n    i=xyz[1]\\n    j=xyz[2]\\n    k=xyz[3]\\n    \\n    library(akima)\\n    library(reshape)\\n    fld &lt;- with(df, interp(x = df[[i]], y = df[[j]], z = df[[k]]))\\n    # prepare data in long format\\n    df2 &lt;- melt(fld$z, na.rm = TRUE)\\n    names(df2) &lt;-c(\"x\", \"y\", \"z\")\\n    df2$x &lt;- fld$x[df2$x]\\n    df2$y &lt;- fld$y[df2$y]\\n    names(df2) &lt;- names(df)[c(i,j,k)]\\n    as_tibble(df2)\\n}\\nregular_grid(df,xyz=c(4,3,2))\\n'.\nR error message: 'Error in library(akima) : there is no package called ‘akima’'\n\n\n\n%%R \n#foo$location &lt;- factor(foo$location, levels = c(\"Paris\", \"Madrid\", \"London\"))\np1&lt;-ggplot(df)+\n    geom_point(aes(x=conlink,y=divlink,shape=movietype,size=f),stroke=2,fill='black')+\n    scale_shape_manual(values=c(18,20))+\n    theme_light()+\n    geom_text_repel(aes(x=conlink,y=divlink,label=V),color=\"gray40\")+\n    #geom_density2d(data=.df,aes(x=conlink,y=divlink,fill=f),color=\"gray80\",linetype = \"dashed\")+\n    geom_contour(data=regular_grid(df,xyz=c(4,3,2)),aes(x=conlink,y=divlink,z=f),color='gray50',size=0.5)+\n    ylab(\"Out-degree\")+xlab(\"In-degree\")+\n    ggtitle(\"\")+\n    theme(plot.title=element_text(face=\"bold.italic\",size=rel(2)))+\n    theme(axis.title.x=element_text(face=4,size=rel(1)))+\n    theme(axis.title.y=element_text(face=4,size=rel(1)))+\n    theme(legend.position = \"none\")\nshow(p1)\nggsave(plot=p1,\"./2021-12-10-p1.pdf\",width=10,height=7)\n\n\n\n\n\n\n\n\n\n\ngfft 수행하고 결과를 저장함.\n\n%%R \ng1&lt;-gfft(f,WEuclid)\ng2&lt;-gfft(f,Wgraph)\ng3&lt;-gfft(f,Whst)\n\n\n\n아이겐플랏\n\n%%R \nlibrary(gridExtra)\ne1&lt;-eigenplot(g1)+ggtitle(\"(a)\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(1)))\ne2&lt;-eigenplot(g2)+ggtitle(\"(b)\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(1)))\ne3&lt;-eigenplot(g3)+ggtitle(\"(c)\")+theme(plot.title=element_text(face=\"bold.italic\",size=rel(1)))\ns1&lt;-specplot(g1)\ns2&lt;-specplot(g2)\ns3&lt;-specplot(g3)\np2&lt;-grid.arrange(e1,e2,e3,s1,s2,s3,nrow=2)\nggsave(plot=p2,\"./2021-12-10-p2.pdf\",width=5,height=3)\n\n\n\n\n\n\n\n\n\n\n분해\n\n%%R\nd1&lt;-decompose(f,WEuclid,V=V) # 0, 35000, 60000, 80000\nd2&lt;-decompose(f,Wgraph,V=V) # 0, 35000, 60000, 80000\nd3&lt;-decompose(f,Whst,V=V) # 0, 35000, 60000, 80000\n\nd1$case&lt;-\"Euclid\"\nd2$case&lt;-\"Graph\"\nd3$case&lt;-\"HST\"\n.df2 &lt;-rbind(d1,d2,d3)\n.df2 %&gt;% group_by(case,eigenvectorindex) #%&gt;% mutate(textsize= 10*(abs(fhat)&gt;70))\ndf2=merge(df, .df2 %&gt;% group_by(case,eigenvectorindex) %&gt;% mutate(textsize= 10*(abs(fhat)&gt;70))) %&gt;% as_tibble\ndf2\n\n# A tibble: 1,587 × 12\n   V          f divlink conlink  link movietype Vindex eigenvectorindex     fhat\n   &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;int&gt;            &lt;dbl&gt;    &lt;dbl&gt;\n 1 Ant-m…  519.    1.75    1.10  1.42 singlehe…     12                1  561.   \n 2 Ant-m…  519.    1.75    1.10  1.42 singlehe…     12                6 -142.   \n 3 Ant-m…  519.    1.75    1.10  1.42 singlehe…     12               17   -1.52 \n 4 Ant-m…  519.    1.75    1.10  1.42 singlehe…     12                5   61.6  \n 5 Ant-m…  519.    1.75    1.10  1.42 singlehe…     12               12    0.274\n 6 Ant-m…  519.    1.75    1.10  1.42 singlehe…     12               15    0.328\n 7 Ant-m…  519.    1.75    1.10  1.42 singlehe…     12                8   28.4  \n 8 Ant-m…  519.    1.75    1.10  1.42 singlehe…     12               22   -0.843\n 9 Ant-m…  519.    1.75    1.10  1.42 singlehe…     12               18   -6.37 \n10 Ant-m…  519.    1.75    1.10  1.42 singlehe…     12                2    4.86 \n# … with 1,577 more rows, and 3 more variables: eigenvalue &lt;dbl&gt;, case &lt;chr&gt;,\n#   textsize &lt;dbl&gt;\n\n\n\n%%R \ndf2\n\n# A tibble: 1,587 × 12\n   V          f divlink conlink  link movietype Vindex eigenvectorindex     fhat\n   &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;int&gt;            &lt;dbl&gt;    &lt;dbl&gt;\n 1 Ant-m…  519.    1.75    1.10  1.42 singlehe…     12                1  561.   \n 2 Ant-m…  519.    1.75    1.10  1.42 singlehe…     12                6 -142.   \n 3 Ant-m…  519.    1.75    1.10  1.42 singlehe…     12               17   -1.52 \n 4 Ant-m…  519.    1.75    1.10  1.42 singlehe…     12                5   61.6  \n 5 Ant-m…  519.    1.75    1.10  1.42 singlehe…     12               12    0.274\n 6 Ant-m…  519.    1.75    1.10  1.42 singlehe…     12               15    0.328\n 7 Ant-m…  519.    1.75    1.10  1.42 singlehe…     12                8   28.4  \n 8 Ant-m…  519.    1.75    1.10  1.42 singlehe…     12               22   -0.843\n 9 Ant-m…  519.    1.75    1.10  1.42 singlehe…     12               18   -6.37 \n10 Ant-m…  519.    1.75    1.10  1.42 singlehe…     12                2    4.86 \n# … with 1,577 more rows, and 3 more variables: eigenvalue &lt;dbl&gt;, case &lt;chr&gt;,\n#   textsize &lt;dbl&gt;\n\n\n\n%%R -r 150 -w 900 -h 1200\np3 &lt;- ggplot(data=filter(df2,eigenvectorindex %in% 1:8))+\n    geom_point(aes(x=conlink,y=divlink,alpha=abs(fhat),shape=movietype,color=(fhat&gt;0)),size=4)+\n    #geom_density2d(data=.df,aes(x=conlink,y=divlink),size=0.2,color=\"gray80\",linetype = \"dashed\")+\n    geom_contour(data=regular_grid(df,xyz=c(4,3,2)),aes(x=conlink,y=divlink,z=f),color='gray50',size=0.1)+\n    scale_shape_manual(values=c(18,20))+\n    theme_light()+\n    facet_grid(eigenvectorindex~case)+\n    theme(legend.position=\"none\")\nshow(p3)\n\n\n\n\n\n\n\n\n\n%%R -r 150 -w 1000 -h 5500\n        \np3&lt;-ggplot(data=filter(df2, case=='HST',eigenvectorindex %in% 1:23))+\n    geom_col(aes(x=Vindex,y=fhat,fill=fhat&gt;0),width=0.7)+\n    geom_text_repel(aes(x=Vindex,y=fhat,label=V,size=textsize),col=1,fontface=4,alpha=0.8,segment.size=0.2,segment.color=\"gray60\",min.segment.length=5,hjust=0.1)+\n    scale_radius(range = c(0,1.8))+\n    guides(size=FALSE)+\n    facet_wrap('eigenvectorindex',ncol=1)+\n    geom_hline(aes(yintercept=0),col=\"gray60\",lty=2)+\n    xlab(\"\")+ylab(\"\")+guides(fill=FALSE)+\n    theme(axis.text.x=element_text(angle=85,hjust=1,vjust=1,face=4,size=rel(0.7),colour=\"gray60\"))+\n    theme_light()+\n    theme(strip.text.x = element_text(size = 10, color = \"black\", face = \"bold.italic\"))+\n    theme(strip.text.y = element_text(size = 10, color = \"black\", face = \"bold.italic\"))+\n    theme(plot.title=element_text(face=\"bold.italic\",size=rel(1.5)))\nshow(p3)\n\n#ggsave(plot=p3,\"./fig/p3.pdf\",width=6,height=6)\n\n\n\n\n\n\n\n\n\n%%R\ndat3_Euclid &lt;- decomp_dat %&gt;% filter(case==\"Euclid\",eigenvectorindex==1) %&gt;% select(V,case,eigenvectorindex,textsize,fhat)\ndat3_Euclid &lt;- left_join(dat,dat3_Euclid,by=\"V\")\n\nfor(j in 2:23){\n        decomp_filtered_dat_&lt;- decomp_dat %&gt;% filter(case==\"Euclid\",eigenvectorindex==j) %&gt;% select(V,case,eigenvectorindex,textsize,fhat)\n        decomp_filtered_dat_&lt;- left_join(dat,decomp_filtered_dat_,by=\"V\")\n        dat3_Euclid&lt;-rbind(dat3_Euclid,decomp_filtered_dat_)\n}\n\ndat3_Graph &lt;- decomp_dat %&gt;% filter(case==\"Graph\",eigenvectorindex==1) %&gt;% select(V,case,eigenvectorindex,textsize,fhat)\ndat3_Graph &lt;- left_join(dat,dat3_Graph,by=\"V\")\n\nfor(j in 2:23){\n        decomp_filtered_dat_&lt;- decomp_dat %&gt;% filter(case==\"Graph\",eigenvectorindex==j) %&gt;% select(V,case,eigenvectorindex,textsize,fhat)\n        decomp_filtered_dat_&lt;- left_join(dat,decomp_filtered_dat_,by=\"V\")\n        dat3_Graph&lt;-rbind(dat3_Graph,decomp_filtered_dat_)\n}\n\ndat3_HST &lt;- decomp_dat %&gt;% filter(case==\"HST\",eigenvectorindex==1) %&gt;% select(V,case,eigenvectorindex,textsize,fhat)\ndat3_HST &lt;- left_join(dat,dat3_HST,by=\"V\")\n\nfor(j in 2:23){\n        decomp_filtered_dat_&lt;- decomp_dat %&gt;% filter(case==\"HST\",eigenvectorindex==j) %&gt;% select(V,case,eigenvectorindex,textsize,fhat)\n        decomp_filtered_dat_&lt;- left_join(dat,decomp_filtered_dat_,by=\"V\")\n        dat3_HST&lt;-rbind(dat3_HST,decomp_filtered_dat_)\n}\ndat3&lt;-rbind(dat3_Euclid,dat3_Graph,dat3_HST)\n\nR[write to console]: Error in filter(., case == \"Euclid\", eigenvectorindex == 1) : \n  object 'decomp_dat' not found\n\nR[write to console]: In addition: \nR[write to console]: There were 50 or more warnings (use warnings() to see the first 50)\nR[write to console]: \n\n\n\n\nError in filter(., case == \"Euclid\", eigenvectorindex == 1) : \n  object 'decomp_dat' not found\n\n\nRInterpreterError: Failed to parse and evaluate line 'dat3_Euclid &lt;- decomp_dat %&gt;% filter(case==\"Euclid\",eigenvectorindex==1) %&gt;% select(V,case,eigenvectorindex,textsize,fhat)\\ndat3_Euclid &lt;- left_join(dat,dat3_Euclid,by=\"V\")\\n\\nfor(j in 2:23){\\n        decomp_filtered_dat_&lt;- decomp_dat %&gt;% filter(case==\"Euclid\",eigenvectorindex==j) %&gt;% select(V,case,eigenvectorindex,textsize,fhat)\\n        decomp_filtered_dat_&lt;- left_join(dat,decomp_filtered_dat_,by=\"V\")\\n        dat3_Euclid&lt;-rbind(dat3_Euclid,decomp_filtered_dat_)\\n}\\n\\ndat3_Graph &lt;- decomp_dat %&gt;% filter(case==\"Graph\",eigenvectorindex==1) %&gt;% select(V,case,eigenvectorindex,textsize,fhat)\\ndat3_Graph &lt;- left_join(dat,dat3_Graph,by=\"V\")\\n\\nfor(j in 2:23){\\n        decomp_filtered_dat_&lt;- decomp_dat %&gt;% filter(case==\"Graph\",eigenvectorindex==j) %&gt;% select(V,case,eigenvectorindex,textsize,fhat)\\n        decomp_filtered_dat_&lt;- left_join(dat,decomp_filtered_dat_,by=\"V\")\\n        dat3_Graph&lt;-rbind(dat3_Graph,decomp_filtered_dat_)\\n}\\n\\ndat3_HST &lt;- decomp_dat %&gt;% filter(case==\"HST\",eigenvectorindex==1) %&gt;% select(V,case,eigenvectorindex,textsize,fhat)\\ndat3_HST &lt;- left_join(dat,dat3_HST,by=\"V\")\\n\\nfor(j in 2:23){\\n        decomp_filtered_dat_&lt;- decomp_dat %&gt;% filter(case==\"HST\",eigenvectorindex==j) %&gt;% select(V,case,eigenvectorindex,textsize,fhat)\\n        decomp_filtered_dat_&lt;- left_join(dat,decomp_filtered_dat_,by=\"V\")\\n        dat3_HST&lt;-rbind(dat3_HST,decomp_filtered_dat_)\\n}\\ndat3&lt;-rbind(dat3_Euclid,dat3_Graph,dat3_HST)\\n'.\nR error message: 'Error in filter(., case == \"Euclid\", eigenvectorindex == 1) : \\n  object \\'decomp_dat\\' not found'\n\n\n\n%%R -r 300 -w 2000 -h 3000\nhull_cyl &lt;- dat3 %&gt;%\n            group_by(case,eigenvectorindex) %&gt;% \n            filter(textsize&gt;0) %&gt;% \n            slice(chull(f, divlink))\np4&lt;-ggplot(dat3%&gt;% filter(eigenvectorindex&lt;8))+geom_point(aes(x=f,y=divlink,col=textsize&gt;0,size=fhat*(fhat&gt;0)),alpha=0.8)+\n        geom_shape(data=hull_cyl%&gt;% filter(eigenvectorindex&lt;8) ,aes(x=f,y=divlink),alpha=0.05,col=\"gray30\",radius=0.05,expand=0.05)+\n        facet_grid(eigenvectorindex~case)+\n        scale_size_continuous(range=c(2,2.5))+\n        scale_color_manual(values=c(\"gray80\", \"gray20\"))+\n        ylim(0,8)+xlim(0,3000)+\n        guides(alpha=F)+\n        guides(col=F)+\n        guides(size=F)+\n        ylab(\"\")+xlab(\"\")+\n        geom_hline(aes(yintercept=2),col=\"gray30\",lty=2,lwd=0.2)+\n        geom_vline(aes(xintercept=1000),col=\"gray30\",lty=2,lwd=0.2)+\n        theme_light()+\n        theme(strip.text.x = element_text(size = 10, color = \"black\", face = \"bold.italic\"))+\n        theme(strip.text.y = element_text(size = 10, color = \"black\", face = \"bold.italic\"))+\n        theme(plot.title=element_text(face=\"bold.italic\",size=rel(1.5)))\nshow(p4)\n#ggsave(plot=p4,\"./fig/p4.pdf\",width=7,height=7)\n\n\n%%R -r 300 -w 2000 -h 3000\nhull_cyl &lt;- dat3 %&gt;%\n            group_by(case,eigenvectorindex) %&gt;% \n            filter(textsize&gt;0) %&gt;% \n            slice(chull(f, conlink))\np5&lt;-ggplot(dat3%&gt;% filter(eigenvectorindex&lt;8))+geom_point(aes(x=f,y=conlink,col=textsize&gt;0,size=fhat*(fhat&gt;0)),alpha=0.8)+\n        geom_shape(data=hull_cyl%&gt;% filter(eigenvectorindex&lt;8) ,aes(x=f,y=conlink),alpha=0.05,col=\"gray30\",radius=0.05,expand=0.05)+\n        facet_grid(eigenvectorindex~case)+\n        scale_size_continuous(range=c(2,2.5))+\n        scale_color_manual(values=c(\"gray80\", \"gray20\"))+        \n        ylim(0,10)+xlim(0,3000)+\n        guides(col=F)+\n        guides(alpha=F)+\n        guides(size=F)+       \n        ylab(\"\")+xlab(\"\")+\n        geom_hline(aes(yintercept=3.75),col=\"gray30\",lty=2,lwd=0.2)+\n        geom_vline(aes(xintercept=1000),col=\"gray30\",lty=2,lwd=0.2)+\n        theme_light()+\n        theme(strip.text.x = element_text(size = 10, color = \"black\", face = \"bold.italic\"))+\n        theme(strip.text.y = element_text(size = 10, color = \"black\", face = \"bold.italic\"))+\n        theme(plot.title=element_text(face=\"bold.italic\",size=rel(1.5)))\nshow(p5)\n#ggsave(plot=p5,\"./fig/p5.pdf\",width=7,height=7)        \n\n\n%%R -r 300 -w 2000 -h 1500\np_&lt;-grid.arrange(p4,p5,ncol=2)\n#ggsave(plot=p6,\"./fig/p6.pdf\",width=10,height=12)\n\n\n%%R -r 200 -w 2000 -h 3000\np6&lt;-grid.arrange(p1,p_,nrow=2,heights=c(3,5))\n\n\n%run heavysnow \ngs=GraphSignal(V,hst.snowweight,f)\nspa=SpectralAnalysis(gs)\n\n\nspa.n\n\n\nspa.graphFouriertransform()\nspa.decompose()\n\n\nspa.V\n\n\ndf=pd.DataFrame(spa.components)\ndf\n\n\ndf=df.stack().reset_index().rename(columns={'level_0':'vertex','level_1':'comp',0:'fhat'})\n\n\ndf \n\n\ndf['fill']= df.fhat &gt;0 \n\n\ndf\n\n\nn=23\nfig=ggplot(df)\nfacet=facet_wrap('comp',ncol=1)\naes1=aes(x='vertex',y='fhat',fill='fill')\naes3=aes(x='vertex',y='fhat',label=spa.V)\ngeom1=geom_col(aes1,alpha=0.8)\ngeom2=geom_hline(yintercept = 0,linetype='dashed',color='gray',size=0.3)\n#geom3=geom_text_repel(aes(x=Vindex,y=fhat,label=V)\n\n\nfig+facet+geom1+geom2+xlab(\"\")+ylab(\"\")+theme(figure_size=(3, 3*n))+theme(legend_position=\"none\")"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-미구현코드.html",
    "href": "연구/교수님이랑/EBT/2024-01-16-미구현코드.html",
    "title": "(연구&교수님) EBT – 미구현코드",
    "section": "",
    "text": "#########################################################################################################################################\n# ELASTIC BAND TRANSFORM\n## Sattistics of Elastic-Bands\n#########################################################################################################################################\n\n# FIG 2\nlen=500\ntau&lt;-5\nh&lt;-c(rep(0,len-(tau-1)),1:tau,(tau-1):1,rep(0,len-tau))/tau^2\nomega_hat&lt;-seq(from=-pi,to=pi,len=len*2)\n#pdf(paste(PATH, \"2-2]Homega.pdf\", sep=\"\"), width=7, height=3)\npar(mar=c(2.5,2.5,2.5,2.5))\npar(mfrow=c(1,3))\nplot(omega_hat,c(abs(fft(h))[501:1000],abs(fft(h))[1:500]),type='l',xlab=\"\",ylab=\"\",main=\"(a)\")\ntau&lt;-10\nh&lt;-c(rep(0,len-(tau-1)),1:tau,(tau-1):1,rep(0,len-tau))/tau^2\nomega_hat&lt;-seq(from=-pi,to=pi,len=len*2)\nplot(omega_hat,c(abs(fft(h))[501:1000],abs(fft(h))[1:500]),type='l',xlab=\"\",ylab=\"\",main=\"(b)\")\ntau&lt;-30\nh&lt;-c(rep(0,len-(tau-1)),1:tau,(tau-1):1,rep(0,len-tau))/tau^2\nomega_hat&lt;-seq(from=-pi,to=pi,len=len*2)\nplot(omega_hat,c(abs(fft(h))[501:1000],abs(fft(h))[1:500]),type='l',xlab=\"\",ylab=\"\",main=\"(c)\")\n#dev.off()\n\n#########################################################################################################################################\n# ELASTIC BAND TRANSFORM\n## Visualization\n#########################################################################################################################################\n# FIG 1\nset.seed(100)\nv1&lt;-rnorm(150,mean=0,sd=0.5) # ~150\nv2&lt;-rnorm(150,mean=0,sd=0.5) # ~300\nv3&lt;-rnorm(150,mean=1.5,sd=3) # ~450\nv4&lt;-rnorm(150,mean=1.5,sd=3) # ~600\nv5&lt;-rnorm(150,mean=1.5,sd=2) # ~750\nv6&lt;-rnorm(150,mean=1.5,sd=1) # ~900\nv7&lt;-rnorm(150,mean=3.0,sd=1) # ~1050\nv8&lt;-rnorm(150,mean=4.5,sd=1) # ~1200\nv9&lt;-rnorm(150,mean=6.0,sd=1) # ~1350\nv10&lt;-rnorm(150,mean=7.5,sd=1) # ~1500\nf&lt;-c(v1,v2,v3,v4,v5,v6,v7,v8,v9,v10) \nmaxtau=200\nlen&lt;-length(f)\nMM1&lt;-Mmap(f,maxtau=maxtau,M=\"mean\",V=\"var\")\nVM1&lt;-Vmap(f,maxtau=maxtau,M=\"mean\",V=\"var\")\ndMM1_t&lt;-diff(MM1)\ndVM1_t&lt;-diff(VM1)\n\nlibrary(fields)\n#pdf(paste(PATH, \"2-3]MmapVmap.pdf\", sep=\"\"), width=7, height=5)\npar(mar=c(2.5,3,3,4))\npar(mfrow=c(3,2))\nplot(f,xlab=\"\",ylab=\"\",main=\"(a)\",type='l')\npar(mar=c(2.5,3,3,1))\nmintau&lt;-10\nmaxtau&lt;-200\nimage.plot(x=1:len,y=mintau:maxtau,z=MM1[1:len,mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(b)\")\nabline(v=c(300,900,1050,1200,1350),lty=2,lwd=1)\npar(mar=c(2.5,2.5,2.5,1))\nmintau&lt;-50\nmaxtau&lt;-100\nimage.plot(x=1:len,y=mintau:maxtau,z=dMM1_t[1:(len-1),mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(c)\")\nabline(v=c(300,900,1050,1200,1350),lty=2,lwd=1)\npar(mar=c(2.5,2.5,2.5,1))\nmintau&lt;-50\nmaxtau&lt;-200\nimage.plot(x=1:len,y=mintau:maxtau,z=VM1[1:len,mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(d)\")\nabline(v=c(300,600,750),lty=2,lwd=1)\nmintau&lt;-50\nmaxtau&lt;-200\nimage.plot(x=1:len,y=mintau:maxtau,z=abs(dVM1_t[1:(len-1),mintau:maxtau]),xlab=\"\",ylab=\"\",main=\"(e)\")\nabline(v=c(300,600,750),lty=2,lwd=1)\npar(mar=c(2.5,2.5,2.5,1))\nmintau&lt;-100\nmaxtau&lt;-200\nimage.plot(x=1:len,y=mintau:maxtau,z=dMM1_t[1:(len-1),mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(f)\")\nabline(v=c(300,900,1050,1200,1350),lty=2,lwd=1)\n#dev.off() \n\n# FIG 2\nlibrary(wavelets)\ndata(ecg)\nf&lt;-as.vector(ecg)\nt&lt;-seq(0,11.37,length=2048)\nmaxtau=180\nlen&lt;-length(f)\nMM2&lt;-Mmap(f,maxtau=maxtau,M=\"mean\",V=\"var\")\nVM2&lt;-Vmap(f,maxtau=maxtau,M=\"mean\",V=\"var\")\ndMM2_t&lt;-diff(MM1)\ndMM2_tau&lt;-t(diff(t(MM2)))\ndVM2_t&lt;-diff(VM2)\ndVM2_tau&lt;-t(diff(t(VM2)))\n# \n# #pdf(paste(PATH, \"2-3]MmapVmapECG.pdf\", sep=\"\"), width=7, height=5)\n# par(mfrow=c(3,2))\n# par(mar=c(2.5,2.5,2.5,4))\n# plot(t,f,xlab=\"\",ylab=\"\",main=\"(a)\",type='l')\n# \n# par(mar=c(2.5,2.5,2.5,1))\n# mintau&lt;-5\n# maxtau&lt;-180\n# image.plot(x=t,y=mintau:maxtau,z=MM2[1:len,mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(b)\",legend.mar=10)\n# mintau&lt;-50\n# maxtau&lt;-175\n# par(mar=c(2.5,2.5,2.5,1))\n# image.plot(x=t,y=mintau:maxtau,z=VM2[1:len,mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(c)\",legend.mar=5)\n# par(mar=c(2.5,2.5,2.5,1))\n# mintau&lt;-50\n# maxtau&lt;-100\n# image.plot(x=t,y=mintau:maxtau,z=dVM2_t[1:(len-1),mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(d)\",legend.mar=10)\n# par(mar=c(2.5,2.5,2.5,1))\n# mintau&lt;-50\n# maxtau&lt;-175\n# image.plot(x=t,y=mintau:maxtau,z=dVM2_tau[1:len,mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(e)\",legend.mar=5)\n# library(phonTools)\n# library(fields)\n# temp&lt;-spectrogram(f,fs=180,windowlength = 5*22050/180,show=F)$spectrogram\n# par(mar=c(2.5,2.5,2.5,1))\n# image.plot(x=seq(0,11.37,length=941),y=seq(0,90,length=617),z=temp[1:941,1:617],xlab=\"\",ylab=\"\",main=\"(f)\",legend.mar=10)\n# #dev.off() \n# \n\n\npdf(paste(\"MmapVmapECG.png\", sep=\"\"), width=7, height=5*2/3)\npar(mfrow=c(2,2))\npar(mar=c(2.5,2.5,2.5,4))\nplot(t,f,xlab=\"\",ylab=\"\",main=\"(a)\",type='l')\n\npar(mar=c(2.5,2.5,2.5,1))\nmintau&lt;-5\nmaxtau&lt;-180\nimage.plot(x=t,y=mintau:maxtau,z=MM2[1:len,mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(b)\",legend.mar=10)\nmintau&lt;-50\nmaxtau&lt;-175\npar(mar=c(2.5,2.5,2.5,1))\nimage.plot(x=t,y=mintau:maxtau,z=VM2[1:len,mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(c)\",legend.mar=5)\npar(mar=c(2.5,2.5,2.5,1))\n# mintau&lt;-50\n# maxtau&lt;-100\n# image.plot(x=t,y=mintau:maxtau,z=dVM2_t[1:(len-1),mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(d)\",legend.mar=10)\n# par(mar=c(2.5,2.5,2.5,1))\nmintau&lt;-50\nmaxtau&lt;-175\nimage.plot(x=t,y=mintau:maxtau,z=dVM2_tau[1:len,mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(d)\",legend.mar=10)\nlibrary(phonTools)\nlibrary(fields)\n# temp&lt;-spectrogram(f,fs=180,windowlength = 5*22050/180,show=F)$spectrogram\n# par(mar=c(2.5,2.5,2.5,1))\n# image.plot(x=seq(0,11.37,length=941),y=seq(0,90,length=617),z=temp[1:941,1:617],xlab=\"\",ylab=\"\",main=\"(f)\",legend.mar=10)\ndev.off() \n\n# FIG 2-1\nlibrary(wavelets)\ndata(ecg)\nf&lt;-as.vector(ecg)\nt&lt;-seq(0,11.37,length=2048)\nmaxtau=180\nlen&lt;-length(f)\nMM2&lt;-Mmap(f,maxtau=maxtau,M=\"mean\",V=\"volume\")\nVM2&lt;-Vmap(f,maxtau=maxtau,M=\"mean\",V=\"volume\")\ndMM2_t&lt;-diff(MM1)\ndMM2_tau&lt;-t(diff(t(MM2)))\ndVM2_t&lt;-diff(VM2)\ndVM2_tau&lt;-t(diff(t(VM2)))\n\n#pdf(paste(PATH, \"2-3]MmapVmapECG_1.pdf\", sep=\"\"), width=7, height=2.3)\npar(mfrow=c(1,2))\npar(mar=c(2.5,2.5,2.5,1))\nimage.plot(x=t,y=mintau:maxtau,z=VM2[1:len,mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(a)\",legend.mar=5)\npar(mar=c(2.5,2.5,2.5,1))\nmintau&lt;-50\nmaxtau&lt;-100\nimage.plot(x=t,y=mintau:maxtau,z=dVM2_t[1:(len-1),mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(b)\",legend.mar=10)\npar(mar=c(2.5,2.5,2.5,1))\nmintau&lt;-50\nmaxtau&lt;-175\n#dev.off() \n\n#########################################################################################################################################\n# ELASTIC BAND TRANSFORM\n## Useful Applications of Elastic-Band Transform\n### Testing Chage of Cycle in Cyclostationary Stochastic Process\n#########################################################################################################################################\n# FIG 6\nset.seed(2)\n# fs&lt;-90\n# Ts&lt;-1/90\n# t=seq(-10,10,length=20*fs)\n# vartau&lt;-seq(from=90,to=95,by=2)\n# truetau&lt;-90;\n# len&lt;-length(t)\n# lenhalf&lt;-round(len*0.5)\n# \n# u1&lt;-c(cos(fs/truetau*2*pi*t[1:lenhalf]),rep(0,len-lenhalf))\n# u2&lt;-c(rep(0,lenhalf),cos(fs/vartau[freqindex]*2*pi*t[(lenhalf+1):len]))\n# u&lt;-u1+u2\n# \n# v1&lt;-swave(truetau/2,lenhalf)\n# v2&lt;-swave(vartau[freqindex]/2,len-lenhalf)\n# v&lt;-c(v1,v2)\n# \n# snr&lt;-2\n# noise1&lt;-rnorm(len,mean=0,sd=sd((u)/snr))  \n# noise2&lt;-rnorm(len,mean=0,sd=sd((v)/snr))  \n# f=u+noise1\n# g=v+noise2\n\necgmat&lt;-read.csv(\"C:/Users/gbchoi/Desktop/data/ecgdata.csv\",head=T)\nnoise&lt;-rnorm(1800,mean=0,sd=sd(ecgmat[,1])/2)\na.ecg1&lt;-c(ecgmat[,1],ecgmat[,1])+noise\na.ecg2&lt;-c(ecgmat[,1],ecgmat[,2])+noise\na.ecg3&lt;-c(ecgmat[,1],ecgmat[,3])+noise\na.ecg4&lt;-c(ecgmat[,1],ecgmat[,4])+noise\na.ecg5&lt;-c(ecgmat[,1],ecgmat[,5])+noise\nt=seq(0,20,length=20*90)\n\n# VMf&lt;-Vmap(f,maxtau=150,M=\"mean\",V=\"var\")\n# VMg&lt;-Vmap(g,maxtau=150,M=\"mean\",V=\"var\")\n\nVMecg1&lt;-Vmap(a.ecg1,maxtau=150,M=\"mean\",V=\"volume\")\nVMecg5&lt;-Vmap(a.ecg5,maxtau=150,M=\"mean\",V=\"volume\")\n\npdf(paste(PATH, \"2-3]periodchange.pdf\", sep=\"\"), width=10, height=6)\npar(mfrow=c(2,2))\npar(mar=c(2.5, 2.5, 2.5, 3))\nplot(t,a.ecg1,xlab=\"\",ylab=\"\",main=\"(a)\",type='l')\nplot(t,a.ecg5,xlab=\"\",ylab=\"\",main=\"(b)\",type='l')\n\nlibrary(fields)\n# mintau&lt;-20\n# maxtau&lt;-150\n# par(mar=c(2.5, 2.5, 2.5, 1))\n# image.plot(x=t,y=mintau:maxtau,z=VMf[1:len,mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(c)\",legend.mar=5)\n# par(mar=c(2.5, 2.5, 2.5, 1))\n# mintau&lt;-20\n# maxtau&lt;-150\n# image.plot(x=t,y=mintau:maxtau,z=VMg[1:len,mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(d)\",legend.mar=5)\npar(mar=c(2.5, 2.5, 2.5, 1))\nmintau&lt;-20\nmaxtau&lt;-120\nimage.plot(x=t,y=mintau:maxtau,z=VMecg1[1:length(a.ecg1),mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(c)\",legend.mar=5)\nimage.plot(x=t,y=mintau:maxtau,z=VMecg5[1:length(a.ecg5),mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(d)\",legend.mar=5)\ndev.off() \n# \n# library(phonTools)\n# temp1&lt;-spectrogram(f,fs=fs,windowlength = 5*22050/fs,show=F)$spectrogram\n# temp2&lt;-spectrogram(g,fs=fs,windowlength = 5*22050/fs,show=F)$spectrogram\n# par(mar=c(2.5,2.5,2.5,1))\n# image.plot(x=seq(-10,10,length=958),y=seq(0,fs/2,length=617),z=temp1[1:958,1:617],xlab=\"\",ylab=\"\",main=\"(f)\",legend.mar=10)\n# image.plot(x=seq(-10,,length=958),y=seq(0,fs/2,length=617),z=temp2[1:958,1:617],xlab=\"\",ylab=\"\",main=\"(f)\",legend.mar=10)\nset.seed(7)\nITER&lt;-100\npval&lt;-rep(0,ITER*5); dim(pval)&lt;-c(ITER,5)\na.ecg&lt;-list()\nfor(iter in 1:ITER)\n{\n  for(f1index in 1:5)\n    {\n      noise&lt;-rnorm(1800,mean=0,sd=sd(ecgmat[,1])/2)\n      a.ecg[[f1index]]&lt;-c(ecgmat[,1],ecgmat[,f1index])+noise\n      hat_tau&lt;-tauest(a.ecg[[f1index]],taulist=80:120,V=\"volume\")\n      pval[iter,f1index]&lt;-st.test(hat_tau[200:1600])\n    }\n}\nround(1-apply(pval,2,mean),3)\naction&lt;-pval&lt;0.05\nround(apply(action,c(2,3),mean),3)\n\n\n#########################################################################################################################################\n# ELASTIC BAND TRANSFORM\n## Useful Applications of Elastic-Band Transform\n### Change Point Detections\n#########################################################################################################################################\n## FIG 1\npdf(paste(PATH, \"2-4]CPsignal.pdf\", sep=\"\"), width=7, height=4)\npar(mar=c(2.5,2.5,2.5,2.5))\npar(mfrow=c(2,2))\nset.seed(1)\nf1&lt;-c(rnorm(400,0,0.5),\n      rnorm(20,0,0.7),\n      rnorm(20,0,0.9),\n      rnorm(20,0,1.1),\n      rnorm(20,0,1.3),\n      rnorm(20,0,1.5),\n      rnorm(20,0,1.7),\n      rnorm(20,0,1.9),\n      rnorm(20,0,2.1),\n      rnorm(20,0,2.3),\n      rnorm(20,0,2.5),\n      rnorm(800,0,3.5))\nplot(f1[101:(1200-100)],type='l',main=\"(a)\")\nset.seed(1)\nf2&lt;-c(rnorm(400,0,0.5),\n      rnorm(20,0,0.7),\n      rnorm(20,0,0.9),\n      rnorm(20,0,1.1),\n      rnorm(20,0,1.3),\n      rnorm(20,0,1.5),\n      rnorm(20,0,1.7),\n      rnorm(20,0,1.9),\n      rnorm(20,0,2.1),\n      rnorm(20,0,2.3),\n      rnorm(20,0,2.5),\n      rnorm(800,0,3.5*2))\nplot(f2[101:(1200-100)],type='l',main=\"(b)\")\nset.seed(1)\nf3&lt;-c(rnorm(400,0,0.5),\n      rnorm(20,0,0.7),\n      rnorm(20,0,0.9),\n      rnorm(20,0,1.1),\n      rnorm(20,0,1.3),\n      rnorm(20,0,1.5),\n      rnorm(20,0,1.7),\n      rnorm(20,0,1.9),\n      rnorm(20,0,2.1),\n      rnorm(20,0,2.3),\n      rnorm(20,0,2.5),\n      rnorm(800,0,3.5*3))\nplot(f3[101:(1200-100)],type='l',main=\"(c)\")\nset.seed(1)\nf4&lt;-c(rnorm(400,0,0.5),\n      rnorm(20,0,0.7),\n      rnorm(20,0,0.9),\n      rnorm(20,0,1.1),\n      rnorm(20,0,1.3),\n      rnorm(20,0,1.5),\n      rnorm(20,0,1.7),\n      rnorm(20,0,1.9),\n      rnorm(20,0,2.1),\n      rnorm(20,0,2.3),\n      rnorm(20,0,2.5),\n      rnorm(800,0,3.5*4))\nplot(f4[101:(1200-100)],type='l',main=\"(d)\")\ndev.off() \n\n## TABLE 1\nJ=4; Tau=8; ITER=1;\ncp&lt;-rep(0,ITER*Tau*J); dim(cp)&lt;-c(ITER,Tau,J)\nset.seed(1000); \n# sim.result3&lt;-generate.gaussian(Tx=1000,nsim=1000);\nfor(iter in 1:ITER)\n{\n  for(j in 1:J)\n  {\n    f&lt;-c(rnorm(400,0,1.5),\n          rnorm(20,0,1.6),\n          rnorm(20,0,1.7),\n          rnorm(20,0,1.8),\n          rnorm(20,0,1.9),\n          rnorm(20,0,2.0),\n          rnorm(20,0,2.1),\n          rnorm(20,0,2.2),\n          rnorm(20,0,2.3),\n          rnorm(20,0,2.4),\n          rnorm(20,0,2.5),\n          rnorm(800,0,3.5*j))\n    taulist&lt;-c(5,10,15,20,25,30,35,40) \n    for(tau in 1:Tau)\n    {\n      ebtres&lt;-ebt(f,tau=taulist[tau])\n      fV&lt;-ebtres$V[101:1100]\n      cp[iter,tau,j]&lt;-cp.find(x=fV,sim.result=sim.result3)\n      par(mfrow=c(2,1))\n      plot(f[101:1100],type='l'); abline(v=cp[iter,tau,j],col=2); plot(f[101:1100],type='l',main=cp[iter,tau,j]); abline(v=cp[iter,tau,j],col=2);\n      par(mfrow=c(1,1))\n    }\n  }\n}\n#cp\nt(apply(cp,c(2,3),median))\n\n#########################################################################################################################################\n# Extracting Periodic signals\n## AM-demodulation via Elastic-Band Transform\n#########################################################################################################################################\n# FIG 1\nfs=1000\nt=-2000:2000/fs\nv1=0.4*sin(2*pi*t)+1\nv2=2*cos(20*pi*t)\nv3=2*cos(20*pi*t)-2\nf1=v1*v2;\nf2=v1*v3;\nAMebt1&lt;-ebt(f1,t,tau=100,V=\"volume\")\nAMebt2&lt;-ebt(f2,t,tau=100,V=\"volume\")\n\npdf(paste(PATH, \"3-1]AM.pdf\", sep=\"\"), width=10, height=5)\npar(mar=c(2.5,2.5,2.5,2.5))\npar(mfrow=c(1,2))\nvis(AMebt1,M=F,V=F,xlim=c(t[1500],t[2500]),band=1:100,ylim=c(-3,3),obs=\"lines\",bandlwd=0.5,main=\"(a)\")\nlines(t,v1,col=2,lwd=2)\nlines(t,AMebt1$U,col=4,lty=2,lwd=2)\nlines(t,AMebt1$U/2,col=4,lty=2,lwd=2)\nvis(AMebt2,M=F,V=F,xlim=c(t[1500],t[2500]),band=1:100,ylim=c(-8,2),obs=\"lines\",bandlwd=0.5,main=\"(b)\")\nlines(t,v1,col=2,lwd=2)\nlines(t,AMebt2$L,col=4,lty=2,lwd=2)\nlines(t,AMebt2$L/(-4),col=4,lty=2,lwd=2)\ndev.off() \n\n#########################################################################################################################################\n# Extracting Periodic signals\n## Decomposition\n### Noise Free Setting\n#########################################################################################################################################\n# FIG 1 \nt=-2000:2000/1000\nv1=cos(14*pi*t) #tau=142.8571\nv2=cos(80*pi*t) #tau=25\nf=v1+v2\nylim1&lt;-c(-2.5,2.5)\nebt1&lt;-ebt(f,t,tau=25,V=\"volume\")\nebt2&lt;-ebt(f-ebt1$M,t,tau=25,V=\"volume\")\n\npdf(paste(PATH, \"3-2]SignalExtraction_fig1.pdf\", sep=\"\"), width=7.5, height=4.5)\npar(mar=c(2.5,2.5,2.5,2.5))\npar(mfrow=c(3,2))\nplot(t,v1,xlim=c(-0.5,0.5),ylim=ylim1, type='l',col=1, xlab=\"\",ylab=\"\",main=\"(a)\")\nplot(t,v2,xlim=c(-0.5,0.5),ylim=ylim1, type='l',col=1, xlab=\"\",ylab=\"\",main=\"(b)\")\nplot(t,v1+v2,xlim=c(-0.5,0.5),ylim=ylim1, type='l',col=1, xlab=\"\",ylab=\"\",main=\"(c)\")\nplot(t,v1+v2,xlim=c(-0.5,0.5),ylim=ylim1, type='l', xlab=\"\",ylab=\"\",lwd=2,col=\"gray60\",main=\"(d)\")\nlines(t,ebt1$M,col=2)\nlines(t,ebt1$M+ebt1$V/2,col=3)\nlines(t,ebt1$M-ebt1$V/2,col=3)\nplot(t,f-ebt1$M,xlim=c(-0.5,0.5),ylim=ylim1 ,type='l',col=1 ,xlab=\"\",ylab=\"\",main=\"(e)\")\nplot(t,f-ebt1$M-ebt2$M,xlim=c(-0.5,0.5),ylim=ylim1 ,type='l',col=1 ,xlab=\"\",ylab=\"\",main=\"(f)\")\ndev.off() \n\n# FIG 2\nt=-2000:2000/1000\nv1=swave(20,4001) #tau=40\nv2=cos(7*pi*t) #tau=100\nf=v1+v2\nylim1&lt;-c(-2.5,2.5)\nebt1&lt;-ebt(f,t,tau=40,V=\"volume\")\nebt2&lt;-ebt(f-ebt1$M,t,tau=40,V=\"volume\")\n\npdf(paste(PATH, \"3-2]SignalExtraction_fig2.pdf\", sep=\"\"), width=7.5, height=4.5)\npar(mar=c(2.5,2.5,2.5,2.5))\npar(mfrow=c(3,2))\nplot(t,v1,xlim=c(-0.5,0.5),ylim=ylim1, type='l',col=1, xlab=\"\",ylab=\"\",lwd=1,main=\"(a)\")\nplot(t,v2,xlim=c(-0.5,0.5),ylim=ylim1, type='l',col=1, xlab=\"\",ylab=\"\",lwd=1,main=\"(b)\")\nplot(t,v1+v2,xlim=c(-0.5,0.5),ylim=ylim1, type='l',col=1, xlab=\"\",ylab=\"\",lwd=1,main=\"(c)\")\nplot(t,v1+v2,xlim=c(-0.5,0.5),ylim=ylim1, type='l', xlab=\"\",ylab=\"\",lwd=1,col=\"gray60\",main=\"(d)\")\nlines(t,ebt1$M,col=2,lwd=2)\nlines(t,ebt1$M+ebt1$V/2,col=3,lwd=1)\nlines(t,ebt1$M-ebt1$V/2,col=3,lwd=1)\nplot(t,f-ebt1$M,xlim=c(-0.5,0.5),ylim=ylim1 ,type='l',col=1 ,xlab=\"\",ylab=\"\",lwd=1,main=\"(e)\")\nplot(t,f-ebt1$M-ebt2$M,xlim=c(-0.5,0.5),ylim=ylim1 ,type='l',col=1 ,xlab=\"\",ylab=\"\",lwd=1,main=\"(f)\")\ndev.off() \n\n# FIG 3 \nt=-2000:2000/1000\nv1=cos(5*pi*t) #tau=100\nv2=cos(50*pi*t) #tau=40\nv3=cos(80*pi*t) #tau=25\nf=v1+v2+v3\nexf&lt;-extract.hfreq(t,f,tau=40,tol=0.00001,iter=0)\nexf2&lt;-extract.hfreq(t,f,tau=40,tol=0.00001,iter=5)\nexf3&lt;-extract.hfreq(t,f,tau=40,tol=0.00001,iter=20)\nexf4&lt;-extract.hfreq(t,f,tau=40,tol=0.00001,iter=150)\n\n\npdf(paste(PATH, \"3-2]SignalExtraction_fig3.pdf\", sep=\"\"), width=7.5, height=4)\npar(mar=c(2.5,2.5,2.5,2.5))\npar(mfrow=c(2,3))\nplot(t,f,xlim=c(-0.5,0.5),ylim=c(-3.5,3.5),type='l',col=1, xlab=\"\",ylab=\"\",main=\"(a)\",lwd=0.7)\nplot(t,v2,xlim=c(-0.5,0.5),ylim=c(-3.5,3.5), type='l',col=1, xlab=\"\",ylab=\"\",main=\"(b)\",lwd=0.7)\nplot(t,exf,xlim=c(-0.5,0.5),ylim=c(-3.5,3.5) ,type='l',col=1 ,xlab=\"\",ylab=\"\",main=\"(c)\",lwd=0.7)\nplot(t,exf2,xlim=c(-0.5,0.5),ylim=c(-3.5,3.5) ,type='l',col=1 ,xlab=\"\",ylab=\"\",main=\"(d)\",lwd=0.7)\nplot(t,exf3,xlim=c(-0.5,0.5),ylim=c(-3.5,3.5) ,type='l',col=1 ,xlab=\"\",ylab=\"\",main=\"(e)\",lwd=0.7)\nplot(t,exf4,xlim=c(-0.5,0.5),ylim=c(-3.5,3.5) ,type='l',col=1,xlab=\"\",ylab=\"\",main=\"(f)\",lwd=0.7)\ndev.off() \n\n# FIG 4 \nt=-2000:2000/1000\nv1=cos(5*pi*t) #tau=100\nv2=cos(50*pi*t) #tau=40\nv3=cos(80*pi*t) #tau=25\nf=v1+v2+v3\nmode1&lt;-extract.hfreq(t,f,tau=25,tol=0.000000001,iter=10)\nmode2&lt;-extract.hfreq(t,f-mode1,tau=40,tol=0.000000001,iter=1)\nmode3&lt;-f-mode1-mode2\n\npdf(paste(PATH, \"3-2]SignalExtraction_fig4.pdf\", sep=\"\"), width=7.5, height=5)\nm &lt;- matrix(c(1,2,2,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11),nrow = 4,ncol = 4,byrow = TRUE)\nlayout(mat = m)\npar(mar=c(2.5,2.5,2.5,2.5))\nplot(1, type=\"n\", axes=F, xlab=\"\", ylab=\"\")\nplot(t,f,xlim=c(-0.5,0.5),ylim=c(-4,4),xlab=\"\",ylab=\"\",type='l',main=\"(a)\")\nplot(1, type=\"n\", axes=F, xlab=\"\", ylab=\"\")\nplot(t,v1,xlim=c(-0.5,0.5),ylim=c(-4,4),type='l',col=1, xlab=\"\",ylab=\"\",main=\"(b)\")\nplot(t,mode3,xlim=c(-0.5,0.5),ylim=c(-4,4) ,type='l',col=1 ,xlab=\"\",ylab=\"\",main=\"(c)\")\nplot(t,v2,xlim=c(-0.5,0.5),ylim=c(-4,4), type='l',col=1, xlab=\"\",ylab=\"\",main=\"(d)\")\nplot(t,mode2,xlim=c(-0.5,0.5),ylim=c(-4,4) ,type='l',col=1 ,xlab=\"\",ylab=\"\",main=\"(e)\")\nplot(t,v3,xlim=c(-0.5,0.5),ylim=c(-4,4) ,type='l',col=1 ,xlab=\"\",ylab=\"\",main=\"(f)\")\nplot(t,mode1,xlim=c(-0.5,0.5),ylim=c(-4,4) ,type='l',xlab=\"\",ylab=\"\",main=\"(g)\")\ndev.off() \n\n# FIG 5 \nt=-2000:2000/1000\nv1=cos(2*pi*t) \nv2=c(rep(0,1500),0.5*cos(40*pi*t[1500:1600]),rep(0,2400)) # tau=50\nv3=c(rep(0,2000),0.5*cos(40*pi*t[2000:2200]),rep(0,1800)) # tau=50\nv4=c(rep(0,2500),0.5*cos(40*pi*t[2500:2700]),rep(0,1300)) \nf=v1+v2+v3+v4;\nplot(t,f,xlim=c(-1,1),type='l')\nplot(t,v2+v3+v4,xlim=c(-1,1),type='l')\next3&lt;-extract.hfreq(t,f,tau=200)\n\nlibrary(EMD)\ntry &lt;- emd(f, t, boundary=\"wave\")\n# \n# ### Ploting the IMF's\n# par(mfrow=c(try$nimf+1, 1), mar=c(2,1,2,1))\n# rangeimf &lt;- range(try$imf)\n# for(i in 1:try$nimf) {\n#   plot(t, try$imf[,i], type=\"l\", xlab=\"\", ylab=\"\", ylim=rangeimf,\n#        main=paste(i, \"-th IMF\", sep=\"\")); abline(h=0)\n# }\n# plot(t, try$residue, xlab=\"\", ylab=\"\", main=\"residue\", type=\"l\", axes=FALSE); box()\n\npdf(paste(PATH, \"3-2]SignalExtraction_fig5.pdf\", sep=\"\"), width=7.5, height=7)\nm &lt;- matrix(c(1,2,2,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11),nrow = 5,ncol = 4,byrow = TRUE)\nlayout(mat = m)\npar(mar=c(2.5,2.5,2.5,2.5))\nplot(1, type=\"n\", axes=F, xlab=\"\", ylab=\"\")\nplot(t,f,xlim=c(-1,1),ylim=c(-1.8,1.5),xlab=\"\",ylab=\"\",type='l',main=\"(a)\")\nplot(1, type=\"n\", axes=F, xlab=\"\", ylab=\"\")\nplot(t,ext3,xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',xlab=\"\",ylab=\"\",lty=1,main=\"(b)\")\nplot(t,try$imf[,1],xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',main=\"(c)\")\nplot(t,f-ext3,xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',xlab=\"\",ylab=\"\",lty=1,main=\"(d)\")\nplot(t,try$imf[,2],xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',main=\"(e)\")\nplot(1, type=\"n\", axes=F, xlab=\"\", ylab=\"\")\nplot(t,try$imf[,3],xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',main=\"(f)\")\nplot(1, type=\"n\", axes=F, xlab=\"\", ylab=\"\")\nplot(t,try$residue,xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',main=\"(g)\")\ndev.off()\n\n# FIG 6\nt=-2000:2000/1000\nv1=t*c(cos(14*pi*t[1:2000]),rep(0,2001))\nv2=-t*c(rep(0,2000),cos(80*pi*t[2001:4001]))\nf=v1+v2;\next3&lt;-extract.hfreq(t,f,tau=25)\ntry &lt;- emd(f, t, boundary=\"wave\")\n# ### Ploting the IMF's\n# par(mfrow=c(try$nimf+1, 1), mar=c(2,1,2,1))\n# rangeimf &lt;- range(try$imf)\n# for(i in 1:try$nimf) {\n#   plot(t, try$imf[,i], type=\"l\", xlab=\"\", ylab=\"\", ylim=rangeimf,\n#        main=paste(i, \"-th IMF\", sep=\"\")); abline(h=0)\n# }\n# plot(t, try$residue, xlab=\"\", ylab=\"\", main=\"residue\", type=\"l\", axes=FALSE); box()\n\n\npdf(paste(PATH, \"3-2]SignalExtraction_fig6.pdf\", sep=\"\"), width=7.5, height=8)\nm &lt;- matrix(c(1,2,2,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11,12,12,13,13),nrow = 6,ncol = 4,byrow = TRUE)\nlayout(mat = m)\npar(mar=c(2.5,2.5,2.5,2.5))\nplot(1, type=\"n\", axes=F, xlab=\"\", ylab=\"\")\nplot(t,f,xlim=c(-1,1),ylim=c(-1.8,1.5),xlab=\"\",ylab=\"\",type='l',main=\"(a)\")\nplot(1, type=\"n\", axes=F, xlab=\"\", ylab=\"\")\nplot(t,ext3,xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',xlab=\"\",ylab=\"\",lty=1,main=\"(b)\")\nplot(t,try$imf[,1],xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',main=\"(c)\")\nplot(t,f-ext3,xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',xlab=\"\",ylab=\"\",lty=1,main=\"(d)\")\nplot(t,try$imf[,2],xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',main=\"(e)\")\nplot(1, type=\"n\", axes=F, xlab=\"\", ylab=\"\")\nplot(t,try$imf[,3],xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',main=\"(f)\")\nplot(1, type=\"n\", axes=F, xlab=\"\", ylab=\"\")\nplot(t,try$imf[,4],xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',main=\"(g)\")\nplot(1, type=\"n\", axes=F, xlab=\"\", ylab=\"\")\nplot(t,try$residue,xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',main=\"(h)\")\ndev.off() \n\n\n#########################################################################################################################################\n# Designing Filter by Elastic Band Transform \n## Extracting Signal with Noise\n#########################################################################################################################################\n# FIG 1 \npdf(paste(PATH, \"4-2]DenoisingPeriodicSignal_fig1.pdf\", sep=\"\"), width=7, height=7)\npar(mar=c(2.3,2.3,2.3,2.3))\npar(mfrow=c(4,1))\nt=-2000:2000/1000\nv1=cos(200*pi*t) #tau=10\nv2=swave(5,4001) #tau=10\nsnr&lt;-3\nnoise1&lt;-rnorm(4001,mean=0,sd=sd((v1)/snr))  \nnoise2&lt;-rnorm(4001,mean=0,sd=sd((v2)/snr))  \nf1=v1+noise\nf2=v2+noise\nplot(t,f1,xlim=c(-0.1,0.1),type='l',ylim=c(-2.5,2.5),main=\"(a)\")\nplot(t,f1,xlim=c(-0.1,0.1),ylim=c(-2.5,2.5),col=\"gray60\",xlab=\"\",ylab=\"\",cex=0.9,main=\"(b)\")\nlines(t,v1hat,col=2)\nlines(t,v1,col=1, lty=2)\nplot(t,f2,xlim=c(-0.1,0.1),type='l',ylim=c(-2.5,2.5),main=\"(c)\")\n# v1hat&lt;-extract.hfreq(t,f1,tau=10,tol=0.00000000000000005,iter=1000)\n# v2hat&lt;-extract.hfreq(t,f2,tau=10,tol=0.00000000000000005,iter=1000)\nplot(t,f2,xlim=c(-0.1,0.1),ylim=c(-2.5,2.5),col=\"gray60\",xlab=\"\",ylab=\"\",cex=0.9,main=\"(d)\")\nlines(t,v2hat,col=2)\nlines(t,v2,col=1, lty=2)\ndev.off() \n\n\n#########################################################################################################################################\n# Denosing technique with elastic band transform\n## Nadaraya-Watson Kernel Estimator\n#########################################################################################################################################\n# FIG 1 \nt=-2000:2000/1000\nf1&lt;-25\nv1=cos(f1*pi*t) #tau=40\nsnr&lt;-3\nset.seed(1)\nnoise&lt;-rnorm(4001,mean=0,sd=sd(v1)/snr)\nf=v1+noise\nlen=length(f)\nomega_hat&lt;-seq(from=0,to=pi,len=ceiling(len/2))\nfft_f&lt;-c(1-(1-abs(fft(f))[((len+1)/2):len]),1-(1-abs(fft(f))[1:((len+1)/2-1)]))/len\nlwd=1.5\ncol=\"gray40\"\n\npdf(paste(PATH, \"4-1]NadarayaWatsonKernelEstimator_fig1.pdf\", sep=\"\"), width=7, height=5)\nxlim=c(-0.05,0.05)\npar(mar=c(2.5,2.5,2.5,2.5))\npar(mfrow=c(4,2))\nplot(t,f,xlim=xlim,ylim=c(-1.5,1.5),col=col,xlab=\"\",ylab=\"\",cex=0.9)\nlines(t,v1,lty=2)\nlines(t,ebt(f,tau=5)$M,col=2)\nget.h(f,tau=5,plot=T,log=T)\nlines(omega_hat,fft_f[ceiling(len/2):1],col=col,lwd=lwd)\n\nplot(t,f,xlim=xlim,ylim=c(-1.5,1.5),col=col,xlab=\"\",ylab=\"\",cex=0.9)\nlines(t,v1,lty=2)\nlines(t,ebt(f,tau=20)$M,col=2)\nget.h(f,tau=20,plot=T,log=T)\nlines(omega_hat,fft_f[ceiling(len/2):1],col=col,lwd=lwd)\n\nplot(t,f,xlim=xlim,ylim=c(-1.5,1.5),col=col,xlab=\"\",ylab=\"\",cex=0.9)\nlines(t,v1,lty=2)\nlines(t,ebt(f,tau=40)$M,col=2)\nget.h(f,tau=40,plot=T,log=T)\nlines(omega_hat,fft_f[ceiling(len/2):1],col=col,lwd=lwd)\n\nplot(t,f,xlim=xlim,ylim=c(-1.5,1.5),col=col,xlab=\"\",ylab=\"\",cex=0.9)\nlines(t,v1,lty=2)\nlines(t,ebt(f,tau=60)$M,col=2)\nget.h(f,tau=60,plot=T,log=T)\nlines(omega_hat,fft_f[ceiling(len/2):1],col=col,lwd=lwd)\ndev.off() \n# \n# # FIG 2\n# t=-2000:2000/1000\n# f1&lt;-25\n# v1=cos(f1*pi*t) #tau=40\n# snr&lt;-3\n# set.seed(1)\n# noise&lt;-rnorm(4001,mean=0,sd=sd(v1)/snr)\n# f=v1+noise\n# \n# \n# pdf(paste(PATH, \"5-1]NadarayaWatsonKernelEstimator_fig2.pdf\", sep=\"\"), width=7, height=4)\n# par(mar=c(2.5,2.5,2.5,2.5))\n# par(mfrow=c(3,2))\n# plot(omega_hat,fft_f,type='l',xlab=\"\",ylab=\"\",main=\"(a)\",col=\"gray60\",ylim=c(0,1)) ## plot \n# get.h(f,tau=5,main=\"(b)\",plot=T)\n# lines(omega_hat,fft_f,col=\"gray60\")\n# get.h(f,tau=20,main=\"(c)\",plot=T)\n# lines(omega_hat,fft_f,col=\"gray60\")\n# get.h(f,tau=40,main=\"(d)\",plot=T)\n# lines(omega_hat,fft_f,col=\"gray60\")\n# get.h(f,tau=60,main=\"(e)\",plot=T)\n# lines(omega_hat,fft_f,col=\"gray60\")\n# get.h(f,tau=80,main=\"(f)\",plot=T)\n# lines(omega_hat,fft_f,col=\"gray60\")\n# dev.off() \n\n#########################################################################################################################################\n# Denosing technique with elastic band transform\n## Design Denoising Filter\n#########################################################################################################################################\n\n# FIG 1\nlen=4001\npdf(paste(PATH, \"4-2]DesignDenoisingFilter_fig1.pdf\", sep=\"\"), width=8, height=3)\npar(mar=c(2.5,2.5,2.5,2.5))\npar(mfrow=c(2,2))\nmain=c(\"(a)\",\"(b)\",\"(c)\",\"(d)\")\ntaulist=c(5,20,40,60)\nfor(k in 1:4)\n{\n  h&lt;-c(rep(0,len-(taulist[k]-1)),1:taulist[k],(taulist[k]-1):1,rep(0,len-taulist[k]))/taulist[k]^2\n  omega_hat&lt;-seq(from=-pi,to=pi,len=len*2)\n  iter=1\n  H&lt;-c(1-(1-abs(fft(h))[(len+1):(2*len)])^iter,1-(1-abs(fft(h))[1:len])^iter)\n  plot(omega_hat[omega_hat&gt;0],H[omega_hat&gt;0],type='l',xlab=\"\",ylab=\"\",main=main[k],log=\"x\")\n  index1&lt;-which((H^2-0.5)^2==min((H^2-0.5)^2))[1]\n  index2&lt;-8000-index1\n  Ideal&lt;-0*H\n  Ideal[index1:index2]&lt;-1\n  lines(omega_hat[omega_hat&gt;0],Ideal[omega_hat&gt;0],col=2,lty=2,lwd=1)\n}\ndev.off()\n\n# FIG 2\nt=-2000:2000/1000\nf1&lt;-25\nv1=cos(f1*pi*t) #tau=40\nsnr&lt;-3\nset.seed(1)\nnoise&lt;-rnorm(4001,mean=0,sd=sd(v1)/snr)\nf=v1+noise\nlen=length(f)\nomega_hat&lt;-seq(from=-pi,to=pi,len=len)\nfft_f&lt;-c(1-(1-abs(fft(f))[((len+1)/2):len]),1-(1-abs(fft(f))[1:((len+1)/2-1)]))/len\ndf1_tau20&lt;-ebt(f,t,tau=20)$M\ndf2_tau20&lt;-f-extract.hfreq(t,f,tau=20,iter=1)\ndf3_tau20&lt;-f-extract.hfreq(t,f,tau=20,iter=2)\ndf4_tau20&lt;-f-extract.hfreq(t,f,tau=20,iter=3)\n\ndf1_tau40&lt;-ebt(f,t,tau=40)$M\ndf2_tau40&lt;-f-extract.hfreq(t,f,tau=40,iter=1)\ndf3_tau40&lt;-f-extract.hfreq(t,f,tau=40,iter=2)\ndf4_tau40&lt;-f-extract.hfreq(t,f,tau=40,iter=3)\n\npdf(paste(PATH, \"4-2]DesignDenoisingFilter_fig2.pdf\", sep=\"\"), width=8, height=6)\npar(mar=c(2.5,2.5,2.5,2.5))\npar(mfrow=c(4,2))\nplot(t,f,xlim=xlim,col=\"gray60\",xlab=\"\",ylab=\"\")\nlines(t,v1,col=1,lty=2)\nlines(t,df1_tau20,col=2,lwd=1)\nlines(t,df1_tau40,col=4,lwd=1)\nget.h(f,tau=20,plot=T,iter=1,log=T,col=2)\nh40&lt;-get.h(f,tau=40,plot=F,iter=1,log=F);\nlines(h40$omega_hat[h40$omega_hat&gt;0],h40$H_iter[h40$omega_hat&gt;0],col=4)\nlines(omega_hat[h40$omega_hat&gt;0],fft_f[h40$omega_hat&gt;0],col=\"gray60\")\n\nplot(t,f,xlim=xlim,col=\"gray60\",xlab=\"\",ylab=\"\")\nlines(t,v1,col=1,lty=2)\nlines(t,df2_tau20,col=2,lwd=1)\nlines(t,df2_tau40,col=4,lwd=1)\nget.h(f,tau=20,plot=T,iter=2,log=T,col=2)\nh40&lt;-get.h(f,tau=40,plot=F,iter=2,log=F);\nlines(h40$omega_hat[h40$omega_hat&gt;0],h40$H_iter[h40$omega_hat&gt;0],col=4)\nlines(omega_hat[h40$omega_hat&gt;0],fft_f[h40$omega_hat&gt;0],col=\"gray60\")\n\nplot(t,f,xlim=xlim,col=\"gray60\",xlab=\"\",ylab=\"\")\nlines(t,v1,col=1,lty=2)\nlines(t,df3_tau20,col=2,lwd=1)\nlines(t,df3_tau40,col=4,lwd=1)\nget.h(f,tau=20,plot=T,iter=3,log=T,col=2)\nh40&lt;-get.h(f,tau=40,plot=F,iter=3,log=F);\nlines(h40$omega_hat[h40$omega_hat&gt;0],h40$H_iter[h40$omega_hat&gt;0],col=4)\nlines(omega_hat[h40$omega_hat&gt;0],fft_f[h40$omega_hat&gt;0],col=\"gray60\")\n\nplot(t,f,xlim=xlim,col=\"gray60\",xlab=\"\",ylab=\"\")\nlines(t,v1,col=1,lty=2)\nlines(t,df4_tau20,col=2,lwd=1)\nlines(t,df4_tau40,col=4,lwd=1)\nget.h(f,tau=20,plot=T,iter=4,log=T,col=2)\nh40&lt;-get.h(f,tau=40,plot=F,iter=4,log=F);\nlines(h40$omega_hat[h40$omega_hat&gt;0],h40$H_iter[h40$omega_hat&gt;0],col=4)\nlines(omega_hat[h40$omega_hat&gt;0],fft_f[h40$omega_hat&gt;0],col=\"gray60\")\ndev.off() \n\n# \n# # FIG 3\n# t=-2000:2000/1000\n# f1&lt;-25\n# v1=cos(f1*pi*t) #tau=40\n# snr&lt;-3\n# set.seed(1)\n# noise&lt;-rnorm(4001,mean=0,sd=sd(v1)/snr)\n# f=v1+noise\n# len=length(f)\n# omega_hat&lt;-seq(from=-pi,to=pi,len=len)\n# fft_f&lt;-c(1-(1-abs(fft(f))[((len+1)/2):len]),1-(1-abs(fft(f))[1:((len+1)/2-1)]))/len\n# df1&lt;-ebt(f,t,tau=40)$M\n# df2&lt;-f-extract.hfreq(t,f,tau=40,iter=1)\n# df3&lt;-f-extract.hfreq(t,f,tau=40,iter=2)\n# df4&lt;-f-extract.hfreq(t,f,tau=40,iter=3)\n# \n# pdf(paste(PATH, \"5-2]DesignDenoisingFilter_fig3.pdf\", sep=\"\"), width=8, height=6)\n# par(mar=c(2.5,2.5,2.5,2.5))\n# par(mfrow=c(4,2))\n# plot(t,f,xlim=xlim,col=\"gray60\",xlab=\"\",ylab=\"\",main=\"(a)\")\n# lines(t,v1,col=1,lty=2)\n# lines(t,df1,col=2,lwd=1)\n# get.h(f,tau=40,main=\"(b)\",plot=T,iter=1)\n# lines(omega_hat,fft_f,col=\"gray60\")\n# plot(t,f,xlim=xlim,col=\"gray60\",xlab=\"\",ylab=\"\",main=\"(c)\")\n# lines(t,v1,col=1,lty=2)\n# lines(t,df2,col=2,lwd=1)\n# get.h(f,tau=40,main=\"(d)\",plot=T,iter=2)\n# lines(omega_hat,fft_f,col=\"gray60\")\n# plot(t,f,xlim=xlim,col=\"gray60\",xlab=\"\",ylab=\"\",main=\"(e)\")\n# lines(t,v1,col=1,lty=2)\n# lines(t,df3,col=2,lwd=1)\n# get.h(f,tau=40,main=\"(f)\",plot=T,iter=3)\n# lines(omega_hat,fft_f,col=\"gray60\")\n# plot(t,f,xlim=xlim,col=\"gray60\",xlab=\"\",ylab=\"\",main=\"(g)\")\n# lines(t,v1,col=1,lty=2)\n# lines(t,df4,col=2,lwd=1)\n# get.h(f,tau=40,main=\"(h)\",plot=T,iter=4)\n# lines(omega_hat,fft_f,col=\"gray60\")\n# dev.off() \n\n\n#########################################################################################################################################\n# Denosing technique with elastic band transform\n## Data-adaptive $\\tau$ selection  \n#########################################################################################################################################\n# FIG 1 \nlibrary(wavethresh)\ndonoho.noise&lt;-DJ.EX(n=1000, signal=1, rsnr=5, noisy=TRUE, plotfn=FALSE)\ndonoho&lt;-DJ.EX(n=1000, signal=1, rsnr=5, noisy=FALSE, plotfn=FALSE)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n\nVM&lt;-list()\ndf&lt;-list()\nlambda&lt;-c(0.08,0.2,0.045,0.06)\niter&lt;-c(1,1,4,1)\npdf(paste(PATH, \"4-3]DataAdaptiveTauSelection_fig1.pdf\", sep=\"\"), width=8, height=6)\npar(mfrow=c(4,3))\nfor(i in 1:4)\n{\n  par(mar=c(2.5,2.5,2.5,2.5))\n  f&lt;-donoho.noise[[i]]\n  plot(f,type='l',xlab=\"\",ylab=\"\",col=\"gray60\")\n  maxtau=50\n  len&lt;-length(f)\n  VM[[i]]&lt;-Vmap(f,maxtau=maxtau,M=\"mean\",V=\"var\")\n  mintau&lt;-5\n  par(mar=c(2.5,1,2.5,3.5))\n  image.plot(x=1:len,y=mintau:maxtau,z=VM[[i]][1:len,mintau:maxtau],xlab=\"\",ylab=\"\",legend.mar=2)\n  #contour(x=1:len,y=mintau:maxtau,z=VM[[i]][1:len,mintau:maxtau],add = TRUE, nlevels = 3)\n  par(mar=c(2.5,3.5,2.5,2.5))\n  df[[i]]&lt;-denoise3(t=1:1000,donoho.noise[[i]],tau.list=50:3,lambda=lambda[i],iter=iter[i])\n  plot(df[[i]],type='l',ylab=\"\")\n  lines(donoho.noise[[i]],col=\"gray60\",lwd=0.7)\n  lines(df[[i]],lwd=1.2)\n}\npar(mfrow=c(1,1))\ndev.off() \n\n\n#########################################################################################################################################\n# Real Data Analysis\n#########################################################################################################################################\n\nlibrary(wavelets)\ndata(ecg)\necg&lt;-as.vector(ecg)\nt=1:length(ecg)\next&lt;-extract.hfreq(t,ecg,tau=132)\next.df1&lt;-denoise3(t,ext,tau.list=35:2,tol=0.005,lambda=0.01)\next.df2&lt;-denoise3(t,ext,tau.list=35:2,tol=0.005,lambda=0.02)\next.df3&lt;-denoise3(t,ext,tau.list=35:2,tol=0.0005,lambda=0.035)\next.df4&lt;-denoise3(t,ext,tau.list=15:2,tol=0.05,lambda=0.1)\n\npdf(paste(PATH, \"5]RealDataAnalysis_fig1.pdf\", sep=\"\"), width=10,height=10)\npar(mar=c(2.5,2.5,2.5,2.5))\npar(mfrow=c(4,1))\nplot(t,ecg,type='l',xlab=\"\",ylab=\"\",ylim=c(-1.5,1.8),main=\"(a)\")\nplot(t,ecg-ext,type='l',xlab=\"\",ylab=\"\",ylim=c(-1.5,1.8),lwd=1,main=\"(b)\")\nplot(t,ext,type='l',xlab=\"\",ylab=\"\",ylim=c(-1.5,1.8),lwd=1,main=\"(c)\")\nplot(t,ext.df4,type='l',xlab=\"\",ylab=\"\",ylim=c(-1.5,1.8),lwd=1,main=\"(d)\")\n#plot(t,ext-ext.df3,type='l',xlab=\"\",ylab=\"\",ylim=c(-1.5,1.5),lwd=1,main=\"(e)\")\ndev.off()"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html",
    "title": "(연구&교수님) EBT – 첫 논문 재현",
    "section": "",
    "text": "getwd()\n\nNameError: name 'getwd' is not defined\nlibrary(devtools)\ninstall_github(\"guebin/EBT\",force=TRUE)\ninstall_github(\"seoyeonc/gglite\",force=TRUE)\nlibrary(ebt)\nlibrary(gglite)\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(patchwork)\n\nLoading required package: usethis\n\nDownloading GitHub repo guebin/EBT@HEAD\n\nDownloading GitHub repo seoyeonc/gglite@HEAD\n\n\nAttaching package: ‘gglite’\n\n\nThe following objects are masked from ‘package:stats’:\n\n    density, line, smooth, step\n\n\nThe following object is masked from ‘package:graphics’:\n\n    boxplot\n\n\nThe following objects are masked from ‘package:base’:\n\n    col, jitter\n\n\n── Attaching core tidyverse packages ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n── R CMD build ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n✔  checking for file ‘/tmp/RtmpKneRZt/remotesde24041b4ce54/guebin-EBT-f065664/DESCRIPTION’\n─  preparing ‘ebt’:\n✔  checking DESCRIPTION meta-information\n─  checking for LF line-endings in source and make files and shell scripts\n─  checking for empty or unneeded directories\n   Omitted ‘LazyData’ from DESCRIPTION\n─  building ‘ebt_0.1.0.tar.gz’\n   \n── R CMD build ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n✔  checking for file ‘/tmp/RtmpKneRZt/remotesde2401590c26a/seoyeonc-gglite-f30eecb/DESCRIPTION’\n─  preparing ‘gglite’:\n✔  checking DESCRIPTION meta-information\n─  checking for LF line-endings in source and make files and shell scripts\n─  checking for empty or unneeded directories\n   Omitted ‘LazyData’ from DESCRIPTION\n─  building ‘gglite_0.1.0.tar.gz’"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html#a.-signal",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html#a.-signal",
    "title": "(연구&교수님) EBT – 첫 논문 재현",
    "section": "A. signal",
    "text": "A. signal\n\nfs=1000\nt=-2000:2000/fs\nv1=sin(2*pi*t)\nv2=cos(20*pi*t)\nf=v1*v2\n\nSyntaxError: invalid syntax (3853967732.py, line 2)\n\n\n\nfigsize(4,3,300)\ngglite()+line(t,f)+coord_cartesian(xlim=c(-0.22,0.22))+xlab(\"\")+ylab(\"\")"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html#b.-ebt",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html#b.-ebt",
    "title": "(연구&교수님) EBT – 첫 논문 재현",
    "section": "B. EBT",
    "text": "B. EBT\n\nout1&lt;-ebt(t,f,tau=60)\ni1&lt;-out1$sampled_index[[1]]\ni2&lt;-out1$sampled_index[[20]]\ni3&lt;-out1$sampled_index[[40]]\nout2&lt;-ebt(t,f,tau=80)\ni4&lt;-out2$sampled_index[[1]]\ni5&lt;-out2$sampled_index[[20]]\ni6&lt;-out2$sampled_index[[40]]"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html#c.-fig1a---fig1f",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html#c.-fig1a---fig1f",
    "title": "(연구&교수님) EBT – 첫 논문 재현",
    "section": "C. fig1a - fig1f",
    "text": "C. fig1a - fig1f\n\nfigsize(4,3,300)\nfig1a = gglite() + \npoint(t,f,col=\"gray60\",cex=0.1) + \nggtitle(\"Original Signal\")+xlab(\"\")+ylab(\"\")+\ncoord_cartesian(xlim=c(-0.22,0.22))\nfig1a\n\n\n\n\n\n\n\n\n\nfig1b = fig1a + ggtitle(\"Single Touch of Dessin\") + \npoint(t[i1],out1$band[,1][i1],cex=2,col=2) + # band1, point\nline(t[i1],out1$band[,1][i1],col=2,alpha=0.2,lwd=1) # band1, line\nfig1b\n\n\n\n\n\n\n\n\n\nfig1c = fig1a + ggtitle(\"Three Touches\") + \npoint(t[i1],out1$band[,1][i1],cex=2,col=2)+ # band1, point\nline(t[i1],out1$band[,1][i1],col=2,alpha=0.2,lwd=1)+ # band1, line \npoint(t[i2],out1$band[,20][i2],cex=2,col=4)+ # band20, point \nline(t[i2],out1$band[,20][i2],col=4,alpha=0.2,lwd=1)+ # band20, line\npoint(t[i3],out1$band[,40][i3],cex=2,col=3)+ # band40, point\nline(t[i3],out1$band[,40][i3],col=3,alpha=0.2,lwd=1) # band40, line\nfig1c\n\n\n\n\n\n\n\n\n\nfig1d &lt;- fig1c + line(t,out1$band,col=\"gray60\",lwd=0.05) + ggtitle(\"All Possible Touches\")\nfig1d\n\n\nfig1e &lt;- fig1a + point(t[i4],out2$band[,1][i4],cex=2,col=2)+ # band1, point\nline(t[i4],out2$band[,1][i4],col=2,alpha=0.2,lwd=1)+ # band1, line \npoint(t[i5],out2$band[,20][i5],cex=2,col=4)+ # band20, point \nline(t[i5],out2$band[,20][i5],col=4,alpha=0.2,lwd=1)+ # band20, line\npoint(t[i6],out2$band[,40][i6],cex=2,col=3)+ # band40, point\nline(t[i6],out2$band[,40][i6],col=3,alpha=0.2,lwd=1)+ # band40, line\nggtitle(\"Three Touches (With Larger Interval)\")\nfig1e\n\n\nfig1f &lt;- fig1e + line(t,out2$band,col=\"gray60\",lwd=0.05) + ggtitle(\"All Possible Touches (With Larger Interval)\")\nfig1f"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html#d.-fig1",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html#d.-fig1",
    "title": "(연구&교수님) EBT – 첫 논문 재현",
    "section": "D. fig1",
    "text": "D. fig1\n\nfigsize(10,10)\nfig1 &lt;- (fig1a|fig1b)/(fig1c|fig1d)/(fig1e|fig1f)\nfig1\nfigsize()"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html#e.-ggsave",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html#e.-ggsave",
    "title": "(연구&교수님) EBT – 첫 논문 재현",
    "section": "E. ggsave",
    "text": "E. ggsave\n\nfig1d &lt;- fig1c + line(t,out1$band[,1:60],col=\"gray60\",lwd=0.05,alpha=0.2) + ggtitle(\"All Possible Touches\")\nfig1f &lt;- fig1e + line(t,out2$band[,1:80],col=\"gray60\",lwd=0.05,alpha=0.2) + ggtitle(\"All Possible Touches (With Larger Interval)\")\nfig1 &lt;- (fig1a|fig1b)/(fig1c|fig1d)/(fig1e|fig1f)\nggsave(\"fig1.pdf\",fig1,width = 8, height = 6, dpi = 150)"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html#a.-signal-1",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html#a.-signal-1",
    "title": "(연구&교수님) EBT – 첫 논문 재현",
    "section": "A. signal",
    "text": "A. signal\n\nfs=10\nt=-30:30/fs\nf=cos(pi*t^2)\n\n\ngglite()+point(t,f)+line(t,f)+xlim(0,2)+xlab(\"\")+ylab(\"\")"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html#b.-ebt-linear-fig2ace",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html#b.-ebt-linear-fig2ace",
    "title": "(연구&교수님) EBT – 첫 논문 재현",
    "section": "B. EBT: linear – fig2a,c,e",
    "text": "B. EBT: linear – fig2a,c,e\n\nout&lt;-ebt(t,f,tau=3)\ni1&lt;-out$sampled_index[[1]]\ni2&lt;-out$sampled_index[[2]]\ni3&lt;-out$sampled_index[[3]]\n\n\nfig2_base = gglite()+point(t,out$f)+xlim(0,2)+xlab(\"\")+ylab(\"\")\nfig2a = fig2_base + point(t[i1],out$band[,1][i1],col=2,cex=5,pch=1)+line(t,out$band[,1],col=2,lwd=1)+ggtitle(\"(a)\")\nfig2a\n\n\n\n\n\n\n\n\n\nfig2c = fig2_base + point(t[i2],out$band[,2][i2],col=3,cex=5,pch=1) + line(t,out$band[,2],col=3,lwd=1)+ggtitle(\"(c)\")\nfig2c\n\n\n\n\n\n\n\n\n\nfig2e = fig2_base + point(t[i3],out$band[,3][i3],col=4,cex=5,pch=1) + line(t,out$band[,3],col=4,lwd=1)+ggtitle(\"(e)\")\nfig2e"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html#c.-ebt-cubic-fig2bdf",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html#c.-ebt-cubic-fig2bdf",
    "title": "(연구&교수님) EBT – 첫 논문 재현",
    "section": "C. EBT: cubic – fig2b,d,f",
    "text": "C. EBT: cubic – fig2b,d,f\n\nout&lt;-ebt(t,f,tau=3,inter_method='cubic')\ni1&lt;-out$sampled_index[[1]]\ni2&lt;-out$sampled_index[[2]]\ni3&lt;-out$sampled_index[[3]]\n\n\nfig2_base = gglite()+point(t,out$f)+xlim(0,2)+xlab(\"\")+ylab(\"\")\nfig2b = fig2_base + point(t[i1],out$band[,1][i1],col=2,cex=5,pch=1)+line(t,out$band[,1],col=2,lwd=1)+ggtitle(\"(b)\")\nfig2b\n\n\n\n\n\n\n\n\n\nfig2d = fig2_base + point(t[i2],out$band[,2][i2],col=3,cex=5,pch=1) + line(t,out$band[,2],col=3,lwd=1)+ggtitle(\"(d)\")\nfig2d\n\n\n\n\n\n\n\n\n\nfig2f = fig2_base + point(t[i3],out$band[,3][i3],col=4,cex=5,pch=1) + line(t,out$band[,3],col=4,lwd=1)+ggtitle(\"(f)\")\nfig2f"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html#d.-fig2",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html#d.-fig2",
    "title": "(연구&교수님) EBT – 첫 논문 재현",
    "section": "D. fig2",
    "text": "D. fig2\n\nfigsize(10,6)\nfig2 &lt;- (fig2a|fig2b)/(fig2c|fig2d)/(fig2e|fig2f)\nfig2\nfigsize()"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html#e.-ggsave-1",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html#e.-ggsave-1",
    "title": "(연구&교수님) EBT – 첫 논문 재현",
    "section": "E. ggsave",
    "text": "E. ggsave\n\nggsave(\"fig2.pdf\",fig2, height = 6.67/1.5)\n\nSaving 6.67 x 4.45 in image"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html#a.-signal-2",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html#a.-signal-2",
    "title": "(연구&교수님) EBT – 첫 논문 재현",
    "section": "A. signal",
    "text": "A. signal\n\n# FIG 1\nfs=100\nt=-200:200/fs\nv1=cos(2*pi*t)\nv2=cos(3*pi*t)\nf=v1+v2\n\n\nfig3_base &lt;- gglite()+point(t,f,size=0.5,col=\"gray20\")+xlim(c(-1,1))+xlab(\"\")+ylab(\"\")\nfig3_base"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html#b.-ebt-1",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html#b.-ebt-1",
    "title": "(연구&교수님) EBT – 첫 논문 재현",
    "section": "B. EBT",
    "text": "B. EBT\n\nout1&lt;-ebt(t,f,tau=30)\nout2&lt;-ebt(t,f,tau=45)\nout3&lt;-ebt(t,f,tau=60)"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html#c.-fig3",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html#c.-fig3",
    "title": "(연구&교수님) EBT – 첫 논문 재현",
    "section": "C. fig3",
    "text": "C. fig3\n\nfig3a &lt;- gglite()+point(t,f,size=0.5)+xlim(c(-1,1))+xlab(\"\")+ylab(\"\")+ggtitle(\"(a)\")\nfig3b &lt;- fig3a+line(t,out1$band,col=2,lwd=0.01)+ggtitle(\"(b)\")\nfig3c &lt;- fig3a+line(t,out2$band,col=3,lwd=0.01)+ggtitle(\"(c)\")\nfig3d &lt;- fig3a+line(t,out3$band,col=4,lwd=0.01)+ggtitle(\"(d)\")\nfig3e &lt;- gglite()+xlim(c(-1,1))+point(t,f,alpha=0)+xlab(\"\")+ylab(\"\")+line(t,out1$M,lwd=1,col=2)+line(t,out2$M,lwd=1,col=3)+line(t,out3$M,lwd=1,col=4)+ggtitle(\"(e)\")\nfig3f &lt;- gglite()+xlim(c(-1,1))+line(t,out1$V,col=2)+line(t,out2$V,col=3)+line(t,out3$V,col=4)+ggtitle(\"(f)\")+xlab(\"\")+ylab(\"\")\n\n\nfigsize(10,6)\nfig3 &lt;- (fig3a|fig3b)/(fig3c|fig3d)/(fig3e|fig3f)\nfig3\nfigsize()"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html#d.-ggsave",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html#d.-ggsave",
    "title": "(연구&교수님) EBT – 첫 논문 재현",
    "section": "D. ggsave",
    "text": "D. ggsave\n\nfig3a &lt;- gglite()+point(t,f,size=0.5)+xlim(c(-1,1))+xlab(\"\")+ylab(\"\")+ggtitle(\"(a)\")\nfig3b &lt;- fig3a+line(t,out1$band,col=2,lwd=0.01,alpha=0.1)+ggtitle(\"(b)\")\nfig3c &lt;- fig3a+line(t,out2$band,col=3,lwd=0.01,alpha=0.1)+ggtitle(\"(c)\")\nfig3d &lt;- fig3a+line(t,out3$band,col=4,lwd=0.01,alpha=0.1)+ggtitle(\"(d)\")\nfig3e &lt;- gglite()+xlim(c(-1,1))+point(t,f,alpha=0)+xlab(\"\")+ylab(\"\")+line(t,out1$M,lwd=1,col=2)+line(t,out2$M,lwd=1,col=3)+line(t,out3$M,lwd=1,col=4)+ggtitle(\"(e)\")\nfig3f &lt;- gglite()+xlim(c(-1,1))+line(t,out1$V,col=2)+line(t,out2$V,col=3)+line(t,out3$V,col=4)+ggtitle(\"(f)\")+xlab(\"\")+ylab(\"\")\nfig3 &lt;- (fig3a|fig3b)/(fig3c|fig3d)/(fig3e|fig3f)\nggsave(\"fig3.pdf\",fig3,height = 6.67/1.2)\n\nSaving 6.67 x 5.56 in image"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html#a.-signal-3",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html#a.-signal-3",
    "title": "(연구&교수님) EBT – 첫 논문 재현",
    "section": "A. signal",
    "text": "A. signal\n\nset.seed(100)\nv1&lt;-rnorm(150,mean=0,sd=0.5) # ~150\nv2&lt;-rnorm(150,mean=0,sd=0.5) # ~300\nv3&lt;-rnorm(150,mean=1.5,sd=3) # ~450\nv4&lt;-rnorm(150,mean=1.5,sd=3) # ~600\nv5&lt;-rnorm(150,mean=1.5,sd=2) # ~750\nv6&lt;-rnorm(150,mean=1.5,sd=1) # ~900\nv7&lt;-rnorm(150,mean=3.0,sd=1) # ~1050\nv8&lt;-rnorm(150,mean=4.5,sd=1) # ~1200\nv9&lt;-rnorm(150,mean=6.0,sd=1) # ~1350\nv10&lt;-rnorm(150,mean=7.5,sd=1) # ~1500\nf&lt;-c(v1,v2,v3,v4,v5,v6,v7,v8,v9,v10) \n\n\ngglite()+line(f,col='gray60')+xlab(\"\")+ylab(\"\")"
  },
  {
    "objectID": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html#b.",
    "href": "연구/교수님이랑/EBT/2024-01-16-첫 논문 재현.html#b.",
    "title": "(연구&교수님) EBT – 첫 논문 재현",
    "section": "B.",
    "text": "B.\n\nMM1&lt;-Mmap(f,maxtau=maxtau,M=\"mean\",V=\"var\")\nVM1&lt;-Vmap(f,maxtau=maxtau,M=\"mean\",V=\"var\")\ndMM1_t&lt;-diff(MM1)\ndVM1_t&lt;-diff(VM1)\n\n\n# #########################################################################################################################################\n# # ELASTIC BAND TRANSFORM\n# ## Sattistics of Elastic-Bands\n# #########################################################################################################################################\n\n# # FIG 2\n# len=500\n# tau&lt;-5\n# h&lt;-c(rep(0,len-(tau-1)),1:tau,(tau-1):1,rep(0,len-tau))/tau^2\n# omega_hat&lt;-seq(from=-pi,to=pi,len=len*2)\n# #pdf(paste(PATH, \"2-2]Homega.pdf\", sep=\"\"), width=7, height=3)\n# par(mar=c(2.5,2.5,2.5,2.5))\n# par(mfrow=c(1,3))\n# plot(omega_hat,c(abs(fft(h))[501:1000],abs(fft(h))[1:500]),type='l',xlab=\"\",ylab=\"\",main=\"(a)\")\n# tau&lt;-10\n# h&lt;-c(rep(0,len-(tau-1)),1:tau,(tau-1):1,rep(0,len-tau))/tau^2\n# omega_hat&lt;-seq(from=-pi,to=pi,len=len*2)\n# plot(omega_hat,c(abs(fft(h))[501:1000],abs(fft(h))[1:500]),type='l',xlab=\"\",ylab=\"\",main=\"(b)\")\n# tau&lt;-30\n# h&lt;-c(rep(0,len-(tau-1)),1:tau,(tau-1):1,rep(0,len-tau))/tau^2\n# omega_hat&lt;-seq(from=-pi,to=pi,len=len*2)\n# plot(omega_hat,c(abs(fft(h))[501:1000],abs(fft(h))[1:500]),type='l',xlab=\"\",ylab=\"\",main=\"(c)\")\n# #dev.off()\n\n# #########################################################################################################################################\n# # ELASTIC BAND TRANSFORM\n# ## Visualization\n# #########################################################################################################################################\n# # FIG 1\n# set.seed(100)\n# v1&lt;-rnorm(150,mean=0,sd=0.5) # ~150\n# v2&lt;-rnorm(150,mean=0,sd=0.5) # ~300\n# v3&lt;-rnorm(150,mean=1.5,sd=3) # ~450\n# v4&lt;-rnorm(150,mean=1.5,sd=3) # ~600\n# v5&lt;-rnorm(150,mean=1.5,sd=2) # ~750\n# v6&lt;-rnorm(150,mean=1.5,sd=1) # ~900\n# v7&lt;-rnorm(150,mean=3.0,sd=1) # ~1050\n# v8&lt;-rnorm(150,mean=4.5,sd=1) # ~1200\n# v9&lt;-rnorm(150,mean=6.0,sd=1) # ~1350\n# v10&lt;-rnorm(150,mean=7.5,sd=1) # ~1500\n# f&lt;-c(v1,v2,v3,v4,v5,v6,v7,v8,v9,v10) \n# maxtau=200\n# len&lt;-length(f)\n\n# MM1&lt;-Mmap(f,maxtau=maxtau,M=\"mean\",V=\"var\")\n# VM1&lt;-Vmap(f,maxtau=maxtau,M=\"mean\",V=\"var\")\n# dMM1_t&lt;-diff(MM1)\n# dVM1_t&lt;-diff(VM1)\n\n# library(fields)\n# #pdf(paste(PATH, \"2-3]MmapVmap.pdf\", sep=\"\"), width=7, height=5)\n# par(mar=c(2.5,3,3,4))\n# par(mfrow=c(3,2))\n# plot(f,xlab=\"\",ylab=\"\",main=\"(a)\",type='l')\n# par(mar=c(2.5,3,3,1))\n# mintau&lt;-10\n# maxtau&lt;-200\n# image.plot(x=1:len,y=mintau:maxtau,z=MM1[1:len,mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(b)\")\n# abline(v=c(300,900,1050,1200,1350),lty=2,lwd=1)\n# par(mar=c(2.5,2.5,2.5,1))\n# mintau&lt;-50\n# maxtau&lt;-100\n# image.plot(x=1:len,y=mintau:maxtau,z=dMM1_t[1:(len-1),mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(c)\")\n# abline(v=c(300,900,1050,1200,1350),lty=2,lwd=1)\n# par(mar=c(2.5,2.5,2.5,1))\n# mintau&lt;-50\n# maxtau&lt;-200\n# image.plot(x=1:len,y=mintau:maxtau,z=VM1[1:len,mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(d)\")\n# abline(v=c(300,600,750),lty=2,lwd=1)\n# mintau&lt;-50\n# maxtau&lt;-200\n# image.plot(x=1:len,y=mintau:maxtau,z=abs(dVM1_t[1:(len-1),mintau:maxtau]),xlab=\"\",ylab=\"\",main=\"(e)\")\n# abline(v=c(300,600,750),lty=2,lwd=1)\n# par(mar=c(2.5,2.5,2.5,1))\n# mintau&lt;-100\n# maxtau&lt;-200\n# image.plot(x=1:len,y=mintau:maxtau,z=dMM1_t[1:(len-1),mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(f)\")\n# abline(v=c(300,900,1050,1200,1350),lty=2,lwd=1)\n# #dev.off() \n\n# # FIG 2\n# library(wavelets)\n# data(ecg)\n# f&lt;-as.vector(ecg)\n# t&lt;-seq(0,11.37,length=2048)\n# maxtau=180\n# len&lt;-length(f)\n# MM2&lt;-Mmap(f,maxtau=maxtau,M=\"mean\",V=\"var\")\n# VM2&lt;-Vmap(f,maxtau=maxtau,M=\"mean\",V=\"var\")\n# dMM2_t&lt;-diff(MM1)\n# dMM2_tau&lt;-t(diff(t(MM2)))\n# dVM2_t&lt;-diff(VM2)\n# dVM2_tau&lt;-t(diff(t(VM2)))\n# # \n# # #pdf(paste(PATH, \"2-3]MmapVmapECG.pdf\", sep=\"\"), width=7, height=5)\n# # par(mfrow=c(3,2))\n# # par(mar=c(2.5,2.5,2.5,4))\n# # plot(t,f,xlab=\"\",ylab=\"\",main=\"(a)\",type='l')\n# # \n# # par(mar=c(2.5,2.5,2.5,1))\n# # mintau&lt;-5\n# # maxtau&lt;-180\n# # image.plot(x=t,y=mintau:maxtau,z=MM2[1:len,mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(b)\",legend.mar=10)\n# # mintau&lt;-50\n# # maxtau&lt;-175\n# # par(mar=c(2.5,2.5,2.5,1))\n# # image.plot(x=t,y=mintau:maxtau,z=VM2[1:len,mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(c)\",legend.mar=5)\n# # par(mar=c(2.5,2.5,2.5,1))\n# # mintau&lt;-50\n# # maxtau&lt;-100\n# # image.plot(x=t,y=mintau:maxtau,z=dVM2_t[1:(len-1),mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(d)\",legend.mar=10)\n# # par(mar=c(2.5,2.5,2.5,1))\n# # mintau&lt;-50\n# # maxtau&lt;-175\n# # image.plot(x=t,y=mintau:maxtau,z=dVM2_tau[1:len,mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(e)\",legend.mar=5)\n# # library(phonTools)\n# # library(fields)\n# # temp&lt;-spectrogram(f,fs=180,windowlength = 5*22050/180,show=F)$spectrogram\n# # par(mar=c(2.5,2.5,2.5,1))\n# # image.plot(x=seq(0,11.37,length=941),y=seq(0,90,length=617),z=temp[1:941,1:617],xlab=\"\",ylab=\"\",main=\"(f)\",legend.mar=10)\n# # #dev.off() \n# # \n\n\n# pdf(paste(\"MmapVmapECG.png\", sep=\"\"), width=7, height=5*2/3)\n# par(mfrow=c(2,2))\n# par(mar=c(2.5,2.5,2.5,4))\n# plot(t,f,xlab=\"\",ylab=\"\",main=\"(a)\",type='l')\n\n# par(mar=c(2.5,2.5,2.5,1))\n# mintau&lt;-5\n# maxtau&lt;-180\n# image.plot(x=t,y=mintau:maxtau,z=MM2[1:len,mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(b)\",legend.mar=10)\n# mintau&lt;-50\n# maxtau&lt;-175\n# par(mar=c(2.5,2.5,2.5,1))\n# image.plot(x=t,y=mintau:maxtau,z=VM2[1:len,mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(c)\",legend.mar=5)\n# par(mar=c(2.5,2.5,2.5,1))\n# # mintau&lt;-50\n# # maxtau&lt;-100\n# # image.plot(x=t,y=mintau:maxtau,z=dVM2_t[1:(len-1),mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(d)\",legend.mar=10)\n# # par(mar=c(2.5,2.5,2.5,1))\n# mintau&lt;-50\n# maxtau&lt;-175\n# image.plot(x=t,y=mintau:maxtau,z=dVM2_tau[1:len,mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(d)\",legend.mar=10)\n# library(phonTools)\n# library(fields)\n# # temp&lt;-spectrogram(f,fs=180,windowlength = 5*22050/180,show=F)$spectrogram\n# # par(mar=c(2.5,2.5,2.5,1))\n# # image.plot(x=seq(0,11.37,length=941),y=seq(0,90,length=617),z=temp[1:941,1:617],xlab=\"\",ylab=\"\",main=\"(f)\",legend.mar=10)\n# dev.off() \n\n# # FIG 2-1\n# library(wavelets)\n# data(ecg)\n# f&lt;-as.vector(ecg)\n# t&lt;-seq(0,11.37,length=2048)\n# maxtau=180\n# len&lt;-length(f)\n# MM2&lt;-Mmap(f,maxtau=maxtau,M=\"mean\",V=\"volume\")\n# VM2&lt;-Vmap(f,maxtau=maxtau,M=\"mean\",V=\"volume\")\n# dMM2_t&lt;-diff(MM1)\n# dMM2_tau&lt;-t(diff(t(MM2)))\n# dVM2_t&lt;-diff(VM2)\n# dVM2_tau&lt;-t(diff(t(VM2)))\n\n# #pdf(paste(PATH, \"2-3]MmapVmapECG_1.pdf\", sep=\"\"), width=7, height=2.3)\n# par(mfrow=c(1,2))\n# par(mar=c(2.5,2.5,2.5,1))\n# image.plot(x=t,y=mintau:maxtau,z=VM2[1:len,mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(a)\",legend.mar=5)\n# par(mar=c(2.5,2.5,2.5,1))\n# mintau&lt;-50\n# maxtau&lt;-100\n# image.plot(x=t,y=mintau:maxtau,z=dVM2_t[1:(len-1),mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(b)\",legend.mar=10)\n# par(mar=c(2.5,2.5,2.5,1))\n# mintau&lt;-50\n# maxtau&lt;-175\n# #dev.off() \n\n# #########################################################################################################################################\n# # ELASTIC BAND TRANSFORM\n# ## Useful Applications of Elastic-Band Transform\n# ### Testing Chage of Cycle in Cyclostationary Stochastic Process\n# #########################################################################################################################################\n# # FIG 6\n# set.seed(2)\n# # fs&lt;-90\n# # Ts&lt;-1/90\n# # t=seq(-10,10,length=20*fs)\n# # vartau&lt;-seq(from=90,to=95,by=2)\n# # truetau&lt;-90;\n# # len&lt;-length(t)\n# # lenhalf&lt;-round(len*0.5)\n# # \n# # u1&lt;-c(cos(fs/truetau*2*pi*t[1:lenhalf]),rep(0,len-lenhalf))\n# # u2&lt;-c(rep(0,lenhalf),cos(fs/vartau[freqindex]*2*pi*t[(lenhalf+1):len]))\n# # u&lt;-u1+u2\n# # \n# # v1&lt;-swave(truetau/2,lenhalf)\n# # v2&lt;-swave(vartau[freqindex]/2,len-lenhalf)\n# # v&lt;-c(v1,v2)\n# # \n# # snr&lt;-2\n# # noise1&lt;-rnorm(len,mean=0,sd=sd((u)/snr))  \n# # noise2&lt;-rnorm(len,mean=0,sd=sd((v)/snr))  \n# # f=u+noise1\n# # g=v+noise2\n\n# ecgmat&lt;-read.csv(\"C:/Users/gbchoi/Desktop/data/ecgdata.csv\",head=T)\n# noise&lt;-rnorm(1800,mean=0,sd=sd(ecgmat[,1])/2)\n# a.ecg1&lt;-c(ecgmat[,1],ecgmat[,1])+noise\n# a.ecg2&lt;-c(ecgmat[,1],ecgmat[,2])+noise\n# a.ecg3&lt;-c(ecgmat[,1],ecgmat[,3])+noise\n# a.ecg4&lt;-c(ecgmat[,1],ecgmat[,4])+noise\n# a.ecg5&lt;-c(ecgmat[,1],ecgmat[,5])+noise\n# t=seq(0,20,length=20*90)\n\n# # VMf&lt;-Vmap(f,maxtau=150,M=\"mean\",V=\"var\")\n# # VMg&lt;-Vmap(g,maxtau=150,M=\"mean\",V=\"var\")\n\n# VMecg1&lt;-Vmap(a.ecg1,maxtau=150,M=\"mean\",V=\"volume\")\n# VMecg5&lt;-Vmap(a.ecg5,maxtau=150,M=\"mean\",V=\"volume\")\n\n# pdf(paste(PATH, \"2-3]periodchange.pdf\", sep=\"\"), width=10, height=6)\n# par(mfrow=c(2,2))\n# par(mar=c(2.5, 2.5, 2.5, 3))\n# plot(t,a.ecg1,xlab=\"\",ylab=\"\",main=\"(a)\",type='l')\n# plot(t,a.ecg5,xlab=\"\",ylab=\"\",main=\"(b)\",type='l')\n\n# library(fields)\n# # mintau&lt;-20\n# # maxtau&lt;-150\n# # par(mar=c(2.5, 2.5, 2.5, 1))\n# # image.plot(x=t,y=mintau:maxtau,z=VMf[1:len,mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(c)\",legend.mar=5)\n# # par(mar=c(2.5, 2.5, 2.5, 1))\n# # mintau&lt;-20\n# # maxtau&lt;-150\n# # image.plot(x=t,y=mintau:maxtau,z=VMg[1:len,mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(d)\",legend.mar=5)\n# par(mar=c(2.5, 2.5, 2.5, 1))\n# mintau&lt;-20\n# maxtau&lt;-120\n# image.plot(x=t,y=mintau:maxtau,z=VMecg1[1:length(a.ecg1),mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(c)\",legend.mar=5)\n# image.plot(x=t,y=mintau:maxtau,z=VMecg5[1:length(a.ecg5),mintau:maxtau],xlab=\"\",ylab=\"\",main=\"(d)\",legend.mar=5)\n# dev.off() \n# # \n# # library(phonTools)\n# # temp1&lt;-spectrogram(f,fs=fs,windowlength = 5*22050/fs,show=F)$spectrogram\n# # temp2&lt;-spectrogram(g,fs=fs,windowlength = 5*22050/fs,show=F)$spectrogram\n# # par(mar=c(2.5,2.5,2.5,1))\n# # image.plot(x=seq(-10,10,length=958),y=seq(0,fs/2,length=617),z=temp1[1:958,1:617],xlab=\"\",ylab=\"\",main=\"(f)\",legend.mar=10)\n# # image.plot(x=seq(-10,,length=958),y=seq(0,fs/2,length=617),z=temp2[1:958,1:617],xlab=\"\",ylab=\"\",main=\"(f)\",legend.mar=10)\n# set.seed(7)\n# ITER&lt;-100\n# pval&lt;-rep(0,ITER*5); dim(pval)&lt;-c(ITER,5)\n# a.ecg&lt;-list()\n# for(iter in 1:ITER)\n# {\n#   for(f1index in 1:5)\n#     {\n#       noise&lt;-rnorm(1800,mean=0,sd=sd(ecgmat[,1])/2)\n#       a.ecg[[f1index]]&lt;-c(ecgmat[,1],ecgmat[,f1index])+noise\n#       hat_tau&lt;-tauest(a.ecg[[f1index]],taulist=80:120,V=\"volume\")\n#       pval[iter,f1index]&lt;-st.test(hat_tau[200:1600])\n#     }\n# }\n# round(1-apply(pval,2,mean),3)\n# action&lt;-pval&lt;0.05\n# round(apply(action,c(2,3),mean),3)\n\n\n# #########################################################################################################################################\n# # ELASTIC BAND TRANSFORM\n# ## Useful Applications of Elastic-Band Transform\n# ### Change Point Detections\n# #########################################################################################################################################\n# ## FIG 1\n# pdf(paste(PATH, \"2-4]CPsignal.pdf\", sep=\"\"), width=7, height=4)\n# par(mar=c(2.5,2.5,2.5,2.5))\n# par(mfrow=c(2,2))\n# set.seed(1)\n# f1&lt;-c(rnorm(400,0,0.5),\n#       rnorm(20,0,0.7),\n#       rnorm(20,0,0.9),\n#       rnorm(20,0,1.1),\n#       rnorm(20,0,1.3),\n#       rnorm(20,0,1.5),\n#       rnorm(20,0,1.7),\n#       rnorm(20,0,1.9),\n#       rnorm(20,0,2.1),\n#       rnorm(20,0,2.3),\n#       rnorm(20,0,2.5),\n#       rnorm(800,0,3.5))\n# plot(f1[101:(1200-100)],type='l',main=\"(a)\")\n# set.seed(1)\n# f2&lt;-c(rnorm(400,0,0.5),\n#       rnorm(20,0,0.7),\n#       rnorm(20,0,0.9),\n#       rnorm(20,0,1.1),\n#       rnorm(20,0,1.3),\n#       rnorm(20,0,1.5),\n#       rnorm(20,0,1.7),\n#       rnorm(20,0,1.9),\n#       rnorm(20,0,2.1),\n#       rnorm(20,0,2.3),\n#       rnorm(20,0,2.5),\n#       rnorm(800,0,3.5*2))\n# plot(f2[101:(1200-100)],type='l',main=\"(b)\")\n# set.seed(1)\n# f3&lt;-c(rnorm(400,0,0.5),\n#       rnorm(20,0,0.7),\n#       rnorm(20,0,0.9),\n#       rnorm(20,0,1.1),\n#       rnorm(20,0,1.3),\n#       rnorm(20,0,1.5),\n#       rnorm(20,0,1.7),\n#       rnorm(20,0,1.9),\n#       rnorm(20,0,2.1),\n#       rnorm(20,0,2.3),\n#       rnorm(20,0,2.5),\n#       rnorm(800,0,3.5*3))\n# plot(f3[101:(1200-100)],type='l',main=\"(c)\")\n# set.seed(1)\n# f4&lt;-c(rnorm(400,0,0.5),\n#       rnorm(20,0,0.7),\n#       rnorm(20,0,0.9),\n#       rnorm(20,0,1.1),\n#       rnorm(20,0,1.3),\n#       rnorm(20,0,1.5),\n#       rnorm(20,0,1.7),\n#       rnorm(20,0,1.9),\n#       rnorm(20,0,2.1),\n#       rnorm(20,0,2.3),\n#       rnorm(20,0,2.5),\n#       rnorm(800,0,3.5*4))\n# plot(f4[101:(1200-100)],type='l',main=\"(d)\")\n# dev.off() \n\n# ## TABLE 1\n# J=4; Tau=8; ITER=1;\n# cp&lt;-rep(0,ITER*Tau*J); dim(cp)&lt;-c(ITER,Tau,J)\n# set.seed(1000); \n# # sim.result3&lt;-generate.gaussian(Tx=1000,nsim=1000);\n# for(iter in 1:ITER)\n# {\n#   for(j in 1:J)\n#   {\n#     f&lt;-c(rnorm(400,0,1.5),\n#           rnorm(20,0,1.6),\n#           rnorm(20,0,1.7),\n#           rnorm(20,0,1.8),\n#           rnorm(20,0,1.9),\n#           rnorm(20,0,2.0),\n#           rnorm(20,0,2.1),\n#           rnorm(20,0,2.2),\n#           rnorm(20,0,2.3),\n#           rnorm(20,0,2.4),\n#           rnorm(20,0,2.5),\n#           rnorm(800,0,3.5*j))\n#     taulist&lt;-c(5,10,15,20,25,30,35,40) \n#     for(tau in 1:Tau)\n#     {\n#       ebtres&lt;-ebt(f,tau=taulist[tau])\n#       fV&lt;-ebtres$V[101:1100]\n#       cp[iter,tau,j]&lt;-cp.find(x=fV,sim.result=sim.result3)\n#       par(mfrow=c(2,1))\n#       plot(f[101:1100],type='l'); abline(v=cp[iter,tau,j],col=2); plot(f[101:1100],type='l',main=cp[iter,tau,j]); abline(v=cp[iter,tau,j],col=2);\n#       par(mfrow=c(1,1))\n#     }\n#   }\n# }\n# #cp\n# t(apply(cp,c(2,3),median))\n\n# #########################################################################################################################################\n# # Extracting Periodic signals\n# ## AM-demodulation via Elastic-Band Transform\n# #########################################################################################################################################\n# # FIG 1\n# fs=1000\n# t=-2000:2000/fs\n# v1=0.4*sin(2*pi*t)+1\n# v2=2*cos(20*pi*t)\n# v3=2*cos(20*pi*t)-2\n# f1=v1*v2;\n# f2=v1*v3;\n# AMebt1&lt;-ebt(f1,t,tau=100,V=\"volume\")\n# AMebt2&lt;-ebt(f2,t,tau=100,V=\"volume\")\n\n# pdf(paste(PATH, \"3-1]AM.pdf\", sep=\"\"), width=10, height=5)\n# par(mar=c(2.5,2.5,2.5,2.5))\n# par(mfrow=c(1,2))\n# vis(AMebt1,M=F,V=F,xlim=c(t[1500],t[2500]),band=1:100,ylim=c(-3,3),obs=\"lines\",bandlwd=0.5,main=\"(a)\")\n# lines(t,v1,col=2,lwd=2)\n# lines(t,AMebt1$U,col=4,lty=2,lwd=2)\n# lines(t,AMebt1$U/2,col=4,lty=2,lwd=2)\n# vis(AMebt2,M=F,V=F,xlim=c(t[1500],t[2500]),band=1:100,ylim=c(-8,2),obs=\"lines\",bandlwd=0.5,main=\"(b)\")\n# lines(t,v1,col=2,lwd=2)\n# lines(t,AMebt2$L,col=4,lty=2,lwd=2)\n# lines(t,AMebt2$L/(-4),col=4,lty=2,lwd=2)\n# dev.off() \n\n# #########################################################################################################################################\n# # Extracting Periodic signals\n# ## Decomposition\n# ### Noise Free Setting\n# #########################################################################################################################################\n# # FIG 1 \n# t=-2000:2000/1000\n# v1=cos(14*pi*t) #tau=142.8571\n# v2=cos(80*pi*t) #tau=25\n# f=v1+v2\n# ylim1&lt;-c(-2.5,2.5)\n# ebt1&lt;-ebt(f,t,tau=25,V=\"volume\")\n# ebt2&lt;-ebt(f-ebt1$M,t,tau=25,V=\"volume\")\n\n# pdf(paste(PATH, \"3-2]SignalExtraction_fig1.pdf\", sep=\"\"), width=7.5, height=4.5)\n# par(mar=c(2.5,2.5,2.5,2.5))\n# par(mfrow=c(3,2))\n# plot(t,v1,xlim=c(-0.5,0.5),ylim=ylim1, type='l',col=1, xlab=\"\",ylab=\"\",main=\"(a)\")\n# plot(t,v2,xlim=c(-0.5,0.5),ylim=ylim1, type='l',col=1, xlab=\"\",ylab=\"\",main=\"(b)\")\n# plot(t,v1+v2,xlim=c(-0.5,0.5),ylim=ylim1, type='l',col=1, xlab=\"\",ylab=\"\",main=\"(c)\")\n# plot(t,v1+v2,xlim=c(-0.5,0.5),ylim=ylim1, type='l', xlab=\"\",ylab=\"\",lwd=2,col=\"gray60\",main=\"(d)\")\n# lines(t,ebt1$M,col=2)\n# lines(t,ebt1$M+ebt1$V/2,col=3)\n# lines(t,ebt1$M-ebt1$V/2,col=3)\n# plot(t,f-ebt1$M,xlim=c(-0.5,0.5),ylim=ylim1 ,type='l',col=1 ,xlab=\"\",ylab=\"\",main=\"(e)\")\n# plot(t,f-ebt1$M-ebt2$M,xlim=c(-0.5,0.5),ylim=ylim1 ,type='l',col=1 ,xlab=\"\",ylab=\"\",main=\"(f)\")\n# dev.off() \n\n# # FIG 2\n# t=-2000:2000/1000\n# v1=swave(20,4001) #tau=40\n# v2=cos(7*pi*t) #tau=100\n# f=v1+v2\n# ylim1&lt;-c(-2.5,2.5)\n# ebt1&lt;-ebt(f,t,tau=40,V=\"volume\")\n# ebt2&lt;-ebt(f-ebt1$M,t,tau=40,V=\"volume\")\n\n# pdf(paste(PATH, \"3-2]SignalExtraction_fig2.pdf\", sep=\"\"), width=7.5, height=4.5)\n# par(mar=c(2.5,2.5,2.5,2.5))\n# par(mfrow=c(3,2))\n# plot(t,v1,xlim=c(-0.5,0.5),ylim=ylim1, type='l',col=1, xlab=\"\",ylab=\"\",lwd=1,main=\"(a)\")\n# plot(t,v2,xlim=c(-0.5,0.5),ylim=ylim1, type='l',col=1, xlab=\"\",ylab=\"\",lwd=1,main=\"(b)\")\n# plot(t,v1+v2,xlim=c(-0.5,0.5),ylim=ylim1, type='l',col=1, xlab=\"\",ylab=\"\",lwd=1,main=\"(c)\")\n# plot(t,v1+v2,xlim=c(-0.5,0.5),ylim=ylim1, type='l', xlab=\"\",ylab=\"\",lwd=1,col=\"gray60\",main=\"(d)\")\n# lines(t,ebt1$M,col=2,lwd=2)\n# lines(t,ebt1$M+ebt1$V/2,col=3,lwd=1)\n# lines(t,ebt1$M-ebt1$V/2,col=3,lwd=1)\n# plot(t,f-ebt1$M,xlim=c(-0.5,0.5),ylim=ylim1 ,type='l',col=1 ,xlab=\"\",ylab=\"\",lwd=1,main=\"(e)\")\n# plot(t,f-ebt1$M-ebt2$M,xlim=c(-0.5,0.5),ylim=ylim1 ,type='l',col=1 ,xlab=\"\",ylab=\"\",lwd=1,main=\"(f)\")\n# dev.off() \n\n# # FIG 3 \n# t=-2000:2000/1000\n# v1=cos(5*pi*t) #tau=100\n# v2=cos(50*pi*t) #tau=40\n# v3=cos(80*pi*t) #tau=25\n# f=v1+v2+v3\n# exf&lt;-extract.hfreq(t,f,tau=40,tol=0.00001,iter=0)\n# exf2&lt;-extract.hfreq(t,f,tau=40,tol=0.00001,iter=5)\n# exf3&lt;-extract.hfreq(t,f,tau=40,tol=0.00001,iter=20)\n# exf4&lt;-extract.hfreq(t,f,tau=40,tol=0.00001,iter=150)\n\n\n# pdf(paste(PATH, \"3-2]SignalExtraction_fig3.pdf\", sep=\"\"), width=7.5, height=4)\n# par(mar=c(2.5,2.5,2.5,2.5))\n# par(mfrow=c(2,3))\n# plot(t,f,xlim=c(-0.5,0.5),ylim=c(-3.5,3.5),type='l',col=1, xlab=\"\",ylab=\"\",main=\"(a)\",lwd=0.7)\n# plot(t,v2,xlim=c(-0.5,0.5),ylim=c(-3.5,3.5), type='l',col=1, xlab=\"\",ylab=\"\",main=\"(b)\",lwd=0.7)\n# plot(t,exf,xlim=c(-0.5,0.5),ylim=c(-3.5,3.5) ,type='l',col=1 ,xlab=\"\",ylab=\"\",main=\"(c)\",lwd=0.7)\n# plot(t,exf2,xlim=c(-0.5,0.5),ylim=c(-3.5,3.5) ,type='l',col=1 ,xlab=\"\",ylab=\"\",main=\"(d)\",lwd=0.7)\n# plot(t,exf3,xlim=c(-0.5,0.5),ylim=c(-3.5,3.5) ,type='l',col=1 ,xlab=\"\",ylab=\"\",main=\"(e)\",lwd=0.7)\n# plot(t,exf4,xlim=c(-0.5,0.5),ylim=c(-3.5,3.5) ,type='l',col=1,xlab=\"\",ylab=\"\",main=\"(f)\",lwd=0.7)\n# dev.off() \n\n# # FIG 4 \n# t=-2000:2000/1000\n# v1=cos(5*pi*t) #tau=100\n# v2=cos(50*pi*t) #tau=40\n# v3=cos(80*pi*t) #tau=25\n# f=v1+v2+v3\n# mode1&lt;-extract.hfreq(t,f,tau=25,tol=0.000000001,iter=10)\n# mode2&lt;-extract.hfreq(t,f-mode1,tau=40,tol=0.000000001,iter=1)\n# mode3&lt;-f-mode1-mode2\n\n# pdf(paste(PATH, \"3-2]SignalExtraction_fig4.pdf\", sep=\"\"), width=7.5, height=5)\n# m &lt;- matrix(c(1,2,2,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11),nrow = 4,ncol = 4,byrow = TRUE)\n# layout(mat = m)\n# par(mar=c(2.5,2.5,2.5,2.5))\n# plot(1, type=\"n\", axes=F, xlab=\"\", ylab=\"\")\n# plot(t,f,xlim=c(-0.5,0.5),ylim=c(-4,4),xlab=\"\",ylab=\"\",type='l',main=\"(a)\")\n# plot(1, type=\"n\", axes=F, xlab=\"\", ylab=\"\")\n# plot(t,v1,xlim=c(-0.5,0.5),ylim=c(-4,4),type='l',col=1, xlab=\"\",ylab=\"\",main=\"(b)\")\n# plot(t,mode3,xlim=c(-0.5,0.5),ylim=c(-4,4) ,type='l',col=1 ,xlab=\"\",ylab=\"\",main=\"(c)\")\n# plot(t,v2,xlim=c(-0.5,0.5),ylim=c(-4,4), type='l',col=1, xlab=\"\",ylab=\"\",main=\"(d)\")\n# plot(t,mode2,xlim=c(-0.5,0.5),ylim=c(-4,4) ,type='l',col=1 ,xlab=\"\",ylab=\"\",main=\"(e)\")\n# plot(t,v3,xlim=c(-0.5,0.5),ylim=c(-4,4) ,type='l',col=1 ,xlab=\"\",ylab=\"\",main=\"(f)\")\n# plot(t,mode1,xlim=c(-0.5,0.5),ylim=c(-4,4) ,type='l',xlab=\"\",ylab=\"\",main=\"(g)\")\n# dev.off() \n\n# # FIG 5 \n# t=-2000:2000/1000\n# v1=cos(2*pi*t) \n# v2=c(rep(0,1500),0.5*cos(40*pi*t[1500:1600]),rep(0,2400)) # tau=50\n# v3=c(rep(0,2000),0.5*cos(40*pi*t[2000:2200]),rep(0,1800)) # tau=50\n# v4=c(rep(0,2500),0.5*cos(40*pi*t[2500:2700]),rep(0,1300)) \n# f=v1+v2+v3+v4;\n# plot(t,f,xlim=c(-1,1),type='l')\n# plot(t,v2+v3+v4,xlim=c(-1,1),type='l')\n# ext3&lt;-extract.hfreq(t,f,tau=200)\n\n# library(EMD)\n# try &lt;- emd(f, t, boundary=\"wave\")\n# # \n# # ### Ploting the IMF's\n# # par(mfrow=c(try$nimf+1, 1), mar=c(2,1,2,1))\n# # rangeimf &lt;- range(try$imf)\n# # for(i in 1:try$nimf) {\n# #   plot(t, try$imf[,i], type=\"l\", xlab=\"\", ylab=\"\", ylim=rangeimf,\n# #        main=paste(i, \"-th IMF\", sep=\"\")); abline(h=0)\n# # }\n# # plot(t, try$residue, xlab=\"\", ylab=\"\", main=\"residue\", type=\"l\", axes=FALSE); box()\n\n# pdf(paste(PATH, \"3-2]SignalExtraction_fig5.pdf\", sep=\"\"), width=7.5, height=7)\n# m &lt;- matrix(c(1,2,2,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11),nrow = 5,ncol = 4,byrow = TRUE)\n# layout(mat = m)\n# par(mar=c(2.5,2.5,2.5,2.5))\n# plot(1, type=\"n\", axes=F, xlab=\"\", ylab=\"\")\n# plot(t,f,xlim=c(-1,1),ylim=c(-1.8,1.5),xlab=\"\",ylab=\"\",type='l',main=\"(a)\")\n# plot(1, type=\"n\", axes=F, xlab=\"\", ylab=\"\")\n# plot(t,ext3,xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',xlab=\"\",ylab=\"\",lty=1,main=\"(b)\")\n# plot(t,try$imf[,1],xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',main=\"(c)\")\n# plot(t,f-ext3,xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',xlab=\"\",ylab=\"\",lty=1,main=\"(d)\")\n# plot(t,try$imf[,2],xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',main=\"(e)\")\n# plot(1, type=\"n\", axes=F, xlab=\"\", ylab=\"\")\n# plot(t,try$imf[,3],xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',main=\"(f)\")\n# plot(1, type=\"n\", axes=F, xlab=\"\", ylab=\"\")\n# plot(t,try$residue,xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',main=\"(g)\")\n# dev.off()\n\n# # FIG 6\n# t=-2000:2000/1000\n# v1=t*c(cos(14*pi*t[1:2000]),rep(0,2001))\n# v2=-t*c(rep(0,2000),cos(80*pi*t[2001:4001]))\n# f=v1+v2;\n# ext3&lt;-extract.hfreq(t,f,tau=25)\n# try &lt;- emd(f, t, boundary=\"wave\")\n# # ### Ploting the IMF's\n# # par(mfrow=c(try$nimf+1, 1), mar=c(2,1,2,1))\n# # rangeimf &lt;- range(try$imf)\n# # for(i in 1:try$nimf) {\n# #   plot(t, try$imf[,i], type=\"l\", xlab=\"\", ylab=\"\", ylim=rangeimf,\n# #        main=paste(i, \"-th IMF\", sep=\"\")); abline(h=0)\n# # }\n# # plot(t, try$residue, xlab=\"\", ylab=\"\", main=\"residue\", type=\"l\", axes=FALSE); box()\n\n\n# pdf(paste(PATH, \"3-2]SignalExtraction_fig6.pdf\", sep=\"\"), width=7.5, height=8)\n# m &lt;- matrix(c(1,2,2,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11,12,12,13,13),nrow = 6,ncol = 4,byrow = TRUE)\n# layout(mat = m)\n# par(mar=c(2.5,2.5,2.5,2.5))\n# plot(1, type=\"n\", axes=F, xlab=\"\", ylab=\"\")\n# plot(t,f,xlim=c(-1,1),ylim=c(-1.8,1.5),xlab=\"\",ylab=\"\",type='l',main=\"(a)\")\n# plot(1, type=\"n\", axes=F, xlab=\"\", ylab=\"\")\n# plot(t,ext3,xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',xlab=\"\",ylab=\"\",lty=1,main=\"(b)\")\n# plot(t,try$imf[,1],xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',main=\"(c)\")\n# plot(t,f-ext3,xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',xlab=\"\",ylab=\"\",lty=1,main=\"(d)\")\n# plot(t,try$imf[,2],xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',main=\"(e)\")\n# plot(1, type=\"n\", axes=F, xlab=\"\", ylab=\"\")\n# plot(t,try$imf[,3],xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',main=\"(f)\")\n# plot(1, type=\"n\", axes=F, xlab=\"\", ylab=\"\")\n# plot(t,try$imf[,4],xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',main=\"(g)\")\n# plot(1, type=\"n\", axes=F, xlab=\"\", ylab=\"\")\n# plot(t,try$residue,xlim=c(-1,1),ylim=c(-1.8,1.5),type='l',main=\"(h)\")\n# dev.off() \n\n\n# #########################################################################################################################################\n# # Designing Filter by Elastic Band Transform \n# ## Extracting Signal with Noise\n# #########################################################################################################################################\n# # FIG 1 \n# pdf(paste(PATH, \"4-2]DenoisingPeriodicSignal_fig1.pdf\", sep=\"\"), width=7, height=7)\n# par(mar=c(2.3,2.3,2.3,2.3))\n# par(mfrow=c(4,1))\n# t=-2000:2000/1000\n# v1=cos(200*pi*t) #tau=10\n# v2=swave(5,4001) #tau=10\n# snr&lt;-3\n# noise1&lt;-rnorm(4001,mean=0,sd=sd((v1)/snr))  \n# noise2&lt;-rnorm(4001,mean=0,sd=sd((v2)/snr))  \n# f1=v1+noise\n# f2=v2+noise\n# plot(t,f1,xlim=c(-0.1,0.1),type='l',ylim=c(-2.5,2.5),main=\"(a)\")\n# plot(t,f1,xlim=c(-0.1,0.1),ylim=c(-2.5,2.5),col=\"gray60\",xlab=\"\",ylab=\"\",cex=0.9,main=\"(b)\")\n# lines(t,v1hat,col=2)\n# lines(t,v1,col=1, lty=2)\n# plot(t,f2,xlim=c(-0.1,0.1),type='l',ylim=c(-2.5,2.5),main=\"(c)\")\n# # v1hat&lt;-extract.hfreq(t,f1,tau=10,tol=0.00000000000000005,iter=1000)\n# # v2hat&lt;-extract.hfreq(t,f2,tau=10,tol=0.00000000000000005,iter=1000)\n# plot(t,f2,xlim=c(-0.1,0.1),ylim=c(-2.5,2.5),col=\"gray60\",xlab=\"\",ylab=\"\",cex=0.9,main=\"(d)\")\n# lines(t,v2hat,col=2)\n# lines(t,v2,col=1, lty=2)\n# dev.off() \n\n\n# #########################################################################################################################################\n# # Denosing technique with elastic band transform\n# ## Nadaraya-Watson Kernel Estimator\n# #########################################################################################################################################\n# # FIG 1 \n# t=-2000:2000/1000\n# f1&lt;-25\n# v1=cos(f1*pi*t) #tau=40\n# snr&lt;-3\n# set.seed(1)\n# noise&lt;-rnorm(4001,mean=0,sd=sd(v1)/snr)\n# f=v1+noise\n# len=length(f)\n# omega_hat&lt;-seq(from=0,to=pi,len=ceiling(len/2))\n# fft_f&lt;-c(1-(1-abs(fft(f))[((len+1)/2):len]),1-(1-abs(fft(f))[1:((len+1)/2-1)]))/len\n# lwd=1.5\n# col=\"gray40\"\n\n# pdf(paste(PATH, \"4-1]NadarayaWatsonKernelEstimator_fig1.pdf\", sep=\"\"), width=7, height=5)\n# xlim=c(-0.05,0.05)\n# par(mar=c(2.5,2.5,2.5,2.5))\n# par(mfrow=c(4,2))\n# plot(t,f,xlim=xlim,ylim=c(-1.5,1.5),col=col,xlab=\"\",ylab=\"\",cex=0.9)\n# lines(t,v1,lty=2)\n# lines(t,ebt(f,tau=5)$M,col=2)\n# get.h(f,tau=5,plot=T,log=T)\n# lines(omega_hat,fft_f[ceiling(len/2):1],col=col,lwd=lwd)\n\n# plot(t,f,xlim=xlim,ylim=c(-1.5,1.5),col=col,xlab=\"\",ylab=\"\",cex=0.9)\n# lines(t,v1,lty=2)\n# lines(t,ebt(f,tau=20)$M,col=2)\n# get.h(f,tau=20,plot=T,log=T)\n# lines(omega_hat,fft_f[ceiling(len/2):1],col=col,lwd=lwd)\n\n# plot(t,f,xlim=xlim,ylim=c(-1.5,1.5),col=col,xlab=\"\",ylab=\"\",cex=0.9)\n# lines(t,v1,lty=2)\n# lines(t,ebt(f,tau=40)$M,col=2)\n# get.h(f,tau=40,plot=T,log=T)\n# lines(omega_hat,fft_f[ceiling(len/2):1],col=col,lwd=lwd)\n\n# plot(t,f,xlim=xlim,ylim=c(-1.5,1.5),col=col,xlab=\"\",ylab=\"\",cex=0.9)\n# lines(t,v1,lty=2)\n# lines(t,ebt(f,tau=60)$M,col=2)\n# get.h(f,tau=60,plot=T,log=T)\n# lines(omega_hat,fft_f[ceiling(len/2):1],col=col,lwd=lwd)\n# dev.off() \n# # \n# # # FIG 2\n# # t=-2000:2000/1000\n# # f1&lt;-25\n# # v1=cos(f1*pi*t) #tau=40\n# # snr&lt;-3\n# # set.seed(1)\n# # noise&lt;-rnorm(4001,mean=0,sd=sd(v1)/snr)\n# # f=v1+noise\n# # \n# # \n# # pdf(paste(PATH, \"5-1]NadarayaWatsonKernelEstimator_fig2.pdf\", sep=\"\"), width=7, height=4)\n# # par(mar=c(2.5,2.5,2.5,2.5))\n# # par(mfrow=c(3,2))\n# # plot(omega_hat,fft_f,type='l',xlab=\"\",ylab=\"\",main=\"(a)\",col=\"gray60\",ylim=c(0,1)) ## plot \n# # get.h(f,tau=5,main=\"(b)\",plot=T)\n# # lines(omega_hat,fft_f,col=\"gray60\")\n# # get.h(f,tau=20,main=\"(c)\",plot=T)\n# # lines(omega_hat,fft_f,col=\"gray60\")\n# # get.h(f,tau=40,main=\"(d)\",plot=T)\n# # lines(omega_hat,fft_f,col=\"gray60\")\n# # get.h(f,tau=60,main=\"(e)\",plot=T)\n# # lines(omega_hat,fft_f,col=\"gray60\")\n# # get.h(f,tau=80,main=\"(f)\",plot=T)\n# # lines(omega_hat,fft_f,col=\"gray60\")\n# # dev.off() \n\n# #########################################################################################################################################\n# # Denosing technique with elastic band transform\n# ## Design Denoising Filter\n# #########################################################################################################################################\n\n# # FIG 1\n# len=4001\n# pdf(paste(PATH, \"4-2]DesignDenoisingFilter_fig1.pdf\", sep=\"\"), width=8, height=3)\n# par(mar=c(2.5,2.5,2.5,2.5))\n# par(mfrow=c(2,2))\n# main=c(\"(a)\",\"(b)\",\"(c)\",\"(d)\")\n# taulist=c(5,20,40,60)\n# for(k in 1:4)\n# {\n#   h&lt;-c(rep(0,len-(taulist[k]-1)),1:taulist[k],(taulist[k]-1):1,rep(0,len-taulist[k]))/taulist[k]^2\n#   omega_hat&lt;-seq(from=-pi,to=pi,len=len*2)\n#   iter=1\n#   H&lt;-c(1-(1-abs(fft(h))[(len+1):(2*len)])^iter,1-(1-abs(fft(h))[1:len])^iter)\n#   plot(omega_hat[omega_hat&gt;0],H[omega_hat&gt;0],type='l',xlab=\"\",ylab=\"\",main=main[k],log=\"x\")\n#   index1&lt;-which((H^2-0.5)^2==min((H^2-0.5)^2))[1]\n#   index2&lt;-8000-index1\n#   Ideal&lt;-0*H\n#   Ideal[index1:index2]&lt;-1\n#   lines(omega_hat[omega_hat&gt;0],Ideal[omega_hat&gt;0],col=2,lty=2,lwd=1)\n# }\n# dev.off()\n\n# # FIG 2\n# t=-2000:2000/1000\n# f1&lt;-25\n# v1=cos(f1*pi*t) #tau=40\n# snr&lt;-3\n# set.seed(1)\n# noise&lt;-rnorm(4001,mean=0,sd=sd(v1)/snr)\n# f=v1+noise\n# len=length(f)\n# omega_hat&lt;-seq(from=-pi,to=pi,len=len)\n# fft_f&lt;-c(1-(1-abs(fft(f))[((len+1)/2):len]),1-(1-abs(fft(f))[1:((len+1)/2-1)]))/len\n# df1_tau20&lt;-ebt(f,t,tau=20)$M\n# df2_tau20&lt;-f-extract.hfreq(t,f,tau=20,iter=1)\n# df3_tau20&lt;-f-extract.hfreq(t,f,tau=20,iter=2)\n# df4_tau20&lt;-f-extract.hfreq(t,f,tau=20,iter=3)\n\n# df1_tau40&lt;-ebt(f,t,tau=40)$M\n# df2_tau40&lt;-f-extract.hfreq(t,f,tau=40,iter=1)\n# df3_tau40&lt;-f-extract.hfreq(t,f,tau=40,iter=2)\n# df4_tau40&lt;-f-extract.hfreq(t,f,tau=40,iter=3)\n\n# pdf(paste(PATH, \"4-2]DesignDenoisingFilter_fig2.pdf\", sep=\"\"), width=8, height=6)\n# par(mar=c(2.5,2.5,2.5,2.5))\n# par(mfrow=c(4,2))\n# plot(t,f,xlim=xlim,col=\"gray60\",xlab=\"\",ylab=\"\")\n# lines(t,v1,col=1,lty=2)\n# lines(t,df1_tau20,col=2,lwd=1)\n# lines(t,df1_tau40,col=4,lwd=1)\n# get.h(f,tau=20,plot=T,iter=1,log=T,col=2)\n# h40&lt;-get.h(f,tau=40,plot=F,iter=1,log=F);\n# lines(h40$omega_hat[h40$omega_hat&gt;0],h40$H_iter[h40$omega_hat&gt;0],col=4)\n# lines(omega_hat[h40$omega_hat&gt;0],fft_f[h40$omega_hat&gt;0],col=\"gray60\")\n\n# plot(t,f,xlim=xlim,col=\"gray60\",xlab=\"\",ylab=\"\")\n# lines(t,v1,col=1,lty=2)\n# lines(t,df2_tau20,col=2,lwd=1)\n# lines(t,df2_tau40,col=4,lwd=1)\n# get.h(f,tau=20,plot=T,iter=2,log=T,col=2)\n# h40&lt;-get.h(f,tau=40,plot=F,iter=2,log=F);\n# lines(h40$omega_hat[h40$omega_hat&gt;0],h40$H_iter[h40$omega_hat&gt;0],col=4)\n# lines(omega_hat[h40$omega_hat&gt;0],fft_f[h40$omega_hat&gt;0],col=\"gray60\")\n\n# plot(t,f,xlim=xlim,col=\"gray60\",xlab=\"\",ylab=\"\")\n# lines(t,v1,col=1,lty=2)\n# lines(t,df3_tau20,col=2,lwd=1)\n# lines(t,df3_tau40,col=4,lwd=1)\n# get.h(f,tau=20,plot=T,iter=3,log=T,col=2)\n# h40&lt;-get.h(f,tau=40,plot=F,iter=3,log=F);\n# lines(h40$omega_hat[h40$omega_hat&gt;0],h40$H_iter[h40$omega_hat&gt;0],col=4)\n# lines(omega_hat[h40$omega_hat&gt;0],fft_f[h40$omega_hat&gt;0],col=\"gray60\")\n\n# plot(t,f,xlim=xlim,col=\"gray60\",xlab=\"\",ylab=\"\")\n# lines(t,v1,col=1,lty=2)\n# lines(t,df4_tau20,col=2,lwd=1)\n# lines(t,df4_tau40,col=4,lwd=1)\n# get.h(f,tau=20,plot=T,iter=4,log=T,col=2)\n# h40&lt;-get.h(f,tau=40,plot=F,iter=4,log=F);\n# lines(h40$omega_hat[h40$omega_hat&gt;0],h40$H_iter[h40$omega_hat&gt;0],col=4)\n# lines(omega_hat[h40$omega_hat&gt;0],fft_f[h40$omega_hat&gt;0],col=\"gray60\")\n# dev.off() \n\n# # \n# # # FIG 3\n# # t=-2000:2000/1000\n# # f1&lt;-25\n# # v1=cos(f1*pi*t) #tau=40\n# # snr&lt;-3\n# # set.seed(1)\n# # noise&lt;-rnorm(4001,mean=0,sd=sd(v1)/snr)\n# # f=v1+noise\n# # len=length(f)\n# # omega_hat&lt;-seq(from=-pi,to=pi,len=len)\n# # fft_f&lt;-c(1-(1-abs(fft(f))[((len+1)/2):len]),1-(1-abs(fft(f))[1:((len+1)/2-1)]))/len\n# # df1&lt;-ebt(f,t,tau=40)$M\n# # df2&lt;-f-extract.hfreq(t,f,tau=40,iter=1)\n# # df3&lt;-f-extract.hfreq(t,f,tau=40,iter=2)\n# # df4&lt;-f-extract.hfreq(t,f,tau=40,iter=3)\n# # \n# # pdf(paste(PATH, \"5-2]DesignDenoisingFilter_fig3.pdf\", sep=\"\"), width=8, height=6)\n# # par(mar=c(2.5,2.5,2.5,2.5))\n# # par(mfrow=c(4,2))\n# # plot(t,f,xlim=xlim,col=\"gray60\",xlab=\"\",ylab=\"\",main=\"(a)\")\n# # lines(t,v1,col=1,lty=2)\n# # lines(t,df1,col=2,lwd=1)\n# # get.h(f,tau=40,main=\"(b)\",plot=T,iter=1)\n# # lines(omega_hat,fft_f,col=\"gray60\")\n# # plot(t,f,xlim=xlim,col=\"gray60\",xlab=\"\",ylab=\"\",main=\"(c)\")\n# # lines(t,v1,col=1,lty=2)\n# # lines(t,df2,col=2,lwd=1)\n# # get.h(f,tau=40,main=\"(d)\",plot=T,iter=2)\n# # lines(omega_hat,fft_f,col=\"gray60\")\n# # plot(t,f,xlim=xlim,col=\"gray60\",xlab=\"\",ylab=\"\",main=\"(e)\")\n# # lines(t,v1,col=1,lty=2)\n# # lines(t,df3,col=2,lwd=1)\n# # get.h(f,tau=40,main=\"(f)\",plot=T,iter=3)\n# # lines(omega_hat,fft_f,col=\"gray60\")\n# # plot(t,f,xlim=xlim,col=\"gray60\",xlab=\"\",ylab=\"\",main=\"(g)\")\n# # lines(t,v1,col=1,lty=2)\n# # lines(t,df4,col=2,lwd=1)\n# # get.h(f,tau=40,main=\"(h)\",plot=T,iter=4)\n# # lines(omega_hat,fft_f,col=\"gray60\")\n# # dev.off() \n\n\n# #########################################################################################################################################\n# # Denosing technique with elastic band transform\n# ## Data-adaptive $\\tau$ selection  \n# #########################################################################################################################################\n# # FIG 1 \n# library(wavethresh)\n# donoho.noise&lt;-DJ.EX(n=1000, signal=1, rsnr=5, noisy=TRUE, plotfn=FALSE)\n# donoho&lt;-DJ.EX(n=1000, signal=1, rsnr=5, noisy=FALSE, plotfn=FALSE)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n\n# VM&lt;-list()\n# df&lt;-list()\n# lambda&lt;-c(0.08,0.2,0.045,0.06)\n# iter&lt;-c(1,1,4,1)\n# pdf(paste(PATH, \"4-3]DataAdaptiveTauSelection_fig1.pdf\", sep=\"\"), width=8, height=6)\n# par(mfrow=c(4,3))\n# for(i in 1:4)\n# {\n#   par(mar=c(2.5,2.5,2.5,2.5))\n#   f&lt;-donoho.noise[[i]]\n#   plot(f,type='l',xlab=\"\",ylab=\"\",col=\"gray60\")\n#   maxtau=50\n#   len&lt;-length(f)\n#   VM[[i]]&lt;-Vmap(f,maxtau=maxtau,M=\"mean\",V=\"var\")\n#   mintau&lt;-5\n#   par(mar=c(2.5,1,2.5,3.5))\n#   image.plot(x=1:len,y=mintau:maxtau,z=VM[[i]][1:len,mintau:maxtau],xlab=\"\",ylab=\"\",legend.mar=2)\n#   #contour(x=1:len,y=mintau:maxtau,z=VM[[i]][1:len,mintau:maxtau],add = TRUE, nlevels = 3)\n#   par(mar=c(2.5,3.5,2.5,2.5))\n#   df[[i]]&lt;-denoise3(t=1:1000,donoho.noise[[i]],tau.list=50:3,lambda=lambda[i],iter=iter[i])\n#   plot(df[[i]],type='l',ylab=\"\")\n#   lines(donoho.noise[[i]],col=\"gray60\",lwd=0.7)\n#   lines(df[[i]],lwd=1.2)\n# }\n# par(mfrow=c(1,1))\n# dev.off() \n\n\n# #########################################################################################################################################\n# # Real Data Analysis\n# #########################################################################################################################################\n\n# library(wavelets)\n# data(ecg)\n# ecg&lt;-as.vector(ecg)\n# t=1:length(ecg)\n# ext&lt;-extract.hfreq(t,ecg,tau=132)\n# ext.df1&lt;-denoise3(t,ext,tau.list=35:2,tol=0.005,lambda=0.01)\n# ext.df2&lt;-denoise3(t,ext,tau.list=35:2,tol=0.005,lambda=0.02)\n# ext.df3&lt;-denoise3(t,ext,tau.list=35:2,tol=0.0005,lambda=0.035)\n# ext.df4&lt;-denoise3(t,ext,tau.list=15:2,tol=0.05,lambda=0.1)\n\n# pdf(paste(PATH, \"5]RealDataAnalysis_fig1.pdf\", sep=\"\"), width=10,height=10)\n# par(mar=c(2.5,2.5,2.5,2.5))\n# par(mfrow=c(4,1))\n# plot(t,ecg,type='l',xlab=\"\",ylab=\"\",ylim=c(-1.5,1.8),main=\"(a)\")\n# plot(t,ecg-ext,type='l',xlab=\"\",ylab=\"\",ylim=c(-1.5,1.8),lwd=1,main=\"(b)\")\n# plot(t,ext,type='l',xlab=\"\",ylab=\"\",ylim=c(-1.5,1.8),lwd=1,main=\"(c)\")\n# plot(t,ext.df4,type='l',xlab=\"\",ylab=\"\",ylim=c(-1.5,1.8),lwd=1,main=\"(d)\")\n# #plot(t,ext-ext.df3,type='l',xlab=\"\",ylab=\"\",ylim=c(-1.5,1.5),lwd=1,main=\"(e)\")\n# dev.off()"
  },
  {
    "objectID": "연구/교수님이랑/MS_Review/ENV.html",
    "href": "연구/교수님이랑/MS_Review/ENV.html",
    "title": "(연구&교수님) 다중척도논문 – 환경설정",
    "section": "",
    "text": "conda install -c conda-forge r-essentials\nconda install conda-forge::scikit-learn\npip install rpy2\nconda install -c conda-forge pywavelets\npip install matplotlib\nconda install conda-forge::r-devtools\ninstall.packages(\"SiZer\")\nconda install conda-forge::librosa\nconda install -c conda-forge statsmodels\nconda install conda-forge::r-magick"
  },
  {
    "objectID": "연구/교수님이랑/MS_Review/STFT.html",
    "href": "연구/교수님이랑/MS_Review/STFT.html",
    "title": "(연구&교수님) 다중척도논문 – STFT",
    "section": "",
    "text": "주파수 변조 신호의 수식\n\n시간 \\(t\\) 에 따른 주파수 \\(f(t)\\) 는 다음과 같이 선형적으로 증가합니다: \\[\nf(t) = f_0 + \\frac{f_1 - f_0}{T} t\n\\] 여기서 \\(f_0\\) 는 시작 주파수, \\(f_1\\) 는 종료 주파수, \\(T\\) 는 전체 신호의 지속 시간입니다.\n즉각적인 주파수에 따른 각주파수 \\(\\omega(t)\\) 는 다음과 같습니다: \\[\\omega(t) = 2 \\pi f(t) = 2 \\pi \\left( f_0 + \\frac{f_1 - f_0}{T} t\\right)\n\\]\n각주파수 \\(\\omega(t)\\) 를 시간에 대해 적분하면 위상 \\(\\phi(t)\\) 를 얻을 수 있습니다: \\[\n\\phi(t) = \\int \\omega(t) \\, dt = \\int 2 \\pi \\left( f_0 + \\frac{f_1 - f_0}{T} t \\right) dt\n\\]\n위상 \\(\\phi(t)\\) 는 다음과 같이 계산됩니다: \\[\n\\phi(t) = 2 \\pi \\left( f_0 t + \\frac{f_1 - f_0}{T} \\frac{t^2}{2} \\right)\n\\]\n따라서 신호 \\(x(t)\\) 는 다음과 같이 표현됩니다: \\[\nx(t) = \\sin(\\phi(t)) = \\sin \\left( 2 \\pi \\left( f_0 t + \\frac{f_1 - f_0}{T} \\frac{t^2}{2} \\right) \\right)\n\\]\n\n\n\n예제 신호에 적용\n주어진 예제에서 \\(f_0 = 50\\) Hz, \\(f_1 = 300\\) Hz, \\(T = 2\\) 초이므로, 신호는 다음과 같습니다: \\[\nx(t) = \\sin \\left( 2 \\pi \\left( 50t + \\frac{300 - 50}{2} \\frac{t^2}{2} \\right) \\right) = \\sin \\left( 2 \\pi \\left( 50t + 125t^2 \\right) \\right)\n\\]\n따라서, 예제에서 사용된 신호의 수식은 다음과 같습니다: \\[\nx(t) = \\sin \\left( 2 \\pi \\left( 50t + 125t^2 \\right) \\right)\n\\]\n이 수식은 시간 \\(t\\) 에 따라 주파수가 선형적으로 증가하는 신호를 정확하게 나타냅니다.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.fft import fft, fftfreq\nfrom scipy.signal import stft\nfrom matplotlib.colors import LinearSegmentedColormap\nplt.rcParams['text.usetex'] = True\n# Define a custom colormap\ncolors = [\n    (0.0, 0.0, 0.0),    # Black\n    (0.2, 0.0, 0.3),    # Dark Purple\n    (0.4, 0.0, 0.5),    # Purple\n    (0.6, 0.0, 0.7),    # Bright Purple\n    (0.8, 0.3, 0.7),    # Light Purple\n    (1.0, 0.7, 0.4)     # Yellow/Orange\n]\ncmap = LinearSegmentedColormap.from_list(\"custom_cmap\", colors, N=256)\n\n# 샘플링 주파수 및 시간 축 설정\nfs = 10000\nt = np.linspace(0, 2, 2 * fs, endpoint=False)\n\n# 주파수가 선형적으로 증가하는 신호 생성\nf0 = 50  # 시작 주파수\nf1 = 300  # 종료 주파수\nsignal = np.sin(2 * np.pi * (f0 + (f1 - f0)/2 * t/2) * t)\n\n# 푸리에 변환 수행\nyf = fft(signal)\nxf = fftfreq(len(t), 1 / fs)\n\n# STFT 수행\nf, t_stft, Zxx = stft(signal, fs, nperseg=256)\n\n# 그림 생성\nfig, axes = plt.subplots(3, 1, figsize=(10, 10), tight_layout=True)\n\n# 원 신호\naxes[0].plot(t, signal,color='k',linewidth=0.3)\naxes[0].set_title(r\"Time-varying Frequency Signal\")\naxes[0].set_xlabel(\"Time [s]\")\naxes[0].set_ylabel(\"Amplitude\")\n\n# 푸리에 변환 결과\naxes[1].plot(xf, np.abs(yf),color='k',linewidth=0.3)\naxes[1].set_title(\"Frequency Spectrum: DFT of the Signal\")\naxes[1].set_xlabel(\"Frequency [Hz]\")\naxes[1].set_ylabel(\"Amplitude\")\naxes[1].set_xlim(0, 400)\n\n# STFT 결과\nim = axes[2].pcolormesh(t_stft, f, np.abs(Zxx), shading='gouraud', cmap=cmap)\naxes[2].set_title(\"Spectrogram: DSTFT of the Signal\")\naxes[2].set_xlabel(\"Time [s]\")\naxes[2].set_ylabel(\"Frequency [Hz]\")\naxes[2].set_ylim(0, 400)\n\n# Color bar below the STFT plot\ncbar = fig.colorbar(im, ax=axes[2], orientation='horizontal', pad=0.2)\ncbar.set_label('Magnitude')\n\n# 그림 저장\nplt.tight_layout()\nplt.savefig(\"./Dropbox/03_Yechan3/연구/교수님이랑/MS_Review/signal_analysis.pdf\")\nplt.show()\n\n\n\n\n\n\n\n\nThe provided figures illustrate the analysis of a signal whose frequency varies linearly over time. The analysis consists of three main parts: the time-domain signal, its Fourier Transform, and its Short-Time Fourier Transform (STFT).\nThe top plot shows the signal in the time domain. This signal starts at a low frequency of 50 Hz and linearly increases to a high frequency of 300 Hz over a span of 2 seconds. The mathematical representation of this signal is ( s(t) = (2(f_0 + t) t) ), where ( f_0 ) is the initial frequency and ( f_1 ) is the final frequency. This plot provides a clear view of how the signal’s amplitude varies with time.\nThe middle plot depicts the Fourier Transform of the signal, displaying the frequency spectrum. The x-axis represents the frequency in Hz, and the y-axis indicates the amplitude of each frequency component. Unlike a pure sine wave, which would show a single peak at a specific frequency, this plot reveals a spread of frequencies. This spread occurs because the signal’s frequency changes over time, causing it to contain multiple frequency components simultaneously. However, this plot does not convey when these frequency changes occur.\nThe bottom plot presents the STFT of the signal, providing a time-frequency representation. Here, the x-axis represents time in seconds, the y-axis represents frequency in Hz, and the color intensity indicates the magnitude of the frequency components. The STFT divides the signal into short segments and computes the Fourier Transform for each segment, thereby revealing how the frequency content of the signal evolves over time. This plot clearly shows the linear increase in frequency from 50 Hz to 300 Hz as time progresses, offering a detailed view of the signal’s time-varying frequency characteristics.\nThe key points of comparison between the Fourier Transform and STFT are as follows:\n\nInclusion of Time Information:\n\nFourier Transform: It provides the frequency components of the entire signal without any information about when these frequencies occur. This makes it useful for analyzing the overall frequency content but not for understanding time-dependent changes.\nSTFT: It includes both time and frequency information, allowing us to observe how the frequency content of the signal changes over time. This is essential for analyzing signals with time-varying frequencies.\n\nTime-Frequency Resolution:\n\nFourier Transform: It offers high frequency resolution but no time resolution, as it considers the entire signal duration.\nSTFT: It provides a trade-off between time and frequency resolution. By segmenting the signal into smaller time windows, STFT sacrifices some frequency resolution to gain time resolution, making it possible to track changes in frequency over time.\n\nDetection of Frequency Changes:\n\nFourier Transform: While it can detect the presence of multiple frequency components, it cannot indicate when these changes occur within the signal.\nSTFT: It clearly shows when frequency changes happen, as illustrated by the linear increase in frequency over time in the STFT plot. This makes STFT particularly useful for signals with non-stationary frequency content.\n\n\nBoth the Fourier Transform and STFT are powerful tools for signal analysis, but they serve different purposes. The Fourier Transform is ideal for identifying the overall frequency components of a signal, whereas the STFT is better suited for analyzing signals whose frequency content changes over time. In this analysis, the STFT provides a comprehensive view of the time-varying frequency characteristics of the signal, highlighting its ability to capture the dynamic nature of the signal’s frequency evolution."
  },
  {
    "objectID": "연구/교수님이랑/MS_Review/librosa.html",
    "href": "연구/교수님이랑/MS_Review/librosa.html",
    "title": "(연구&교수님) 다중척도논문 – librosa",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nimport librosa\nimport librosa.display\nimport pywt\nimport soundfile as sf\nplt.rcParams['text.usetex'] = True\n\n\n\n# 바이올린과 피아노 샘플 로드\nviolin_audio, sr = librosa.load(librosa.example('trumpet'), sr=None, duration=5.0)\npiano_audio, sr = librosa.load(librosa.example('brahms'), sr=None, duration=5.0)\n# 파일로 저장\nsf.write('./violin_sample.wav', violin_audio, sr)\nsf.write('./piano_sample.wav', piano_audio, sr)\n\n\n# 샘플레이트 설정\nsr = 22050\nduration = 5 \n# 오디오 파일 로드\ntrumpet_audio, sr = librosa.load(librosa.ex('trumpet'), sr=sr, duration=5.0)\nbrahms_audio, sr = librosa.load(librosa.ex('brahms'), sr=sr, duration=5.0)\nchoice_audio, sr = librosa.load(librosa.ex('choice'), sr=sr, duration=5.0)\nfishin_audio, sr = librosa.load(librosa.ex('fishin'), sr=sr, duration=5.0)\nvibeace_audio, sr = librosa.load(librosa.ex('vibeace'), sr=sr, duration=5.0)\nnutcracker_audio, sr = librosa.load(librosa.ex('nutcracker'), sr=sr, duration=5.0)\n\n\n# 오디오 신호 리스트\nsignals = {\n    'Trumpet': trumpet_audio,\n    'Brahms': brahms_audio,\n    'Choice': choice_audio,\n    'Fishin': fishin_audio,\n    'Vibeace': vibeace_audio,\n    'Nutcracker': nutcracker_audio\n}\n\n# STFT와 CWT 수행 및 시각화\nplt.figure(figsize=(18, 20))\n\nfor i, (title, audio) in enumerate(signals.items()):\n    # STFT 수행\n    stft = librosa.stft(audio)\n    stft_db = librosa.amplitude_to_db(np.abs(stft), ref=np.max)\n    \n    # CWT 수행\n    widths = np.arange(1, 128)\n    cwtmatr, freqs = pywt.cwt(audio, widths, 'cmor', sampling_period=1/sr)\n    \n    # STFT 시각화\n    plt.subplot(len(signals), 2, 2 * i + 1)\n    librosa.display.specshow(stft_db, sr=sr, x_axis='time')\n    plt.title(f'Spectrogram: DSTFT of {title}')\n    plt.colorbar(format='%+2.0f dB')\n    \n    # CWT 시각화\n    plt.subplot(len(signals), 2, 2 * i + 2)\n    plt.imshow(np.abs(cwtmatr), extent=[0, duration, 1, 128], cmap='PRGn', aspect='auto', vmax=abs(cwtmatr).max(), vmin=-abs(cwtmatr).max())\n    plt.title(f'Scalogram: DWT of {title}')\n    plt.xlabel(\"Time [s]\")\n    plt.ylabel(\"Scale (or Frequency)\")\n    plt.colorbar(label='Magnitude')\n\nplt.tight_layout()\nplt.savefig('./Dropbox/03_Yechan3/연구/교수님이랑/MS_Review/audio_signals_analysis.pdf')  # 그림 저장\nplt.show()\n\n/home/cgb2/anaconda3/envs/multiscale/lib/python3.12/site-packages/pywt/_cwt.py:121: FutureWarning: Wavelets from the family cmor, without parameters specified in the name are deprecated. The name should takethe form cmorB-C where B and C are floats representing the bandwidth frequency and center frequency, respectively (example: cmor1.5-1.0).\n  wavelet = DiscreteContinuousWavelet(wavelet)\n\n\n\n\n\n\n\n\n\n이 그림은 librosa` 패키지를 이용하여 다양한 신호를 분석한 결과를 보여줍니다. 각 신호는 고유한 특징을 가지고 있습니다. 트럼펫 소리는 명확한 조화 구조를 가지고 있으며, 이는 주기적인 성분들이 시간 축에서 반복적으로 나타나는 패턴을 의미합니다. 브람스 음악은 다양한 악기의 복잡한 주파수 성분을 특징으로 합니다. 피아노 소리(Choice)는 명확한 주파수 성분과 배음이 있으며, 음의 변화가 뚜렷합니다. 바이올린 연주(Fishin)는 고주파수 성분이 두드러지며, 세밀한 음의 변화가 특징입니다. 비브라폰 연주(Vibeace)는 다양한 주파수 성분이 복합적으로 나타나며, 넛크래커 음악(Nutcracker)은 여러 악기의 복잡한 주파수 분포와 동적 변화를 특징으로 합니다.\nSTFT(Short-Time Fourier Transform)은 고정된 크기의 윈도우를 사용하여 일정한 시간-주파수 해상도를 가집니다. 이는 주기적이고 조화적인 성분, 즉 주파수와 배음들이 반복적으로 나타나는 패턴을 잘 포착합니다. 트럼펫 소리에서 이러한 조화 구조가 명확히 드러나며, 브람스 음악에서는 연속적인 주파수 분포를 관찰할 수 있습니다. 피아노 소리의 주파수 성분도 잘 분리되어 나타나고, 바이올린 연주의 고주파수 성분이 명확하게 보입니다. 비브라폰 연주에서는 조화 구조가 뚜렷하며, 넛크래커 음악은 복잡한 주파수 분포를 보여줍니다.\n반면, CWT(Continuous Wavelet Transform)는 웨이블릿 기저를 사용하여 다양한 시간과 주파수 스케일에서 신호를 분석합니다. 이는 시간-주파수 해상도가 높아 급격한 주파수 변화를 더 세밀하게 포착할 수 있습니다. 트럼펫 소리의 시간-주파수 변화를 더 세밀하게 포착하고, 브람스 음악의 다양한 주파수 성분을 더 명확히 드러냅니다. 피아노 음의 세밀한 변화를 잘 포착하며, 바이올린 소리의 시간-주파수 변화를 세밀하게 나타냅니다. 비브라폰 소리의 다양한 주파수 성분이 명확하게 드러나고, 넛크래커 음악의 동적 변화를 더 잘 포착합니다.\n이처럼, STFT는 일정한 시간-주파수 해상도로 조화 구조를 잘 보여주지만, 급격한 변화 포착에는 한계가 있습니다. 반면, CWT는 다양한 주파수 성분을 세밀하게 분석할 수 있어, 특히 빠르게 변하는 주파수를 가진 신호 분석에 유용합니다. 이 비교를 통해 CWT의 우수성을 확인할 수 있습니다.\nThis image shows the results of analyzing various signals using the librosa package. Each signal has unique characteristics. The trumpet sound has clear harmonic structures, meaning periodic components repeat over time. Brahms’ music features complex frequency components from multiple instruments. The piano sound (Choice) has distinct frequency components and harmonics with clear changes in tone. Violin performance (Fishin) is characterized by prominent high-frequency components and fine tonal changes. Vibraphone performance (Vibeace) exhibits complex frequency components, while Nutcracker music (Nutcracker) features complex frequency distributions and dynamic changes from various instruments.\nSTFT (Short-Time Fourier Transform) uses fixed-size windows, providing a consistent time-frequency resolution, effectively capturing periodic and harmonic components, such as in the trumpet sound, where these structures are clear. Brahms’ music shows continuous frequency distributions, and the piano sound’s frequency components are well-separated. Violin performance shows clear high-frequency components, and vibraphone performance reveals distinct harmonic structures, with Nutcracker music demonstrating complex frequency distributions.\nIn contrast, CWT (Continuous Wavelet Transform) uses wavelet bases to analyze signals across various time and frequency scales. This results in higher time-frequency resolution, capturing rapid frequency changes more precisely. The trumpet sound’s time-frequency changes are detailed, and Brahms’ music’s diverse frequency components are more evident. The piano sound’s fine tonal changes are well captured, and the violin sound’s time-frequency changes are clearly shown. Vibraphone sound’s diverse frequency components are distinct, and Nutcracker music’s dynamic changes are better captured.\nThus, STFT effectively shows harmonic structures with consistent resolution but has limitations in capturing rapid changes. Conversely, CWT provides detailed analysis of various frequency components, especially for signals with rapid frequency changes, demonstrating its superiority."
  },
  {
    "objectID": "연구/교수님이랑/MS_Review/CWT.html",
    "href": "연구/교수님이랑/MS_Review/CWT.html",
    "title": "(연구&교수님) 다중척도논문 – DWT",
    "section": "",
    "text": "예제 설명\n\n신호 생성: 주파수가 시간에 따라 변하는 신호를 생성합니다. 예를 들어, 주파수가 선형적으로 증가하는 신호와 주기적인 진동을 포함하는 신호를 생성합니다.\nSTFT 수행: STFT를 사용하여 신호를 분석하고 시간-주파수 스펙트로그램을 생성합니다.\n웨이블릿 변환 수행: 웨이블릿 변환을 사용하여 신호를 분석하고 시간-주파수 스펙트로그램을 생성합니다.\n결과 비교: 두 방법의 결과를 시각적으로 비교합니다.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.gridspec import GridSpec\nplt.rcParams['text.usetex'] = True\nfrom scipy.signal import stft\nimport pywt\n\n# 샘플링 주파수 및 시간 축 설정\nfs = 10000\nt = np.linspace(0, 2.0, 2 * fs, endpoint=False)\n\n# 주파수가 선형적으로 증가하는 신호 생성\nf0 = 70   # 시작 주파수\nf1 = 90  # 종료 주파수\nlinear_chirp = np.sin(2 * np.pi * (f0 + (f1 - f0)/2 * t / 2) * t)\n\n# 주기적인 진동 신호 생성\nperiodic_signal = np.sin(2 * np.pi * 80 * t) * (t &gt; 1)\n\n# 신호 합성\nsignal = linear_chirp + periodic_signal\n\n# STFT 수행\nf_1200, t_stft_1200, Zxx_1200 = stft(signal, fs, nperseg=1200)\nf_300, t_stft_300, Zxx_300 = stft(signal, fs, nperseg=300)\n\n# 웨이블릿 변환 수행\nwidths = np.arange(1, 128)\ncwtmatr, freqs = pywt.cwt(signal, widths, 'cmor', sampling_period=1/fs)\n\n# 그림 설정\nfig = plt.figure(figsize=(12, 14))\ngs = GridSpec(4, 2, width_ratios=[20, 1])\n\n# 원 신호 플롯\nax0 = fig.add_subplot(gs[0, 0])\nax0.plot(t, signal, color='k', linewidth=0.2)\nax0.set_title(\"Time-varying Frequency Signal with Periodic Component\")\nax0.set_xlabel(\"Time [s]\")\nax0.set_ylabel(\"Amplitude\")\n\n# STFT 플롯 (nperseg=1200)\nax1 = fig.add_subplot(gs[1, 0])\nstft_plot_1200 = ax1.pcolormesh(t_stft_1200, f_1200, np.abs(Zxx_1200), shading='gouraud', cmap='magma')\nax1.set_title(\"Spectrogram (number of samples per segment=1200)\")\nax1.set_xlabel(\"Time [s]\")\nax1.set_ylabel(\"Frequency [Hz]\")\nax1.set_ylim(0, 100)\n\n# STFT (nperseg=1200) 컬러바\ncbar1 = fig.add_subplot(gs[1, 1])\nfig.colorbar(stft_plot_1200, cax=cbar1, label='Magnitude')\n\n# STFT 플롯 (nperseg=300)\nax2 = fig.add_subplot(gs[2, 0])\nstft_plot_300 = ax2.pcolormesh(t_stft_300, f_300, np.abs(Zxx_300), shading='gouraud', cmap='magma')\nax2.set_title(\"Spectrogram (number of samples per segment=300)\")\nax2.set_xlabel(\"Time [s]\")\nax2.set_ylabel(\"Frequency [Hz]\")\nax2.set_ylim(0, 100)\n\n# STFT (nperseg=300) 컬러바\ncbar2 = fig.add_subplot(gs[2, 1])\nfig.colorbar(stft_plot_300, cax=cbar2, label='Magnitude')\n\n# 웨이블릿 변환 플롯 (스칼로그램)\nax4 = fig.add_subplot(gs[3, 0])\nwavelet_plot = ax4.imshow(np.abs(cwtmatr), extent=[0, 2, 1, 128], cmap='PRGn', aspect='auto', vmax=abs(cwtmatr).max(), vmin=-abs(cwtmatr).max())\nax4.set_title(\"Scalogram: DWT of the Signal\")\nax4.set_xlabel(\"Time [s]\")\nax4.set_ylabel(\"Scale (or Frequency)\")\n\n# 웨이블릿 컬러바\ncbar4 = fig.add_subplot(gs[3, 1])\nfig.colorbar(wavelet_plot, cax=cbar4, label='Magnitude')\n\nplt.tight_layout()\n\n# 그림 PDF로 저장\nplt.savefig(\"/home/cgb2/Dropbox/03_Yechan3/연구/교수님이랑/MS_Review/cwt_signal_analysis.pdf\")\n# 그림 표시\nplt.show()\n\n\n\n\n\n\n\n\n결과 비교\n위의 플롯을 비교하면 다음과 같은 차이를 볼 수 있습니다:\n\nSTFT: 주파수 해상도가 일정하지만, 시간 해상도는 고정된 창 길이에 의존합니다. 시간-주파수 스펙트로그램에서 선형적인 변화와 주기적인 신호를 모두 잘 보여줍니다.\n웨이블릿 변환: 주파수 해상도와 시간 해상도가 스케일에 따라 달라집니다. 낮은 주파수에서는 더 높은 주파수 해상도, 높은 주파수에서는 더 높은 시간 해상도를 제공합니다. 웨이블릿 변환은 신호의 국소적인 특성을 더 잘 포착할 수 있습니다.\n\n위 예시는 일반적인 신호 처리 방법을 설명하기 위해 작성된 것이며, 특정 출처가 있는 것이 아니라 신호 처리 이론에 기반한 예제입니다. STFT와 웨이블릿 변환은 신호 처리 분야에서 널리 사용되는 기법으로, 이러한 예제는 많은 신호 처리 교재나 튜토리얼에서 다루고 있습니다. 특히, 다음과 같은 교재나 자료에서 유사한 내용을 찾을 수 있습니다:\n\n교재\n\n“Time-Frequency Analysis” by Leon Cohen\n“Wavelet Transform and Time-Frequency Signal Analysis” by Lokenath Debnath\n“Discrete-Time Signal Processing” by Alan V. Oppenheim and Ronald W. Schafer\n\n온라인 자료\n\nMATLAB 및 Python 관련 신호 처리 튜토리얼\nSciPy 공식 문서와 관련 신호 처리 예제\nPyWavelets 라이브러리 문서 및 튜토리얼\n\n\n이러한 교재와 온라인 자료에서는 STFT와 웨이블릿 변환의 기본 개념, 수학적 배경, 그리고 구현 예제 등을 다루고 있으며, 이를 바탕으로 위와 같은 예제를 구성할 수 있습니다.\n위 코드는 기본적인 신호 생성, STFT 및 웨이블릿 변환을 시각화하기 위해 Python의 NumPy, SciPy, Matplotlib, 그리고 PyWavelets 라이브러리를 사용하여 작성되었습니다. 특정 출처에 기반하지 않은, 신호 처리 기법을 설명하기 위한 예시 코드입니다."
  },
  {
    "objectID": "연구/교수님이랑/MS_Review/Beat.html",
    "href": "연구/교수님이랑/MS_Review/Beat.html",
    "title": "(연구&교수님) 다중척도논문 – Beat",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt \nplt.rcParams['text.usetex'] = True\n\n\n# Define the time vector\nt = np.linspace(1, 1000, 2000) / 2000\n\n# Compute the signal components\ny1 = np.cos(62 * np.pi * t)\ny2 = np.cos(58 * np.pi * t)\nam = 2 * np.cos(2 * np.pi * t)\ny = y1 + y2\n\n\n# Create the subplots with captions\nfig, axs = plt.subplots(3, 1, figsize=(8, 5), tight_layout=True)\n\n# First subplot\naxs[0].plot(t, y1, color='C0')\naxs[0].set_xlim(0, 0.5)\naxs[0].set_ylim(-2, 2)\naxs[0].set_title(r\"Signal $\\cos(62\\pi t_n)$\", fontsize=12)\n\n# Second subplot\naxs[1].plot(t, y2, color='C1')\naxs[1].set_xlim(0, 0.5)\naxs[1].set_ylim(-2, 2)\naxs[1].set_title(r'Signal $\\cos(58\\pi t_n)$', fontsize=12)\n\n# Third subplot\naxs[2].plot(t, y1 + y2, color='black')\naxs[2].plot(t, y1, color='C0', alpha=0.5, linewidth=0.5)\naxs[2].plot(t, y2, color='C1', alpha=0.5, linewidth=0.5)\naxs[2].plot(t, am, 'k--')\naxs[2].set_xlim(0, 0.5)\naxs[2].set_ylim(-2, 2)\naxs[2].set_title(r'Combined Signal $\\cos(62\\pi t_n)+\\cos(58\\pi t_n) = 2\\cos(2\\pi t_n)\\cos(60 \\pi t)$', fontsize=12)\n#plt.savefig('./Dropbox/03_Yechan3/연구/교수님이랑/MS_Review/beat.pdf')\nplt.savefig('./beat.pdf')"
  },
  {
    "objectID": "연구/교수님이랑/MS_Review/SiZer.html",
    "href": "연구/교수님이랑/MS_Review/SiZer.html",
    "title": "(연구&교수님) 다중척도논문 – SiZer",
    "section": "",
    "text": "#install.packages(\"SiZer\")\n\n\nlibrary(devtools)\ninstall_github(\"seoyeonc/gglite\",force=TRUE)\nlibrary(gglite)\nlibrary(tidyverse)\nlibrary(patchwork)\n\nLoading required package: usethis\n\nDownloading GitHub repo seoyeonc/gglite@HEAD\n\n\nAttaching package: ‘gglite’\n\n\nThe following objects are masked from ‘package:stats’:\n\n    density, line, smooth, step\n\n\nThe following object is masked from ‘package:graphics’:\n\n    boxplot\n\n\nThe following objects are masked from ‘package:base’:\n\n    col, jitter\n\n\n── Attaching core tidyverse packages ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n── R CMD build ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n✔  checking for file ‘/tmp/RtmpHrt0oc/remotes2b9907378360/seoyeonc-gglite-0a5190e/DESCRIPTION’\n─  preparing ‘gglite’:\n✔  checking DESCRIPTION meta-information\n─  checking for LF line-endings in source and make files and shell scripts\n─  checking for empty or unneeded directories\n   Omitted ‘LazyData’ from DESCRIPTION\n─  building ‘gglite_0.1.0.tar.gz’\n   \n\n\n\nERROR: Error in library(patchwork): there is no package called ‘patchwork’\n\n\n\nfigsize()\n\n\n1. Sizer 기본개념\nSiZer 분석은 다양한 밴드위스에서 데이터 스무딩을 통해 시간 시계열 데이터의 트렌드를 분석하는 방법이다. 여기서 밴드위스는 데이터를 스무딩할 때 사용하는 창의 너비를 의미한다. SiZer 분석은 각 밴드위스에서 스무딩된 데이터의 1차 도함수를 계산하여, 그 도함수의 값이 양수인지(증가 추세), 음수인지(감소 추세), 아니면 0에 가까운지를 확인한다.\n\n밴드위스에서 변화의 통계적 유의미성\n\n통계적 유의미성: 특정 밴드위스에서 변화가 통계적으로 유의미하다는 것은, 해당 밴드위스에서 관찰된 트렌드(증가 또는 감소)가 데이터의 잡음이나 우연에 의한 것이 아니라 실제로 존재하는 트렌드임을 의미한다.\n통계적으로 유의미하지 않음: 특정 밴드위스에서 변화가 통계적으로 유의미하지 않다는 것은, 해당 밴드위스에서 관찰된 변화가 데이터의 잡음이나 우연에 의한 것일 가능성이 높다는 것을 의미한다. 즉, 그 밴드위스에서의 변화가 실제 트렌드가 아닐 수 있다는 것을 뜻한다.\n\nSiZer 분석을 통해 다양한 밴드위스에서의 트렌드를 확인함으로써, 데이터의 잡음에 의한 변화를 걸러내고 실제로 의미 있는 트렌드를 파악할 수 있다.\n\n\n\n2. 기본 SiZer 분석\n\n# 필요한 패키지 로드\n# install.packages(\"SiZer\")\nlibrary(SiZer)\n\n# 시계열 데이터 생성\nset.seed(0)\nt &lt;- seq(0, 1, length.out = 200)\ntrend &lt;- 3 * t\nnoise &lt;- rnorm(length(t), 0, 0.3)\ntime_series &lt;- trend + noise\n\n# PDF 파일로 저장\npdf(\"./Dropbox/03_Yechan3/연구/교수님이랑/MS_Review/SiZer1.pdf\", width = 7, height = 7)\n\n# 그래픽 매개변수 설정\npar(mfrow = c(2, 1), mar = c(2, 2, 2, 1), oma = c(0, 0, 0, 0), family = \"Helvetica\")\n\n# 첫 번째 그래프: 시계열 데이터 (점과 선으로 연결)\nplot(t, time_series, type = 'b', main = 'Time Series with Trend and Noise', xlab = 'Time', ylab = 'Value',\n     cex.main = 0.8, cex.lab = 0.8, cex.axis = 0.7, pch = 19, col = \"black\")\n\n# 다양한 밴드위스 사용\nsizer_result &lt;- SiZer(x = t, y = time_series, h = seq(0.01, 0.1, by = 0.01))\n\n# 두 번째 그래프: SiZer 결과\nplot(sizer_result, main = 'SiZer Analysis', xlab = 'Time', ylab = 'Bandwidth', \n     cex.main = 0.8, cex.lab = 0.8, cex.axis = 0.7)\n\n# 그래픽 디바이스 닫기\ndev.off()\n\npng: 2\n\n\n\nSiZer 결과 해석\nSiZer 플롯에서는 각 밴드위스에 대한 추세의 통계적 유의성을 시각적으로 확인할 수 있음: - y축의 값이 작은 영역: 작은 밴드위스를 사용한 결과를 나타냄 - y축의 값이 큰 영역: 큰 밴드위스를 사용한 결과를 나타냄\n플롯 색상 의미: - 파란색 영역: 해당 밴드위스에서 증가 추세가 통계적으로 유의미함을 나타냄 - 빨간색 영역: 해당 밴드위스에서 감소 추세가 통계적으로 유의미함을 나타냄 - 보라색 영역: 해당 밴드위스에서 변화가 통계적으로 유의미하지 않음을 나타냄\n\n\n다양한 밴드위스 사용의 중요성\n세부 변화 탐지: - 작은 밴드위스를 사용하면 데이터의 세부적인 변화를 감지할 수 있음 - 데이터의 세밀한 구조를 이해하는 데 유용함\n전체 트렌드 이해: - 큰 밴드위스를 사용하면 데이터의 전반적인 트렌드를 이해할 수 있음 - 데이터의 큰 흐름을 파악하는 데 유용함\n다중 스케일 분석: - 여러 밴드위스를 동시에 사용하면 데이터의 여러 스케일에서 중요한 변화를 탐지할 수 있음 - 다양한 수준에서 데이터의 특성을 이해하는 데 도움이 됨\n\n\n종합 정리\n\nSiZer 분석은 다양한 밴드위스를 사용하여 데이터의 중요한 추세를 여러 스케일에서 분석할 수 있는 강력한 도구임.\n이를 통해 데이터의 전반적인 흐름뿐만 아니라 세부적인 변화까지도 정확히 파악할 수 있음.\nSiZer의 다중 스케일 분석 기능은 데이터 분석에서 매우 유용하며, 특히 복잡한 시계열 데이터에서 중요한 통계적 특징을 식별하는 데 효과적임.\n\n\n\n\n3. 복잡한 시계열\n\n# 필요한 패키지 로드\n# install.packages(\"SiZer\")\nlibrary(SiZer)\n\n# 복잡한 시계열 데이터 생성\nset.seed(0)\nt &lt;- seq(0, 1, length.out = 200)\ntrend &lt;- 3 * t + sin(2 * pi * t * 10)\nnoise &lt;- rnorm(length(t), 0, 0.3)\ncomplex_series &lt;- trend + noise\n\n# SiZer 분석\nsizer_result &lt;- SiZer(x = t, y = complex_series, h = seq(0.01, 0.1, by = 0.01))\n\n# PDF 파일로 저장\npdf(\"./Dropbox/03_Yechan3/연구/교수님이랑/MS_Review/SiZer2.pdf\", width = 7, height = 7)\n\n# 그래픽 매개변수 설정\npar(mfrow = c(2, 1), mar = c(2, 2, 2, 1), oma = c(0, 0, 0, 0), family = \"Helvetica\")\n\n# 첫 번째 그래프: 복잡한 시계열 데이터 (점과 선으로 연결)\nplot(t, complex_series, type = 'b', main = 'Complex Time Series with Trend and Noise', xlab = 'Time', ylab = 'Value',\n     cex.main = 0.8, cex.lab = 0.8, cex.axis = 0.7, pch = 19, col = \"black\")\n\n# 두 번째 그래프: SiZer 결과\nplot(sizer_result, main = 'SiZer Analysis', xlab = 'Time', ylab = 'Bandwidth', \n     cex.main = 0.8, cex.lab = 0.8, cex.axis = 0.7)\n\n# 그래픽 디바이스 닫기\ndev.off()\n\npng: 2\n\n\n\n\n4. Nile\n\n# 필요한 패키지 로드\n# install.packages(\"SiZer\")\nlibrary(SiZer)\n\n# Nile 데이터셋 사용\ndata(\"Nile\")\nnile_data &lt;- data.frame(\n  Year = as.numeric(time(Nile)),\n  Flow = as.numeric(Nile)\n)\n\n# SiZer 분석\nsizer_result &lt;- SiZer(x = time(Nile), y = as.numeric(Nile), h = seq(10, 100, by = 10))\n\n# PDF 파일로 저장\npdf(\"./Dropbox/03_Yechan3/연구/교수님이랑/MS_Review/SiZer3.pdf\", width = 7, height = 7)\n\n# 그래픽 매개변수 설정\npar(mfrow = c(2, 1), mar = c(3, 3, 2, 1), oma = c(0, 0, 0, 0), family = \"Helvetica\")\n\n# 첫 번째 그래프: Nile 데이터 (점과 선으로 연결)\nplot(nile_data$Year, nile_data$Flow, type = 'b', main = 'Flow of the River Nile', xlab = 'Year', ylab = 'Flow',\n     cex.main = 0.8, cex.lab = 0.8, cex.axis = 0.7, pch = 19, col = \"black\", las = 1)\n\n# 두 번째 그래프: SiZer 결과\nplot(sizer_result, main = 'SiZer Analysis', xlab = 'Year', ylab = 'Bandwidth', \n     cex.main = 0.8, cex.lab = 0.8, cex.axis = 0.7)\n\n# 그래픽 디바이스 닫기\ndev.off()\n\npng: 2\n\n\n이 자료는 R의 Nile 데이터셋을 시각화한 것이다. Nile 데이터셋은 1871년부터 1970년까지의 100년 동안 나일 강의 연간 흐름량을 기록한 시계열 데이터다.\n\n주요 내용\n\n플롯 유형: 이 플롯은 선 그래프와 점 그래프를 결합한 형태로, 나일 강의 연간 흐름량 변화를 시각적으로 나타낸다.\nx축 (Year): 1871년부터 1970년까지의 연도.\ny축 (Flow): 각 연도에 측정된 나일 강의 흐름량.\n\n\n\n해석\n\n연도별 흐름량 변동: 플롯은 100년 동안 나일 강의 흐름량이 어떻게 변했는지를 보여준다. 흐름량은 시간이 지남에 따라 증가하고 감소하는 패턴을 보인다.\n주요 트렌드: 플롯을 통해 특정 기간 동안 흐름량이 증가하거나 감소하는 경향을 쉽게 파악할 수 있다.\n\n이 플롯을 통해 나일 강의 흐름량 변화와 주요 트렌드를 시각적으로 이해할 수 있다.\n이 그림은 Nile 데이터셋을 SiZer(SIgnificant ZERo crossings) 방법으로 분석한 결과를 시각화한 것이다. SiZer 플롯은 다양한 밴드위스에서 데이터의 추세를 시각적으로 보여주며, 추세의 통계적 유의미성을 평가한다. 각 색상은 데이터의 증가, 감소, 혹은 유의미하지 않은 변화를 나타낸다.\n\n\n그림 해석\n\ny축 (log10(h)): 밴드위스의 로그 스케일 값을 나타냄. 밴드위스는 데이터를 스무딩할 때 사용하는 창의 너비를 의미하며, y축 값이 작을수록 작은 밴드위스를, y축 값이 클수록 큰 밴드위스를 의미함.\nx축 (x$x.grid): 연도. 나일 강의 연간 흐름량이 기록된 시간 범위를 나타냄.\n\n\n\n색상 의미\n\n파란색 영역: 해당 밴드위스에서 증가 추세가 통계적으로 유의미함을 나타냄.\n빨간색 영역: 해당 밴드위스에서 감소 추세가 통계적으로 유의미함을 나타냄.\n보라색 영역: 해당 밴드위스에서 변화가 통계적으로 유의미하지 않음을 나타냄.\n\n\n\n주요 해석\n\n1870년대~1900년대 초반:\n\n대부분의 밴드위스에서 감소 추세(빨간색)가 유의미함.\n\n1900년대 초반~1940년대:\n\n주로 보라색 영역으로, 이 시기에는 대부분의 밴드위스에서 통계적으로 유의미한 변화가 없음.\n\n1940년대 후반~1960년대:\n\n다양한 밴드위스에서 증가 추세(파란색)가 유의미함.\n\n\n\n\n결론\nSiZer 플롯을 통해 나일 강의 연간 흐름량 변화에서 다음과 같은 중요한 패턴을 파악할 수 있음:\n\n1870년대부터 1900년대 초반까지는 주로 감소 추세가 유의미하게 나타남.\n1900년대 초반부터 1940년대까지는 통계적으로 유의미한 변화가 거의 없음.\n1940년대 후반부터 1960년대까지는 증가 추세가 유의미하게 나타남.\n\n이러한 분석은 나일 강의 흐름량이 시간에 따라 어떻게 변화했는지, 그리고 그 변화가 통계적으로 유의미한지에 대한 통찰을 제공함."
  },
  {
    "objectID": "연구/교수님이랑/MS_Review/figs.html",
    "href": "연구/교수님이랑/MS_Review/figs.html",
    "title": "(연구&교수님) 다중척도논문 – 그림들",
    "section": "",
    "text": "library(devtools)\ninstall_github(\"seoyeonc/gglite\",force=TRUE)\nlibrary(gglite)\nlibrary(tidyverse)\nlibrary(patchwork)\n\nLoading required package: usethis\n\nDownloading GitHub repo seoyeonc/gglite@HEAD\n\n\nAttaching package: ‘gglite’\n\n\nThe following objects are masked from ‘package:stats’:\n\n    density, line, smooth, step\n\n\nThe following object is masked from ‘package:graphics’:\n\n    boxplot\n\n\nThe following objects are masked from ‘package:base’:\n\n    col, jitter\n\n\nWarning message:\n“package ‘stringr’ was built under R version 4.3.2”\n── Attaching core tidyverse packages ────────────────────────────────────────────────────────────────────────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ──────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n── R CMD build ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n✔  checking for file ‘/tmp/Rtmp6FRsEf/remotesfaeefdab6a5d/seoyeonc-gglite-1c0c2e5/DESCRIPTION’\n─  preparing ‘gglite’:\n✔  checking DESCRIPTION meta-information\n─  checking for LF line-endings in source and make files and shell scripts\n─  checking for empty or unneeded directories\n   Omitted ‘LazyData’ from DESCRIPTION\n─  building ‘gglite_0.1.0.tar.gz’\n   \n\n\n\n\n1. 비트시그널\n\\[y_t = \\cos(62\\pi t) + \\cos(58\\pi t)\\]\n\nt = 1:1000/2000\ny1 = cos(62*pi*t) \ny2 = cos(58*pi*t)\nam = 2*cos(2*pi*t)\ny = y1 + y2 \nfig1 = gglite() + line(t,y1,col=2) + line(t,y,alpha=0) + ylab(\"\") + xlab(\"\")\nfig2 = gglite() + line(t,y2,col=4) + line(t,y,alpha=0) + ylab(\"\") + xlab(\"\")\nfig3 = gglite() + line(t,y1+y2) + line(t,y1,col=2,alpha=0.5,lwd=0.2) + line(t,y2,col=4,alpha=0.5,lwd=0.2) + line(t,am,lty=2) + ylab(\"\") + xlab(\"\")\nfig = fig1/fig2/fig3\n\n\nfigsize(5,4)\nfig = fig1/fig2/fig3\nfig\nfigsize()\n\n\n\n\n\n\n\n\n\nggsave(\"beat.pdf\",fig)\n\nSaving 6.67 x 6.67 in image\n\n\n\n\n2. 퓨리에변환\n\nspec &lt;- function(y){\n    n = length(y)\n    spec = (abs(fft(y)))/n\n    omega = 1:n/n \n    if(n%%2 ==0){\n        m = (n/2)+1\n    } else {\n        m = (n-1)/2+1\n    }\n    spec = c(spec[(m+1):n],spec[1:m])\n    omega = c(omega[(m+1):n]-1,omega[1:m]) -1/n\n    list(freq=omega*2*pi,spec=spec)\n}       \n\n\nt = (1:40)/40\neps = rnorm(40)\nconst = -2+t*0\nlow = 9*sin(2*pi*t)\nhigh = 4*cos(4*2*pi*t)\nytrue = const + low + high\ny = ytrue + eps\n\n\nfreq = spec(y)$freq \ny_spec = spec(y)$spec \nconst_spec = spec(const)$spec\nlow_spec = spec(low)$spec\nhigh_spec = spec(high)$spec\neps_spec = spec(eps)$spec\n\n\nfigsize(8,6)\na = gglite() + line(t,y,col=\"gray60\",cex=0.5) + point(t,y,col=\"gray60\",cex=0.5)+line(t,ytrue,col=\"gray60\",alpha=0.5) + xlab(\"\") + ylab(\"\")\nb = gglite() + point(freq,y_spec,cex=0.25) + ylim(0,5.5)+ xlab(\"\") + ylab(\"\") + geom_segment(aes(x=freq, xend = freq, y= y_spec, yend = 0))\nc = gglite() + line(t,const,col=\"gray60\")+ point(t,const,col=\"gray60\",cex=0.5)+ xlab(\"\") + ylab(\"\")\nd = gglite() + point(freq,const_spec,cex=0.25) + ylim(0,5.5)+ xlab(\"\") + ylab(\"\")+ geom_segment(aes(x=freq, xend = freq, y= const_spec, yend = 0))\ne = gglite() + line(t,low,col=\"gray60\")+ point(t,low,col=\"gray60\",cex=0.5)+ xlab(\"\") + ylab(\"\")\nf = gglite() + point(freq,low_spec,cex=0.25) + ylim(0,5.5)+ xlab(\"\") + ylab(\"\")+ geom_segment(aes(x=freq, xend = freq, y= low_spec, yend = 0))\ng = gglite() + line(t,high,col=\"gray60\")+ point(t,high,col=\"gray60\",cex=0.5)+ xlab(\"\") + ylab(\"\")\nh = gglite() + point(freq,high_spec,cex=0.25) + ylim(0,5.5)+ xlab(\"\") + ylab(\"\")+ geom_segment(aes(x=freq, xend = freq, y= high_spec, yend = 0))\ni = gglite() + line(t,eps,col=\"gray60\")+ point(t,eps,col=\"gray60\",cex=0.5)+ xlab(\"\") + ylab(\"\")\nj = gglite() + point(freq,eps_spec,cex=0.25) + ylim(0,5.5)+ xlab(\"\") + ylab(\"\")+ geom_segment(aes(x=freq, xend = freq, y= eps_spec, yend = 0))\n\n(a|b) / (c|d) / (e|f) / (g|h) / (i|j)\nfigsize()"
  },
  {
    "objectID": "연구/교수님이랑/EPT_DISSIM/2023-08-18-(연구) EPT-DISSIM -- 데이터전처리.html",
    "href": "연구/교수님이랑/EPT_DISSIM/2023-08-18-(연구) EPT-DISSIM -- 데이터전처리.html",
    "title": "(연구&교수님) EPT-DISSIM – PRCP_KOR2 데이터정리",
    "section": "",
    "text": "import pandas as pd\n\n\ndf = pd.read_csv('PRCP_KOR.csv')\ndf\n\n\n\n\n\n\n\n\nStation_ID\nStation_Name\nDate\nPrecipitation\n\n\n\n\n0\n90\n속초\n2013-08-09\n15.5\n\n\n1\n90\n속초\n2013-08-10\n9.5\n\n\n2\n90\n속초\n2013-08-16\n0.1\n\n\n3\n90\n속초\n2013-08-18\n0.0\n\n\n4\n90\n속초\n2013-08-19\n9.0\n\n\n...\n...\n...\n...\n...\n\n\n127200\n295\n남해\n2023-07-22\n4.3\n\n\n127201\n295\n남해\n2023-07-23\n13.4\n\n\n127202\n295\n남해\n2023-07-24\n17.0\n\n\n127203\n295\n남해\n2023-07-25\n4.7\n\n\n127204\n295\n남해\n2023-07-26\n42.5\n\n\n\n\n127205 rows × 4 columns\n\n\n\n\n# 'Date' 칼럼의 데이터 타입을 datetime으로 변경\ndf['Date'] = pd.to_datetime(df['Date'])\n\n# 다시 각 기상 관측소별로 누락된 날짜를 찾아 0으로 채움\nfilled_dfs = []\nfor (station_id, station_name), group in df.groupby(['Station_ID', 'Station_Name']):\n    all_dates = pd.date_range(start=group['Date'].min(), end=group['Date'].max())\n    filled_data = all_dates.to_frame(name='Date').merge(group, on='Date', how='left')\n    filled_data['Station_ID'].fillna(station_id, inplace=True)\n    filled_data['Station_Name'].fillna(station_name, inplace=True)\n    filled_data['Precipitation'].fillna(0, inplace=True)\n    filled_dfs.append(filled_data)\n\n# 모든 기상 관측소의 보정된 데이터를 결합\ndf2 = pd.concat(filled_dfs)\n\ndf2.head()\n\n\n\n\n\n\n\n\nDate\nStation_ID\nStation_Name\nPrecipitation\n\n\n\n\n0\n2013-08-09\n90.0\n속초\n15.5\n\n\n1\n2013-08-10\n90.0\n속초\n9.5\n\n\n2\n2013-08-11\n90.0\n속초\n0.0\n\n\n3\n2013-08-12\n90.0\n속초\n0.0\n\n\n4\n2013-08-13\n90.0\n속초\n0.0\n\n\n\n\n\n\n\n\ndf2.to_csv(\"PRCP_KOR2.csv\")"
  },
  {
    "objectID": "연구/교수님이랑/EPT_DISSIM/2023-08-07-(연구) EPT-DISSIM -- PRCP_KOR 데이터정리.html",
    "href": "연구/교수님이랑/EPT_DISSIM/2023-08-07-(연구) EPT-DISSIM -- PRCP_KOR 데이터정리.html",
    "title": "(연구&교수님) EPT-DISSIM – PRCP_KOR 데이터정리",
    "section": "",
    "text": "import pandas as pd\n\n1. load raw-data\n\ndf = pd.read_csv(\"OBS_ASOS_DD_20230807193646.csv\", encoding='EUC-KR')\ndf = df.rename({'지점':'Station_ID','지점명':'Station_Name','일시':'Date','일강수량(mm)':'Precipitation'},axis=1)\ndf\n\n\n\n\n\n\n\n\nStation_ID\nStation_Name\nDate\nPrecipitation\n\n\n\n\n0\n90\n속초\n2013-08-09\n15.5\n\n\n1\n90\n속초\n2013-08-10\n9.5\n\n\n2\n90\n속초\n2013-08-16\n0.1\n\n\n3\n90\n속초\n2013-08-18\n0.0\n\n\n4\n90\n속초\n2013-08-19\n9.0\n\n\n...\n...\n...\n...\n...\n\n\n127200\n295\n남해\n2023-07-22\n4.3\n\n\n127201\n295\n남해\n2023-07-23\n13.4\n\n\n127202\n295\n남해\n2023-07-24\n17.0\n\n\n127203\n295\n남해\n2023-07-25\n4.7\n\n\n127204\n295\n남해\n2023-07-26\n42.5\n\n\n\n\n127205 rows × 4 columns\n\n\n\n2. save dataframe as PRCP_KOR.csv\n\ndf.to_csv('PRCP_KOR.csv',index=False)"
  },
  {
    "objectID": "자료.html",
    "href": "자료.html",
    "title": "자료",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nJan 18, 2024\n\n\n(자료) 신용카드 사기거래\n\n\n신록예찬 \n\n\n\n\nNov 9, 2023\n\n\n(자료) 데이터생성 – 성별,몸무게 –&gt; 키\n\n\n신록예찬 \n\n\n\n\n\nNo matching items",
    "crumbs": [
      "DL2024",
      "자료"
    ]
  },
  {
    "objectID": "교수님.html",
    "href": "교수님.html",
    "title": "오희석 교수님",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\n \n\n\n(연구&교수님) EBT – 첫 논문 재현 // 11월28일 다시~!\n\n\n \n\n\n\n\nAug 6, 2024\n\n\n(연구&교수님) 다중척도논문 – EMD 2\n\n\n최규빈 \n\n\n\n\nAug 1, 2024\n\n\n(연구&교수님) EBT – 첫 논문 재현 // 2024년 8월\n\n\n최규빈 \n\n\n\n\nAug 1, 2024\n\n\n(연구&교수님) EBT – 첫 논문 재현\n\n\n최규빈 \n\n\n\n\nJul 30, 2024\n\n\n(연구&교수님) EBT – ECG 자료 시각화\n\n\n최규빈 \n\n\n\n\nJul 27, 2024\n\n\n(연구&교수님) 다중척도논문 – TPT-FirstFig\n\n\n최규빈 \n\n\n\n\nJul 24, 2024\n\n\n(연구&교수님) 다중척도논문 – TPT, 미국지수분석\n\n\n최규빈 \n\n\n\n\nJul 24, 2024\n\n\n(연구&교수님) 다중척도논문 – TPT, 미국지수분석 (2)\n\n\n최규빈 \n\n\n\n\nJul 23, 2024\n\n\n(연구&교수님) 다중척도논문 – FFT\n\n\n최규빈 \n\n\n\n\nJul 23, 2024\n\n\n(연구&교수님) 다중척도논문 – Beat\n\n\n최규빈 \n\n\n\n\nJul 22, 2024\n\n\n(연구&교수님) 다중척도논문 – librosa\n\n\n최규빈 \n\n\n\n\nJul 22, 2024\n\n\n(연구&교수님) 다중척도논문 – TPT, TPMA 설명\n\n\n최규빈 \n\n\n\n\nJul 10, 2024\n\n\n(연구&교수님) 다중척도논문 – STFT\n\n\n최규빈 \n\n\n\n\nJul 10, 2024\n\n\n(연구&교수님) 다중척도논문 – EMD\n\n\n최규빈 \n\n\n\n\nJul 10, 2024\n\n\n(연구&교수님) 다중척도논문 – DWT\n\n\n최규빈 \n\n\n\n\nJul 10, 2024\n\n\n(연구&교수님) 다중척도논문 – SiZer\n\n\n최규빈 \n\n\n\n\nJul 10, 2024\n\n\n(연구&교수님) 다중척도논문 – 그림들\n\n\n최규빈 \n\n\n\n\nJun 9, 2024\n\n\n(연구&교수님) 다중척도논문 – 환경설정\n\n\n최규빈 \n\n\n\n\nJan 16, 2024\n\n\n(연구&교수님) EBT – 미구현코드\n\n\n최규빈 \n\n\n\n\nAug 18, 2023\n\n\n(연구&교수님) EPT-DISSIM – PRCP_KOR2 데이터정리\n\n\n신록예찬 \n\n\n\n\nAug 8, 2023\n\n\n(연구&교수님) EPT-DISSIM – 진행사항\n\n\n신록예찬 \n\n\n\n\nAug 7, 2023\n\n\n(연구&교수님) EPT-DISSIM – PRCP_KOR 데이터정리\n\n\n신록예찬 \n\n\n\n\nJul 12, 2023\n\n\n(연구&교수님) 그래프신호만들고시각화하기\n\n\n신록예찬 \n\n\n\n\nJul 12, 2023\n\n\n(연구&교수님) 링형태의자료만들기\n\n\n신록예찬 \n\n\n\n\nJul 12, 2023\n\n\n(연구&교수님) old_hst\n\n\n신록예찬 \n\n\n\n\nDec 10, 2021\n\n\n(연구&교수님) HST example 3\n\n\n신록예찬 \n\n\n\n\nOct 29, 2021\n\n\n(연구&교수님) HST example 3, 파이썬으로 변경\n\n\n신록예찬 \n\n\n\n\nSep 18, 2021\n\n\n(연구&교수님) hst plots\n\n\n신록예찬 \n\n\n\n\nAug 15, 2021\n\n\n(연구&교수님) HST example 3\n\n\n신록예찬 \n\n\n\n\nAug 9, 2021\n\n\n(연구&교수님) HST example 2 이거로하자\n\n\n신록예찬 \n\n\n\n\nAug 9, 2021\n\n\n(연구&교수님) HST example 2 (1)\n\n\n신록예찬 \n\n\n\n\nAug 9, 2021\n\n\n(연구&교수님) HST example 2 (6)\n\n\n신록예찬 \n\n\n\n\nAug 9, 2021\n\n\n(연구&교수님) HST example 2 (7)\n\n\n신록예찬 \n\n\n\n\nAug 9, 2021\n\n\n(연구&교수님) HST example 2 (2)\n\n\n신록예찬 \n\n\n\n\nAug 9, 2021\n\n\n(연구&교수님) HST example 2 (4)\n\n\n신록예찬 \n\n\n\n\nAug 9, 2021\n\n\n(연구&교수님) HST example 1, Appendix 추가 (2)\n\n\n신록예찬 \n\n\n\n\nAug 9, 2021\n\n\n(연구&교수님) HST example 2 (5)\n\n\n신록예찬 \n\n\n\n\nAug 9, 2021\n\n\n(연구&교수님) HST example 1, Appendix 추가 (1)\n\n\n신록예찬 \n\n\n\n\nAug 9, 2021\n\n\n(연구&교수님) HST example 2 (3)\n\n\n신록예찬 \n\n\n\n\nAug 5, 2021\n\n\n(연구&교수님) HST example 1, Appendix 추가\n\n\n신록예찬 \n\n\n\n\nAug 5, 2021\n\n\n(연구&교수님) HST 이론개발\n\n\n신록예찬 \n\n\n\n\nAug 5, 2021\n\n\n(연구&교수님) HST example 2, Appendix 추가\n\n\n신록예찬 \n\n\n\n\nAug 3, 2021\n\n\n(연구&교수님) HST example 2 (1)\n\n\n신록예찬 \n\n\n\n\nAug 3, 2021\n\n\n(연구&교수님) HST example 2 (8)\n\n\n신록예찬 \n\n\n\n\nAug 3, 2021\n\n\n(연구&교수님) HST example 2 (5)\n\n\n신록예찬 \n\n\n\n\nAug 3, 2021\n\n\n(연구&교수님) HST example 2 (6)\n\n\n신록예찬 \n\n\n\n\nAug 3, 2021\n\n\n(연구&교수님) HST example 2 (2)\n\n\n신록예찬 \n\n\n\n\nAug 3, 2021\n\n\n(연구&교수님) HST example 2 (7)\n\n\n신록예찬 \n\n\n\n\nAug 3, 2021\n\n\n(연구&교수님) HST example 2 (4), 결과좋다\n\n\n신록예찬 \n\n\n\n\nAug 3, 2021\n\n\n(연구&교수님) HST example 2 (3)\n\n\n신록예찬 \n\n\n\n\nAug 2, 2021\n\n\n(연구&교수님) HST example 1 (6)\n\n\n신록예찬 \n\n\n\n\nAug 2, 2021\n\n\n(연구&교수님) HST example 1 (3)\n\n\n신록예찬 \n\n\n\n\nAug 2, 2021\n\n\n(연구&교수님) HST example 1 (1)\n\n\n신록예찬 \n\n\n\n\nAug 2, 2021\n\n\n(연구&교수님) HST example 1 (4)\n\n\n신록예찬 \n\n\n\n\nAug 2, 2021\n\n\n(연구&교수님) HST example 1 (2)\n\n\n신록예찬 \n\n\n\n\nAug 2, 2021\n\n\n(연구&교수님) HST example 1 (7)\n\n\n신록예찬 \n\n\n\n\nAug 2, 2021\n\n\n(연구&교수님) HST example 1 (5), 이것도 좋아\n\n\n신록예찬 \n\n\n\n\nAug 2, 2021\n\n\n(연구&교수님) HST example 1 (8), 결과좋음\n\n\n신록예찬 \n\n\n\n\nJul 27, 2021\n\n\n(연구&교수님) HST example 2\n\n\n신록예찬 \n\n\n\n\nJul 22, 2021\n\n\n(연구&교수님) HST example 1\n\n\n신록예찬 \n\n\n\n\nJul 14, 2021\n\n\n(연구&교수님) HST old exam (Python)\n\n\n신록예찬 \n\n\n\n\nJul 14, 2021\n\n\n(연구&교수님) HST old exam (R)\n\n\n신록예찬 \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "공부/2023-01-20-(공부) 추정.out.html",
    "href": "공부/2023-01-20-(공부) 추정.out.html",
    "title": "(공부) 추정",
    "section": "",
    "text": "신록예찬\n2023-01-20\nusing Distributions, Plots"
  },
  {
    "objectID": "공부/2023-01-20-(공부) 추정.out.html#mle의-일치성에-대한-구체적인-논의",
    "href": "공부/2023-01-20-(공부) 추정.out.html#mle의-일치성에-대한-구체적인-논의",
    "title": "(공부) 추정",
    "section": "MLE의 일치성에 대한 구체적인 논의",
    "text": "MLE의 일치성에 대한 구체적인 논의\n\\(X_1,\\dots,X_{10} \\overset{i.i.d.}{\\sim} Ber(\\theta)\\) 이라고 하자.\n[1] 거의 암산가능\n[2] 균등확률수렴성은 로그가능도함수가 strictly convex일 경우 성립한다는 것이 알려져 있음\n[3] https://en.wikipedia.org/wiki/Identifiability\n\nx = rand(Bernoulli(0.3),10)\nx\n\n10-element Vector{Bool}:\n 0\n 0\n 1\n 1\n 1\n 1\n 0\n 0\n 0\n 0\n\n\n여기에서 \\(\\theta\\)는 추정해야할 미지의 모수이지만 우리는 시뮬레이션의 편의상 \\(\\theta\\)의 참값을 \\(\\theta_0=\\frac{1}{3}\\)로 알고 있다고 하자. MLE를 논의함에 있어 핵심적인 역할을 하는 것은 \\(Y_1=\\log f(X_1;\\theta)\\)이다. 아래는 \\(Y_1\\)에 대한 몇가지 코멘트이다.\n(1) \\(Y_1\\)은 \\(X_1\\)와 \\(\\theta\\)의 함수이다.\n\n우선 \\(X_1\\)의 함수이므로 \\(Y_1\\)역시 확률변수이다. 따라서 \\(Y_1\\)에 대하여 평균등을 취할 수 있으며 LLN을 쓸 수 있다.\n\\(Y_1\\)은 \\(\\theta\\)에 대한 함수이므로 \\(\\theta\\)에 대하여 미분할 수 있다.\n\n(베르누이 예제)\n우리의 베르누이 예제에서 \\(Y_1\\)은 아래와 같이 계산된다.\n\\[Y_1 = \\log f(X_1;\\theta)= X_1 \\log \\theta + (1-X_1)\\log(1-\\theta)\\]\n보는 것 처럼 \\(Y_1\\)은 \\(X_1\\)와 \\(\\theta\\)의 함수임\n(2) \\(\\mathbb{E}_{\\theta_0}(Y_1)\\)은 \\(\\theta\\) 만의 함수이다. 적당한 조건[1]이 만족된다면 \\(\\mathbb{E}_{\\theta_0}(Y_1)\\)은 \\(\\theta_0\\) 에서 최대화 된다.\n(베르누이 예제)\n\\(\\mathbb{E}_{\\theta_0}(Y_1) = \\mathbb{E}_{\\theta_0}(X_1)\\log\\theta + (1-\\mathbb{E}_{\\theta_0}(X_1))\\log(1-\\theta) = \\frac{1}{3} \\log\\theta + (1-\\frac{1}{3})\\log(1-\\theta)\\)\n\n일반적인 상황에서는 참모수를 모르지만 우리는 시뮬레이션을 \\(\\theta=1/3\\)에서 하였으므로 참모수 \\(\\theta_0=\\mathbb{E}_{\\theta_0}(X_1)=\\frac{1}{3}\\)을 알고 있다고 가정한다.\n\n[1] identifiable & common support\n\nplot(θ -&gt; (1/3)*log(θ) + (1-1/3)*log(1-θ)) \n\n\n\n\n\n\n\n\n보는것처럼 이 함수 \\(\\mathbb{E}_{\\theta_0}(Y_1)\\)은 \\(\\theta=\\theta_0=\\frac{1}{3}\\) 에서 최대값을 가진다.\n(3) \\(\\frac{\\partial}{\\partial \\theta}Y_1\\) 역시 \\(X_1\\)와 \\(\\theta\\)의 함수이다.\n\n따라서 \\(\\frac{\\partial}{\\partial \\theta}Y_1\\) 역시 확률변수이고 \\(\\frac{\\partial}{\\partial \\theta}Y_1\\)에 대하여 평균등을 취할 수 있으며 LLN을 쓸 수 있다.\n\n(베르누이 예제)\n\\(\\frac{\\partial}{\\partial\\theta}Y_1 = X_1\\frac{1}{\\theta} + (1-X_1)\\frac{-1}{1-\\theta}\\)\n(4) \\(\\mathbb{E}_{\\theta}[\\frac{\\partial}{\\partial \\theta}Y_1]=0\\) 이다.\n(베르누이 예제)\n\\(\\mathbb{E}_{\\theta}[\\frac{\\partial}{\\partial\\theta}Y_1] = \\theta\\frac{1}{\\theta} + (1-\\theta)\\frac{-1}{1-\\theta}=0\\)\n(5) \\(\\mathbb{V}_{\\theta}[\\frac{\\partial}{\\partial\\theta}Y_1]=\\mathbb{E}_{\\theta}[-\\frac{\\partial^2}{\\partial \\theta^2}Y_1]=I(\\theta)\\)\n(베르누이 예제)\n\\(\\mathbb{V}_{\\theta}\\big[\\frac{\\partial}{\\partial\\theta}Y_1\\big]=\\mathbb{E}_{\\theta}\\big[(\\frac{\\partial}{\\partial\\theta}Y_1)^2\\big]=\\mathbb{E}_{\\theta}\\big[-\\frac{\\partial^2}{\\partial\\theta^2}Y_1\\big]=\\frac{1}{\\theta(1-\\theta)}\\)\n\n두번째 등호는 \\(\\mathbb{E}_{\\theta}[\\frac{\\partial}{\\partial\\theta}Y_1]=0\\)을 이용하여 증명가능하다.\n언뜻 보면 \\(\\mathbb{V}_{\\theta}\\big[\\frac{\\partial}{\\partial\\theta}Y_1\\big]\\)를 계산하는 것이 \\(\\mathbb{E}_{\\theta}\\big[-\\frac{\\partial^2}{\\partial\\theta^2}Y_1\\big]\\)를 계산하는것보다 훨씬 쉬워보인다. 그런데 \\(X_1\\)와 \\(1-X_1\\)이 독립이 아니라서 \\(\\mathbb{V}(X+Y)=\\mathbb{V}(X)+\\mathbb{V}(V)+2\\text{Cov}(X,Y)\\)와 같이 공분산 term을 계산해야 하므로 계산이 까다롭다.\n\n\n베르누이에 대한 피셔정보량은 https://en.wikipedia.org/wiki/Fisher_information 에서 확인할 수 있음"
  },
  {
    "objectID": "공부/CGSP/2022-12-26-Chap-12.2.html",
    "href": "공부/CGSP/2022-12-26-Chap-12.2.html",
    "title": "(공부) CGSP – Chap 12.2: Weakly Stationary Graph Processes",
    "section": "",
    "text": "using LinearAlgebra, DSP"
  },
  {
    "objectID": "공부/CGSP/2022-12-26-Chap-12.2.html#simultaneously-diagonalizable",
    "href": "공부/CGSP/2022-12-26-Chap-12.2.html#simultaneously-diagonalizable",
    "title": "(공부) CGSP – Chap 12.2: Weakly Stationary Graph Processes",
    "section": "Simultaneously Diagonalizable",
    "text": "Simultaneously Diagonalizable\n매트릭스 \\({\\bf A}\\)와 \\({\\bf B}\\)가 대각화 가능하다는 것은 아래의 표현을 만족하는 적당한 invertible matrix \\({\\bf \\Psi}_A\\), \\({\\bf \\Psi}_B\\)와 대각행렬 \\({\\bf \\Lambda}_A\\), \\({\\bf \\Lambda}_B\\)가 존재한다는 의미가 된다.\n\\[{\\bf A} = {\\bf V}_{A} {\\bf \\Lambda}_A {\\bf V}_{A}^{-1}\\]\n\\[{\\bf B} = {\\bf V}_{B} {\\bf \\Lambda}_B {\\bf V}_{B}^{-1}\\]\n그리고 만약에 \\({\\bf V}_{A}={\\bf V}_{B}\\)이라면 즉\n\\[{\\bf A} = {\\bf V} {\\bf \\Lambda}_A {\\bf V}^{-1}\\]\n\\[{\\bf B} = {\\bf V} {\\bf \\Lambda}_B {\\bf V}^{-1}\\]\n이라면 \\(\\{{\\bf A},{\\bf B}\\}\\)가 simultaneously diagonalzable 하다고 표현한다."
  },
  {
    "objectID": "공부/CGSP/2022-12-26-Chap-12.2.html#commute",
    "href": "공부/CGSP/2022-12-26-Chap-12.2.html#commute",
    "title": "(공부) CGSP – Chap 12.2: Weakly Stationary Graph Processes",
    "section": "Commute",
    "text": "Commute\n두 matrix \\({\\bf A}\\)와 \\({\\bf B}\\)에 대하여\n\\[{\\bf A}{\\bf B}= {\\bf B}{\\bf A}\\]\n인 관계가 성립하면 두 매트릭스가 commute 한다고 표현한다. 그런데 \\({\\bf A}{\\bf B}={\\bf A}{\\bf B}\\)의 조건은 \\({\\bf A}, {\\bf B}\\)가 동시대각화가능할 (simultaneously diagonalzable) 조건과 같다. 1 따라서 simultaneously diagonalzable 는 commute와 같은 말이라 생각해도 무방하다.\n1 필요충분조건이다.\n참고: 위키피디아.."
  },
  {
    "objectID": "공부/CGSP/2022-12-26-Chap-12.2.html#shift-invariant-filter",
    "href": "공부/CGSP/2022-12-26-Chap-12.2.html#shift-invariant-filter",
    "title": "(공부) CGSP – Chap 12.2: Weakly Stationary Graph Processes",
    "section": "Shift Invariant Filter",
    "text": "Shift Invariant Filter\n\nref: Djuric and Richard (2018) Chap 8.3 의 내용 중 일부\n\nDjuric, Petar, and Cédric Richard. 2018. Cooperative and Graph Signal Processing: Principles and Applications. Academic Press.\n\nDefine the matrix \\({\\bf B}\\) as periodic shift matrix such that\n\\[\n{\\bf B} = \\begin{bmatrix}\n0 & 0 & 0 & \\dots  & 0 & 1 \\\\\n1 & 0 & 0 & \\dots & 0 & 0 \\\\\n0 & 1 & 0 & \\dots & 0 & 0 \\\\\n\\dots & \\dots & \\dots & \\dots & \\dots & \\dots\\\\\n0 & 0 & \\dots & 1 & 0 & 0 \\\\\n0 & 0 & \\dots & 0 & 1 & 0 \\\\\n\\end{bmatrix}.\\]\nA generic filter \\({\\boldsymbol h}\\) is given by its \\(z\\)-transform\n\\[h(z)=h_0z^0+h_1z^{-1}+\\cdots +h_{N-1}z^{-(N-1)}\\]\nwhere \\(s_{n-1}=z^{-1}s_n\\). In vector notation, and with respect to the standard basis \\({\\bf I}\\), the filter is represented by the matrix \\({\\bf H}\\), a polynomial in the cyclic shift\n\\[{\\bf H}=h({\\bf B})=h_0{\\bf B}^0+h_1{\\bf B}^1+\\cdots+h_{N-1}{\\bf B}^{N-1}.\\]\nFilters are shift invariant iff\n\\[z\\cdot h(z) = h(z)\\cdot z\\]\nor from the matrix representation\n\\[{\\bf B}h({\\bf B})=h({\\bf B}){\\bf B}.\\]\nExample\nLet \\({\\bf B}\\) as\n\nB= [0 1 0 0 0 0 0\n    0 0 1 0 0 0 0 \n    0 0 0 1 0 0 0 \n    0 0 0 0 1 0 0 \n    0 0 0 0 0 1 0 \n    0 0 0 0 0 0 1 \n    1 0 0 0 0 0 0]\n\n7×7 Matrix{Int64}:\n 0  1  0  0  0  0  0\n 0  0  1  0  0  0  0\n 0  0  0  1  0  0  0\n 0  0  0  0  1  0  0\n 0  0  0  0  0  1  0\n 0  0  0  0  0  0  1\n 1  0  0  0  0  0  0\n\n\nDefine \\({\\boldsymbol h}\\) as\n\nh = [1/3,1/3,1/3]\n\n3-element Vector{Float64}:\n 0.3333333333333333\n 0.3333333333333333\n 0.3333333333333333\n\n\nFurthermore define \\({\\bf H}=h({\\bf B})=h_0{\\bf B}^0+h_1{\\bf B}^1+h_2{\\bf B}^2\\)\n\nH = (1/3)*B^0 + (1/3)*B^1 + (1/3)*B^2 \n\n7×7 Matrix{Float64}:\n 0.333333  0.333333  0.333333  0.0       0.0       0.0       0.0\n 0.0       0.333333  0.333333  0.333333  0.0       0.0       0.0\n 0.0       0.0       0.333333  0.333333  0.333333  0.0       0.0\n 0.0       0.0       0.0       0.333333  0.333333  0.333333  0.0\n 0.0       0.0       0.0       0.0       0.333333  0.333333  0.333333\n 0.333333  0.0       0.0       0.0       0.0       0.333333  0.333333\n 0.333333  0.333333  0.0       0.0       0.0       0.0       0.333333\n\n\nObserve following:\n\nB*H == H*B \n\ntrue\n\n\nThus, filter \\({\\boldsymbol h}\\) is shift invariant filter and matrix \\({\\bf H}\\) is shift invariant operator.\nnote: \\({\\boldsymbol h}\\) is moving average filter.\nnote: for any \\({\\bf x}\\), \\({\\bf H}{\\bf x}\\) is definded by\n\\[\\left[\\frac{x_{n-1}+x_n+x_1}{3},\\frac{x_n+x_1+x_2}{3},\\dots,\\frac{x_{n-3}+x_{n-2}+x_n}{3}\\right].\\]\n\nx = [1,1,1,1,2,2,2]\nH*x\n\n7-element Vector{Float64}:\n 1.0\n 1.0\n 1.3333333333333333\n 1.6666666666666665\n 2.0\n 1.6666666666666665\n 1.3333333333333333\n\n\nnote: In some sense, the matrix \\({\\bf H}{\\bf x}\\) can be thought as generalized version of \\({\\boldsymbol h}\\star {\\bf x}\\) where \\(\\star\\) is convolution up to shift\n\nconv(h,x)\n\n9-element Vector{Float64}:\n 0.3333333333333334\n 0.6666666666666667\n 1.0\n 1.0\n 1.3333333333333333\n 1.6666666666666667\n 2.0\n 1.3333333333333333\n 0.6666666666666667\n\n\nFinally, we observe that, from the Cayley-Hamilton Theorem, \\({\\bf B}\\) satisfies its characteristic polynomial \\(\\Delta({\\bf B})\\), where \\(\\Delta(\\lambda)\\) is the determinant of \\(\\lambda{\\bf I}-{\\bf B}\\). The characteristic polynomial \\(\\Delta({\\bf B})\\) has degree \\(N\\), so, in DSP, as described so far, linear filters are (matrix) polynomial with degree at most \\(N-1\\).\n\n이 부분은 책에 써있길래 가져오긴 했는데, 무슨 의미인지 모르겠음"
  },
  {
    "objectID": "공부/CGSP/2022-12-26-Chap-12.2.html#coexisting-approaches",
    "href": "공부/CGSP/2022-12-26-Chap-12.2.html#coexisting-approaches",
    "title": "(공부) CGSP – Chap 12.2: Weakly Stationary Graph Processes",
    "section": "Coexisting Approaches",
    "text": "Coexisting Approaches\nStationary graph processes were first defined and analyzed in (Girault 2015). The fundamental problem identified there is that GSOs do not preserve energy in general and therefore cannot be isometric (Gavili and Zhang 2017). This problem is addressed in (Girault, Gonçalves, and Fleury 2015) with the definition of an isometric graph shift that preserves the eigenvector space of the Laplacian GSO but modifies its eigenvalues.\n\nGirault, Benjamin. 2015. “Stationary Graph Signals Using an Isometric Graph Translation.” In 2015 23rd European Signal Processing Conference (EUSIPCO), 1516–20. IEEE.\n\nGavili, Adnan, and Xiao-Ping Zhang. 2017. “On the Shift Operator, Graph Frequency, and Optimal Filtering in Graph Signal Processing.” IEEE Transactions on Signal Processing 65 (23): 6303–18.\n\nGirault, Benjamin, Paulo Gonçalves, and Éric Fleury. 2015. “Translation on Graphs: An Isometric Shift Operator.” IEEE Signal Processing Letters 22 (12): 2416–20.\nA stationary graph process is then defined as one whose probability distributions are invariant with respect to multiplications with the isometric shift. One drawback of this approach is that the isometric shift is a complex-valued operator and has a sparsity structure (if any) different from \\({\\bf S}\\). By contrast, the vertex-based definition in\n\\[\\mathbb{E} \\bigg[ \\big({\\bf S}^a{\\bf x}\\big)\\Big(\\big({\\bf S}^H)^b {\\bf x}\\Big)^H  \\bigg]=\\mathbb{E}\\bigg[\\big({\\bf S}^{a+c}{\\bf x}\\big)\\Big(\\big({\\bf S}^H\\big)^{b-c}{\\bf x} \\Big)^H \\bigg]\\]\nis based on the original GSO \\({\\bf S}\\), which is local and real-valued. As a result, above Eq. provides intuition on the relations between stationarity and locality, which can be leveraged to develop stationarity tests or estimation schemes that work with local information. Graph stationarity was also studied in (Perraudin and Vandergheynst 2017) where the requirement of having a covariance matrix diagonalizable by the eigenvectors of the Laplacian GSO is adopted as a definition. This condition is shown to be equivalent to statistical invariance with respect to the translation operator introduced in (Shuman, Ricaud, and Vandergheynst 2016). When the shift \\({\\bf S}\\) coincides with the Laplacian of the graph and the eigenvalues of \\({\\bf S}\\) are all distinct, Definitions 12.1 and 12.2 are equivalent to those in Perraudin and Vandergheynst (2017). Hence, the definitions presented here differ from (Perraudin and Vandergheynst 2017) in that we consider general normal shifts instead of Laplacians and that we see Definition 12.1 as a definition, not a property. These are mathematically minor differences that are important in practice though; see Segarra et al. (2017) for more details.\n\nPerraudin, Nathanaël, and Pierre Vandergheynst. 2017. “Stationary Signal Processing on Graphs.” IEEE Transactions on Signal Processing 65 (13): 3462–77.\n\nShuman, David I, Benjamin Ricaud, and Pierre Vandergheynst. 2016. “Vertex-Frequency Analysis on Graphs.” Applied and Computational Harmonic Analysis 40 (2): 260–91.\n\nSegarra, Santiago, Antonio G Marques, Gonzalo Mateos, and Alejandro Ribeiro. 2017. “Network Topology Inference from Spectral Templates.” IEEE Transactions on Signal and Information Processing over Networks 3 (3): 467–83."
  },
  {
    "objectID": "공부/CGSP/2023-01-15-Chap-12.4.html",
    "href": "공부/CGSP/2023-01-15-Chap-12.4.html",
    "title": "(공부) CGSP – Chap 12.4: Node Subsampling for PSD Estimation",
    "section": "",
    "text": "using LinearAlgebra, Plots, FFTW, Statistics\n\n\ncolumnwise_kron = \n(C,D) -&gt; hcat([kron(C[:,i],D[:,i]) for i in 1:size(C)[2]]...)\n\n#49 (generic function with 1 method)\n\n\n\n12.4.1 The Sampling Problem\n아래와 같이 길이가 \\(N=10\\) 인 신호 \\({\\bf x}\\)를 고려하자.\n\nx = rand(10)\n\n10-element Vector{Float64}:\n 0.03235208758206609\n 0.5069925854414447\n 0.5795228508497553\n 0.682832351742401\n 0.64422613488741\n 0.24116013388795854\n 0.8439116925218157\n 0.6362602319916778\n 0.386069828675059\n 0.5313655894235898\n\n\n여기에서 1,3,4,5 번째 원소만 추출하여길이가 \\(K=4\\) 인 신호 \\({\\bf y}\\)를 만들고 싶다.\n\ny = x[[1,3,4,5]]\n\n4-element Vector{Float64}:\n 0.03235208758206609\n 0.5795228508497553\n 0.682832351742401\n 0.64422613488741\n\n\n이 과정은 아래와 같이 수행할 수도 있다.\n\nΦ= [1 0 0 0 0 0 0 0 0 0\n    0 0 1 0 0 0 0 0 0 0\n    0 0 0 1 0 0 0 0 0 0\n    0 0 0 0 1 0 0 0 0 0]\n\n4×10 Matrix{Int64}:\n 1  0  0  0  0  0  0  0  0  0\n 0  0  1  0  0  0  0  0  0  0\n 0  0  0  1  0  0  0  0  0  0\n 0  0  0  0  1  0  0  0  0  0\n\n\n\nΦ*x\n\n4-element Vector{Float64}:\n 0.03235208758206609\n 0.5795228508497553\n 0.682832351742401\n 0.64422613488741\n\n\n즉 적당한 \\(K\\times N\\) selection matrix를 선언하여 subsampling을 수행할 수 있다. 이때 매트릭스 \\({\\bf \\Phi}\\)를 subsampling matrix 혹은 sparse sampling matrix 라고 부른다.\n\n\n12.4.2 Compressed LS Estimator\n\nN = 10\nV = [i*j for i in 0:(N-1) for j in 0:(N-1)] |&gt; \n    x -&gt; reshape(x,(N,N)) .|&gt; \n    x -&gt; exp(im * (2π/N) * x) \n\n10×10 Matrix{ComplexF64}:\n 1.0+0.0im        1.0+0.0im          …        1.0+0.0im\n 1.0+0.0im   0.809017+0.587785im         0.809017-0.587785im\n 1.0+0.0im   0.309017+0.951057im         0.309017-0.951057im\n 1.0+0.0im  -0.309017+0.951057im        -0.309017-0.951057im\n 1.0+0.0im  -0.809017+0.587785im        -0.809017-0.587785im\n 1.0+0.0im       -1.0+1.22465e-16im  …       -1.0+1.10218e-15im\n 1.0+0.0im  -0.809017-0.587785im        -0.809017+0.587785im\n 1.0+0.0im  -0.309017-0.951057im        -0.309017+0.951057im\n 1.0+0.0im   0.309017-0.951057im         0.309017+0.951057im\n 1.0+0.0im   0.809017-0.587785im         0.809017+0.587785im\n\n\n\nG = columnwise_kron(conj(V),V)\n\n100×10 Matrix{ComplexF64}:\n 1.0+0.0im        1.0+0.0im          …        1.0+0.0im\n 1.0+0.0im   0.809017+0.587785im         0.809017-0.587785im\n 1.0+0.0im   0.309017+0.951057im         0.309017-0.951057im\n 1.0+0.0im  -0.309017+0.951057im        -0.309017-0.951057im\n 1.0+0.0im  -0.809017+0.587785im        -0.809017-0.587785im\n 1.0+0.0im       -1.0+1.22465e-16im  …       -1.0+1.10218e-15im\n 1.0+0.0im  -0.809017-0.587785im        -0.809017+0.587785im\n 1.0+0.0im  -0.309017-0.951057im        -0.309017+0.951057im\n 1.0+0.0im   0.309017-0.951057im         0.309017+0.951057im\n 1.0+0.0im   0.809017-0.587785im         0.809017+0.587785im\n 1.0+0.0im   0.809017-0.587785im     …   0.809017+0.587785im\n 1.0+0.0im        1.0+0.0im                   1.0+0.0im\n 1.0+0.0im   0.809017+0.587785im         0.809017-0.587785im\n    ⋮                                ⋱  \n 1.0+0.0im        1.0+0.0im                   1.0+0.0im\n 1.0+0.0im   0.809017+0.587785im         0.809017-0.587785im\n 1.0+0.0im   0.809017+0.587785im     …   0.809017-0.587785im\n 1.0+0.0im   0.309017+0.951057im         0.309017-0.951057im\n 1.0+0.0im  -0.309017+0.951057im        -0.309017-0.951057im\n 1.0+0.0im  -0.809017+0.587785im        -0.809017-0.587785im\n 1.0+0.0im       -1.0-1.11022e-16im          -1.0+2.27596e-15im\n 1.0+0.0im  -0.809017-0.587785im     …  -0.809017+0.587785im\n 1.0+0.0im  -0.309017-0.951057im        -0.309017+0.951057im\n 1.0+0.0im   0.309017-0.951057im         0.309017+0.951057im\n 1.0+0.0im   0.809017-0.587785im         0.809017+0.587785im\n 1.0+0.0im        1.0+0.0im                   1.0+0.0im\n\n\n- 방법1\n\nĉx = vec(x*x')\np̂ = inv(G' * G) * G' * ĉx\n\n10-element Vector{ComplexF64}:\n    0.25854107856772546 + 2.245922875954761e-20im\n   0.004743491121735806 - 1.3138893409553828e-18im\n   0.006946482731189413 - 9.791191432641327e-19im\n   0.001721693617954179 - 1.9827974128203887e-18im\n   0.011344167525098774 + 2.6827005818057562e-19im\n 0.00012662617844242917 - 3.748573865136995e-20im\n   0.011344167525098762 + 2.7448152053954017e-18im\n  0.0017216936179541913 - 9.35534609073096e-19im\n   0.006946482731189404 + 1.954408900185458e-18im\n   0.004743491121735756 - 2.561030398375897e-18im\n\n\n- 방법2\n\nĉy = vec(y*y')\np̂ = (kron(Φ,Φ)*G)' * ĉy\n\n10-element Vector{ComplexF64}:\n   3.759462826821233 + 0.0im\n   2.765185174577697 - 2.0816681711721685e-17im\n   1.077337414764992 + 2.7755575615628914e-17im\n 0.11594812606807317 + 2.0816681711721685e-17im\n 0.08838298603932843 + 3.903127820947816e-17im\n 0.32863702713833354 + 4.622231866529366e-33im\n 0.08838298603932859 + 9.540979117872439e-18im\n  0.1159481260680729 - 2.0816681711721685e-17im\n  1.0773374147649915 + 0.0im\n  2.7651851745776965 - 2.0816681711721685e-17im"
  },
  {
    "objectID": "공부/2019-04-26-(공부) 퓨리에변환.html",
    "href": "공부/2019-04-26-(공부) 퓨리에변환.html",
    "title": "(공부) 퓨리에변환",
    "section": "",
    "text": "About this doc\n- 이번에는 퓨리에 표현들을 정리하도록 하겠다. 내생각엔 퓨리에 표현들도 벡터의 미분만큼 복잡한 것 같다. 정의가 너무 많고 그게 그거 같아서 그렇다. 이번기회에 깔끔하게 정리하도록 하자. 참고한 문헌은 아래와 같다.\n\nHaykin, S., & Van Veen, B. (2007). Signals and systems. John Wiley & Sons.\n\n\n\n들어가며\n- 우선 신호와 하나의 신호값을 구분하는 notation을 생각하자. 우리가 다루는 신호 즉 데이터는 값들의 집합이다. 우리가 시계열자료를 다룬다면 데이터는 아래와 같이 표현한다.\n\n\\(\\{x_i: i \\in \\mathbb{Z}\\}\\)\n\n이와 유시하게 우리가 다루는 자료가 \\(t \\in \\mathbb{R}\\)인 연속신호라면 아래와 같이 표현한다.\n\n\\(\\{x(t): t \\in \\mathbb{R}\\}\\)\n\n우리가 모든 \\(i \\in \\mathbb{Z}\\) 혹은 모든 \\(t \\in \\mathbb{R}\\)에서 신호를 다룰 생각이 없다면 아래와 같은 표현도 얼마든지 가능하다.\n\n\\(\\{x_i: i=0,1,\\dots, \\xi-1 \\}\\)\n\\(\\{x(t):t \\in (0,\\zeta) \\}\\)\n\n- 위와 같이 집합의 표현 없이 단독으로 \\(x_i\\), \\(x(t)\\)와 같이 쓰면 하나의 고정된 값 \\(i,t\\)에 대한 \\(x_i\\), \\(x(t)\\)로 이해하자. 솔직히 이렇게 꼭 신호를 엄밀하게 집합으로 정의하는게 유별나 보일수도 있다. 일반적으로 사람들은 \\(\\{x(t): ~t \\in \\mathbb{R} \\}\\) 대신에 보통 \\(x(t)\\)로 간단하게 줄여서 쓰곤한다.1 하지만 이 포스팅에 한정하여 위와 같이 집합의 형태로 엄밀하게 구분해 쓰도록 하자. 처음에는 익숙하지 않지만 나중에는 편리하다.\n1 나도 그렇다.\n\n퓨리에표현들\n- 지금부터 우리가 고려하는 모든 신호들은 기본적으로 (1) infinity range에서 정의된 신호라고 가정한다. 즉 연속신호이면 \\(\\mathbb{R}\\)에서 정의된다고 가정하고 이산신호면 \\(\\mathbb{Z}\\)에서 정의된다고 가정한다. 또한 우리가 분석하고자 하는 신호는 (2) integrable 하다고 가정한다. 이건 퓨리에표현들이 적분 혹은 무한합의 형태로 표현된다는 것을 상기하면 타당하여 보인다.\n- 즉 우리가 고려하는 신호는 인피니티-레인지에서 정의되며 인피니티-레인지에서 적분값이 유한한 연속신호 혹은 이산신호 임을 알 수 있다. 이러한 신호는 구체적으로는 아래와 같이 쓸 수 있다.\n\n\\(\\left\\{x(t): \\int_{-\\infty}^{\\infty} |x(t)| dt &lt;\\infty,~ t \\in \\mathbb{R} \\right\\}\\)\n\\(\\left\\{x_i: \\sum_{i=-\\infty}^{\\infty} |x_i| &lt;\\infty,~ i \\in \\mathbb{Z} \\right\\}\\)\n\n- 그런데 integrable 한 함수들만을 고려하다 보면 우리가 다룰 수 있는 신호의 범위가 확 줄어들게 된다. 가령 예를 들어서 아래와 같은 신호는 적분을 하면 무한대가 나오기 때문에 intergrable 하지 않다.\n\n\\(\\left\\{x(t): x(t)=\\sin(t)+1 ,~ t \\in \\mathbb{R} \\right\\}\\)\n\n이것은 좀 불합리해 보이는데 위의 신호는 주기신호라서 한 주기의 패턴만 분석하면 될것 같이 보이기 때문이다. 위의 신호는 intergrable 하지않지만 아래의 신호는 intergrable 하다.\n\n\\(\\left\\{x(t): x(t)=\\sin(t)+1 ,~ t \\in (0,2\\pi) \\right\\}\\)\n\n우리는 이런신호까지 분석하기로 한다. 이런신호를 분석할 수 있는 이유는 해석학 교재를 참고하면 된다.2\n2 사실 나도 잘 모름 (뭐 quotient group이런거 알아야 하는데 공부하려면 꽤 걸릴듯)- 아무튼 우리는 (1) 인피니티-레인지에서 정의되는 가지는 신호 (2) 인피니티-레인지에서 적분값이 잘 정의되는 신호, 혹은 한 주기만 적분해 보았을때 그 값이 잘 정의되는 주기신호 를 타겟팅해 분석한다. 즉 분석하는 신호는 구체적으로 아래의 4가지이다.\ncase 1: 연속/비주기\n\\(\\left\\{x(t): \\int_{-\\infty}^{\\infty} |x(t)| dt &lt;\\infty,~ t \\in \\mathbb{R} \\right\\}.\\)\ncase 2: 연속/주기\n\\(\\left\\{x(t): \\int_{0}^{\\zeta} |x(t)| dt &lt;\\infty, ~ , x(t)=x(t+\\zeta), ~ t \\in \\mathbb{R}, \\right\\}.\\)\ncase 3: 이산/비주기(=이산/무한)\n\\(\\left\\{x_i: \\sum_{i=-\\infty}^{\\infty} |x_i| &lt;\\infty,~ i \\in \\mathbb{Z} \\right\\}.\\)\ncase 4: 이산/주기(=이산/유한)\n\\(\\left\\{x_i: \\sum_{i=0}^{\\xi-1} |x_i| &lt;\\infty,~ i, x_i=x_{i+\\xi},~ i \\in \\mathbb{Z} \\right\\}.\\)\n- 표현들을 정리하기에 앞서서 몇 가지 알아두어야 할 사항이 있다. (1) 시간축에서 연속인 신호는 주파수측에서는 비주기신호가 나온다. (2) 시간축에서 디스크릿한 신호는 주파수측에서는 주기신호이다. (3) 시간축에서 주기인 신호는 주파수에서는 디스크릿하다. (4) 시간축에서 비주기신호는 주파수에서 연속이다. 이 사실들을 종합하면 각각의 경우에 해당하는 퓨리에 표현들은 아래와 같은 특징을 가지고 있음을 알 수 있다.\ncase 1: 연속/비주기 \\(\\star\\)\n\\(\\left\\{x(t): \\int_{-\\infty}^{\\infty} |x(t)| dt &lt;\\infty,~ t \\in \\mathbb{R} \\right\\}\\) – 시간\n\\(\\quad \\overset{FT}{\\Longleftrightarrow}\\)\n\\(\\left\\{\\hat x(\\omega): \\int_{-\\infty}^{\\infty} |\\hat x(\\omega)| d\\omega &lt;\\infty,~ \\omega \\in \\mathbb{R} \\right\\}\\) – 주파수\ncase 2: 연속/주기\n\\(\\left\\{x(t): \\int_{0}^{\\zeta} |x(t)| dt &lt;\\infty,~ x(t)=x(t+\\zeta),~ t \\in \\mathbb{R} \\right\\}\\) – 시간\n\\(\\quad \\overset{FS}{\\Longleftrightarrow}\\)\n\\(\\left\\{\\hat x_k: \\sum_{k=-\\infty}^{\\infty} |\\hat x_k| &lt;\\infty,~ k \\in \\mathbb{Z} \\right\\}\\) – 주파수\ncase 3: 이산/비주기(=이산/무한)\n\\(\\left\\{x_i: \\sum_{i=-\\infty}^{\\infty} |x_i| &lt;\\infty,~ i \\in \\mathbb{Z} \\right\\}\\)\n\\(\\quad \\overset{DTFT}{\\Longleftrightarrow}\\)\n\\(\\left\\{\\hat x(\\omega): \\int_{0}^{2\\pi} |\\hat x(\\omega)| d\\omega &lt;\\infty,~ \\hat x(\\omega)=\\hat x(\\omega+2\\pi),~ \\omega \\in \\mathbb{R} \\right\\}\\)\ncase 4: 이산/주기(=이산/유한) \\(\\star\\)\n\\(\\left\\{x_i: \\sum_{i=0}^{\\xi-1} |x_i| &lt;\\infty,~ x_i=x_{i+\\xi},~ i \\in \\mathbb{R} \\right\\}\\)\n\\(\\quad \\overset{DTFS}{\\Longleftrightarrow}\\)\n\\(\\left\\{\\hat x_k: \\sum_{k=0}^{\\xi-1} |\\hat x_k| &lt;\\infty,~\\hat x_k = \\hat x_{k+\\xi} ,~ k \\in \\mathbb{Z} \\right\\}\\)\n- 여기에서 \\(\\zeta\\)는 (시간축에서) 연속신호의 주기라고 정의하고 \\(\\xi\\)는 (시간축에서) 이산신호의 주기라고 약속하자. 주파수영역이 디스크릿하게 나오면 FS라고 부르고 주파수영역이 컨티뉴어스하게 나오면 FT라고 부른다. 특이한점은 비주기-이산신호에 대한 FS \\(\\hat x(\\omega)\\)는 주파수 영역에서 주기가 \\(2\\pi\\)임을 파악할 수 있다. 이유는 궁금해하지말자. (내생각에 그냥 \\(\\omega\\)를 적당히 스케일링하여 주기를 \\(2\\pi\\)로 맞췄을 거다.)\n- 이제 짜증나는 적분가능조건따위는 버리도록 하자. 대신에 각 경우에 퓨리에변환(혹은series)과 그 역이 어떻게 정의되는지 알아보자. 그리고 외우자. 각 신호가 어떠한 도메인에서 정의되는지만 잘 파악하면 의외로 외우기 쉽다.\ncase 1. 연속/비주기 \\(\\star\\star\\star\\)\n\\(\\left\\{x(t): x(t)=\\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty} \\hat x(\\omega)e^{j\\omega t} d\\omega,~ t \\in \\mathbb{R} \\right\\}\\)\n\\(\\quad \\overset{FT}{\\Longleftrightarrow}\\)\n\\(\\left\\{\\hat x(\\omega): \\hat x(\\omega)=\\int_{-\\infty}^{\\infty} x(t)e^{-j\\omega t} dt,~ \\omega \\in \\mathbb{R} \\right\\}\\)\ncase 2. 연속/주기\n\\(\\left\\{x(t): x(t)= \\sum_{k=-\\infty}^{\\infty} \\hat x_k e^{j \\frac{2\\pi}{\\zeta} t} ,~ t \\in \\mathbb{R} \\right\\}\\)\n\\(\\quad \\overset{FS}{\\Longleftrightarrow}\\)\n\\(\\left\\{\\hat x_k: \\hat x_k= \\frac{1}{\\zeta}\\int_{0}^{\\zeta}x(t)e^{-j \\frac{2\\pi k}{\\zeta}t}dt,~ k \\in \\mathbb{Z} \\right\\}\\)\ncase 3. 이산/비주기(=이산/무한)\n\\(\\left\\{x_i: x_i=\\frac{1}{2\\pi}\\int_{0}^{2\\pi}\\hat x(\\omega)e^{j \\omega i}d\\omega, ~ i \\in \\mathbb{Z} \\right\\}\\)\n\\(\\quad \\overset{DTFT}{\\Longleftrightarrow}\\)\n\\(\\left\\{\\hat x(\\omega): \\hat x(\\omega)=\\sum_{i=-\\infty}^{\\infty}x_ie^{-j\\omega i}, ~\\omega \\in \\mathbb{R} \\right\\}\\)\ncase 4. 이산/주기(=이산/유한) \\(\\star\\star\\star\\)\n\\(\\left\\{x_i: x_i=\\sum_{k=0}^{\\xi-1} \\hat x_k e^{-j\\frac{2\\pi k}{\\xi}i},~ i \\in \\mathbb{Z} \\right\\}\\)\n\\(\\quad \\overset{DTFS}{\\Longleftrightarrow}\\)\n\\(\\left\\{\\hat x_k: \\hat x_k= \\frac{1}{\\xi}\\sum_{i=0}^{\\xi-1} x_i e^{-j\\frac{2\\pi k}{\\xi}i},~ k \\in \\mathbb{Z} \\right\\}\\)\n- 주기함수는 (그것이 이산이든 연속이든) 주파수영역에서의 값이 디스크릿하다. 즉 위에서 case2와 case4인 경우는 주파수영역에서 값이 디스크릿하다. 이것을 연속함수인것처럼 바꿔보면 아래와 같이 쓸 수 있다.\ncase 2. 연속/주기\n\\(\\left\\{x(t): x(t)= \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty} \\hat x(\\omega)e^{j\\omega t} d\\omega,~ t \\in \\mathbb{R} \\right\\}\\)\n\\(\\quad \\overset{FT}{\\Longleftrightarrow}\\)\n\\(\\left\\{\\hat x(\\omega): 2\\pi\\sum_{k=-\\infty}^{\\infty}\\left[\\frac{1}{\\zeta}\\int_{0}^{\\zeta}x(t)e^{-j \\frac{2\\pi k}{\\zeta}t}dt\\right]\\delta\\left(\\omega-\\frac{2\\pi k}{\\zeta}\\right), ~ k \\in \\mathbb{Z} \\right\\}\\)\ncase 4. 이산/주기(=이산/유한)\n\\(\\left\\{x_i: x_i=\\frac{1}{2\\pi}\\int_{0}^{2\\pi}\\hat x(\\omega)e^{j \\omega i}d\\omega,,~ i \\in \\mathbb{Z} \\right\\}\\)\n\\(\\quad\\overset{DTFT}{\\Longleftrightarrow}\\)\n\\(\\left\\{\\hat x(\\omega): 2\\pi\\sum_{k=-\\infty}^{\\infty}\\left[\\frac{1}{\\xi}\\sum_{i=0}^{\\xi-1} x_i e^{-j\\frac{2\\pi k}{\\xi}i}\\right]\\delta\\left(\\omega-\\frac{2\\pi k}{\\xi}\\right),~ k \\in \\mathbb{Z} \\right\\}\\)\n- 주목할것은 주기가 \\(\\zeta\\) 혹은 \\(\\xi\\) 인 함수의 주파수 응답은 오로지\n\n\\(\\omega \\in \\left\\{\\frac{2 \\pi k}{\\zeta}, k \\in \\mathbb{Z}\\right\\}\\)\n\n혹은\n\n\\(\\omega \\in \\left\\{\\frac{2 \\pi k}{\\xi}, k \\in \\mathbb{Z}\\right\\}\\)\n\n에서만 존재한다는 점이다. 또한 이산신호의 경우 \\(x_i\\)의 주기가 \\(\\xi\\) 이면 \\(\\hat{x}(\\omega)\\)의 주기역시 \\(\\xi\\) 라는점 역시 주목할만한 부분이다.\n- 주파수영역에서 디스크릿한 함수를 연속인것처럼 표현했듯이 시간영역에서 디스크릿한 함수 역시 연속인것처럼 표현할 수 있다. 예를들면 \\(\\{x_i: x_i=x(iT),~i \\in \\mathbb{Z}\\}\\) 와 같은 관계가 있는 경우 아래와 같이 표현 가능하다.\n\\[x_{\\delta}(t)=\\sum_{i=-\\infty}^{\\infty}x_i\\delta(t-iT).\\]\n이거 엄청 중요하다."
  },
  {
    "objectID": "공부/2023-03-01-(공부&서연) 지수분포 가설검정.out.html",
    "href": "공부/2023-03-01-(공부&서연) 지수분포 가설검정.out.html",
    "title": "(공부&서연) 지수분포 가설검정",
    "section": "",
    "text": "신록예찬\n2023-03-01\n\nusing Distributions, Plots\n\n(문제) \\(X_1,X_2\\)가 평균이 \\(\\theta\\)인 지수분포에서 추출한 랜덤표본이라고 하자. 가설 \\(H_0: \\theta=2\\) vs \\(H_1:\\theta=1\\) 에 대하여, \\(H_0\\)에 대한 기각영역을\n\\[\\frac{f(x_1;\\theta=2)f(x_2;\\theta=2)}{f(x_1;\\theta=1)f(x_2;\\theta=1)}&lt;\\frac{1}{2}\\]\n와 같이 설정하자. 이와 같은 검정법에 대한 \\(\\alpha\\)와 \\(\\beta\\)를 구하라.\n(풀이)\n문제요약\n\n\\(f(x) = \\frac{1}{\\theta} \\exp(-\\frac{x}{\\theta})\\) -&gt; 평균이 \\(\\theta\\) 인 지수분포\n검정통계량: \\(T=\\frac{f(x_1;2)f(x_2;2)}{f(x_1;1)f(x_2;1)}\\)\n\\(\\alpha = P(\\text{Reject $H_0$|$H_0$ is true}) = P(T&lt;\\frac{1}{2} | \\text{$H_0$ is true})\\)\n\\(\\beta = P(\\text{Accept $H_0$|$H_1$ is true}) = P(T&gt;\\frac{1}{2} | \\text{$H_1$ is true})\\)\n\n풀이시작\n\nT= x -&gt; 0.5*exp(-0.5*x[1]) * 0.5*exp(-0.5*x[2])  / (exp(-x[1])*exp(-x[2]))\n\n#1 (generic function with 1 method)\n\n\n\\(\\alpha\\)를 구해보자. (시뮬)\n\nθ=2 \nx = rand(Exponential(θ),2)\n\n2-element Vector{Float64}:\n 1.4932782791687658\n 3.904496314340747\n\n\n\nT(x)\n\n3.715796051759978\n\n\n\nTs = [rand(Exponential(θ),2) |&gt; T for i in 1:1400000]\nmean(Ts .&lt; 1/2)\n\n0.1535007142857143\n\n\n\\(\\beta\\)를 구해보자. (시뮬)\n\nθ=1\nx = rand(Exponential(θ),2)\n\n2-element Vector{Float64}:\n 1.0915718974295616\n 3.322182470278192\n\n\n\nTs = [rand(Exponential(θ),2) |&gt; T for i in 1:1400000]\nmean(Ts .&gt; 1/2)\n\n0.5967985714285714\n\n\n\\(\\alpha\\)를 구해보자. (이론)\n\\(T(X_1,X_2) = \\frac{0.25\\exp(-0.5X_1 -0.5X_2)}{\\exp(-X_1-X_2)}=0.25\\exp(0.5X_1+0.5X_2)\\)\n$T(X_1,X_2)&lt; (0.5X_1+0.5X_2) &lt; 2 X_1+X_2&lt; 2 $\n그런데 \\(X_1+X_2 \\sim \\chi^2(4)\\) under \\(H_0\\)\n\\(P(X_1+X_2 &lt; 2\\ln2) = \\int_0^{2\\ln2} \\frac{1}{4\\Gamma(2)}x e^{-x/2}dx=\\int_0^{\\ln2} t e^{-t}dt=\\big[t(-e^{-t})-e^{-t}\\big]_0^{\\ln2}\\)\n\nt = log(2) \nu = t*(-exp(-t)) - exp(-t)\nt = 0\nl = t*(-exp(-t)) - exp(-t)\n\n-1.0\n\n\n\nu-l\n\n0.1534264097200273\n\n\n\\(\\beta\\)를 구해보자. (이론)\n$T(X_1,X_2)&gt; (0.5X_1+0.5X_2) &gt; 2 (X_1+X_2)&gt; 4 $\n그런데 \\(2(X_1+X_2) \\sim \\chi^2(4)\\) under \\(H_1\\)\n\\(P(2(X_1+X_2) &gt; 4\\ln2) = \\int_{4\\ln2}^{\\infty}\\frac{1}{4\\Gamma(2)}x e^{-x/2}dx=\\int_{2\\ln2}^{\\infty} t e^{-t}dt=\\big[t(-e^{-t})-e^{-t}\\big]_{2\\ln2}^{\\infty}\\)\n\nu = 0\nt = 2*log(2)\nl = t*(-exp(-t)) - exp(-t)\nu-l\n\n0.5965735902799727"
  },
  {
    "objectID": "공부/HF/2024-08-29-image_classification.html",
    "href": "공부/HF/2024-08-29-image_classification.html",
    "title": "(공부) image_classification",
    "section": "",
    "text": "# Transformers installation\n# ! pip install transformers datasets\n# To install from source instead of the last release, comment the command above and uncomment the following one.\n# ! pip install git+https://github.com/huggingface/transformers.git"
  },
  {
    "objectID": "공부/HF/2024-08-29-image_classification.html#load-food-101-dataset",
    "href": "공부/HF/2024-08-29-image_classification.html#load-food-101-dataset",
    "title": "(공부) image_classification",
    "section": "Load Food-101 dataset",
    "text": "Load Food-101 dataset\nStart by loading a smaller subset of the Food-101 dataset from the 🤗 Datasets library. This will give you a chance to experiment and make sure everything works before spending more time training on the full dataset.\n\nfrom datasets import load_dataset\n\nfood = load_dataset(\"food101\", split=\"train[:5000]\")\n\n/root/anaconda3/envs/hf/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n\nSplit the dataset’s train split into a train and test set with the train_test_split method:\n\nfood = food.train_test_split(test_size=0.2)\n\nThen take a look at an example:\n\nfood[\"train\"][0]\n\n{'image': &lt;PIL.Image.Image image mode=RGB size=512x512&gt;, 'label': 81}\n\n\nEach example in the dataset has two fields:\n\nimage: a PIL image of the food item\nlabel: the label class of the food item\n\nTo make it easier for the model to get the label name from the label id, create a dictionary that maps the label name to an integer and vice versa:\n\nlabels = food[\"train\"].features[\"label\"].names\nlabel2id, id2label = dict(), dict()\nfor i, label in enumerate(labels):\n    label2id[label] = str(i)\n    id2label[str(i)] = label\n\nNow you can convert the label id to a label name:\n\nid2label[str(79)]\n\n'prime_rib'"
  },
  {
    "objectID": "공부/HF/2024-08-29-image_classification.html#preprocess",
    "href": "공부/HF/2024-08-29-image_classification.html#preprocess",
    "title": "(공부) image_classification",
    "section": "Preprocess",
    "text": "Preprocess\nThe next step is to load a ViT image processor to process the image into a tensor:\n\nfrom transformers import AutoImageProcessor\n\ncheckpoint = \"google/vit-base-patch16-224-in21k\"\nimage_processor = AutoImageProcessor.from_pretrained(checkpoint)\n\nFast image processor class &lt;class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'&gt; is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n\n\nApply some image transformations to the images to make the model more robust against overfitting. Here you’ll use torchvision’s transforms module, but you can also use any image library you like.\nCrop a random part of the image, resize it, and normalize it with the image mean and standard deviation:\n\nfrom torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor\n\nnormalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\nsize = (\n    image_processor.size[\"shortest_edge\"]\n    if \"shortest_edge\" in image_processor.size\n    else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n)\n_transforms = Compose([RandomResizedCrop(size), ToTensor(), normalize])\n\nThen create a preprocessing function to apply the transforms and return the pixel_values - the inputs to the model - of the image:\n\ndef transforms(examples):\n    examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n    del examples[\"image\"]\n    return examples\n\nTo apply the preprocessing function over the entire dataset, use 🤗 Datasets with_transform method. The transforms are applied on the fly when you load an element of the dataset:\n\nfood = food.with_transform(transforms)\n\nNow create a batch of examples using DefaultDataCollator. Unlike other data collators in 🤗 Transformers, the DefaultDataCollator does not apply additional preprocessing such as padding.\n\nfrom transformers import DefaultDataCollator\n\ndata_collator = DefaultDataCollator()"
  },
  {
    "objectID": "공부/HF/2024-08-29-image_classification.html#evaluate",
    "href": "공부/HF/2024-08-29-image_classification.html#evaluate",
    "title": "(공부) image_classification",
    "section": "Evaluate",
    "text": "Evaluate\nIncluding a metric during training is often helpful for evaluating your model’s performance. You can quickly load an evaluation method with the 🤗 Evaluate library. For this task, load the accuracy metric (see the 🤗 Evaluate quick tour to learn more about how to load and compute a metric):\n\nimport evaluate\n\naccuracy = evaluate.load(\"accuracy\")\n\nThen create a function that passes your predictions and labels to compute to calculate the accuracy:\n\nimport numpy as np\n\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return accuracy.compute(predictions=predictions, references=labels)\n\nYour compute_metrics function is ready to go now, and you’ll return to it when you set up your training."
  },
  {
    "objectID": "공부/HF/2024-08-29-image_classification.html#train",
    "href": "공부/HF/2024-08-29-image_classification.html#train",
    "title": "(공부) image_classification",
    "section": "Train",
    "text": "Train\n\nIf you aren’t familiar with finetuning a model with the Trainer, take a look at the basic tutorial here!\n\nYou’re ready to start training your model now! Load ViT with AutoModelForImageClassification. Specify the number of labels along with the number of expected labels, and the label mappings:\n\nfrom transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n\nmodel = AutoModelForImageClassification.from_pretrained(\n    checkpoint,\n    num_labels=len(labels),\n    id2label=id2label,\n    label2id=label2id,\n)\n\nSome weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n\nAt this point, only three steps remain:\n\nDefine your training hyperparameters in TrainingArguments. It is important you don’t remove unused columns because that’ll drop the image column. Without the image column, you can’t create pixel_values. Set remove_unused_columns=False to prevent this behavior! The only other required parameter is output_dir which specifies where to save your model. You’ll push this model to the Hub by setting push_to_hub=True (you need to be signed in to Hugging Face to upload your model). At the end of each epoch, the Trainer will evaluate the accuracy and save the training checkpoint.\nPass the training arguments to Trainer along with the model, dataset, tokenizer, data collator, and compute_metrics function.\nCall train() to finetune your model.\n\n\n# training_args = TrainingArguments(\n#     output_dir=\"my_awesome_food_model\",\n#     remove_unused_columns=False,\n#     eval_strategy=\"epoch\",\n#     save_strategy=\"epoch\",\n#     learning_rate=5e-5,\n#     per_device_train_batch_size=16,\n#     gradient_accumulation_steps=4,\n#     per_device_eval_batch_size=16,\n#     num_train_epochs=3,\n#     warmup_ratio=0.1,\n#     logging_steps=10,\n#     load_best_model_at_end=True,\n#     metric_for_best_model=\"accuracy\",\n#     push_to_hub=False,\n# )\n\n# trainer = Trainer(\n#     model=model,\n#     args=training_args,\n#     data_collator=data_collator,\n#     train_dataset=food[\"train\"],\n#     eval_dataset=food[\"test\"],\n#     tokenizer=image_processor,\n#     compute_metrics=compute_metrics,\n# )\n\n# trainer.train()\n\ntraining_args = TrainingArguments(\n    output_dir=\"/tmp/training_output\",  # 임시 디렉토리를 지정\n    remove_unused_columns=False,\n    eval_strategy=\"epoch\",  # 평가 전략을 유지하여 최적의 모델을 찾기 위함\n    save_strategy=\"no\",  # 모델 체크포인트 저장 비활성화\n    logging_strategy=\"no\",  # 로그 저장 비활성화\n    learning_rate=5e-5,\n    per_device_train_batch_size=16,\n    gradient_accumulation_steps=4,\n    per_device_eval_batch_size=16,\n    num_train_epochs=3,\n    warmup_ratio=0.1,\n    load_best_model_at_end=False,  # 최적의 모델을 자동으로 로드\n    push_to_hub=False,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=food[\"train\"],\n    eval_dataset=food[\"test\"],\n    tokenizer=image_processor,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()\n\n\n    \n      \n      \n      [186/186 03:20, Epoch 2/3]\n    \n    \n\n\n\nEpoch\nTraining Loss\nValidation Loss\nAccuracy\n\n\n\n\n0\nNo log\n1.102476\n0.919000\n\n\n2\nNo log\n0.813274\n0.915000\n\n\n\n\n\n\nTrainOutput(global_step=186, training_loss=0.9891333631289903, metrics={'train_runtime': 201.1188, 'train_samples_per_second': 59.666, 'train_steps_per_second': 0.925, 'total_flos': 9.232831524962304e+17, 'train_loss': 0.9891333631289903, 'epoch': 2.976})\n\n\n\nFor a more in-depth example of how to finetune a model for image classification, take a look at the corresponding PyTorch notebook."
  },
  {
    "objectID": "공부/HF/2024-08-29-image_classification.html#inference",
    "href": "공부/HF/2024-08-29-image_classification.html#inference",
    "title": "(공부) image_classification",
    "section": "Inference",
    "text": "Inference\nGreat, now that you’ve fine-tuned a model, you can use it for inference!\nLoad an image you’d like to run inference on:\n\nds = load_dataset(\"food101\", split=\"validation[:10]\")\nimage = ds[\"image\"][0]\n\n\n&lt;img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\" alt=\"image of beignets\"/&gt;\n\nThe simplest way to try out your finetuned model for inference is to use it in a pipeline(). Instantiate a pipeline for image classification with your model, and pass your image to it:\n\nfrom transformers import pipeline\n\n#classifier = pipeline(\"image-classification\", model=\"my_awesome_food_model\")\nclassifier = pipeline(\"image-classification\", model=trainer.model)\nclassifier(image)\n\nOSError: my_awesome_food_model does not appear to have a file named config.json. Checkout 'https://huggingface.co/my_awesome_food_model/tree/None' for available files.\n\n\nYou can also manually replicate the results of the pipeline if you’d like:\nLoad an image processor to preprocess the image and return the input as PyTorch tensors:\n\nfrom transformers import AutoImageProcessor\nimport torch\n\nimage_processor = AutoImageProcessor.from_pretrained(\"my_awesome_food_model\")\ninputs = image_processor(image, return_tensors=\"pt\")\n\nPass your inputs to the model and return the logits:\n\nfrom transformers import AutoModelForImageClassification\n\nmodel = AutoModelForImageClassification.from_pretrained(\"my_awesome_food_model\")\nwith torch.no_grad():\n    logits = model(**inputs).logits\n\nGet the predicted label with the highest probability, and use the model’s id2label mapping to convert it to a label:\n\npredicted_label = logits.argmax(-1).item()\nmodel.config.id2label[predicted_label]\n\n'beignets'"
  },
  {
    "objectID": "공부/HF/2024-10-31-(강의) 이미지캡셔닝2.html",
    "href": "공부/HF/2024-10-31-(강의) 이미지캡셔닝2.html",
    "title": "(강의) 이미지캡셔닝2",
    "section": "",
    "text": "# Transformers installation\n# ! pip install transformers datasets\n# To install from source instead of the last release, comment the command above and uncomment the following one.\n# ! pip install git+https://github.com/huggingface/transformers.git\n\npip install transformers datasets evaluate -q\npip install jiwer -q\n\n1. Imports\n\nimport PIL.Image\nimport torchvision\nimport io\nimport requests\nimport datasets\nimport transformers\nfrom transformers import TrainingArguments, Trainer\nimport torch\nfrom transformers import AutoProcessor\n\n/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n\n\ncoco = datasets.load_dataset(\"UCSC-VLAA/Recap-COCO-30K\")['train'].train_test_split(test_size=0.3)\n\n\ncoco\n\nDatasetDict({\n    train: Dataset({\n        features: ['image_id', 'coco_url', 'image', 'caption', 'recaption'],\n        num_rows: 21352\n    })\n    test: Dataset({\n        features: ['image_id', 'coco_url', 'image', 'caption', 'recaption'],\n        num_rows: 9152\n    })\n})\n\n\n\nfrom transformers import AutoProcessor\n\ncheckpoint = \"microsoft/git-base\"\nprocessor = AutoProcessor.from_pretrained(checkpoint)\n\n\n#processor(coco['train'][:5]['image'],coco['train'][:5]['caption'])\n\n\ndef transforms(example_batch):\n    images = [x for x in example_batch[\"image\"]]\n    captions = [x for x in example_batch[\"caption\"]]\n    inputs = processor(images=images, text=captions, padding=\"max_length\")\n    inputs.update({\"labels\": inputs[\"input_ids\"]})\n    return inputs\n\n\ncoco['train'].set_transform(transforms)\ncoco['test'].set_transform(transforms)\n\n\nfrom transformers import AutoModelForCausalLM\n\nmodel = AutoModelForCausalLM.from_pretrained(checkpoint)\n\n\nfrom evaluate import load\nimport torch\n\nwer = load(\"wer\")\n\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predicted = logits.argmax(-1)\n    decoded_labels = processor.batch_decode(labels, skip_special_tokens=True)\n    decoded_predictions = processor.batch_decode(predicted, skip_special_tokens=True)\n    wer_score = wer.compute(predictions=decoded_predictions, references=decoded_labels)\n    return {\"wer_score\": wer_score}\n\n\nfrom transformers import TrainingArguments, Trainer\n\nmodel_name = checkpoint.split(\"/\")[1]\n\ntraining_args = TrainingArguments(\n    output_dir=f\"{model_name}-pokemon\",\n    learning_rate=5e-5,\n    num_train_epochs=50,\n    fp16=True,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    # gradient_accumulation_steps=2,\n    # save_total_limit=3,\n    # eval_strategy=\"steps\",\n    # eval_steps=50,\n    # save_strategy=\"steps\",\n    # save_steps=50,\n    # logging_steps=50,\n    remove_unused_columns=False,\n    push_to_hub=True,\n    label_names=[\"labels\"],\n    load_best_model_at_end=True,\n)\n\nValueError: --load_best_model_at_end requires the save and eval strategy to match, but found\n- Evaluation strategy: IntervalStrategy.NO\n- Save strategy: IntervalStrategy.STEPS\n\n\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=coco['train'],\n    eval_dataset=coco['test'],\n    compute_metrics=compute_metrics,\n)\n\n/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n\n\n\ntrainer.train()\n\n\n    \n      \n      \n      [    51/533800 00:04 &lt; 13:52:13, 10.69 it/s, Epoch 0.00/50]\n    \n    \n\n\n\nStep\nTraining Loss\nValidation Loss\n\n\n\n\n\n\n    \n      \n      \n      [ 121/9152 00:17 &lt; 21:29, 7.00 it/s]\n    \n    \n\n\nOutOfMemoryError: CUDA out of memory. Tried to allocate 9.84 GiB. GPU 0 has a total capacity of 23.68 GiB of which 9.76 GiB is free. Including non-PyTorch memory, this process has 13.89 GiB memory in use. Of the allocated memory 11.84 GiB is allocated by PyTorch, and 1.73 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
  },
  {
    "objectID": "공부/HF/2024-11-16-(강의) 데이터콜렉터.html#a.-외우세요-starstarstar",
    "href": "공부/HF/2024-11-16-(강의) 데이터콜렉터.html#a.-외우세요-starstarstar",
    "title": "(강의) 데이터콜렉터",
    "section": "A. 외우세요 \\((\\star\\star\\star)\\)",
    "text": "A. 외우세요 \\((\\star\\star\\star)\\)\n- data_collator를 잘 설계하는 방법: trainer_input과 model이 주어졌을때 data_collator는 아래의 코드가 동작하도록 설계하면 된다.\ntrainer_input = ~~~\nmodel = ~~~~ \nbatch_maker = transformers.Trainer(\n    model = model,\n    data_collator = lambda x: x\n) # 이 과정에서 model이 cuda로 감 \n_batched_data = batch_maker.get_test_dataloader(trainer_input) # 이 과정에서 trainer_input이 cuda로 감\nbatched_data = list(_batched_data)\nsingle_batch = batched_data[0]\nmodel.to(\"cpu\") # 경우에 따라 생략해야할수도있음\nmodel(**data_collator(single_batch))\n- 위의 코드가 오류없이 실행되었다면 아래의 코드를 사용할 수 있다.\ntrainer = transformers.Trainer(\n    model = model,\n    data_collator = data_collator\n)\ntrainer.predict(trainer_input)\n\n이걸 어떻게 알았냐고요? 코드뜯어봤습니다.. \\(\\to\\) 숙제\n\n\n\n\n\n\n\nImportant\n\n\n\n코랩사용자의 경우 아래와 같이 wandb(Weights & Biases) 로그인을 요구하는 문제가 있습니다.\nwandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\nwandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\nwandb: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\nwandb: You can find your API key in your browser here: https://wandb.ai/authorize\nwandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\n이를 해결하기 위해서는 아래의 코드를 코랩처음에 실행하면 됩니다.\nimport os\nos.environ[\"WANDB_MODE\"] = \"offline\"\n\n\n\n\n\n\n\n\nNote\n\n\n\n주의: data의 type이 꼭 Dataset 일 필요는 없다.."
  },
  {
    "objectID": "공부/HF/2024-11-16-(강의) 데이터콜렉터.html#b.-imdb-복습",
    "href": "공부/HF/2024-11-16-(강의) 데이터콜렉터.html#b.-imdb-복습",
    "title": "(강의) 데이터콜렉터",
    "section": "B. IMDB – 복습",
    "text": "B. IMDB – 복습\nref: https://huggingface.co/docs/transformers/tasks/sequence_classification\n1. 데이터준비: \"guebin/imdb-tiny\" \\(\\to\\) trainer_input\n\nimdb = datasets.load_dataset(\"guebin/imdb-tiny\")\ntokenizer = transformers.AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\") \ndef preprocess_function(examples):\n    return tokenizer(examples[\"text\"], truncation=True)\ntokenized_imdb = imdb.map(preprocess_function,batched=True)\ntrainer_input = tokenized_imdb['train']\n\n2. 모델준비: \"distilbert/distilbert-base-uncased\" \\(\\to\\)model\n\nmodel = transformers.AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert/distilbert-base-uncased\", num_labels=2\n)\n\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n\n3. 데이터콜렉터: DataCollatorWithPadding() \\(\\to\\) data_collator\n\ndata_collator = transformers.DataCollatorWithPadding(tokenizer=tokenizer)\ndata_collator\n\nDataCollatorWithPadding(tokenizer=DistilBertTokenizerFast(name_or_path='distilbert/distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n    0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n    100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n    101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n    102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n    103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n}, padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')\n\n\n\n데이터콜렉터가 올바로 설정되었는지 체크하고, 적당한 trainer를 만들어\ntrainer.predict(trainer_input)\n이 정상동작하는지 확인하라.\n(풀이)\n\nbatch_maker = transformers.Trainer(\n    model = model,\n    data_collator = lambda x: x,\n) # 이 과정에서 model이 cuda로 감 \n_batched_data = batch_maker.get_test_dataloader(trainer_input) # 이 과정에서 trainer_input이 cuda로 감\nbatched_data = list(_batched_data)\nsingle_batch = batched_data[0]\nmodel.to(\"cpu\") # 경우에 따라 생략해야할수도있음\nmodel(**data_collator(single_batch))\n\nSequenceClassifierOutput(loss=tensor(0.6714, grad_fn=&lt;NllLossBackward0&gt;), logits=tensor([[-0.0168, -0.0577],\n        [ 0.0035, -0.0523],\n        [-0.0044, -0.0638],\n        [ 0.0191, -0.0579],\n        [ 0.0050, -0.0271],\n        [ 0.0182, -0.0258],\n        [ 0.0243, -0.0059],\n        [ 0.0056, -0.0080]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)\n\n\n\n잘 돌아감..\n잘 설계된 data_collator라는 의미\n이걸 이용해서 진짜 trainer를 만들자..\n\n\ntrainer = transformers.Trainer(\n    model = model,\n    data_collator = data_collator\n)\nout = trainer.predict(trainer_input)\nout \n\n\n\n\nPredictionOutput(predictions=array([[-0.01682485, -0.05772787],\n       [ 0.00350759, -0.05234354],\n       [-0.0044021 , -0.06378944],\n       [ 0.01906627, -0.05794427],\n       [ 0.00501909, -0.02714018],\n       [ 0.0182183 , -0.02577444],\n       [ 0.02433074, -0.00588998],\n       [ 0.00561093, -0.00798136],\n       [ 0.015525  , -0.01578641],\n       [ 0.03086514, -0.00874608]], dtype=float32), label_ids=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), metrics={'test_loss': 0.6722059845924377, 'test_model_preparation_time': 0.0015, 'test_runtime': 0.2214, 'test_samples_per_second': 45.168, 'test_steps_per_second': 9.034})\n\n\n#\n- 관찰1: 여기에서 batched_data[-1]은 하나의 배치를 의미, 그런데 모델의 입력으로 사용하기에는 형식이 맞지 않음\n\n#batched_data[-1] -- 안될것같은 형식\n\n\nmodel.to(\"cpu\") # 경우에 따라 생략해야할수도있음\nmodel(**batched_data[-1])\n\nTypeError: DistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): DistilBertSdpaAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n) argument after ** must be a mapping, not list\n\n\n- 관찰2: 여기에서 data_collator(batched_data[-1]) 역시 하나의 배치를 의미. 이번에는 형식이 잘 맞음.\n\n#data_collator(batched_data[-1]) -- 될 것 같은 형식\n\n\nmodel.to(\"cpu\") # 경우에 따라 생략해야할수도있음\nmodel(**data_collator(batched_data[-1]))\n\nSequenceClassifierOutput(loss=tensor(0.6756, grad_fn=&lt;NllLossBackward0&gt;), logits=tensor([[ 0.0155, -0.0158],\n        [ 0.0309, -0.0087]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)\n\n\n\n\n\n\n\n\ndata_collator – 심화이해\n\n\n\n아래의 형식으로 정리된 배치화된 자료가 있다고 하자. (주의: batched_data는 항상 list비슷한 오브젝트이어야함)\nbatched_data = [batch_1, batch_2, ...,batch_n]\ndata_collator 는 각각의 single_batch, 즉 batch_1, batch_2 등을 model이 처리가능한 형태로 “형식”을 맞춰주는 역할을 한다. 즉 아래가 실행되도록 만들어주는 역할을 한다.\nmodel(**data_collator(batch_1))\n\n\n\n\n\n\n\n\ntrainer와 model의 자료처리과정 비교\n\n\n\n#. model의 자료처리과정\n-코드: model.forward(model_input)\n-처리과정: model_input에 정리된 입력을 단순히 model.forward() 함수가 처리.\n#. trainer의 자료처리과정\n-코드: trainer.predict(trainer_input)\n-처리과정: 크게 배치화 \\(\\to\\) 데이터콜렉팅 \\(\\to\\) 추론 의 과정을 거친다.\n\ntrainer_input을 배치(batch)로 나눈다.\n각 배치(=single_batch)를 data_collator를 통해 형식을 맞춘다.\n형식이 조정된 데이터를 model.forward의 입력으로 전달한다.\n\n-슈도코드:\n## 이 코드는.. \ntrainer.predict(trainer_input)\n\n## 대략 아래의 느낌으로 해석하면 된다.. (동일X. 결과정리, GPU처리 등 세부로직이 더 있음)\nbatched_data = some_function(trainer_input)\nfor single_batch in batched_data:\n    collated_data = data_collator(single_batch)\n    model(**collated_data)\n\n\n\n\n\n\n\n\ntrainer.predict() 의 분해\n\n\n\ntrainer.predict()의 동작은 개념적으로 (1) 배치화 (2) 데이터콜렝팅 (3) 추론의 과정으로 분해할 수 있지만, 실제이러한 과정으로 코드를 정확하게 분리하는건 어렵다. (실제로도 별로 그럴 이유가 없다) 하지만 이해를 위해서 코드조각을 분리할 필요가 있는데 아래의 3개 코드조각은 이러한 분해를 최대한 비슷하게 수동구현한 것이다.\n1. 배치화: trainer_input \\(\\to\\) batched_data\nbatch_maker = transformers.Trainer(\n    model = model,\n    data_collator = lambda x: x\n)\n_batched_data = batch_maker.get_test_dataloader(trainer_input)\nbatched_data = list(_batched_data)\n2. 데이터콜렉팅: single_batch \\(\\to\\) collated_data\n#for single_batch in batched_data:\n    collated_data = data_collator(single_batch)\n3. 추론: collated_data \\(\\to\\) model_out\n#for single_batch in batched_data:\n    #collated_data = data_collator(single_batch)\n    model_out = model(**collated_data)"
  },
  {
    "objectID": "공부/HF/2024-11-16-(강의) 데이터콜렉터.html#c.-food101-복습",
    "href": "공부/HF/2024-11-16-(강의) 데이터콜렉터.html#c.-food101-복습",
    "title": "(강의) 데이터콜렉터",
    "section": "C. FOOD101 – 복습",
    "text": "C. FOOD101 – 복습\nref: https://huggingface.co/docs/transformers/tasks/image_classification\n1. 데이터준비: \"guebin/food101-tiny\" \\(\\to\\) trainer_input\n\nfood = datasets.load_dataset(\"guebin/food101-tiny\")\nimage_processor = transformers.AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\nnormalize = torchvision.transforms.Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\nsize = (\n    image_processor.size[\"shortest_edge\"]\n    if \"shortest_edge\" in image_processor.size\n    else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n)\n_transforms = torchvision.transforms.Compose([\n    torchvision.transforms.RandomResizedCrop(size), \n    torchvision.transforms.ToTensor(), \n    normalize\n])\ndef transforms(examples):\n    examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n    del examples[\"image\"]\n    return examples\ntrainer_input = food['train'].with_transform(transforms)\ntrainer_input\n\nFast image processor class &lt;class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'&gt; is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n\n\nDataset({\n    features: ['image', 'label'],\n    num_rows: 10\n})\n\n\n2. 모델준비: \"google/vit-base-patch16-224-in21k\" \\(\\to\\)model\n\nlabels = food[\"train\"].features[\"label\"].names\nlabel2id, id2label = dict(), dict()\nfor i, label in enumerate(labels):\n    label2id[label] = str(i)\n    id2label[str(i)] = label\nmodel = transformers.AutoModelForImageClassification.from_pretrained(\n    \"google/vit-base-patch16-224-in21k\",\n    num_labels=len(labels),\n    id2label=id2label,\n    label2id=label2id,\n)\n\nSome weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n\n3. 데이터콜렉터: DefaultDataCollator() \\(\\to\\) data_collator\n\ndata_collator = transformers.DefaultDataCollator()\ndata_collator\n\nDefaultDataCollator(return_tensors='pt')\n\n\n\n데이터콜렉터가 올바로 설정되었는지 체크하고, 적당한 trainer를 만들어\ntrainer.predict(trainer_input)\n이 정상동작하는지 확인하라.\n(풀이1) – 실패\n\nbatch_maker = transformers.Trainer(\n    model = model,\n    data_collator = lambda x: x\n) # 이 과정에서 model이 cuda로 감 \n_batched_data = batch_maker.get_test_dataloader(trainer_input) # 이 과정에서 trainer_input이 cuda로 감\nbatched_data = list(_batched_data)\nsingle_batch = batched_data[0]\nmodel.to(\"cpu\") # 경우에 따라 생략해야할수도있음\nmodel(**data_collator(single_batch))\n\nKeyError: 'image'\n\n\n- 왜 실패했지?? (예전에는 분명히 되었던 것 같은뎅..)\n\n\n\n\n\n\nNote\n\n\n\n&lt;에러메시지의 해석&gt;\n- 아래가 동작하지 않음.\nbatched_data = list(_batched_data)\n- 그 이유는 아래가 동작하지 않기 때문임.\nnext(dataloader_iter)\n- …(생략)…\n- 최종적으로는 아래가 동작하지 않기 때문에 생긴 문제였음. (그런데 이건 .with_transform()에 있는 코드인데?)\nexamples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n- 결국\n[_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n를 실행하는 시점에서 examples[\"image\"]가 없었다는 의미.\n\n\n\n눈치: with_transform이 지금 실행되는거였어?\n\n- 왜 이런일이 생기지?\n- 배치화를 하는 코드\n_batched_data = batch_maker.get_test_dataloader(trainer_input)\n에서 아래의 column_names:\n\npixel_values\nhead_mask\nlabels\noutput_attentions\noutput_hidden_states\ninterpolate_pos_encoding\nreturn_dict\n\n를 제외하고는 모두 트레이너(batch_maker = trainer)가 강제로 제거하는 로직이 있음.1\n1 왜 이런 로직이 있을까? 이런 로직이 없다면 model의 args를 강제로 외우고 있어야 하니까..- image라는 column_name은 위에 해당되지 않으므로 제거됨.\n- 그리고 image 칼럼이 제거된 이후에 with_transform 이 나중에 실행되면서 (지연실행) 문제가 발생.\n\n이걸 어떻게 알았냐고요? 코드뜯어봤습니다.. \\(\\to\\) 숙제\n\n\n\n\n\n\n\n중간정리\n\n\n\ntrainer.predict() 은 (1) 배치화 (2) 데이터콜렉팅 (3) 추론의 과정을 거친다. 그리고 배치화와 데이터콜렉팅 사이에 “싱글배치”를 만드는 과정이 있다.\n\n세부사항1: 그런데 “배치화”단계에서 model.forward()의 입력으로 사용되지 않는 columns는 지워지는 내부로직이 존재한다.\n세부사항2: trainer_input에 걸려있는 .with_transform()은 “배치화”이후 싱글배치가 만들어지는 과정에서 실행된다.\n\n따라서 .with_transform() 에서 특정컬럼의 변화시키는 동작이 약속된 경우, 그 컬럼이 배치화의 단계에서 자동제거되어 코드가 돌아가지 않을 수 있는 위험성이 존재한다.\n\n\n(풀이2) – image를 return_dict 로 위장.. // 완전 테크니컬한 풀이\n- 현재상황: food['train']에 .with_transform(transforms)을 걸어두고(?) trainer_input을 만든상황\n- 문제: trainer.predict() 내부동작에서 .with_transform(transform) 이 실현될때\n\ntransforms??\n\nSignature: transforms(examples)\nDocstring: &lt;no docstring&gt;\nSource:   \ndef transforms(examples):\n    examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n    del examples[\"image\"]\n    return examples\nFile:      /tmp/ipykernel_706133/1515420127.py\nType:      function\n\n\n이 내용이 실행되어야하는데, image는 model의 입력으로 유하하지 않은 키라서 트레이너가 이미 제거한 상태임.\n- 전략: 제거가 안되게 막아보자..\n\n#model.forward?\n\n\ntrainer_input\n\nDataset({\n    features: ['image', 'label'],\n    num_rows: 10\n})\n\n\n\ntrainer_input2 = trainer_input.rename_columns({'image':'return_dict'})\ntrainer_input2\n\nDataset({\n    features: ['return_dict', 'label'],\n    num_rows: 10\n})\n\n\n\ntrainer_input2[0]\n\n{'label': 6,\n 'pixel_values': tensor([[[-0.7882, -0.7882, -0.7882,  ..., -0.7725, -0.7647, -0.7647],\n          [-0.7882, -0.7961, -0.8039,  ..., -0.7569, -0.7569, -0.7569],\n          [-0.8039, -0.7804, -0.7804,  ..., -0.7490, -0.7490, -0.7569],\n          ...,\n          [-0.2784, -0.2627, -0.2471,  ..., -0.0667, -0.1608, -0.2000],\n          [-0.2627, -0.2235, -0.2157,  ..., -0.1843, -0.1451, -0.0980],\n          [-0.3020, -0.2549, -0.2706,  ..., -0.1608, -0.1686, -0.1216]],\n \n         [[-0.7804, -0.7804, -0.7725,  ..., -0.8275, -0.8275, -0.8275],\n          [-0.7804, -0.7882, -0.7882,  ..., -0.8118, -0.8196, -0.8196],\n          [-0.7961, -0.7647, -0.7647,  ..., -0.8039, -0.8118, -0.8196],\n          ...,\n          [-0.3098, -0.3176, -0.3176,  ..., -0.1608, -0.2549, -0.2941],\n          [-0.2941, -0.2706, -0.2784,  ..., -0.2706, -0.2235, -0.1843],\n          [-0.3333, -0.3020, -0.3255,  ..., -0.2235, -0.2314, -0.1843]],\n \n         [[-0.8353, -0.8353, -0.8353,  ..., -0.9059, -0.9059, -0.9137],\n          [-0.8275, -0.8353, -0.8353,  ..., -0.8980, -0.9059, -0.9059],\n          [-0.8353, -0.8039, -0.7961,  ..., -0.8980, -0.8980, -0.9059],\n          ...,\n          [-0.5216, -0.5216, -0.5137,  ..., -0.3333, -0.4275, -0.4667],\n          [-0.5059, -0.4745, -0.4824,  ..., -0.4431, -0.3961, -0.3569],\n          [-0.5451, -0.5059, -0.5294,  ..., -0.4039, -0.4118, -0.3647]]])}\n\n\n\ndef transforms2(examples):\n    examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"return_dict\"]]\n    del examples[\"return_dict\"]\n    return examples\ntrainer_input3 = trainer_input2.with_transform(transforms2)\ntrainer_input3\n\nDataset({\n    features: ['return_dict', 'label'],\n    num_rows: 10\n})\n\n\n\nbatch_maker = transformers.Trainer(\n    model = model,\n    data_collator = lambda x: x\n)\n_batched_data = batch_maker.get_test_dataloader(trainer_input3)\nbatched_data = list(_batched_data)\nsingle_batch = batched_data[-1]\n#model.to(\"cpu\")\nmodel(**data_collator(single_batch))\n\nNo `TrainingArguments` passed, using `output_dir=tmp_trainer`.\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n\n\nImageClassifierOutput(loss=tensor(4.7354, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;), logits=tensor([[-0.0689,  0.1476, -0.1162, -0.1043, -0.0416,  0.0670, -0.1192, -0.1510,\n          0.0512, -0.0218,  0.0342, -0.0052, -0.0202, -0.1095, -0.2432, -0.1588,\n         -0.1816, -0.0084,  0.0445,  0.0051, -0.0051, -0.3004,  0.2271,  0.0927,\n         -0.0244,  0.0604,  0.0328, -0.2132, -0.0526, -0.0161,  0.1167, -0.0621,\n         -0.0960,  0.2350,  0.0693, -0.1266,  0.2053,  0.0429,  0.0229,  0.2440,\n          0.0103,  0.2298,  0.0807,  0.0563, -0.0894, -0.0288,  0.0675, -0.2696,\n          0.1174,  0.0797, -0.0105,  0.1302, -0.0687, -0.1368, -0.0403, -0.0390,\n          0.1230, -0.0256,  0.1477, -0.1459, -0.1190, -0.1551, -0.0197,  0.0003,\n          0.1087,  0.1157, -0.0924, -0.1210,  0.0742,  0.1664, -0.0729,  0.0445,\n          0.0857,  0.1474,  0.1720, -0.0251,  0.1180, -0.0707, -0.0207, -0.0817,\n         -0.0022,  0.0356,  0.0499,  0.1388,  0.0806,  0.0158,  0.0330,  0.0186,\n          0.0979,  0.1848,  0.1790,  0.0604, -0.1124, -0.0258,  0.0059, -0.0266,\n         -0.0023, -0.1017, -0.0090, -0.1801,  0.1208],\n        [-0.2108,  0.1510, -0.0838, -0.0891, -0.1120, -0.0534, -0.1076, -0.0662,\n          0.0740, -0.0068,  0.0638,  0.0392, -0.0991, -0.0040, -0.1481, -0.1171,\n         -0.0179,  0.0073, -0.0582,  0.0634, -0.1418, -0.1840, -0.0586,  0.0883,\n         -0.0368,  0.1339,  0.0532,  0.0793, -0.0788, -0.0104, -0.0218,  0.0096,\n         -0.1185,  0.1508,  0.1224, -0.1911,  0.2175,  0.0687, -0.0875,  0.0534,\n         -0.0413,  0.1520,  0.0398,  0.0617, -0.0058,  0.0921,  0.1326, -0.1214,\n          0.0273, -0.0643, -0.0886,  0.0894,  0.0073,  0.0416, -0.1266, -0.0339,\n          0.0035,  0.0214, -0.0013,  0.0665, -0.1330, -0.0427,  0.1205,  0.1008,\n         -0.0200,  0.1898, -0.0074, -0.1241, -0.0709,  0.0757,  0.1014,  0.0628,\n          0.0634,  0.0679,  0.1524, -0.1116, -0.0402, -0.0940,  0.0463, -0.0655,\n         -0.1454,  0.0073,  0.0336,  0.1563, -0.1066,  0.0307,  0.0414, -0.1558,\n          0.1143,  0.1420,  0.0836,  0.0133,  0.0067, -0.0532, -0.0095,  0.0595,\n          0.0689, -0.1216, -0.0184, -0.1371,  0.0361]], device='cuda:0',\n       grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)\n\n\n\n성공..\n\n\ntrainer = transformers.Trainer(\n    model=model,\n    data_collator=data_collator,\n)\ntrainer.predict(trainer_input3)\n\nNo `TrainingArguments` passed, using `output_dir=tmp_trainer`.\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n\n***** Running Prediction *****\n  Num examples = 10\n  Batch size = 8\n\n\n\n\n\nPredictionOutput(predictions=array([[ 0.08239509,  0.04826868, -0.02438424, ..., -0.0937563 ,\n        -0.06260583,  0.00630521],\n       [-0.08984111,  0.07344969,  0.00403693, ..., -0.02388449,\n        -0.13815996,  0.16475692],\n       [ 0.07642026, -0.02146504,  0.05515821, ..., -0.12969677,\n        -0.05842251,  0.01547094],\n       ...,\n       [-0.11216477,  0.03565915,  0.00984988, ..., -0.02980242,\n        -0.05086675,  0.17964877],\n       [-0.06892063,  0.14759967, -0.11619416, ..., -0.00896731,\n        -0.18010172,  0.12083632],\n       [-0.2107594 ,  0.15095882, -0.08375154, ..., -0.01836788,\n        -0.13705489,  0.0361177 ]], dtype=float32), label_ids=array([6, 6, 6, 6, 6, 6, 6, 6, 6, 6]), metrics={'test_loss': 4.647078514099121, 'test_model_preparation_time': 0.0013, 'test_runtime': 0.0691, 'test_samples_per_second': 144.64, 'test_steps_per_second': 28.928})\n\n\n(풀이3) – trainer_input 에 예약된 with_transform을 지연실행하지 않고 즉시 실행\n\ntrainer_input\n\nDataset({\n    features: ['image', 'label'],\n    num_rows: 10\n})\n\n\n\ntrainer_input2 = [l for l in trainer_input]\ntrainer_input2\n\n[{'label': 6,\n  'pixel_values': tensor([[[-0.7882, -0.7882, -0.7882,  ..., -0.7725, -0.7647, -0.7647],\n           [-0.7882, -0.7961, -0.8039,  ..., -0.7569, -0.7569, -0.7569],\n           [-0.8039, -0.7804, -0.7804,  ..., -0.7490, -0.7490, -0.7569],\n           ...,\n           [-0.2784, -0.2627, -0.2471,  ..., -0.0667, -0.1608, -0.2000],\n           [-0.2627, -0.2235, -0.2157,  ..., -0.1843, -0.1451, -0.0980],\n           [-0.3020, -0.2549, -0.2706,  ..., -0.1608, -0.1686, -0.1216]],\n  \n          [[-0.7804, -0.7804, -0.7725,  ..., -0.8275, -0.8275, -0.8275],\n           [-0.7804, -0.7882, -0.7882,  ..., -0.8118, -0.8196, -0.8196],\n           [-0.7961, -0.7647, -0.7647,  ..., -0.8039, -0.8118, -0.8196],\n           ...,\n           [-0.3098, -0.3176, -0.3176,  ..., -0.1608, -0.2549, -0.2941],\n           [-0.2941, -0.2706, -0.2784,  ..., -0.2706, -0.2235, -0.1843],\n           [-0.3333, -0.3020, -0.3255,  ..., -0.2235, -0.2314, -0.1843]],\n  \n          [[-0.8353, -0.8353, -0.8353,  ..., -0.9059, -0.9059, -0.9137],\n           [-0.8275, -0.8353, -0.8353,  ..., -0.8980, -0.9059, -0.9059],\n           [-0.8353, -0.8039, -0.7961,  ..., -0.8980, -0.8980, -0.9059],\n           ...,\n           [-0.5216, -0.5216, -0.5137,  ..., -0.3333, -0.4275, -0.4667],\n           [-0.5059, -0.4745, -0.4824,  ..., -0.4431, -0.3961, -0.3569],\n           [-0.5451, -0.5059, -0.5294,  ..., -0.4039, -0.4118, -0.3647]]])},\n {'label': 6,\n  'pixel_values': tensor([[[ 0.7804,  0.7882,  0.7804,  ...,  0.5294,  0.4980,  0.5843],\n           [ 0.7490,  0.7490,  0.7333,  ...,  0.4588,  0.5373,  0.6549],\n           [ 0.6314,  0.6235,  0.6314,  ...,  0.5294,  0.5765,  0.6627],\n           ...,\n           [ 0.2941,  0.2706,  0.2392,  ...,  0.1451,  0.1451,  0.1216],\n           [ 0.2941,  0.2863,  0.2706,  ...,  0.1451,  0.1451,  0.1529],\n           [ 0.3020,  0.3020,  0.2863,  ...,  0.1529,  0.1451,  0.1529]],\n  \n          [[ 0.7020,  0.7098,  0.6941,  ...,  0.3490,  0.3412,  0.4510],\n           [ 0.6157,  0.6078,  0.5843,  ...,  0.2863,  0.4118,  0.5529],\n           [ 0.4980,  0.4824,  0.4902,  ...,  0.3882,  0.4745,  0.5765],\n           ...,\n           [-0.1373, -0.1608, -0.1843,  ..., -0.2627, -0.2627, -0.2863],\n           [-0.1059, -0.1294, -0.1608,  ..., -0.2627, -0.2627, -0.2549],\n           [-0.0667, -0.1059, -0.1373,  ..., -0.2549, -0.2627, -0.2549]],\n  \n          [[ 0.8118,  0.8353,  0.8353,  ...,  0.3961,  0.4039,  0.5216],\n           [ 0.7020,  0.7176,  0.7255,  ...,  0.3490,  0.4824,  0.6392],\n           [ 0.5843,  0.5843,  0.6235,  ...,  0.4667,  0.5686,  0.6863],\n           ...,\n           [-0.2784, -0.3176, -0.3490,  ..., -0.4353, -0.4353, -0.4510],\n           [-0.2392, -0.2863, -0.3333,  ..., -0.4353, -0.4275, -0.4196],\n           [-0.1765, -0.2471, -0.3020,  ..., -0.4196, -0.4275, -0.4196]]])},\n {'label': 6,\n  'pixel_values': tensor([[[ 0.0353,  0.0353,  0.0431,  ..., -0.8667, -0.8745, -0.8824],\n           [ 0.0196,  0.0039, -0.0118,  ..., -0.8745, -0.8745, -0.8824],\n           [-0.0353, -0.0353, -0.0353,  ..., -0.8824, -0.8745, -0.8824],\n           ...,\n           [ 0.2549,  0.3490,  0.3569,  ...,  0.1529,  0.1529,  0.1765],\n           [ 0.0902,  0.2863,  0.3569,  ...,  0.2627,  0.3020,  0.3020],\n           [ 0.2471,  0.3333,  0.3569,  ...,  0.3333,  0.3333,  0.3412]],\n  \n          [[-0.0667, -0.0588, -0.0431,  ..., -0.9137, -0.9216, -0.9216],\n           [-0.1059, -0.1137, -0.1137,  ..., -0.9137, -0.9137, -0.9216],\n           [-0.1922, -0.1765, -0.1765,  ..., -0.9137, -0.9137, -0.9216],\n           ...,\n           [ 0.2471,  0.3412,  0.3569,  ...,  0.1686,  0.1765,  0.2000],\n           [ 0.0902,  0.2863,  0.3569,  ...,  0.2941,  0.3255,  0.3333],\n           [ 0.2471,  0.3333,  0.3569,  ...,  0.3725,  0.3725,  0.3804]],\n  \n          [[-0.0745, -0.0667, -0.0431,  ..., -0.9529, -0.9529, -0.9529],\n           [-0.1216, -0.1216, -0.1137,  ..., -0.9451, -0.9451, -0.9529],\n           [-0.1843, -0.1765, -0.1608,  ..., -0.9373, -0.9451, -0.9529],\n           ...,\n           [ 0.2157,  0.3098,  0.3176,  ...,  0.1294,  0.1294,  0.1529],\n           [ 0.0667,  0.2627,  0.3412,  ...,  0.2627,  0.2863,  0.2941],\n           [ 0.2314,  0.3176,  0.3412,  ...,  0.3412,  0.3255,  0.3333]]])},\n {'label': 6,\n  'pixel_values': tensor([[[ 0.5059,  0.5137,  0.5137,  ...,  0.6392,  0.6314,  0.6235],\n           [ 0.5059,  0.5059,  0.5059,  ...,  0.6392,  0.6392,  0.6314],\n           [ 0.5137,  0.4980,  0.4902,  ...,  0.6471,  0.6471,  0.6549],\n           ...,\n           [ 0.6706,  0.6784,  0.6863,  ...,  0.6784,  0.6784,  0.6627],\n           [ 0.6863,  0.6941,  0.6941,  ...,  0.6627,  0.6549,  0.6471],\n           [ 0.6941,  0.7020,  0.7098,  ...,  0.6706,  0.6706,  0.6549]],\n  \n          [[ 0.3176,  0.3255,  0.3333,  ...,  0.4510,  0.4510,  0.4431],\n           [ 0.3176,  0.3176,  0.3255,  ...,  0.4431,  0.4431,  0.4353],\n           [ 0.3255,  0.3098,  0.3176,  ...,  0.4431,  0.4510,  0.4431],\n           ...,\n           [ 0.6000,  0.6078,  0.6157,  ...,  0.4980,  0.4980,  0.4824],\n           [ 0.6157,  0.6235,  0.6157,  ...,  0.4824,  0.4745,  0.4667],\n           [ 0.6235,  0.6314,  0.6314,  ...,  0.4902,  0.4902,  0.4745]],\n  \n          [[-0.0431, -0.0353, -0.0275,  ..., -0.1451, -0.1529, -0.1608],\n           [-0.0275, -0.0431, -0.0353,  ..., -0.2157, -0.2235, -0.2314],\n           [-0.0196, -0.0431, -0.0510,  ..., -0.2471, -0.2549, -0.2706],\n           ...,\n           [ 0.6078,  0.6157,  0.6235,  ...,  0.2549,  0.2549,  0.2392],\n           [ 0.6235,  0.6314,  0.6235,  ...,  0.2392,  0.2314,  0.2235],\n           [ 0.6471,  0.6392,  0.6392,  ...,  0.2471,  0.2471,  0.2314]]])},\n {'label': 6,\n  'pixel_values': tensor([[[ 0.6784,  0.7020,  0.7412,  ...,  0.9216,  0.9294,  0.9294],\n           [ 0.6941,  0.7098,  0.7255,  ...,  0.9137,  0.9216,  0.9294],\n           [ 0.7176,  0.7176,  0.7255,  ...,  0.9059,  0.9216,  0.9216],\n           ...,\n           [ 0.0275,  0.0275,  0.0275,  ...,  0.6627,  0.6941,  0.7098],\n           [ 0.0196,  0.0196,  0.0196,  ...,  0.7176,  0.7333,  0.7412],\n           [ 0.0275,  0.0275,  0.0275,  ...,  0.8118,  0.8118,  0.8118]],\n  \n          [[ 0.5843,  0.6078,  0.6549,  ...,  0.8902,  0.8980,  0.8980],\n           [ 0.6157,  0.6235,  0.6471,  ...,  0.8824,  0.8902,  0.8980],\n           [ 0.6471,  0.6471,  0.6549,  ...,  0.8824,  0.8902,  0.8980],\n           ...,\n           [-0.1137, -0.1137, -0.1137,  ...,  0.5137,  0.5451,  0.5686],\n           [-0.1137, -0.1137, -0.1137,  ...,  0.5451,  0.5686,  0.5765],\n           [-0.1059, -0.1059, -0.1059,  ...,  0.6235,  0.6235,  0.6235]],\n  \n          [[ 0.4588,  0.4824,  0.5137,  ...,  0.7961,  0.8039,  0.8039],\n           [ 0.4980,  0.4980,  0.5059,  ...,  0.7882,  0.7961,  0.8039],\n           [ 0.5294,  0.5216,  0.5216,  ...,  0.7804,  0.7882,  0.7961],\n           ...,\n           [-0.1922, -0.1922, -0.1922,  ...,  0.3255,  0.3725,  0.3961],\n           [-0.1922, -0.1922, -0.1922,  ...,  0.3490,  0.3804,  0.3961],\n           [-0.1843, -0.1843, -0.1843,  ...,  0.4039,  0.4118,  0.4196]]])},\n {'label': 6,\n  'pixel_values': tensor([[[ 0.2000,  0.2235,  0.2549,  ...,  0.3725,  0.3647,  0.3412],\n           [ 0.1922,  0.2157,  0.2627,  ...,  0.3490,  0.3412,  0.3255],\n           [ 0.1843,  0.2157,  0.2549,  ...,  0.3098,  0.3020,  0.2863],\n           ...,\n           [ 0.1843,  0.1922,  0.1843,  ...,  0.2235,  0.1922,  0.1686],\n           [ 0.1922,  0.2000,  0.1922,  ...,  0.2000,  0.1765,  0.1529],\n           [ 0.1843,  0.1922,  0.2000,  ...,  0.1765,  0.1529,  0.1373]],\n  \n          [[ 0.0275,  0.0510,  0.0824,  ...,  0.1529,  0.1451,  0.1216],\n           [ 0.0275,  0.0510,  0.0902,  ...,  0.1216,  0.1137,  0.0980],\n           [ 0.0196,  0.0510,  0.0902,  ...,  0.0902,  0.0824,  0.0667],\n           ...,\n           [-0.0196, -0.0118, -0.0196,  ...,  0.0353,  0.0196, -0.0039],\n           [-0.0196, -0.0118, -0.0196,  ...,  0.0196, -0.0039, -0.0275],\n           [-0.0275, -0.0196, -0.0118,  ...,  0.0039, -0.0275, -0.0431]],\n  \n          [[-0.1373, -0.1059, -0.0745,  ..., -0.0196, -0.0431, -0.0745],\n           [-0.1294, -0.0980, -0.0667,  ..., -0.0510, -0.0667, -0.0902],\n           [-0.1294, -0.0980, -0.0667,  ..., -0.0824, -0.0902, -0.1137],\n           ...,\n           [-0.2000, -0.1922, -0.2000,  ..., -0.1373, -0.1529, -0.1686],\n           [-0.1843, -0.1843, -0.1922,  ..., -0.1451, -0.1608, -0.1686],\n           [-0.1922, -0.1843, -0.1843,  ..., -0.1608, -0.1686, -0.1765]]])},\n {'label': 6,\n  'pixel_values': tensor([[[-0.2235, -0.2235, -0.2000,  ..., -0.5373, -0.5294, -0.5373],\n           [-0.2314, -0.2471, -0.2078,  ..., -0.5137, -0.4980, -0.5059],\n           [-0.2627, -0.2627, -0.2627,  ..., -0.5137, -0.4980, -0.5216],\n           ...,\n           [-0.1765, -0.1294, -0.0510,  ..., -0.1765, -0.1922, -0.1922],\n           [-0.1529, -0.1373, -0.0510,  ..., -0.1765, -0.1843, -0.1686],\n           [-0.1373, -0.1137, -0.0196,  ..., -0.1608, -0.1686, -0.1686]],\n  \n          [[-0.4588, -0.4588, -0.4353,  ..., -0.7333, -0.7255, -0.7333],\n           [-0.4824, -0.4902, -0.4510,  ..., -0.7255, -0.7098, -0.7020],\n           [-0.5137, -0.5059, -0.5059,  ..., -0.7333, -0.7098, -0.7255],\n           ...,\n           [-0.5216, -0.4745, -0.3961,  ..., -0.5216, -0.5373, -0.5294],\n           [-0.4980, -0.4824, -0.3882,  ..., -0.5216, -0.5294, -0.5059],\n           [-0.4824, -0.4588, -0.3569,  ..., -0.5059, -0.5137, -0.4980]],\n  \n          [[-0.4431, -0.4353, -0.4196,  ..., -0.7647, -0.7569, -0.7647],\n           [-0.4667, -0.4902, -0.4667,  ..., -0.7569, -0.7333, -0.7333],\n           [-0.5059, -0.5137, -0.5216,  ..., -0.7569, -0.7412, -0.7569],\n           ...,\n           [-0.7333, -0.7020, -0.6314,  ..., -0.7490, -0.7647, -0.7569],\n           [-0.7176, -0.7176, -0.6392,  ..., -0.7412, -0.7569, -0.7412],\n           [-0.7098, -0.6941, -0.6078,  ..., -0.7255, -0.7412, -0.7333]]])},\n {'label': 6,\n  'pixel_values': tensor([[[ 0.1765,  0.0980,  0.2549,  ...,  0.8667,  0.8824,  0.8824],\n           [ 0.1843,  0.0980,  0.2471,  ...,  0.8824,  0.8902,  0.8902],\n           [ 0.1843,  0.0902,  0.2157,  ...,  0.8745,  0.8824,  0.8824],\n           ...,\n           [ 0.0039,  0.0588,  0.0588,  ...,  0.8745,  0.8980,  0.8980],\n           [ 0.0275,  0.0667,  0.0353,  ...,  0.8824,  0.8902,  0.8902],\n           [ 0.0510,  0.0902,  0.0431,  ...,  0.8902,  0.8824,  0.8902]],\n  \n          [[-0.1216, -0.2000, -0.0431,  ...,  0.8196,  0.8353,  0.8353],\n           [-0.1137, -0.2000, -0.0510,  ...,  0.8353,  0.8431,  0.8431],\n           [-0.1137, -0.2078, -0.0824,  ...,  0.8275,  0.8353,  0.8353],\n           ...,\n           [-0.5843, -0.5451, -0.5608,  ...,  0.8353,  0.8588,  0.8588],\n           [-0.5765, -0.5373, -0.5843,  ...,  0.8431,  0.8510,  0.8510],\n           [-0.5529, -0.5216, -0.5686,  ...,  0.8510,  0.8431,  0.8510]],\n  \n          [[-0.1451, -0.2235, -0.0667,  ...,  0.8353,  0.8510,  0.8510],\n           [-0.1373, -0.2235, -0.0745,  ...,  0.8510,  0.8588,  0.8588],\n           [-0.1373, -0.2314, -0.1059,  ...,  0.8431,  0.8510,  0.8510],\n           ...,\n           [-0.8588, -0.8118, -0.8196,  ...,  0.8118,  0.8353,  0.8353],\n           [-0.8510, -0.8196, -0.8510,  ...,  0.8196,  0.8275,  0.8275],\n           [-0.8353, -0.8039, -0.8510,  ...,  0.8275,  0.8196,  0.8275]]])},\n {'label': 6,\n  'pixel_values': tensor([[[-0.1843, -0.1843, -0.2235,  ...,  0.8431,  0.8353,  0.8510],\n           [-0.1059, -0.1451, -0.2078,  ...,  0.8431,  0.8588,  0.8667],\n           [ 0.0196, -0.0510, -0.1451,  ...,  0.8275,  0.8431,  0.8431],\n           ...,\n           [ 0.7961,  0.7804,  0.7804,  ...,  0.2941,  0.3647,  0.5529],\n           [ 0.7882,  0.8039,  0.7961,  ...,  0.3333,  0.3412,  0.5059],\n           [ 0.7098,  0.7725,  0.7804,  ...,  0.4824,  0.4275,  0.4510]],\n  \n          [[-0.7020, -0.6941, -0.7255,  ...,  0.6078,  0.6078,  0.6235],\n           [-0.6627, -0.6627, -0.6863,  ...,  0.6000,  0.6157,  0.6235],\n           [-0.5686, -0.5922, -0.6235,  ...,  0.5843,  0.6000,  0.6000],\n           ...,\n           [ 0.4510,  0.4353,  0.4275,  ..., -0.1686, -0.1137,  0.0745],\n           [ 0.4510,  0.4588,  0.4431,  ..., -0.1451, -0.1529,  0.0118],\n           [ 0.4353,  0.4667,  0.4431,  ..., -0.0118, -0.0745, -0.0353]],\n  \n          [[-0.9608, -0.9373, -0.9608,  ...,  0.0667,  0.0902,  0.1216],\n           [-0.9529, -0.9451, -0.9608,  ...,  0.0902,  0.1059,  0.1059],\n           [-0.8824, -0.8980, -0.9294,  ...,  0.0745,  0.0902,  0.0902],\n           ...,\n           [-0.3882, -0.3961, -0.3961,  ..., -0.8431, -0.7569, -0.5529],\n           [-0.3647, -0.3490, -0.3647,  ..., -0.8275, -0.8118, -0.6078],\n           [-0.4118, -0.3412, -0.3961,  ..., -0.7647, -0.8196, -0.7490]]])},\n {'label': 6,\n  'pixel_values': tensor([[[ 0.0824,  0.1137,  0.1373,  ...,  0.5059,  0.5059,  0.5137],\n           [ 0.1294,  0.1529,  0.1765,  ...,  0.4980,  0.4980,  0.4902],\n           [ 0.1373,  0.1451,  0.1529,  ...,  0.4431,  0.4353,  0.4353],\n           ...,\n           [-1.0000, -1.0000, -1.0000,  ..., -0.3255, -0.3098, -0.2706],\n           [-1.0000, -1.0000, -1.0000,  ..., -0.7490, -0.7255, -0.6941],\n           [-0.9922, -0.9922, -0.9922,  ..., -0.9294, -0.9216, -0.9216]],\n  \n          [[ 0.0039,  0.0353,  0.0588,  ...,  0.3176,  0.3176,  0.3255],\n           [ 0.0510,  0.0745,  0.0980,  ...,  0.3098,  0.3098,  0.2941],\n           [ 0.0588,  0.0667,  0.0745,  ...,  0.2471,  0.2392,  0.2392],\n           ...,\n           [-0.9843, -0.9843, -0.9843,  ..., -0.4824, -0.4667, -0.4275],\n           [-0.9843, -0.9843, -0.9843,  ..., -0.8902, -0.8824, -0.8510],\n           [-0.9922, -0.9922, -0.9922,  ..., -0.9843, -0.9843, -0.9922]],\n  \n          [[-0.0902, -0.0510, -0.0275,  ...,  0.3020,  0.3020,  0.3098],\n           [-0.0353, -0.0039,  0.0196,  ...,  0.2863,  0.2863,  0.2863],\n           [-0.0196, -0.0039,  0.0039,  ...,  0.2157,  0.2078,  0.2157],\n           ...,\n           [-1.0000, -1.0000, -1.0000,  ..., -0.5529, -0.5373, -0.4980],\n           [-1.0000, -1.0000, -1.0000,  ..., -0.9216, -0.9059, -0.8902],\n           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]])}]\n\n\n\nbatch_maker = transformers.Trainer(\n    model = model,\n    data_collator = lambda x: x\n)\n_batched_data = batch_maker.get_test_dataloader(trainer_input2)\nbatched_data = list(_batched_data)\nsingle_batch = batched_data[0]\n#model.to(\"cpu\")\nmodel(**data_collator(single_batch));\n\nNo `TrainingArguments` passed, using `output_dir=tmp_trainer`.\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n\n\n\ntrainer = transformers.Trainer(\n    model=model,\n    data_collator=data_collator,\n)\ntrainer.predict(trainer_input2); \n\nNo `TrainingArguments` passed, using `output_dir=tmp_trainer`.\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n\n***** Running Prediction *****\n  Num examples = 10\n  Batch size = 8\n\n\n\n\n\n(풀이4) – 트레이너가 가진 “사용하지 않는 column을 제거하는 기능”을 False 시킴..\n\nbatch_maker = transformers.Trainer(\n    model = model,\n    data_collator = lambda x: x,\n    args = transformers.TrainingArguments(\n        output_dir= \"asdf\", # 아무거나 써야함. \n        remove_unused_columns= False # 이 부분이 포인트!!\n    )        \n)\n_batched_data = batch_maker.get_test_dataloader(trainer_input)\nbatched_data = list(_batched_data)\nsingle_batch = batched_data[0]\n#model.to(\"cpu\")\nmodel(**data_collator(single_batch));\n\n\ntrainer = transformers.Trainer(\n    model=model,\n    data_collator=data_collator,\n    args=transformers.TrainingArguments(\n        output_dir= 'asdf', # 아무거나 써야함\n        remove_unused_columns= False # 이 부분이 포인트!!\n    )        \n)\ntrainer.predict(trainer_input);\n\n\n\n\n#\n(풀이5) – 트레이너가 가진 “사용하지 않는 column을 제거하는 기능”을 False 시킬꺼면, batch_maker를 고려할 필요도 없이 아래와 같이 바로 single_batch를 얻을 수 있음.\n풀이4: 실제로 trainer가 싱글배치를 얻는 과정과 유사하게 얻는 방법\n\nbatch_maker = transformers.Trainer(\n    model = model,\n    data_collator = lambda x: x,\n    args = transformers.TrainingArguments(\n        output_dir= \"asdf\", # 아무거나 써야함. \n        remove_unused_columns= False # 이 부분이 포인트!!\n    )        \n)\n_batched_data = batch_maker.get_test_dataloader(trainer_input)\nbatched_data = list(_batched_data)\nsingle_batch = batched_data[-1]\n#single_batch\n\n\n형식관찰: single_batch는 [Dict, Dict, Dict, .... Dict] 꼴임을 주목하라.\n\n풀이5: 형식관찰에 힌트를 얻어 무식하게 얻은 싱글배치\n\ntrainer_input\n\nDataset({\n    features: ['image', 'label'],\n    num_rows: 10\n})\n\n\n\nsingle_batch = [\n    trainer_input[0],\n    trainer_input[1],\n    trainer_input[2],\n    trainer_input[3],\n    trainer_input[4],\n    trainer_input[5],\n    trainer_input[6],\n    trainer_input[7],\n]\n#single_batch\n\n아무튼 풀이5 스타일로 싱글배치를 얻었다면? 이후의 코드는 동일\n\n## 풀이4 \n### STEP1: 싱글배치로 체크하기 \nbatch_maker = transformers.Trainer(\n    model = model,\n    data_collator = lambda x: x,\n    args = transformers.TrainingArguments(\n        output_dir= \"asdf\",\n        remove_unused_columns= False\n    )        \n)\n_batched_data = batch_maker.get_test_dataloader(trainer_input)\nbatched_data = list(_batched_data)\nsingle_batch = batched_data[0]\n#model.to(\"cpu\")\nmodel(**data_collator(single_batch))\n### STEP2: 트레이너 설계하고 predict하기\ntrainer = transformers.Trainer(\n    model=model,\n    data_collator=data_collator,\n    args=transformers.TrainingArguments(\n        output_dir= 'asdf',\n        remove_unused_columns= False\n    )        \n)\ntrainer.predict(trainer_input)\n\n\n\n\nPredictionOutput(predictions=array([[-3.11896242e-02, -2.25847423e-01,  1.63939549e-03, ...,\n        -2.29127333e-03,  3.87525409e-02,  4.29060608e-02],\n       [ 4.27692719e-02, -1.01897612e-01, -9.16560292e-02, ...,\n         4.52993475e-02, -8.15727636e-02, -5.56547865e-02],\n       [-5.40109351e-04, -1.02955595e-01, -1.03463437e-02, ...,\n        -3.05373464e-02,  9.11735594e-02,  8.82753134e-02],\n       ...,\n       [ 8.04588795e-02,  2.72037834e-02, -1.16188087e-01, ...,\n         6.56688288e-02,  1.24141075e-01,  3.59139368e-02],\n       [ 5.94812930e-02, -9.47779790e-02, -2.50497796e-02, ...,\n         5.41531555e-02,  6.13874942e-03, -5.53418696e-03],\n       [ 7.43777454e-02, -1.62318684e-02,  1.30667584e-04, ...,\n        -3.19715589e-04, -9.09084827e-02, -1.61014676e-01]], dtype=float32), label_ids=array([6, 6, 6, 6, 6, 6, 6, 6, 6, 6]), metrics={'test_loss': 4.532778739929199, 'test_model_preparation_time': 0.0013, 'test_runtime': 0.0551, 'test_samples_per_second': 181.424, 'test_steps_per_second': 36.285})\n\n\n\n## 풀이5\n### STEP1: 싱글배치로 체크하기 \nsingle_batch =[\n    trainer_input[0],\n    trainer_input[1],\n    trainer_input[2],\n    trainer_input[3],\n    trainer_input[4],\n    trainer_input[5],\n    trainer_input[6],\n    trainer_input[7],\n]\nmodel.to(\"cpu\")\nmodel(**data_collator(single_batch));\n### STEP2: 트레이너 설계하고 predict하기\ntrainer = transformers.Trainer(\n    model=model,\n    data_collator=data_collator,\n    args=transformers.TrainingArguments(\n        output_dir= 'asdf', # 아무거나 써야함\n        remove_unused_columns= False # 이 부분이 포인트!!\n    )        \n)\ntrainer.predict(trainer_input)\n\n\n\n\nPredictionOutput(predictions=array([[-3.11896242e-02, -2.25847423e-01,  1.63939549e-03, ...,\n        -2.29127333e-03,  3.87525409e-02,  4.29060608e-02],\n       [ 4.27692719e-02, -1.01897612e-01, -9.16560292e-02, ...,\n         4.52993475e-02, -8.15727636e-02, -5.56547865e-02],\n       [-5.40109351e-04, -1.02955595e-01, -1.03463437e-02, ...,\n        -3.05373464e-02,  9.11735594e-02,  8.82753134e-02],\n       ...,\n       [ 8.04588795e-02,  2.72037834e-02, -1.16188087e-01, ...,\n         6.56688288e-02,  1.24141075e-01,  3.59139368e-02],\n       [ 5.94812930e-02, -9.47779790e-02, -2.50497796e-02, ...,\n         5.41531555e-02,  6.13874942e-03, -5.53418696e-03],\n       [ 7.43777454e-02, -1.62318684e-02,  1.30667584e-04, ...,\n        -3.19715589e-04, -9.09084827e-02, -1.61014676e-01]], dtype=float32), label_ids=array([6, 6, 6, 6, 6, 6, 6, 6, 6, 6]), metrics={'test_loss': 4.532778739929199, 'test_model_preparation_time': 0.0015, 'test_runtime': 0.1057, 'test_samples_per_second': 94.587, 'test_steps_per_second': 18.917})\n\n\n참고1: 아래의 방식으로는 싱글배치를 얻을 수 없음\n\n#trainer_input[:8]\n\n이유:\n\ntrainer_input[:2] == [trainer_input[0], trainer_input[1]]\n\nFalse\n\n\n참고2: 아래의 방식으로도 싱글배치를 얻을 수 없음 – 이유? 지연실행때문에..\n\n#trainer_input.to_list()[:8]"
  },
  {
    "objectID": "공부/HF/2024-11-16-(강의) 데이터콜렉터.html#d.-food101-defaultdatacollator-구현",
    "href": "공부/HF/2024-11-16-(강의) 데이터콜렉터.html#d.-food101-defaultdatacollator-구현",
    "title": "(강의) 데이터콜렉터",
    "section": "D. FOOD101 – DefaultDataCollator 구현",
    "text": "D. FOOD101 – DefaultDataCollator 구현\n1. 데이터준비: \"guebin/food101-tiny\" \\(\\to\\) trainer_input\n\nfood = datasets.load_dataset(\"guebin/food101-tiny\")\nimage_processor = transformers.AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\nnormalize = torchvision.transforms.Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\nsize = (\n    image_processor.size[\"shortest_edge\"]\n    if \"shortest_edge\" in image_processor.size\n    else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n)\n_transforms = torchvision.transforms.Compose([\n    torchvision.transforms.RandomResizedCrop(size), \n    torchvision.transforms.ToTensor(), \n    normalize\n])\ndef transforms(examples):\n    examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n    del examples[\"image\"]\n    return examples\ntrainer_input = food['train'].with_transform(transforms)\ntrainer_input\n\nFast image processor class &lt;class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'&gt; is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n\n\nDataset({\n    features: ['image', 'label'],\n    num_rows: 10\n})\n\n\n2. 모델준비: \"google/vit-base-patch16-224-in21k\" \\(\\to\\)model\n\nlabels = food[\"train\"].features[\"label\"].names\nlabel2id, id2label = dict(), dict()\nfor i, label in enumerate(labels):\n    label2id[label] = str(i)\n    id2label[str(i)] = label\nmodel = transformers.AutoModelForImageClassification.from_pretrained(\n    \"google/vit-base-patch16-224-in21k\",\n    num_labels=len(labels),\n    id2label=id2label,\n    label2id=label2id,\n)\n\nSome weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n\n3. 데이터콜렉터: collate_fn 직접설계\n\n# data_collator = transformers.DefaultDataCollator()\n# data_collator\n\n\ndef collate_fn(single_batch):\n    pass\n\nDefaultDataCollator() 와 동일한 역할을 하는 collate_fn을 설계하라. 이를 이용하여 적당한 trainer를 만들어\ntrainer.predict(trainer_input)\n이 정상동작하는지 확인하라.\n(풀이)\n\n# batch_maker = transformers.Trainer(\n#     model = model,\n#     data_collator = lambda x: x,\n#     args = transformers.TrainingArguments(\n#         output_dir= \"asdf\", # 아무거나 써야함. \n#         remove_unused_columns= False, # 이 부분이 포인트!!\n#     )        \n# )\n# _batched_data = batch_maker.get_test_dataloader(trainer_input)\n# batched_data = list(_batched_data)\n# single_batch = batched_data[-1]\n# single_batch\n#---#\nsingle_batch = [trainer_input[0],trainer_input[1]]\nsingle_batch\n\n[{'label': 6,\n  'pixel_values': tensor([[[ 0.2000,  0.1529,  0.0745,  ...,  0.1686,  0.1137,  0.0824],\n           [ 0.1608,  0.1451,  0.1294,  ...,  0.1686,  0.1451,  0.1373],\n           [ 0.1137,  0.1294,  0.1529,  ...,  0.1608,  0.1686,  0.1765],\n           ...,\n           [-0.0275, -0.0275, -0.0431,  ..., -0.1294, -0.1451, -0.1608],\n           [-0.0980, -0.0745, -0.0431,  ..., -0.1608, -0.1608, -0.1686],\n           [-0.1373, -0.1137, -0.0667,  ..., -0.1843, -0.1922, -0.2000]],\n  \n          [[ 0.1529,  0.1137,  0.0353,  ...,  0.1294,  0.0745,  0.0431],\n           [ 0.1216,  0.1137,  0.0902,  ...,  0.1294,  0.1059,  0.0980],\n           [ 0.0824,  0.0980,  0.1216,  ...,  0.1216,  0.1294,  0.1373],\n           ...,\n           [-0.0902, -0.0902, -0.1059,  ..., -0.1373, -0.1529, -0.1686],\n           [-0.1608, -0.1373, -0.1059,  ..., -0.1686, -0.1686, -0.1765],\n           [-0.2000, -0.1765, -0.1294,  ..., -0.1922, -0.2000, -0.2078]],\n  \n          [[-0.0510, -0.0980, -0.1765,  ..., -0.0431, -0.0980, -0.1294],\n           [-0.0902, -0.0980, -0.1216,  ..., -0.0431, -0.0667, -0.0745],\n           [-0.1294, -0.1137, -0.0902,  ..., -0.0510, -0.0431, -0.0353],\n           ...,\n           [-0.1922, -0.1922, -0.2078,  ..., -0.3020, -0.3176, -0.3255],\n           [-0.2627, -0.2392, -0.2078,  ..., -0.3333, -0.3333, -0.3333],\n           [-0.3020, -0.2784, -0.2314,  ..., -0.3569, -0.3647, -0.3647]]])},\n {'label': 6,\n  'pixel_values': tensor([[[ 0.4824,  0.4824,  0.4980,  ..., -0.4667, -0.4431, -0.3725],\n           [ 0.5765,  0.6000,  0.5451,  ..., -0.4667, -0.4510, -0.3961],\n           [ 0.6706,  0.6549,  0.5922,  ..., -0.4588, -0.4510, -0.4275],\n           ...,\n           [ 0.4667,  0.4118,  0.4039,  ...,  0.1216,  0.0824,  0.0431],\n           [ 0.4824,  0.4510,  0.4353,  ...,  0.1373,  0.1373,  0.1137],\n           [ 0.4824,  0.4667,  0.4353,  ...,  0.1451,  0.1451,  0.1216]],\n  \n          [[ 0.2314,  0.1922,  0.1843,  ..., -0.8118, -0.8118, -0.7569],\n           [ 0.3255,  0.3176,  0.2549,  ..., -0.8196, -0.8118, -0.7725],\n           [ 0.4118,  0.3804,  0.3098,  ..., -0.8039, -0.8118, -0.8039],\n           ...,\n           [ 0.2706,  0.1843,  0.1608,  ..., -0.2863, -0.3176, -0.3490],\n           [ 0.3176,  0.2627,  0.2157,  ..., -0.2706, -0.2706, -0.2863],\n           [ 0.3569,  0.3098,  0.2549,  ..., -0.2471, -0.2471, -0.2627]],\n  \n          [[ 0.3176,  0.3412,  0.3725,  ..., -0.9059, -0.9294, -0.8902],\n           [ 0.4118,  0.4745,  0.4275,  ..., -0.9137, -0.9294, -0.9059],\n           [ 0.4980,  0.5294,  0.4824,  ..., -0.9059, -0.9216, -0.9216],\n           ...,\n           [ 0.3412,  0.2784,  0.2627,  ..., -0.3961, -0.4275, -0.4588],\n           [ 0.3647,  0.3333,  0.2863,  ..., -0.3804, -0.3804, -0.3961],\n           [ 0.3882,  0.3725,  0.3176,  ..., -0.3569, -0.3569, -0.3804]]])}]\n\n\n\n이대로 model(**sigle_batch)를 실행하면 에러가 나겠죠?\n\n\ndef collate_fn(data_collator_input):\n    out = dict()\n    out['pixel_values'] = torch.stack([l['pixel_values'] for l in data_collator_input])\n    out['labels'] = torch.tensor([l['label'] for l in data_collator_input])\n    return out                                  \ncollate_fn(single_batch);\n\n\ncollate_fn(single_batch)\n\n{'pixel_values': tensor([[[[ 0.2000,  0.1529,  0.0745,  ...,  0.1686,  0.1137,  0.0824],\n           [ 0.1608,  0.1451,  0.1294,  ...,  0.1686,  0.1451,  0.1373],\n           [ 0.1137,  0.1294,  0.1529,  ...,  0.1608,  0.1686,  0.1765],\n           ...,\n           [-0.0275, -0.0275, -0.0431,  ..., -0.1294, -0.1451, -0.1608],\n           [-0.0980, -0.0745, -0.0431,  ..., -0.1608, -0.1608, -0.1686],\n           [-0.1373, -0.1137, -0.0667,  ..., -0.1843, -0.1922, -0.2000]],\n \n          [[ 0.1529,  0.1137,  0.0353,  ...,  0.1294,  0.0745,  0.0431],\n           [ 0.1216,  0.1137,  0.0902,  ...,  0.1294,  0.1059,  0.0980],\n           [ 0.0824,  0.0980,  0.1216,  ...,  0.1216,  0.1294,  0.1373],\n           ...,\n           [-0.0902, -0.0902, -0.1059,  ..., -0.1373, -0.1529, -0.1686],\n           [-0.1608, -0.1373, -0.1059,  ..., -0.1686, -0.1686, -0.1765],\n           [-0.2000, -0.1765, -0.1294,  ..., -0.1922, -0.2000, -0.2078]],\n \n          [[-0.0510, -0.0980, -0.1765,  ..., -0.0431, -0.0980, -0.1294],\n           [-0.0902, -0.0980, -0.1216,  ..., -0.0431, -0.0667, -0.0745],\n           [-0.1294, -0.1137, -0.0902,  ..., -0.0510, -0.0431, -0.0353],\n           ...,\n           [-0.1922, -0.1922, -0.2078,  ..., -0.3020, -0.3176, -0.3255],\n           [-0.2627, -0.2392, -0.2078,  ..., -0.3333, -0.3333, -0.3333],\n           [-0.3020, -0.2784, -0.2314,  ..., -0.3569, -0.3647, -0.3647]]],\n \n \n         [[[ 0.4824,  0.4824,  0.4980,  ..., -0.4667, -0.4431, -0.3725],\n           [ 0.5765,  0.6000,  0.5451,  ..., -0.4667, -0.4510, -0.3961],\n           [ 0.6706,  0.6549,  0.5922,  ..., -0.4588, -0.4510, -0.4275],\n           ...,\n           [ 0.4667,  0.4118,  0.4039,  ...,  0.1216,  0.0824,  0.0431],\n           [ 0.4824,  0.4510,  0.4353,  ...,  0.1373,  0.1373,  0.1137],\n           [ 0.4824,  0.4667,  0.4353,  ...,  0.1451,  0.1451,  0.1216]],\n \n          [[ 0.2314,  0.1922,  0.1843,  ..., -0.8118, -0.8118, -0.7569],\n           [ 0.3255,  0.3176,  0.2549,  ..., -0.8196, -0.8118, -0.7725],\n           [ 0.4118,  0.3804,  0.3098,  ..., -0.8039, -0.8118, -0.8039],\n           ...,\n           [ 0.2706,  0.1843,  0.1608,  ..., -0.2863, -0.3176, -0.3490],\n           [ 0.3176,  0.2627,  0.2157,  ..., -0.2706, -0.2706, -0.2863],\n           [ 0.3569,  0.3098,  0.2549,  ..., -0.2471, -0.2471, -0.2627]],\n \n          [[ 0.3176,  0.3412,  0.3725,  ..., -0.9059, -0.9294, -0.8902],\n           [ 0.4118,  0.4745,  0.4275,  ..., -0.9137, -0.9294, -0.9059],\n           [ 0.4980,  0.5294,  0.4824,  ..., -0.9059, -0.9216, -0.9216],\n           ...,\n           [ 0.3412,  0.2784,  0.2627,  ..., -0.3961, -0.4275, -0.4588],\n           [ 0.3647,  0.3333,  0.2863,  ..., -0.3804, -0.3804, -0.3961],\n           [ 0.3882,  0.3725,  0.3176,  ..., -0.3569, -0.3569, -0.3804]]]]),\n 'labels': tensor([6, 6])}\n\n\n\nmodel.to(\"cpu\")\nmodel(**collate_fn(single_batch))\n\nImageClassifierOutput(loss=tensor(4.6280, grad_fn=&lt;NllLossBackward0&gt;), logits=tensor([[-0.1365,  0.1620, -0.0223, -0.1143, -0.0091,  0.0963,  0.0333,  0.0601,\n          0.0912,  0.0556,  0.0271,  0.1042, -0.0219,  0.0306, -0.0393, -0.0080,\n         -0.0542, -0.0108, -0.0006,  0.1087, -0.0748,  0.1145, -0.0873,  0.0175,\n          0.0028,  0.0402, -0.0207, -0.1050,  0.0393, -0.1119,  0.0858,  0.0700,\n          0.2079,  0.1616,  0.0466,  0.0322, -0.0162,  0.0378, -0.0287, -0.0579,\n          0.0594, -0.0013, -0.0045,  0.0189,  0.0158, -0.0060,  0.1940, -0.1585,\n          0.0083, -0.1220, -0.1615,  0.0422, -0.0152, -0.0166, -0.1047, -0.0262,\n          0.0144,  0.1229, -0.0456,  0.0743,  0.0304, -0.2039,  0.0185,  0.1134,\n          0.0305,  0.1549, -0.1589,  0.0945,  0.1259,  0.0856, -0.0828, -0.0904,\n         -0.0898, -0.0174,  0.0313,  0.0354,  0.0230, -0.1014,  0.0152,  0.0344,\n         -0.1159, -0.1117,  0.0662,  0.1179, -0.0779,  0.1350, -0.0319,  0.0505,\n         -0.1316, -0.0474, -0.0665, -0.0066, -0.0134,  0.0536,  0.0452, -0.1686,\n          0.0357, -0.0118,  0.1457, -0.0710,  0.1032],\n        [ 0.0366,  0.0556, -0.0137, -0.1656, -0.0090,  0.0739, -0.0446,  0.1007,\n         -0.0920,  0.0444, -0.0102, -0.0698, -0.1062,  0.0905, -0.0900,  0.1204,\n         -0.1509,  0.0827, -0.1261,  0.1187,  0.0131,  0.1127,  0.1462,  0.0453,\n         -0.1192, -0.0616, -0.0737, -0.0078,  0.0745, -0.0538,  0.0300, -0.2822,\n          0.0087,  0.3359,  0.0989, -0.0393, -0.1764, -0.0209,  0.0560, -0.0405,\n          0.0323, -0.0294, -0.1065,  0.0538,  0.0117,  0.1993, -0.0987, -0.0698,\n          0.0792,  0.0495,  0.0622, -0.1118, -0.0335,  0.1133, -0.1798,  0.2170,\n          0.0649,  0.0884, -0.1315,  0.0037, -0.0107, -0.1050, -0.0190,  0.0721,\n         -0.0200, -0.1063, -0.0141,  0.0931,  0.0818,  0.0013, -0.0913, -0.0590,\n          0.0650,  0.0915, -0.1172, -0.0345,  0.0156, -0.0926, -0.0562,  0.0948,\n          0.0360,  0.0274,  0.1030,  0.0143, -0.0145, -0.0407,  0.0120,  0.0319,\n          0.1479,  0.0513,  0.0342,  0.0604, -0.2672, -0.2135,  0.0936, -0.0181,\n         -0.0566,  0.0828,  0.0910,  0.0048, -0.0291]],\n       grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)\n\n\n\ntrainer = transformers.Trainer(\n    model = model,\n    data_collator = collate_fn,\n    args = transformers.TrainingArguments(\n        output_dir= \"asdf\", # 아무거나 써야함. \n        remove_unused_columns= False, # 이 부분이 포인트!!\n        per_device_eval_batch_size= 2\n    )        \n)\ntrainer.predict(trainer_input)\n\n\n\n\nPredictionOutput(predictions=array([[ 0.03769832,  0.03013101,  0.020927  , ...,  0.12225489,\n        -0.06108126, -0.09649463],\n       [ 0.01888916,  0.04456399, -0.03133049, ...,  0.09108149,\n        -0.03305664, -0.00110111],\n       [ 0.08471692,  0.04713244, -0.07810733, ..., -0.00054852,\n        -0.09846766,  0.08669026],\n       ...,\n       [ 0.03736099, -0.06543357,  0.05543617, ..., -0.06087255,\n         0.08601949,  0.05294777],\n       [-0.02205896,  0.03141039,  0.00066247, ...,  0.17388818,\n        -0.01842239,  0.02367421],\n       [-0.00704368,  0.0352019 , -0.14236571, ...,  0.03917494,\n        -0.04025203,  0.07081404]], dtype=float32), label_ids=array([6, 6, 6, 6, 6, 6, 6, 6, 6, 6]), metrics={'test_loss': 4.671304225921631, 'test_model_preparation_time': 0.0023, 'test_runtime': 0.0835, 'test_samples_per_second': 119.83, 'test_steps_per_second': 59.915})"
  },
  {
    "objectID": "공부/HF/2024-11-16-(강의) 데이터콜렉터.html#e.-imdb-datacollatorwithpadding-구현",
    "href": "공부/HF/2024-11-16-(강의) 데이터콜렉터.html#e.-imdb-datacollatorwithpadding-구현",
    "title": "(강의) 데이터콜렉터",
    "section": "E. IMDB – DataCollatorWithPadding 구현",
    "text": "E. IMDB – DataCollatorWithPadding 구현\nref: https://huggingface.co/docs/transformers/tasks/sequence_classification\n1. 데이터준비: \"guebin/imdb-tiny\" \\(\\to\\) trainer_input\n\nimdb = datasets.load_dataset(\"guebin/imdb-tiny\")\ntokenizer = transformers.AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\") \ndef preprocess_function(examples):\n    return tokenizer(examples[\"text\"], truncation=True)\ntokenized_imdb = imdb.map(preprocess_function,batched=True)\ntrainer_input = tokenized_imdb['train']\n\n2. 모델준비: \"distilbert/distilbert-base-uncased\" \\(\\to\\)model\n\nmodel = transformers.AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert/distilbert-base-uncased\", num_labels=2\n)\n\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n\n3. 데이터콜렉터: collate_fn 직접설계\n\n# data_collator = transformers.DataCollatorWithPadding(tokenizer=tokenizer)\n# data_collator\n\n\ndef collate_fn(single_batch):\n    pass\n\n\nDefaultDataCollator() 와 동일한 역할을 하는 collate_fn을 설계하라. 이를 이용하여 적당한 trainer를 만들어\ntrainer.predict(trainer_input)\n이 정상동작하는지 확인하라.\n(풀이)\n\ntrainer_input\n\nDataset({\n    features: ['text', 'label', 'input_ids', 'attention_mask'],\n    num_rows: 10\n})\n\n\n\nbatch_maker = transformers.Trainer(\n    model = model,\n    data_collator = lambda x: x \n)\n_batched_data = batch_maker.get_test_dataloader(trainer_input)\nbatched_data = list(_batched_data)\nsingle_batch = batched_data[-1]\nshow(single_batch)\n\nList Overview:\nTotal items: 2\n\n1. list[0]\n   - Type: dict\n   - Length: 3\n   - Values: {'label': 0, 'input_ids': [101, 2040, 2024, 2122, 1000, 2027, 1000, 1011, 1996, 5889, 1029, 1996, 16587, 1029, 5121, 2481, 1005, 1056, 2022, 1996, 4378, 1011, 2023, 2003, 2426, 1996, 2087, 2250, 1011, 23893, 2098, 5453, 1999, 4598, 1012, 2009, 1005, 1055, 1996, 2785, 1997, 3185, 2008, 3504, 2066, 2009, 2001, 1037, 2843, 1997, 4569, 2000, 5607, 2205, 2172, 4569, 1010, 6343, 2003, 2893, 2151, 5025, 2147, 2589, 1010, 1998, 2008, 2471, 2467, 3084, 2005, 1037, 3185, 2008, 1005, 1055, 2053, 4569, 2000, 3422, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 23168, 2123, 2015, 7877, 2061, 2004, 2000, 8691, ... 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n\n2. list[1]\n   - Type: dict\n   - Length: 3\n   - Values: {'label': 0, 'input_ids': [101, 2023, 2003, 2056, 2000, 2022, 1037, 3167, 2143, 2005, 2848, 22132, 5280, 18891, 10649, 1012, 2002, 2241, 2009, 2006, 2010, 2166, 2021, 2904, 2477, 2105, 2000, 4906, 1996, 3494, 1010, 2040, 2024, 18145, 1012, 2122, 18145, 3058, 3376, 4275, 1998, 2031, 2053, 3291, 2893, 2068, 1012, 4165, 2062, 2066, 1037, 19965, 18286, 12127, 2084, 1037, 6317, 1010, 2987, 1005, 1056, 2009, 1029, 2023, 2972, 3185, 2001, 2517, 2011, 2848, 1010, 1998, 2009, 3065, 2129, 2041, 1997, 3543, 2007, 2613, 2111, 2002, 2001, 1012, 2017, 1005, 2128, 4011, 2000, 4339, 2054, 2017, 2113, 1010, 1998, 2002, 2106, ... 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n\n\n\nmodel_input = dict()\nmodel_input['labels'] = torch.tensor([l['label'] for l in single_batch])\nmodel_input['labels']\n\ntensor([0, 0])\n\n\n\ninput_ids_list = [torch.tensor(l['input_ids']) for l in single_batch]\nmodel_input['input_ids'] = torch.nn.utils.rnn.pad_sequence(input_ids_list).t()\nmodel_input['input_ids']\n\ntensor([[  101,  2040,  2024,  ..., 22132,  7847,   102],\n        [  101,  2023,  2003,  ...,     0,     0,     0]])\n\n\n\nattention_mask_list = [torch.tensor(l['attention_mask']) for l in single_batch]\nmodel_input['attention_mask'] = torch.nn.utils.rnn.pad_sequence(attention_mask_list).t()\nmodel_input['attention_mask']\n\ntensor([[1, 1, 1,  ..., 1, 1, 1],\n        [1, 1, 1,  ..., 0, 0, 0]])\n\n\n\ndef collate_fn(single_batch):\n    model_input = dict()\n    model_input['labels'] = torch.tensor([l['label'] for l in single_batch])\n    input_ids_list = [torch.tensor(l['input_ids']) for l in single_batch]\n    model_input['input_ids'] = torch.nn.utils.rnn.pad_sequence(input_ids_list).t()\n    attention_mask_list = [torch.tensor(l['attention_mask']) for l in single_batch]\n    model_input['attention_mask'] = torch.nn.utils.rnn.pad_sequence(attention_mask_list).t()\n    return model_input\n\n\nmodel.to(\"cpu\")\nmodel(**collate_fn(single_batch))\n\nSequenceClassifierOutput(loss=tensor(0.6734, grad_fn=&lt;NllLossBackward0&gt;), logits=tensor([[ 0.0025, -0.0352],\n        [ 0.0139, -0.0282]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)\n\n\n\ntrainer = transformers.Trainer(\n    model = model,\n    data_collator = collate_fn\n)\n\n\ntrainer.predict(trainer_input)\n\n\n\n\nPredictionOutput(predictions=array([[ 0.08966769, -0.06166375],\n       [ 0.01500158, -0.06875467],\n       [ 0.03916247, -0.0061186 ],\n       [ 0.0405627 , -0.05440582],\n       [-0.0063449 , -0.03747641],\n       [ 0.03792842, -0.04466516],\n       [ 0.03690895, -0.08592646],\n       [ 0.00534204, -0.05428012],\n       [ 0.00248959, -0.03522498],\n       [ 0.01390314, -0.02818924]], dtype=float32), label_ids=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), metrics={'test_loss': 0.6564630270004272, 'test_model_preparation_time': 0.0012, 'test_runtime': 0.0366, 'test_samples_per_second': 273.189, 'test_steps_per_second': 54.638})"
  },
  {
    "objectID": "공부/HF/2024-11-16-(강의) 데이터콜렉터.html#a.-방법1-고정패딩-collate_fn",
    "href": "공부/HF/2024-11-16-(강의) 데이터콜렉터.html#a.-방법1-고정패딩-collate_fn",
    "title": "(강의) 데이터콜렉터",
    "section": "A. 방법1: 고정패딩, collate_fn",
    "text": "A. 방법1: 고정패딩, collate_fn\n\nspam\n\nDatasetDict({\n    train: Dataset({\n        features: ['sms', 'label'],\n        num_rows: 10\n    })\n})\n\n\n\ndef m_transform_batch(example_batch):\n    # example_batch = {'sms':[xxx,xxxx,...], 'label':[yyy,yyyy,...]}\n    result = tokenizer(example_batch['sms'],padding=True)\n    return result\n\n\nspam2 = spam.map(m_transform_batch,batched=True,batch_size=8)\nspam2.set_format(\"pt\")\nspam2['train'][:8]['input_ids']\n\ntensor([[  101,  2175,  2127, 18414, 17583,  2391,  1010,  4689,  1012,  1012,\n          2800,  2069,  1999, 11829,  2483,  1050,  2307,  2088,  2474,  1041,\n         28305,  1012,  1012,  1012, 25022,  2638,  2045,  2288, 26297, 28194,\n          1012,  1012,  1012,   102,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0],\n        [  101,  7929,  2474,  2099,  1012,  1012,  1012, 16644, 15536,  2546,\n          1057,  2006,  2072,  1012,  1012,  1012,   102,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0],\n        [  101,  2489,  4443,  1999,  1016,  1037,  1059,  2243,  2135,  4012,\n          2361,  2000,  2663,  6904,  2452,  2345,  1056, 25509,  2015,  7398,\n          2089,  2384,  1012,  3793,  6904,  2000,  6584, 12521,  2487,  2000,\n          4374,  4443,  3160,  1006,  2358,  2094, 19067,  2102,  3446,  1007,\n          1056,  1004,  1039,  1005,  1055,  6611,  5511, 19961, 22407, 18613,\n         23352,  7840, 15136,  1005,  1055,   102],\n        [  101,  1057, 24654,  2360,  2061,  2220,  7570,  2099,  1012,  1012,\n          1012,  1057,  1039,  2525,  2059,  2360,  1012,  1012,  1012,   102,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0],\n        [  101, 20976,  1045,  2123,  1005,  1056,  2228,  2002,  3632,  2000,\n          2149,  2546,  1010,  2002,  3268,  2105,  2182,  2295,   102,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0],\n        [  101,  2489,  5244,  2290,  4931,  2045,  9548,  2009,  1005,  1055,\n          2042,  1017,  2733,  1005,  1055,  2085,  1998,  2053,  2773,  2067,\n           999,  1045,  1005,  1040,  2066,  2070,  4569,  2017,  2039,  2005,\n          2009,  2145,  1029, 26419,  7929,   999, 22038,  2595,  2358,  2094,\n         10381,  5620,  2000,  4604,  1010, 14534,  1012,  2753,  2000, 22110,\n          2615,   102,     0,     0,     0,     0],\n        [  101,  2130,  2026,  2567,  2003,  2025,  2066,  2000,  3713,  2007,\n          2033,  1012,  2027,  7438,  2033,  2066,  8387,  7353,  1012,   102,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0],\n        [  101,  2004,  2566,  2115,  5227,  1005, 11463,  2571, 11463,  2571,\n          1006,  2030,  2226,  8117, 28987, 11231,  3070, 18447,  2063, 27617,\n          5575,  2226, 29525, 15464,  1007,  1005,  2038,  2042,  2275,  2004,\n          2115, 20587,  8525,  2638,  2005,  2035, 20587,  2015,  1012,  2811,\n          1008,  1023,  2000,  6100,  2115,  2814, 20587,  8525,  2638,   102,\n             0,     0,     0,     0,     0,     0]])\n\n\n\n이때 input_ids, attention_mask는 매트릭스 O\n\n\nspam2['train'][:9]['input_ids']\n\n[tensor([  101,  2175,  2127, 18414, 17583,  2391,  1010,  4689,  1012,  1012,\n          2800,  2069,  1999, 11829,  2483,  1050,  2307,  2088,  2474,  1041,\n         28305,  1012,  1012,  1012, 25022,  2638,  2045,  2288, 26297, 28194,\n          1012,  1012,  1012,   102,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]),\n tensor([  101,  7929,  2474,  2099,  1012,  1012,  1012, 16644, 15536,  2546,\n          1057,  2006,  2072,  1012,  1012,  1012,   102,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]),\n tensor([  101,  2489,  4443,  1999,  1016,  1037,  1059,  2243,  2135,  4012,\n          2361,  2000,  2663,  6904,  2452,  2345,  1056, 25509,  2015,  7398,\n          2089,  2384,  1012,  3793,  6904,  2000,  6584, 12521,  2487,  2000,\n          4374,  4443,  3160,  1006,  2358,  2094, 19067,  2102,  3446,  1007,\n          1056,  1004,  1039,  1005,  1055,  6611,  5511, 19961, 22407, 18613,\n         23352,  7840, 15136,  1005,  1055,   102]),\n tensor([  101,  1057, 24654,  2360,  2061,  2220,  7570,  2099,  1012,  1012,\n          1012,  1057,  1039,  2525,  2059,  2360,  1012,  1012,  1012,   102,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]),\n tensor([  101, 20976,  1045,  2123,  1005,  1056,  2228,  2002,  3632,  2000,\n          2149,  2546,  1010,  2002,  3268,  2105,  2182,  2295,   102,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]),\n tensor([  101,  2489,  5244,  2290,  4931,  2045,  9548,  2009,  1005,  1055,\n          2042,  1017,  2733,  1005,  1055,  2085,  1998,  2053,  2773,  2067,\n           999,  1045,  1005,  1040,  2066,  2070,  4569,  2017,  2039,  2005,\n          2009,  2145,  1029, 26419,  7929,   999, 22038,  2595,  2358,  2094,\n         10381,  5620,  2000,  4604,  1010, 14534,  1012,  2753,  2000, 22110,\n          2615,   102,     0,     0,     0,     0]),\n tensor([ 101, 2130, 2026, 2567, 2003, 2025, 2066, 2000, 3713, 2007, 2033, 1012,\n         2027, 7438, 2033, 2066, 8387, 7353, 1012,  102,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0]),\n tensor([  101,  2004,  2566,  2115,  5227,  1005, 11463,  2571, 11463,  2571,\n          1006,  2030,  2226,  8117, 28987, 11231,  3070, 18447,  2063, 27617,\n          5575,  2226, 29525, 15464,  1007,  1005,  2038,  2042,  2275,  2004,\n          2115, 20587,  8525,  2638,  2005,  2035, 20587,  2015,  1012,  2811,\n          1008,  1023,  2000,  6100,  2115,  2814, 20587,  8525,  2638,   102,\n             0,     0,     0,     0,     0,     0]),\n tensor([  101,  3453,   999,   999,  2004,  1037, 11126,  2897,  8013,  2017,\n          2031,  2042,  3479,  2000,  4374,  2050,  1069, 21057,  2692,  3396,\n         10377,   999,  2000,  4366,  2655,  5641,  2692,  2575, 16576, 24096,\n         21472,  2487,  1012,  4366,  3642,  1047,  2140, 22022,  2487,  1012,\n          9398,  2260,  2847,  2069,  1012,   102])]\n\n\n\n이때 input_ids, attention_mask는 매트릭스 X\n\n\nspam2['train'][8:]['input_ids'] # 텐서로 묶임..\n\ntensor([[  101,  3453,   999,   999,  2004,  1037, 11126,  2897,  8013,  2017,\n          2031,  2042,  3479,  2000,  4374,  2050,  1069, 21057,  2692,  3396,\n         10377,   999,  2000,  4366,  2655,  5641,  2692,  2575, 16576, 24096,\n         21472,  2487,  1012,  4366,  3642,  1047,  2140, 22022,  2487,  1012,\n          9398,  2260,  2847,  2069,  1012,   102],\n        [  101,  2018,  2115,  4684,  2340,  2706,  2030,  2062,  1029,  1057,\n          1054,  4709,  2000, 10651,  2000,  1996,  6745,  6120,  4684,  2015,\n          2007,  4950,  2005,  2489,   999,  2655,  1996,  4684, 10651,  2522,\n          2489,  2006,  5511,  8889, 24594, 20842,  2692, 14142,   102,     0,\n             0,     0,     0,     0,     0,     0]])\n\n\n\n이때 input_ids, attention_mask는 매트릭스 O\n\n\ntrainer_input = spam2['train'].remove_columns('sms').rename_columns({'label':'labels'})\ntrainer_input\n\nDataset({\n    features: ['labels', 'input_ids', 'attention_mask'],\n    num_rows: 10\n})\n\n\n\nbatch_maker = transformers.Trainer(\n    model=model,\n    data_collator=lambda x: x,\n)\nbatched_data = list(batch_maker.get_test_dataloader(trainer_input))\nsingle_batch = batched_data[-1]\nsingle_batch\n\n[{'labels': tensor(1, device='cuda:0'),\n  'input_ids': tensor([  101,  3453,   999,   999,  2004,  1037, 11126,  2897,  8013,  2017,\n           2031,  2042,  3479,  2000,  4374,  2050,  1069, 21057,  2692,  3396,\n          10377,   999,  2000,  4366,  2655,  5641,  2692,  2575, 16576, 24096,\n          21472,  2487,  1012,  4366,  3642,  1047,  2140, 22022,  2487,  1012,\n           9398,  2260,  2847,  2069,  1012,   102], device='cuda:0'),\n  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         device='cuda:0')},\n {'labels': tensor(1, device='cuda:0'),\n  'input_ids': tensor([  101,  2018,  2115,  4684,  2340,  2706,  2030,  2062,  1029,  1057,\n           1054,  4709,  2000, 10651,  2000,  1996,  6745,  6120,  4684,  2015,\n           2007,  4950,  2005,  2489,   999,  2655,  1996,  4684, 10651,  2522,\n           2489,  2006,  5511,  8889, 24594, 20842,  2692, 14142,   102,     0,\n              0,     0,     0,     0,     0,     0], device='cuda:0'),\n  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n         device='cuda:0')}]\n\n\n\ndef collate_fn(single_batch):\n    out = dict()\n    out['labels'] = torch.tensor([dct['labels'] for dct in single_batch])\n    out['input_ids'] = torch.stack([dct['input_ids'] for dct in single_batch])\n    out['attention_mask'] = torch.stack([dct['attention_mask'] for dct in single_batch])\n    return out \n\n\ncollate_fn(single_batch)\n\n{'labels': tensor([1, 1]),\n 'input_ids': tensor([[  101,  3453,   999,   999,  2004,  1037, 11126,  2897,  8013,  2017,\n           2031,  2042,  3479,  2000,  4374,  2050,  1069, 21057,  2692,  3396,\n          10377,   999,  2000,  4366,  2655,  5641,  2692,  2575, 16576, 24096,\n          21472,  2487,  1012,  4366,  3642,  1047,  2140, 22022,  2487,  1012,\n           9398,  2260,  2847,  2069,  1012,   102],\n         [  101,  2018,  2115,  4684,  2340,  2706,  2030,  2062,  1029,  1057,\n           1054,  4709,  2000, 10651,  2000,  1996,  6745,  6120,  4684,  2015,\n           2007,  4950,  2005,  2489,   999,  2655,  1996,  4684, 10651,  2522,\n           2489,  2006,  5511,  8889, 24594, 20842,  2692, 14142,   102,     0,\n              0,     0,     0,     0,     0,     0]], device='cuda:0'),\n 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]],\n        device='cuda:0')}\n\n\n\ntrainer = transformers.Trainer(\n    model = model,\n    data_collator = collate_fn\n)\n\n\ntrainer.predict(trainer_input)\n\n\n\n\nPredictionOutput(predictions=array([[-0.04641762, -0.03605646],\n       [-0.02506144, -0.01335288],\n       [ 0.02076511, -0.02322948],\n       [-0.00962518,  0.03754075],\n       [-0.03287388, -0.03730439],\n       [-0.02798662, -0.02491809],\n       [-0.09155686, -0.04009426],\n       [-0.0420014 , -0.02552293],\n       [-0.0209422 , -0.01544815],\n       [-0.01533531,  0.01857282]], dtype=float32), label_ids=array([0, 0, 1, 0, 0, 1, 0, 0, 1, 1]), metrics={'test_loss': 0.6999672651290894, 'test_model_preparation_time': 0.0022, 'test_runtime': 0.0163, 'test_samples_per_second': 613.543, 'test_steps_per_second': 122.709})"
  },
  {
    "objectID": "공부/HF/2024-11-16-(강의) 데이터콜렉터.html#b.-방법2-고정패딩-defaultdatacollator",
    "href": "공부/HF/2024-11-16-(강의) 데이터콜렉터.html#b.-방법2-고정패딩-defaultdatacollator",
    "title": "(강의) 데이터콜렉터",
    "section": "B. 방법2: 고정패딩, DefaultDataCollator",
    "text": "B. 방법2: 고정패딩, DefaultDataCollator\n- 방법1과 거의 동일\n\nspam\n\nDatasetDict({\n    train: Dataset({\n        features: ['sms', 'label'],\n        num_rows: 10\n    })\n})\n\n\n\ndef m_transform_batch(example_batch):\n    # example_batch = {'sms':[xxx,xxxx,...], 'label':[yyy,yyyy,...]}\n    result = tokenizer(example_batch['sms'],padding=True)\n    return result\nspam2 = spam.map(m_transform_batch,batched=True,batch_size=8)\nspam2.set_format(\"pt\")\ntrainer_input = spam2['train'].remove_columns('sms').rename_columns({'label':'labels'})\n\n# def collate_fn(single_batch):\n#     out = dict()\n#     out['labels'] = torch.tensor([dct['labels'] for dct in single_batch])\n#     out['input_ids'] = torch.stack([dct['input_ids'] for dct in single_batch])\n#     out['attention_mask'] = torch.stack([dct['attention_mask'] for dct in single_batch])\n#     return out \n\ndata_collator = transformers.DefaultDataCollator()\ntrainer = transformers.Trainer(\n    model = model,\n    data_collator = data_collator\n)\ntrainer.predict(trainer_input)\n\n\n\n\nPredictionOutput(predictions=array([[-0.04641762, -0.03605646],\n       [-0.02506144, -0.01335288],\n       [ 0.02076511, -0.02322948],\n       [-0.00962518,  0.03754075],\n       [-0.03287388, -0.03730439],\n       [-0.02798662, -0.02491809],\n       [-0.09155686, -0.04009426],\n       [-0.0420014 , -0.02552293],\n       [-0.0209422 , -0.01544815],\n       [-0.01533531,  0.01857282]], dtype=float32), label_ids=array([0, 0, 1, 0, 0, 1, 0, 0, 1, 1]), metrics={'test_loss': 0.6999672651290894, 'test_model_preparation_time': 0.0011, 'test_runtime': 0.0125, 'test_samples_per_second': 800.333, 'test_steps_per_second': 160.067})"
  },
  {
    "objectID": "공부/HF/2024-11-16-(강의) 데이터콜렉터.html#c.-방법3-동적패딩-datacollatorwithpadding",
    "href": "공부/HF/2024-11-16-(강의) 데이터콜렉터.html#c.-방법3-동적패딩-datacollatorwithpadding",
    "title": "(강의) 데이터콜렉터",
    "section": "C. 방법3: 동적패딩, DataCollatorWithPadding",
    "text": "C. 방법3: 동적패딩, DataCollatorWithPadding\n\nspam\n\nDatasetDict({\n    train: Dataset({\n        features: ['sms', 'label'],\n        num_rows: 10\n    })\n})\n\n\n\ndef w_transform(examples):\n    #examples = {'input_ids':[xxx,xxxx,....], 'label':[yyy,yyyy]}\n    out = tokenizer(examples['sms'],truncation=True)\n    out['labels'] = torch.tensor(examples['label'])\n    return out\n\n\ntrainer_input = spam.with_transform(w_transform)['train']\ntrainer_input\n\nDataset({\n    features: ['sms', 'label'],\n    num_rows: 10\n})\n\n\n\nbatch_maker = transformers.Trainer(\n    model = model,\n    data_collator= lambda x: x,\n    args=transformers.TrainingArguments(\n        output_dir = \"asdf\",\n        remove_unused_columns=False\n    )\n)\n_batched_data = batch_maker.get_eval_dataloader(trainer_input)\nbatched_data = list(_batched_data)\nsingle_batch = batched_data[-1]\n#single_batch\n\n\ndata_collator = transformers.DataCollatorWithPadding(tokenizer)\ndata_collator(single_batch)\n\n{'input_ids': tensor([[  101,  3453,   999,   999,  2004,  1037, 11126,  2897,  8013,  2017,\n          2031,  2042,  3479,  2000,  4374,  2050,  1069, 21057,  2692,  3396,\n         10377,   999,  2000,  4366,  2655,  5641,  2692,  2575, 16576, 24096,\n         21472,  2487,  1012,  4366,  3642,  1047,  2140, 22022,  2487,  1012,\n          9398,  2260,  2847,  2069,  1012,   102],\n        [  101,  2018,  2115,  4684,  2340,  2706,  2030,  2062,  1029,  1057,\n          1054,  4709,  2000, 10651,  2000,  1996,  6745,  6120,  4684,  2015,\n          2007,  4950,  2005,  2489,   999,  2655,  1996,  4684, 10651,  2522,\n          2489,  2006,  5511,  8889, 24594, 20842,  2692, 14142,   102,     0,\n             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor([1, 1])}\n\n\n\nmodel.to(\"cpu\")\nmodel(**data_collator(single_batch))\n\nSequenceClassifierOutput(loss=tensor(0.6834, grad_fn=&lt;NllLossBackward0&gt;), logits=tensor([[-0.0209, -0.0154],\n        [-0.0153,  0.0186]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)\n\n\n\ntrainer = transformers.Trainer(\n    model = model,\n    data_collator = data_collator,\n    args=transformers.TrainingArguments(\n        output_dir=\"asdf\",\n        remove_unused_columns=False\n    )\n)\ntrainer.predict(trainer_input)\n\n\n\n\nPredictionOutput(predictions=array([[-0.04641762, -0.03605646],\n       [-0.02506144, -0.01335288],\n       [ 0.02076511, -0.02322948],\n       [-0.00962518,  0.03754075],\n       [-0.03287388, -0.03730439],\n       [-0.02798662, -0.02491809],\n       [-0.09155686, -0.04009426],\n       [-0.0420014 , -0.02552293],\n       [-0.0209422 , -0.01544815],\n       [-0.01533531,  0.01857282]], dtype=float32), label_ids=array([0, 0, 1, 0, 0, 1, 0, 0, 1, 1]), metrics={'test_loss': 0.6999672651290894, 'test_model_preparation_time': 0.0007, 'test_runtime': 0.0093, 'test_samples_per_second': 1072.877, 'test_steps_per_second': 214.575})"
  },
  {
    "objectID": "공부/HF/2024-11-16-(강의) 데이터콜렉터.html#d.-방법4-동적패딩-전처리x-star",
    "href": "공부/HF/2024-11-16-(강의) 데이터콜렉터.html#d.-방법4-동적패딩-전처리x-star",
    "title": "(강의) 데이터콜렉터",
    "section": "D. 방법4: 동적패딩, 전처리X \\((\\star)\\)",
    "text": "D. 방법4: 동적패딩, 전처리X \\((\\star)\\)\n\ntrainer_input = spam['train']\ntrainer_input\n\nDataset({\n    features: ['sms', 'label'],\n    num_rows: 10\n})\n\n\n\ndef collate_fn(single_batch):\n    # single_batch = [Dict, Dict, Dict,...]\n    out = tokenizer([dct['sms'] for dct in single_batch],padding=True,return_tensors=\"pt\",truncation=True)\n    out['labels'] = torch.tensor([dct['label'] for dct in single_batch])\n    return out \n\n\ntrainer = transformers.Trainer(\n    model=model,\n    data_collator=collate_fn,\n    args= transformers.TrainingArguments(\n        output_dir= 'asdf',\n        remove_unused_columns= False\n    )\n)\ntrainer.predict(trainer_input)\n\n\n\n\nPredictionOutput(predictions=array([[-0.04641762, -0.03605646],\n       [-0.02506144, -0.01335288],\n       [ 0.02076511, -0.02322948],\n       [-0.00962518,  0.03754075],\n       [-0.03287388, -0.03730439],\n       [-0.02798662, -0.02491809],\n       [-0.09155686, -0.04009426],\n       [-0.0420014 , -0.02552293],\n       [-0.0209422 , -0.01544815],\n       [-0.01533531,  0.01857282]], dtype=float32), label_ids=array([0, 0, 1, 0, 0, 1, 0, 0, 1, 1]), metrics={'test_loss': 0.6999672651290894, 'test_model_preparation_time': 0.0011, 'test_runtime': 0.012, 'test_samples_per_second': 830.013, 'test_steps_per_second': 166.003})"
  },
  {
    "objectID": "공부/HF/2024-10-01-(강의) 비디오분류.html#a.-이미지-자료의-이해",
    "href": "공부/HF/2024-10-01-(강의) 비디오분류.html#a.-이미지-자료의-이해",
    "title": "(강의) 비디오분류",
    "section": "A. 이미지 자료의 이해",
    "text": "A. 이미지 자료의 이해\n- plt.imshow(...) 에서 ...의 shape이 (??,??) 이러한 형태라면 흑백이미지를 출력\n\nplt.imshow([[0,150],[0,255]],cmap='gray')\nplt.colorbar()\n\n\n\n\n\n\n\n\n- plt.imshow(...) 에서 ...의 shape이 (??,??,3) 이러한 형태라면 칼라이미지를 출력\n\nr = [[0,255],[0,255]] # (2,2)\ng = [[255,0],[0,0]] # (2,2)\nb = [[0,0],[255,0]] # (2,2) \nplt.imshow(np.stack([r,g,b],axis=-1))\n\n\n\n\n\n\n\n\n- plt.imshow(...)는 ...의 dtype이 int인지 float인지에 따라서 인식이 다름\n\nr = [[0,1],[0,1]] # (2,2)\ng = [[1,0],[0,0]] # (2,2)\nb = [[0,0],[1,0]] # (2,2) \nplt.imshow(np.stack([r,g,b],axis=-1))\n\n\n\n\n\n\n\n\n\nr = [[0,1],[0,1]] # (2,2)\ng = [[1,0],[0,0]] # (2,2)\nb = [[0,0],[1,0]] # (2,2) \nplt.imshow(np.stack([r,g,b],axis=-1).astype(np.float64))\n\n\n\n\n\n\n\n\n\n이건 마치 1을 255로 생각한 결과"
  },
  {
    "objectID": "공부/HF/2024-10-01-(강의) 비디오분류.html#b.-tsr.permute",
    "href": "공부/HF/2024-10-01-(강의) 비디오분류.html#b.-tsr.permute",
    "title": "(강의) 비디오분류",
    "section": "B. tsr.permute()",
    "text": "B. tsr.permute()\n- 실수로 R,G,B 를 이상한 방식으로 합쳤음..\n\nr = [[0,255],[0,255]] # (2,2)\ng = [[255,0],[0,0]] # (2,2)\nb = [[0,0],[255,0]] # (2,2) \n#img = np.stack([r,g,b],axis=-1) # &lt;-- 시각화를 위해선 이게 맞는 코드\nimg = np.stack([r,g,b])\nplt.imshow(img)\n\nTypeError: Invalid shape (3, 2, 2) for image data\n\n\n\n\n\n\n\n\n\n- 에러를 피하기 위해서 차원을 (3,2,2) 에서 (2,2,3) 으로 바꿈\n\nimg.reshape(2,2,3)\n\narray([[[  0, 255,   0],\n        [255, 255,   0]],\n\n       [[  0,   0,   0],\n        [  0, 255,   0]]])\n\n\n\nplt.imshow(img.reshape(2,2,3)) #???\n\n\n\n\n\n\n\n\n\n우리가 원하는 그림이 아닌데?\n\n- 아래의 결과를 관찰\n\nimg.reshape(2,2,3), np.transpose(img,(1,2,0))\n\n(array([[[  0, 255,   0],\n         [255, 255,   0]],\n \n        [[  0,   0,   0],\n         [  0, 255,   0]]]),\n array([[[  0, 255,   0],\n         [255,   0,   0]],\n \n        [[  0,   0, 255],\n         [255,   0,   0]]]))\n\n\n- 이게 맞는코드\n\nplt.imshow(np.transpose(img,(1,2,0)))\n\n\n\n\n\n\n\n\n- numpy 가 아니고 tensor 라면 아래와 같이 변환가능\n\nplt.imshow(torch.tensor(img).permute(1,2,0).numpy())"
  },
  {
    "objectID": "공부/HF/2024-10-01-(강의) 비디오분류.html#c.-영상-자료-이해",
    "href": "공부/HF/2024-10-01-(강의) 비디오분류.html#c.-영상-자료-이해",
    "title": "(강의) 비디오분류",
    "section": "C. 영상 자료 이해",
    "text": "C. 영상 자료 이해\n\nnp.random.seed(43052)\nv = (np.random.rand(4, 60, 60, 3) * 255).astype('uint8')\n# frame1 \nv[0, :, :, 0] = 255  # R 채널을 최대치로 설정\n# frame2 \nv[1, :, :, 1] = 255  # G 채널을 최대치로 설정\n# frame3 \nv[2, :, :, 2] = 255  # B 채널을 최대치로 설정\n# frame4 \nv[3, :, :, 0] = 255  # R 채널을 최대치로 설정\nv[3, :, :, 1] = 255  # G 채널을 최대치로 설정\nfig,ax = plt.subplots(2,2)\nax[0][0].imshow(v[0])\nax[0][1].imshow(v[1])\nax[1][0].imshow(v[2])\nax[1][1].imshow(v[3])\n\n\n\n\n\n\n\n\n\nframes = [frame for frame in v]\nimageio.mimsave(\"sample.gif\", frames)\n\n\nIPython.display.Image(\"sample.gif\")\n\n&lt;IPython.core.display.Image object&gt;"
  },
  {
    "objectID": "공부/HF/2024-10-01-(강의) 비디오분류.html#d.-arr.clip",
    "href": "공부/HF/2024-10-01-(강의) 비디오분류.html#d.-arr.clip",
    "title": "(강의) 비디오분류",
    "section": "D. arr.clip()",
    "text": "D. arr.clip()\n\narr = np.array([[300, -20, 150], [400, 100, 0], [255, 500, -100]])\narr\n\narray([[ 300,  -20,  150],\n       [ 400,  100,    0],\n       [ 255,  500, -100]])\n\n\n\narr_clipped = np.clip(arr, 0, 255)\narr_clipped\n\narray([[255,   0, 150],\n       [255, 100,   0],\n       [255, 255,   0]])"
  },
  {
    "objectID": "공부/HF/2024-10-01-(강의) 비디오분류.html#a.-다운로드",
    "href": "공부/HF/2024-10-01-(강의) 비디오분류.html#a.-다운로드",
    "title": "(강의) 비디오분류",
    "section": "A. 다운로드",
    "text": "A. 다운로드\n- 처음 /home/cgb3/.cache/의 상태\n- huggingface_hub.hf_hub_download 의 역할: (1) “UCF101_subset.tar.gz” 라는 압축파일을 다운로드 (2) 다운로드한 압축파일의 경로를 str으로 리턴\n\nfile_path = huggingface_hub.hf_hub_download(\n    repo_id=\"sayakpaul/ucf101-subset\", \n    filename=\"UCF101_subset.tar.gz\", \n    repo_type=\"dataset\"\n)\n\n\nfile_path\n\n'/home/cgb3/.cache/huggingface/hub/datasets--sayakpaul--ucf101-subset/snapshots/b9984b8d2a95e4a1879e1b071e9433858d0bc24a/UCF101_subset.tar.gz'"
  },
  {
    "objectID": "공부/HF/2024-10-01-(강의) 비디오분류.html#b.-압축풀기",
    "href": "공부/HF/2024-10-01-(강의) 비디오분류.html#b.-압축풀기",
    "title": "(강의) 비디오분류",
    "section": "B. 압축풀기",
    "text": "B. 압축풀기\n- tarfile.open 사용방법1\n\nt = tarfile.open(file_path)\n\n- t 의 주요기능\n\nt.closed\n\nFalse\n\n\n\nt._check()\n\n\nt.extractall(\"여기에\")\n\n\nt.extractall(\"asdf\")\n\n\nt.extractall(\".\")\n\n\nt.close()\n\n\nt.closed\n\nTrue\n\n\n\nt.extractall(\"저기에\")\n\nOSError: TarFile is closed\n\n\n\nt._check()\n\nOSError: TarFile is closed\n\n\n- tarfile.open + with 문\n아래의 코드를 작성하고 싶음\n1. `TarFile` 오브젝트 만듦.\n2. 열린상태인지 체크. (열린상태라면 에러메시지 발생하고 진행중지)\n3. 압축해제.\n4. 닫음.\n아래와 같이 쓸 수 있음\n\nt = tarfile.open(file_path)\nt._check()\nt.extractall(\".\")\nt.close()\n\n이것을 아래와 같이 줄일 수 있음\n\nwith tarfile.open(file_path) as t:\n    t.extractall(\".\")"
  },
  {
    "objectID": "공부/HF/2024-10-01-(강의) 비디오분류.html#c.-영상확인",
    "href": "공부/HF/2024-10-01-(강의) 비디오분류.html#c.-영상확인",
    "title": "(강의) 비디오분류",
    "section": "C. 영상확인",
    "text": "C. 영상확인\n- 원래는 아래가 실행되어야함.\n\nIPython.display.Video('UCF101_subset/train/ApplyEyeMakeup/v_ApplyEyeMakeup_g02_c03.avi')\n\n\n      Your browser does not support the video element.\n    \n\n\n- avi를 mp4로 변환\n\n#!conda install conda-forge::ffmpeg\n!ffmpeg -i UCF101_subset/train/Basketball/v_Basketball_g01_c01.avi -vcodec libx264 -acodec aac output_video.mp4 -y\n\nffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n  built with gcc 12.3.0 (conda-forge gcc 12.3.0-7)\n  configuration: --prefix=/home/conda/feedstock_root/build_artifacts/ffmpeg_1716145014501/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1716145014501/_build_env/bin/x86_64-conda-linux-gnu-cc --cxx=/home/conda/feedstock_root/build_artifacts/ffmpeg_1716145014501/_build_env/bin/x86_64-conda-linux-gnu-c++ --nm=/home/conda/feedstock_root/build_artifacts/ffmpeg_1716145014501/_build_env/bin/x86_64-conda-linux-gnu-nm --ar=/home/conda/feedstock_root/build_artifacts/ffmpeg_1716145014501/_build_env/bin/x86_64-conda-linux-gnu-ar --disable-doc --disable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libharfbuzz --enable-libfontconfig --enable-libopenh264 --enable-libdav1d --enable-gnutls --enable-libmp3lame --enable-libvpx --enable-libass --enable-pthreads --enable-vaapi --enable-libopenvino --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libopus --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1716145014501/_build_env/bin/pkg-config\n  libavutil      58. 29.100 / 58. 29.100\n  libavcodec     60. 31.102 / 60. 31.102\n  libavformat    60. 16.100 / 60. 16.100\n  libavdevice    60.  3.100 / 60.  3.100\n  libavfilter     9. 12.100 /  9. 12.100\n  libswscale      7.  5.100 /  7.  5.100\n  libswresample   4. 12.100 /  4. 12.100\n  libpostproc    57.  3.100 / 57.  3.100\nInput #0, avi, from 'UCF101_subset/train/Basketball/v_Basketball_g01_c01.avi':\n  Metadata:\n    software        : Lavf52.31.1\n  Duration: 00:00:04.70, start: 0.000000, bitrate: 489 kb/s\n  Stream #0:0: Video: mpeg4 (Simple Profile) (xvid / 0x64697678), yuv420p, 320x240 [SAR 1:1 DAR 4:3], 477 kb/s, 29.97 fps, 29.97 tbr, 29.97 tbn\nStream mapping:\n  Stream #0:0 -&gt; #0:0 (mpeg4 (native) -&gt; h264 (libx264))\nPress [q] to stop, [?] for help\n[libx264 @ 0x5ffc22bccac0] using SAR=1/1\n[libx264 @ 0x5ffc22bccac0] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n[libx264 @ 0x5ffc22bccac0] profile High, level 1.3, 4:2:0, 8-bit\n[libx264 @ 0x5ffc22bccac0] 264 - core 164 r3095 baee400 - H.264/MPEG-4 AVC codec - Copyleft 2003-2022 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=7 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\nOutput #0, mp4, to 'output_video.mp4':\n  Metadata:\n    software        : Lavf52.31.1\n    encoder         : Lavf60.16.100\n  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 320x240 [SAR 1:1 DAR 4:3], q=2-31, 29.97 fps, 30k tbn\n    Metadata:\n      encoder         : Lavc60.31.102 libx264\n    Side data:\n      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n[out#0/mp4 @ 0x5ffc22bb2d80] video:83kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 2.782449%\nframe=  141 fps=0.0 q=-1.0 Lsize=      85kB time=00:00:04.60 bitrate= 151.8kbits/s speed=58.9x    \n[libx264 @ 0x5ffc22bccac0] frame I:1     Avg QP:21.24  size:  8871\n[libx264 @ 0x5ffc22bccac0] frame P:84    Avg QP:22.22  size:   863\n[libx264 @ 0x5ffc22bccac0] frame B:56    Avg QP:28.51  size:    53\n[libx264 @ 0x5ffc22bccac0] consecutive B-frames: 30.5% 42.6% 21.3%  5.7%\n[libx264 @ 0x5ffc22bccac0] mb I  I16..4:  4.7% 93.3%  2.0%\n[libx264 @ 0x5ffc22bccac0] mb P  I16..4:  0.3%  2.3%  0.1%  P16..4: 23.7%  4.5%  6.0%  0.0%  0.0%    skip:63.0%\n[libx264 @ 0x5ffc22bccac0] mb B  I16..4:  0.0%  0.1%  0.0%  B16..8: 13.2%  0.2%  0.1%  direct: 0.1%  skip:86.5%  L0:37.5% L1:61.4% BI: 1.1%\n[libx264 @ 0x5ffc22bccac0] 8x8 transform intra:86.2% inter:75.6%\n[libx264 @ 0x5ffc22bccac0] coded y,uvDC,uvAC intra: 76.2% 86.3% 36.6% inter: 7.9% 14.0% 3.4%\n[libx264 @ 0x5ffc22bccac0] i16 v,h,dc,p: 21% 33% 35% 12%\n[libx264 @ 0x5ffc22bccac0] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 17% 38% 36%  2%  1%  1%  1%  1%  3%\n[libx264 @ 0x5ffc22bccac0] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 42% 39% 10%  1%  2%  2%  1%  0%  3%\n[libx264 @ 0x5ffc22bccac0] i8c dc,h,v,p: 45% 43%  9%  2%\n[libx264 @ 0x5ffc22bccac0] Weighted P-Frames: Y:0.0% UV:0.0%\n[libx264 @ 0x5ffc22bccac0] ref P L0: 80.6%  7.8%  8.5%  3.0%\n[libx264 @ 0x5ffc22bccac0] ref B L0: 82.3% 15.6%  2.1%\n[libx264 @ 0x5ffc22bccac0] ref B L1: 98.6%  1.4%\n[libx264 @ 0x5ffc22bccac0] kb/s:143.42\n\n\n- 영상확인\n\nIPython.display.Video('output_video.mp4')\n\n\n      Your browser does not support the video element."
  },
  {
    "objectID": "공부/HF/2024-10-01-(강의) 비디오분류.html#d.-영상-불러오기",
    "href": "공부/HF/2024-10-01-(강의) 비디오분류.html#d.-영상-불러오기",
    "title": "(강의) 비디오분류",
    "section": "D. 영상 불러오기",
    "text": "D. 영상 불러오기\n\n# 영상 \\(\\to\\) 텐서 // 불러오기\n- 데이터 불러오기\n\n_train = pytorchvideo.data.labeled_video_dataset(\n    data_path = 'UCF101_subset/train',\n    clip_sampler = pytorchvideo.data.make_clip_sampler(\"random\", 15),\n    decode_audio = False,\n)\n\n\nset(dir(_train)) & {'__next__'}\n\n{'__next__'}\n\n\n\nvideo_tensor = next(_train)['video']\nvideo_tensor.shape\n\ntorch.Size([3, 141, 240, 320])\n\n\n\n\n# 텐서 \\(\\to\\) 영상 // 확인용\n- 차원변환\n\nvideo_tensor.permute(1,2,3,0).shape\n\ntorch.Size([141, 240, 320, 3])\n\n\n- 자료형변환전\n\nplt.imshow(video_tensor.permute(1,2,3,0)[0])\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..255.0].\n\n\n\n\n\n\n\n\n\n- 자료형 변환 후\n\nimg = video_tensor.permute(1,2,3,0)[0].numpy()\nplt.imshow(img.astype(\"uint8\"))\n\n\n\n\n\n\n\n\n- gif 만들기\n\nframes = [] \nfor video_frame in video_tensor.permute(1,2,3,0):\n    frames.append(video_frame.numpy().astype(\"uint8\"))\n\n\nimageio.mimsave(\"sample.gif\",frames,duration=0.25)\n\n- gif이미지 display 하기\n\nIPython.display.Image(filename=\"sample.gif\")\n\n&lt;IPython.core.display.Image object&gt;\n\n\n- 정리하기\n\ndef _display_gif(video_tensor):\n    #---#\n    frames = [] \n    for video_frame in video_tensor.permute(1,2,3,0):\n        img = video_frame.numpy().astype(\"uint8\")\n        frames.append(img)\n    imageio.mimsave(\"sample.gif\",frames)\n    return IPython.display.Image(filename=\"sample.gif\")    \n\n\n_display_gif(video_tensor)\n\n&lt;IPython.core.display.Image object&gt;"
  },
  {
    "objectID": "공부/HF/2024-10-01-(강의) 비디오분류.html#e.-모델생성",
    "href": "공부/HF/2024-10-01-(강의) 비디오분류.html#e.-모델생성",
    "title": "(강의) 비디오분류",
    "section": "E. 모델생성",
    "text": "E. 모델생성\n\nid2label = {\n    0: 'ApplyEyeMakeup',\n    1: 'Archery',\n    2: 'BalanceBeam',\n    3: 'BaseballPitch',\n    4: 'BasketballDunk',\n    5: 'ApplyLipstick',\n    6: 'BabyCrawling',\n    7: 'BandMarching',\n    8: 'Basketball',\n    9: 'BenchPress'\n}\n\n\nlabel2id = {\n    'ApplyEyeMakeup': 0, \n    'Archery': 1,\n    'BalanceBeam': 2,\n    'BaseballPitch': 3,\n    'BasketballDunk': 4,\n    'ApplyLipstick': 5,\n    'BabyCrawling': 6,\n    'BandMarching': 7,\n    'Basketball': 8,\n    'BenchPress': 9 \n}\n\n\nmodel = transformers.VideoMAEForVideoClassification.from_pretrained(\n    \"MCG-NJU/videomae-base\",\n    label2id=label2id,\n    id2label=id2label,\n    ignore_mismatched_sizes=True,  # provide this in case you're planning to fine-tune an already fine-tuned checkpoint\n)\n\nSome weights of VideoMAEForVideoClassification were not initialized from the model checkpoint at MCG-NJU/videomae-base and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n\n\nmodel.config.num_frames\n\n16"
  },
  {
    "objectID": "공부/HF/2024-10-01-(강의) 비디오분류.html#f.-변환-to-trvaltest-생성",
    "href": "공부/HF/2024-10-01-(강의) 비디오분류.html#f.-변환-to-trvaltest-생성",
    "title": "(강의) 비디오분류",
    "section": "F. 변환 \\(\\to\\) tr/val/test 생성",
    "text": "F. 변환 \\(\\to\\) tr/val/test 생성\n- 모델에 최적화된 변환기\n\nimage_processor = transformers.VideoMAEImageProcessor.from_pretrained(\"MCG-NJU/videomae-base\")\n\n- 저장된 값들\n\nprint(\n    f\"mean : {image_processor.image_mean}\\n\"\n    f\"std: {image_processor.image_std}\\n\" \n    f\"size: {image_processor.size}\\n\"\n    f\"resize_to: {(224,224)}\\n\"\n    f\"num_frames_to_sample: {16}\\n\"\n    f\"clip_duration: {16 * 4 / 30}\"\n)\n\nmean : [0.485, 0.456, 0.406]\nstd: [0.229, 0.224, 0.225]\nsize: {'shortest_edge': 224}\nresize_to: (224, 224)\nnum_frames_to_sample: 16\nclip_duration: 2.1333333333333333\n\n\n- 최적화된 변환을 적용하여 다시 텐서를 부름\n\ntrain_dataset = pytorchvideo.data.labeled_video_dataset(\n    data_path = 'UCF101_subset/train',\n    clip_sampler = pytorchvideo.data.make_clip_sampler(\"random\", 2.1333333333333333),\n    decode_audio = False,\n    transform = pytorchvideo.transforms.ApplyTransformToKey(\n        key = \"video\",\n        transform = torchvision.transforms.Compose(\n            [\n                pytorchvideo.transforms.UniformTemporalSubsample(16),\n                torchvision.transforms.Lambda(lambda x: x / 255.0),\n                pytorchvideo.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n                pytorchvideo.transforms.RandomShortSideScale(min_size=256, max_size=320),\n                torchvision.transforms.Resize((224, 224)),\n                torchvision.transforms.RandomHorizontalFlip(p=0.5)\n            ]\n        )\n    )\n)\n\n- 변화된 텐서에 맞는 display_gif를 새로 선언\n\ndef display_gif(video_tensor):\n    mean = [0.485, 0.456, 0.406]\n    std = [0.229, 0.224, 0.225]\n    #---#\n    frames = [] \n    for video_frame in video_tensor.permute(1,2,3,0):\n        img = video_frame.numpy()\n        img = (img * std) + mean \n        img = (img * 255).astype(\"uint8\")\n        img = img.clip(0, 255)\n        frames.append(img)\n    imageio.mimsave(\"sample.gif\",frames)\n    return IPython.display.Image(filename=\"sample.gif\")    \n\n\ndisplay_gif(next(train)['video'])\n\n&lt;IPython.core.display.Image object&gt;\n\n\n- 각 변환의 의미를 살펴보자.\n\nUniformTemporalSubsample(16):\nLambda(lambda x: x / 255.0):\nNormalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]):\nRandomShortSideScale(min_size=256, max_size=320):\nRandomHorizontalFlip(p=0.5):\n\n\ntrain_dataset = pytorchvideo.data.labeled_video_dataset(\n    data_path = 'UCF101_subset/train',\n    clip_sampler = pytorchvideo.data.make_clip_sampler(\"random\", 2.1333333333333333),\n    decode_audio = False,\n    transform = pytorchvideo.transforms.ApplyTransformToKey(\n        key = \"video\",\n        transform = torchvision.transforms.Compose(\n            [\n                pytorchvideo.transforms.UniformTemporalSubsample(16),\n                torchvision.transforms.Lambda(lambda x: x / 255.0),\n                pytorchvideo.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n                pytorchvideo.transforms.RandomShortSideScale(min_size=256, max_size=320),\n                torchvision.transforms.Resize((224, 224)),\n                torchvision.transforms.RandomHorizontalFlip(p=0.5)\n            ]\n        )\n    )\n)\ndisplay_gif(next(train)['video'])\n\n&lt;IPython.core.display.Image object&gt;\n\n\n- test, val 도 불러오자.\n\ntest_dataset = pytorchvideo.data.labeled_video_dataset(\n    data_path = 'UCF101_subset/train',\n    clip_sampler = pytorchvideo.data.make_clip_sampler(\"uniform\", 2.1333333333333333),\n    decode_audio = False,\n    transform = pytorchvideo.transforms.ApplyTransformToKey(\n        key = \"video\",\n        transform = torchvision.transforms.Compose(\n            [\n                pytorchvideo.transforms.UniformTemporalSubsample(16),\n                torchvision.transforms.Lambda(lambda x: x / 255.0),\n                pytorchvideo.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n                #pytorchvideo.transforms.RandomShortSideScale(min_size=256, max_size=320),\n                torchvision.transforms.Resize((224, 224)),\n                #torchvision.transforms.RandomHorizontalFlip(p=0.5)\n            ]\n        )\n    )\n)\nval_dataset = pytorchvideo.data.labeled_video_dataset(\n    data_path = 'UCF101_subset/train',\n    clip_sampler = pytorchvideo.data.make_clip_sampler(\"uniform\", 2.1333333333333333),\n    decode_audio = False,\n    transform = pytorchvideo.transforms.ApplyTransformToKey(\n        key = \"video\",\n        transform = torchvision.transforms.Compose(\n            [\n                pytorchvideo.transforms.UniformTemporalSubsample(16),\n                torchvision.transforms.Lambda(lambda x: x / 255.0),\n                pytorchvideo.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n                #pytorchvideo.transforms.RandomShortSideScale(min_size=256, max_size=320),\n                torchvision.transforms.Resize((224, 224)),\n                #torchvision.transforms.RandomHorizontalFlip(p=0.5)\n            ]\n        )\n    )\n)"
  },
  {
    "objectID": "공부/HF/2024-10-01-(강의) 비디오분류.html#g.-데이터콜렉터",
    "href": "공부/HF/2024-10-01-(강의) 비디오분류.html#g.-데이터콜렉터",
    "title": "(강의) 비디오분류",
    "section": "G. 데이터콜렉터",
    "text": "G. 데이터콜렉터\n- 일단 아래가 실행되지 않음을 관찰하자.\n\nmodel(train_dataset)\n\nAttributeError: 'LabeledVideoDataset' object has no attribute 'shape'\n\n\n- 실행되는 형태1: model(tsr-nfchw)\n\nexamples = [next(train_dataset), next(train_dataset)] \n\n\nexamples[0]['video'].shape, examples[1]['video'].shape\n\n(torch.Size([3, 16, 224, 224]), torch.Size([3, 16, 224, 224]))\n\n\n\nexamples[0]['video'].permute(1,0,2,3).shape, examples[1]['video'].permute(1,0,2,3).shape\n\n(torch.Size([16, 3, 224, 224]), torch.Size([16, 3, 224, 224]))\n\n\n\ntorch.stack([examples[0]['video'].permute(1,0,2,3), examples[1]['video'].permute(1,0,2,3)]).shape\n\ntorch.Size([2, 16, 3, 224, 224])\n\n\n\ntsr = torch.stack([examples[i]['video'].permute(1,0,2,3) for i in range(2)])\ntsr.shape\n\ntorch.Size([2, 16, 3, 224, 224])\n\n\n\nmodel(tsr)\n\nImageClassifierOutput(loss=None, logits=tensor([[ 0.4671,  0.4103, -0.3659,  0.0303,  0.1490, -0.5198, -0.4376, -0.2202,\n          0.3834,  0.2408],\n        [ 0.7669, -0.0123, -0.1794,  0.3096,  0.4815, -0.1627, -0.0231, -0.3684,\n          0.1878, -0.1508]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)\n\n\n- 실행되는 형태2: model(**{\"pixel_values\": tsr-nfchw, \"labels\": tsr-n})\n\nexamples[0]['label'], examples[1]['label']\n\n(9, 2)\n\n\n\n[examples[i]['label'] for i in range(2)]\n\n[9, 2]\n\n\n\nlabels = torch.tensor([examples[i]['label'] for i in range(2)])\nlabels\n\ntensor([9, 2])\n\n\n\nmodel(**{'pixel_values':tsr, \"labels\": labels})\n\nImageClassifierOutput(loss=tensor(2.3808, grad_fn=&lt;NllLossBackward0&gt;), logits=tensor([[ 0.4671,  0.4103, -0.3659,  0.0303,  0.1490, -0.5198, -0.4376, -0.2202,\n          0.3834,  0.2408],\n        [ 0.7669, -0.0123, -0.1794,  0.3096,  0.4815, -0.1627, -0.0231, -0.3684,\n          0.1878, -0.1508]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)\n\n\n- 그렇다면 데이터콜렉터는?\n\ndef collate_fn(examples):\n    tsr = torch.stack(\n        [example[\"video\"].permute(1, 0, 2, 3) for example in examples]\n    )\n    labels = torch.tensor([examples[i]['label'] for i in range(2)])\n    return dict(pixel_values=tsr, labels=labels)\n\n\nmodel(**collate_fn(examples))\n\nImageClassifierOutput(loss=tensor(2.3808, grad_fn=&lt;NllLossBackward0&gt;), logits=tensor([[ 0.4671,  0.4103, -0.3659,  0.0303,  0.1490, -0.5198, -0.4376, -0.2202,\n          0.3834,  0.2408],\n        [ 0.7669, -0.0123, -0.1794,  0.3096,  0.4815, -0.1627, -0.0231, -0.3684,\n          0.1878, -0.1508]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)\n\n\n- 좀 더 일반화\n\ndef collate_fn(examples):\n    tsr = torch.stack(\n        [example[\"video\"].permute(1, 0, 2, 3) for example in examples]\n    )\n    labels = torch.tensor([example['label'] for example in examples])\n    return dict(pixel_values=tsr, labels=labels)\nmodel(**collate_fn(examples))    \n\nRuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
  },
  {
    "objectID": "공부/HF/2024-11-08-(강의)-Model.html#a.-텍스트",
    "href": "공부/HF/2024-11-08-(강의)-Model.html#a.-텍스트",
    "title": "(강의) Model",
    "section": "A. 텍스트",
    "text": "A. 텍스트\n\nmodel1 = transformers.AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert/distilbert-base-uncased\", num_labels=2\n)\ntokenizer = transformers.AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n\n# 예제1 – imdb\n\nimdb = datasets.load_dataset('imdb')\nd = imdb['train'].select(range(3))\nd\n\nDataset({\n    features: ['text', 'label'],\n    num_rows: 3\n})\n\n\n(풀이1)\n실패\n\nmodel1(\n    input_ids = torch.tensor(tokenizer(d['text'])['input_ids']),\n    labels = torch.tensor([0,0,1])\n)\n\nValueError: expected sequence of length 363 at dim 1 (got 304)\n\n\n원인분석\n\nmp.show_list(tokenizer(d['text'])['input_ids'])\n\nLevel 1 - Type: list, Length: 3, Content: [[101, 1045, 12524, 1045, ... // ... , 7987, 1013, 1028, 102]]\n     Level 2 - Type: list, Length: 363, Content: [101, 1045, 12524, 1045,  ... // ... 7, 1037, 5436, 1012, 102]\n     Level 2 - Type: list, Length: 304, Content: [101, 1000, 1045, 2572, 8 ... // ... 5, 1055, 4230, 1012, 102]\n     Level 2 - Type: list, Length: 133, Content: [101, 2065, 2069, 2000, 4 ... // ... 6, 7987, 1013, 1028, 102]\n\n\n\nmp.show_list(\n    tokenizer(d['text'],padding=True)['input_ids']\n)\n\nLevel 1 - Type: list, Length: 3, Content: [[101, 1045, 12524, 1045, ... // ...  0, 0, 0, 0, 0, 0, 0, 0]]\n     Level 2 - Type: list, Length: 363, Content: [101, 1045, 12524, 1045,  ... // ... 7, 1037, 5436, 1012, 102]\n     Level 2 - Type: list, Length: 363, Content: [101, 1000, 1045, 2572, 8 ... // ... , 0, 0, 0, 0, 0, 0, 0, 0]\n     Level 2 - Type: list, Length: 363, Content: [101, 2065, 2069, 2000, 4 ... // ... , 0, 0, 0, 0, 0, 0, 0, 0]\n\n\n성공\n\nmodel1(\n    input_ids = torch.tensor(tokenizer(d['text'],padding=True)['input_ids']),\n    labels = torch.tensor([0,0,1])\n)\n\nSequenceClassifierOutput(loss=tensor(0.7086, grad_fn=&lt;NllLossBackward0&gt;), logits=tensor([[-0.0432,  0.0316],\n        [-0.0439,  0.0662],\n        [-0.0688,  0.0301]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)\n\n\n(풀이2)\n\ntokenizer(d['text'],padding=True,return_tensors='pt')['input_ids']\n\ntensor([[  101,  1045, 12524,  ...,  5436,  1012,   102],\n        [  101,  1000,  1045,  ...,     0,     0,     0],\n        [  101,  2065,  2069,  ...,     0,     0,     0]])\n\n\n\nmodel1(\n    input_ids = tokenizer(d['text'],padding=True,return_tensors='pt')['input_ids'],\n    labels = torch.tensor([0,0,1])\n)\n\nSequenceClassifierOutput(loss=tensor(0.7086, grad_fn=&lt;NllLossBackward0&gt;), logits=tensor([[-0.0432,  0.0316],\n        [-0.0439,  0.0662],\n        [-0.0688,  0.0301]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)\n\n\n\nmodel1(\n    tokenizer(d['text'],padding=True,return_tensors='pt')['input_ids'],\n    labels = torch.tensor([0,0,1])\n)\n\nSequenceClassifierOutput(loss=tensor(0.7086, grad_fn=&lt;NllLossBackward0&gt;), logits=tensor([[-0.0432,  0.0316],\n        [-0.0439,  0.0662],\n        [-0.0688,  0.0301]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)\n\n\n#\n# 예제2 – emotion\n\nemotion = datasets.load_dataset('emotion')\n\n\nd = emotion['train'].select(range(3))\nd\n\nDataset({\n    features: ['text', 'label'],\n    num_rows: 3\n})\n\n\n(풀이)\n\nmodel1(\n    torch.tensor(tokenizer(d['text'],padding=True)['input_ids'])\n)\n\nSequenceClassifierOutput(loss=None, logits=tensor([[-0.0105,  0.0449],\n        [ 0.0015,  0.0298],\n        [-0.0091,  0.0532]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)\n\n\n\nmodel1(\n    tokenizer(d['text'],padding=True,return_tensors=\"pt\")['input_ids']\n)\n\nSequenceClassifierOutput(loss=None, logits=tensor([[-0.0105,  0.0449],\n        [ 0.0015,  0.0298],\n        [-0.0091,  0.0532]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)\n\n\n#\n# 예제3 – MBTI\n\nd = datasets.Dataset.from_csv(\"mbti_1.csv\").select(range(3))\nd\n\nDataset({\n    features: ['type', 'posts'],\n    num_rows: 3\n})\n\n\n(풀이1)\n실패\n\nmodel1(\n    tokenizer(d['posts'],padding=True,return_tensors=\"pt\")['input_ids']\n)\n\nRuntimeError: The size of tensor a (2102) must match the size of tensor b (512) at non-singleton dimension 1\n\n\n원인분석\n\nmp.show_list(tokenizer(d['posts'],padding=True,return_tensors=\"pt\")['input_ids'])\n\nToken indices sequence length is longer than the specified maximum sequence length for this model (2102 &gt; 512). Running this sequence through the model will result in indexing errors\n\n\nLevel 1 - Type: Tensor, Length: 3, Content: tensor([[ 101, 1005, 8299 ... // ...  ...,    0,    0,    0]])\n     Level 2 - Type: Tensor, Length: 2102, Content: tensor([ 101, 1005, 8299,  ...,    0,    0,    0])\n     Level 2 - Type: Tensor, Length: 2102, Content: tensor([ 101, 1005, 1045,  ..., 1012, 1005,  102])\n     Level 2 - Type: Tensor, Length: 2102, Content: tensor([ 101, 1005, 2204,  ...,    0,    0,    0])\n\n\n\nmp.show_list(tokenizer(d['posts'],truncation=True,return_tensors=\"pt\")['input_ids'])\n\nLevel 1 - Type: Tensor, Length: 3, Content: tensor([[ 101, 1005, 8299 ... // ...  ..., 1012, 2077,  102]])\n     Level 2 - Type: Tensor, Length: 512, Content: tensor([  101,  1005,  82 ... // ... 7,\n         2215,   102])\n     Level 2 - Type: Tensor, Length: 512, Content: tensor([  101,  1005,  10 ... // ... 9,\n         2028,   102])\n     Level 2 - Type: Tensor, Length: 512, Content: tensor([  101,  1005,  22 ... // ... 2,\n         2077,   102])\n\n\n성공\n\nmodel1(\n    tokenizer(d['posts'],truncation=True,return_tensors=\"pt\")['input_ids']\n)\n\nSequenceClassifierOutput(loss=None, logits=tensor([[-0.0469, -0.0175],\n        [-0.0534, -0.0048],\n        [-0.0759, -0.0220]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)\n\n\n(풀이2) –모델설정변경 (퀴즈5, 모델의 프레임수를 4로 바꾸는 예제에서 사용한 테크닉)\ndistilbert/distilbert-base-uncased 설정값 부르기\n\nconfig = transformers.AutoConfig.from_pretrained(\"distilbert/distilbert-base-uncased\")\nconfig\n\nDistilBertConfig {\n  \"_name_or_path\": \"distilbert/distilbert-base-uncased\",\n  \"activation\": \"gelu\",\n  \"architectures\": [\n    \"DistilBertForMaskedLM\"\n  ],\n  \"attention_dropout\": 0.1,\n  \"dim\": 768,\n  \"dropout\": 0.1,\n  \"hidden_dim\": 3072,\n  \"initializer_range\": 0.02,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"distilbert\",\n  \"n_heads\": 12,\n  \"n_layers\": 6,\n  \"pad_token_id\": 0,\n  \"qa_dropout\": 0.1,\n  \"seq_classif_dropout\": 0.2,\n  \"sinusoidal_pos_embds\": false,\n  \"tie_weights_\": true,\n  \"transformers_version\": \"4.46.2\",\n  \"vocab_size\": 30522\n}\n\n\n설정값체크 – config. + tab\n\nmp.tab(config)\n\n\n\n\n\n\n\n\n\n\n\n \n \nDescription\n\n\nType\nName\n \n\n\n\n\nNoneType\nbad_words_ids\nNone\n\n\nbegin_suppress_tokens\nNone\n\n\nbos_token_id\nNone\n\n\ncross_attention_hidden_size\nNone\n\n\ndecoder_start_token_id\nNone\n\n\neos_token_id\nNone\n\n\nexponential_decay_length_penalty\nNone\n\n\nfinetuning_task\nNone\n\n\nforced_bos_token_id\nNone\n\n\nforced_eos_token_id\nNone\n\n\nprefix\nNone\n\n\nproblem_type\nNone\n\n\nsep_token_id\nNone\n\n\nsuppress_tokens\nNone\n\n\ntask_specific_params\nNone\n\n\ntokenizer_class\nNone\n\n\ntorch_dtype\nNone\n\n\nbool\nadd_cross_attention\nbool(x) -&gt; bool Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.\n\n\ndo_sample\nbool(x) -&gt; bool Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.\n\n\nearly_stopping\nbool(x) -&gt; bool Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.\n\n\nis_composition\nbool(x) -&gt; bool Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.\n\n\nis_decoder\nbool(x) -&gt; bool Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.\n\n\nis_encoder_decoder\nbool(x) -&gt; bool Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.\n\n\noutput_attentions\nbool(x) -&gt; bool Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.\n\n\noutput_hidden_states\nbool(x) -&gt; bool Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.\n\n\noutput_scores\nbool(x) -&gt; bool Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.\n\n\nremove_invalid_values\nbool(x) -&gt; bool Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.\n\n\nreturn_dict\nbool(x) -&gt; bool Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.\n\n\nreturn_dict_in_generate\nbool(x) -&gt; bool Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.\n\n\nsinusoidal_pos_embds\nbool(x) -&gt; bool Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.\n\n\ntf_legacy_loss\nbool(x) -&gt; bool Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.\n\n\ntie_encoder_decoder\nbool(x) -&gt; bool Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.\n\n\ntie_weights_\nbool(x) -&gt; bool Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.\n\n\ntie_word_embeddings\nbool(x) -&gt; bool Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.\n\n\ntorchscript\nbool(x) -&gt; bool Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.\n\n\nuse_bfloat16\nbool(x) -&gt; bool Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.\n\n\nuse_return_dict\nbool(x) -&gt; bool Returns True when the argument x is true, False otherwise. The builtins True and False are the only two instances of the class bool. The class bool is a subclass of the class int, and cannot be subclassed.\n\n\ndict\nattribute_map\ndict() -&gt; new empty dictionary dict(mapping) -&gt; new dictionary initialized from a mapping object's (key, value) pairs dict(iterable) -&gt; new dictionary initialized as if via: d = {} for k, v in iterable: d[k] = v dict(**kwargs) -&gt; new dictionary initialized with the name=value pairs in the keyword argument list. For example: dict(one=1, two=2)\n\n\nid2label\ndict() -&gt; new empty dictionary dict(mapping) -&gt; new dictionary initialized from a mapping object's (key, value) pairs dict(iterable) -&gt; new dictionary initialized as if via: d = {} for k, v in iterable: d[k] = v dict(**kwargs) -&gt; new dictionary initialized with the name=value pairs in the keyword argument list. For example: dict(one=1, two=2)\n\n\nlabel2id\ndict() -&gt; new empty dictionary dict(mapping) -&gt; new dictionary initialized from a mapping object's (key, value) pairs dict(iterable) -&gt; new dictionary initialized as if via: d = {} for k, v in iterable: d[k] = v dict(**kwargs) -&gt; new dictionary initialized with the name=value pairs in the keyword argument list. For example: dict(one=1, two=2)\n\n\npruned_heads\ndict() -&gt; new empty dictionary dict(mapping) -&gt; new dictionary initialized from a mapping object's (key, value) pairs dict(iterable) -&gt; new dictionary initialized as if via: d = {} for k, v in iterable: d[k] = v dict(**kwargs) -&gt; new dictionary initialized with the name=value pairs in the keyword argument list. For example: dict(one=1, two=2)\n\n\nfloat\nattention_dropout\nConvert a string or number to a floating point number, if possible.\n\n\ndiversity_penalty\nConvert a string or number to a floating point number, if possible.\n\n\ndropout\nConvert a string or number to a floating point number, if possible.\n\n\ninitializer_range\nConvert a string or number to a floating point number, if possible.\n\n\nlength_penalty\nConvert a string or number to a floating point number, if possible.\n\n\nqa_dropout\nConvert a string or number to a floating point number, if possible.\n\n\nrepetition_penalty\nConvert a string or number to a floating point number, if possible.\n\n\nseq_classif_dropout\nConvert a string or number to a floating point number, if possible.\n\n\ntemperature\nConvert a string or number to a floating point number, if possible.\n\n\ntop_p\nConvert a string or number to a floating point number, if possible.\n\n\ntypical_p\nConvert a string or number to a floating point number, if possible.\n\n\nint\nchunk_size_feed_forward\nint([x]) -&gt; integer int(x, base=10) -&gt; integer Convert a number or string to an integer, or return 0 if no arguments are given. If x is a number, return x.__int__(). For floating point numbers, this truncates towards zero. If x is not a number or if base is given, then x must be a string, bytes, or bytearray instance representing an integer literal in the given base. The literal can be preceded by '+' or '-' and be surrounded by whitespace. The base defaults to 10. Valid bases are 0 and 2-36. Base 0 means to interpret the base from the string as an integer literal. &gt;&gt;&gt; int('0b100', base=0) 4\n\n\ndim\nint([x]) -&gt; integer int(x, base=10) -&gt; integer Convert a number or string to an integer, or return 0 if no arguments are given. If x is a number, return x.__int__(). For floating point numbers, this truncates towards zero. If x is not a number or if base is given, then x must be a string, bytes, or bytearray instance representing an integer literal in the given base. The literal can be preceded by '+' or '-' and be surrounded by whitespace. The base defaults to 10. Valid bases are 0 and 2-36. Base 0 means to interpret the base from the string as an integer literal. &gt;&gt;&gt; int('0b100', base=0) 4\n\n\nencoder_no_repeat_ngram_size\nint([x]) -&gt; integer int(x, base=10) -&gt; integer Convert a number or string to an integer, or return 0 if no arguments are given. If x is a number, return x.__int__(). For floating point numbers, this truncates towards zero. If x is not a number or if base is given, then x must be a string, bytes, or bytearray instance representing an integer literal in the given base. The literal can be preceded by '+' or '-' and be surrounded by whitespace. The base defaults to 10. Valid bases are 0 and 2-36. Base 0 means to interpret the base from the string as an integer literal. &gt;&gt;&gt; int('0b100', base=0) 4\n\n\nhidden_dim\nint([x]) -&gt; integer int(x, base=10) -&gt; integer Convert a number or string to an integer, or return 0 if no arguments are given. If x is a number, return x.__int__(). For floating point numbers, this truncates towards zero. If x is not a number or if base is given, then x must be a string, bytes, or bytearray instance representing an integer literal in the given base. The literal can be preceded by '+' or '-' and be surrounded by whitespace. The base defaults to 10. Valid bases are 0 and 2-36. Base 0 means to interpret the base from the string as an integer literal. &gt;&gt;&gt; int('0b100', base=0) 4\n\n\nmax_length\nint([x]) -&gt; integer int(x, base=10) -&gt; integer Convert a number or string to an integer, or return 0 if no arguments are given. If x is a number, return x.__int__(). For floating point numbers, this truncates towards zero. If x is not a number or if base is given, then x must be a string, bytes, or bytearray instance representing an integer literal in the given base. The literal can be preceded by '+' or '-' and be surrounded by whitespace. The base defaults to 10. Valid bases are 0 and 2-36. Base 0 means to interpret the base from the string as an integer literal. &gt;&gt;&gt; int('0b100', base=0) 4\n\n\nmax_position_embeddings\nint([x]) -&gt; integer int(x, base=10) -&gt; integer Convert a number or string to an integer, or return 0 if no arguments are given. If x is a number, return x.__int__(). For floating point numbers, this truncates towards zero. If x is not a number or if base is given, then x must be a string, bytes, or bytearray instance representing an integer literal in the given base. The literal can be preceded by '+' or '-' and be surrounded by whitespace. The base defaults to 10. Valid bases are 0 and 2-36. Base 0 means to interpret the base from the string as an integer literal. &gt;&gt;&gt; int('0b100', base=0) 4\n\n\nmin_length\nint([x]) -&gt; integer int(x, base=10) -&gt; integer Convert a number or string to an integer, or return 0 if no arguments are given. If x is a number, return x.__int__(). For floating point numbers, this truncates towards zero. If x is not a number or if base is given, then x must be a string, bytes, or bytearray instance representing an integer literal in the given base. The literal can be preceded by '+' or '-' and be surrounded by whitespace. The base defaults to 10. Valid bases are 0 and 2-36. Base 0 means to interpret the base from the string as an integer literal. &gt;&gt;&gt; int('0b100', base=0) 4\n\n\nn_heads\nint([x]) -&gt; integer int(x, base=10) -&gt; integer Convert a number or string to an integer, or return 0 if no arguments are given. If x is a number, return x.__int__(). For floating point numbers, this truncates towards zero. If x is not a number or if base is given, then x must be a string, bytes, or bytearray instance representing an integer literal in the given base. The literal can be preceded by '+' or '-' and be surrounded by whitespace. The base defaults to 10. Valid bases are 0 and 2-36. Base 0 means to interpret the base from the string as an integer literal. &gt;&gt;&gt; int('0b100', base=0) 4\n\n\nn_layers\nint([x]) -&gt; integer int(x, base=10) -&gt; integer Convert a number or string to an integer, or return 0 if no arguments are given. If x is a number, return x.__int__(). For floating point numbers, this truncates towards zero. If x is not a number or if base is given, then x must be a string, bytes, or bytearray instance representing an integer literal in the given base. The literal can be preceded by '+' or '-' and be surrounded by whitespace. The base defaults to 10. Valid bases are 0 and 2-36. Base 0 means to interpret the base from the string as an integer literal. &gt;&gt;&gt; int('0b100', base=0) 4\n\n\nno_repeat_ngram_size\nint([x]) -&gt; integer int(x, base=10) -&gt; integer Convert a number or string to an integer, or return 0 if no arguments are given. If x is a number, return x.__int__(). For floating point numbers, this truncates towards zero. If x is not a number or if base is given, then x must be a string, bytes, or bytearray instance representing an integer literal in the given base. The literal can be preceded by '+' or '-' and be surrounded by whitespace. The base defaults to 10. Valid bases are 0 and 2-36. Base 0 means to interpret the base from the string as an integer literal. &gt;&gt;&gt; int('0b100', base=0) 4\n\n\nnum_beam_groups\nint([x]) -&gt; integer int(x, base=10) -&gt; integer Convert a number or string to an integer, or return 0 if no arguments are given. If x is a number, return x.__int__(). For floating point numbers, this truncates towards zero. If x is not a number or if base is given, then x must be a string, bytes, or bytearray instance representing an integer literal in the given base. The literal can be preceded by '+' or '-' and be surrounded by whitespace. The base defaults to 10. Valid bases are 0 and 2-36. Base 0 means to interpret the base from the string as an integer literal. &gt;&gt;&gt; int('0b100', base=0) 4\n\n\nnum_beams\nint([x]) -&gt; integer int(x, base=10) -&gt; integer Convert a number or string to an integer, or return 0 if no arguments are given. If x is a number, return x.__int__(). For floating point numbers, this truncates towards zero. If x is not a number or if base is given, then x must be a string, bytes, or bytearray instance representing an integer literal in the given base. The literal can be preceded by '+' or '-' and be surrounded by whitespace. The base defaults to 10. Valid bases are 0 and 2-36. Base 0 means to interpret the base from the string as an integer literal. &gt;&gt;&gt; int('0b100', base=0) 4\n\n\nnum_labels\nint([x]) -&gt; integer int(x, base=10) -&gt; integer Convert a number or string to an integer, or return 0 if no arguments are given. If x is a number, return x.__int__(). For floating point numbers, this truncates towards zero. If x is not a number or if base is given, then x must be a string, bytes, or bytearray instance representing an integer literal in the given base. The literal can be preceded by '+' or '-' and be surrounded by whitespace. The base defaults to 10. Valid bases are 0 and 2-36. Base 0 means to interpret the base from the string as an integer literal. &gt;&gt;&gt; int('0b100', base=0) 4\n\n\nnum_return_sequences\nint([x]) -&gt; integer int(x, base=10) -&gt; integer Convert a number or string to an integer, or return 0 if no arguments are given. If x is a number, return x.__int__(). For floating point numbers, this truncates towards zero. If x is not a number or if base is given, then x must be a string, bytes, or bytearray instance representing an integer literal in the given base. The literal can be preceded by '+' or '-' and be surrounded by whitespace. The base defaults to 10. Valid bases are 0 and 2-36. Base 0 means to interpret the base from the string as an integer literal. &gt;&gt;&gt; int('0b100', base=0) 4\n\n\npad_token_id\nint([x]) -&gt; integer int(x, base=10) -&gt; integer Convert a number or string to an integer, or return 0 if no arguments are given. If x is a number, return x.__int__(). For floating point numbers, this truncates towards zero. If x is not a number or if base is given, then x must be a string, bytes, or bytearray instance representing an integer literal in the given base. The literal can be preceded by '+' or '-' and be surrounded by whitespace. The base defaults to 10. Valid bases are 0 and 2-36. Base 0 means to interpret the base from the string as an integer literal. &gt;&gt;&gt; int('0b100', base=0) 4\n\n\ntop_k\nint([x]) -&gt; integer int(x, base=10) -&gt; integer Convert a number or string to an integer, or return 0 if no arguments are given. If x is a number, return x.__int__(). For floating point numbers, this truncates towards zero. If x is not a number or if base is given, then x must be a string, bytes, or bytearray instance representing an integer literal in the given base. The literal can be preceded by '+' or '-' and be surrounded by whitespace. The base defaults to 10. Valid bases are 0 and 2-36. Base 0 means to interpret the base from the string as an integer literal. &gt;&gt;&gt; int('0b100', base=0) 4\n\n\nvocab_size\nint([x]) -&gt; integer int(x, base=10) -&gt; integer Convert a number or string to an integer, or return 0 if no arguments are given. If x is a number, return x.__int__(). For floating point numbers, this truncates towards zero. If x is not a number or if base is given, then x must be a string, bytes, or bytearray instance representing an integer literal in the given base. The literal can be preceded by '+' or '-' and be surrounded by whitespace. The base defaults to 10. Valid bases are 0 and 2-36. Base 0 means to interpret the base from the string as an integer literal. &gt;&gt;&gt; int('0b100', base=0) 4\n\n\nlist\narchitectures\nBuilt-in mutable sequence. If no argument is given, the constructor creates a new empty list. The argument must be an iterable if specified.\n\n\nmethod\ndict_torch_dtype_to_str\nChecks whether the passed dictionary and its nested dicts have a *torch_dtype* key and if it's not None, converts torch.dtype to a string of just the type. For example, `torch.float32` get converted into *\"float32\"* string, which can then be stored in the json format.\n\n\nfrom_dict\nInstantiates a [`PretrainedConfig`] from a Python dictionary of parameters. Args: config_dict (`Dict[str, Any]`): Dictionary that will be used to instantiate the configuration object. Such a dictionary can be retrieved from a pretrained checkpoint by leveraging the [`~PretrainedConfig.get_config_dict`] method. kwargs (`Dict[str, Any]`): Additional parameters from which to initialize the configuration object. Returns: [`PretrainedConfig`]: The configuration object instantiated from those parameters.\n\n\nfrom_json_file\nInstantiates a [`PretrainedConfig`] from the path to a JSON file of parameters. Args: json_file (`str` or `os.PathLike`): Path to the JSON file containing the parameters. Returns: [`PretrainedConfig`]: The configuration object instantiated from that JSON file.\n\n\nfrom_pretrained\nInstantiate a [`PretrainedConfig`] (or a derived class) from a pretrained model configuration. Args: pretrained_model_name_or_path (`str` or `os.PathLike`): This can be either: - a string, the *model id* of a pretrained model configuration hosted inside a model repo on huggingface.co. - a path to a *directory* containing a configuration file saved using the [`~PretrainedConfig.save_pretrained`] method, e.g., `./my_model_directory/`. - a path or url to a saved configuration JSON *file*, e.g., `./my_model_directory/configuration.json`. cache_dir (`str` or `os.PathLike`, *optional*): Path to a directory in which a downloaded pretrained model configuration should be cached if the standard cache should not be used. force_download (`bool`, *optional*, defaults to `False`): Whether or not to force to (re-)download the configuration files and override the cached versions if they exist. resume_download: Deprecated and ignored. All downloads are now resumed by default when possible. Will be removed in v5 of Transformers. proxies (`Dict[str, str]`, *optional*): A dictionary of proxy servers to use by protocol or endpoint, e.g., `{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.` The proxies are used on each request. token (`str` or `bool`, *optional*): The token to use as HTTP bearer authorization for remote files. If `True`, or not specified, will use the token generated when running `huggingface-cli login` (stored in `~/.huggingface`). revision (`str`, *optional*, defaults to `\"main\"`): The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any identifier allowed by git.\n\nTo test a pull request you made on the Hub, you can pass `revision=\"refs/pr/\"`.\n\nreturn_unused_kwargs (`bool`, *optional*, defaults to `False`): If `False`, then this function returns just the final configuration object. If `True`, then this functions returns a `Tuple(config, unused_kwargs)` where *unused_kwargs* is a dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the part of `kwargs` which has not been used to update `config` and is otherwise ignored. subfolder (`str`, *optional*, defaults to `\"\"`): In case the relevant files are located inside a subfolder of the model repo on huggingface.co, you can specify the folder name here. kwargs (`Dict[str, Any]`, *optional*): The values in kwargs of any keys which are configuration attributes will be used to override the loaded values. Behavior concerning key/value pairs whose keys are *not* configuration attributes is controlled by the `return_unused_kwargs` keyword parameter. Returns: [`PretrainedConfig`]: The configuration object instantiated from this pretrained model. Examples: ```python # We can't instantiate directly the base class *PretrainedConfig* so let's show the examples on a # derived class: BertConfig config = BertConfig.from_pretrained( \"google-bert/bert-base-uncased\" ) # Download configuration from huggingface.co and cache. config = BertConfig.from_pretrained( \"./test/saved_model/\" ) # E.g. config (or model) was saved using *save_pretrained('./test/saved_model/')* config = BertConfig.from_pretrained(\"./test/saved_model/my_configuration.json\") config = BertConfig.from_pretrained(\"google-bert/bert-base-uncased\", output_attentions=True, foo=False) assert config.output_attentions == True config, unused_kwargs = BertConfig.from_pretrained( \"google-bert/bert-base-uncased\", output_attentions=True, foo=False, return_unused_kwargs=True ) assert config.output_attentions == True assert unused_kwargs == {\"foo\": False} ```\n\n\nget_config_dict\nFrom a `pretrained_model_name_or_path`, resolve to a dictionary of parameters, to be used for instantiating a [`PretrainedConfig`] using `from_dict`. Parameters: pretrained_model_name_or_path (`str` or `os.PathLike`): The identifier of the pre-trained checkpoint from which we want the dictionary of parameters. Returns: `Tuple[Dict, Dict]`: The dictionary(ies) that will be used to instantiate the configuration object.\n\n\nget_text_config\nReturns the config that is meant to be used with text IO. On most models, it is the original config instance itself. On specific composite models, it is under a set of valid names. If `decoder` is set to `True`, then only search for decoder config names.\n\n\npush_to_hub\nUpload the configuration file to the 🤗 Model Hub. Parameters: repo_id (`str`): The name of the repository you want to push your config to. It should contain your organization name when pushing to a given organization. use_temp_dir (`bool`, *optional*): Whether or not to use a temporary directory to store the files saved before they are pushed to the Hub. Will default to `True` if there is no directory named like `repo_id`, `False` otherwise. commit_message (`str`, *optional*): Message to commit while pushing. Will default to `\"Upload config\"`. private (`bool`, *optional*): Whether or not the repository created should be private. token (`bool` or `str`, *optional*): The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated when running `huggingface-cli login` (stored in `~/.huggingface`). Will default to `True` if `repo_url` is not specified. max_shard_size (`int` or `str`, *optional*, defaults to `\"5GB\"`): Only applicable for models. The maximum size for a checkpoint before being sharded. Checkpoints shard will then be each of size lower than this size. If expressed as a string, needs to be digits followed by a unit (like `\"5MB\"`). We default it to `\"5GB\"` so that users can easily load models on free-tier Google Colab instances without any CPU OOM issues. create_pr (`bool`, *optional*, defaults to `False`): Whether or not to create a PR with the uploaded files or directly commit. safe_serialization (`bool`, *optional*, defaults to `True`): Whether or not to convert the model weights in safetensors format for safer serialization. revision (`str`, *optional*): Branch to push the uploaded files to. commit_description (`str`, *optional*): The description of the commit that will be created tags (`List[str]`, *optional*): List of tags to push on the Hub. Examples: ```python from transformers import AutoConfig config = AutoConfig.from_pretrained(\"google-bert/bert-base-cased\") # Push the config to your namespace with the name \"my-finetuned-bert\". config.push_to_hub(\"my-finetuned-bert\") # Push the config to an organization with the name \"my-finetuned-bert\". config.push_to_hub(\"huggingface/my-finetuned-bert\") ```\n\n\nregister_for_auto_class\nRegister this class with a given auto class. This should only be used for custom configurations as the ones in the library are already mapped with `AutoConfig`.\n\nThis API is experimental and may have some slight breaking changes in the next releases.\n\nArgs: auto_class (`str` or `type`, *optional*, defaults to `\"AutoConfig\"`): The auto class to register this new configuration with.\n\n\nsave_pretrained\nSave a configuration object to the directory `save_directory`, so that it can be re-loaded using the [`~PretrainedConfig.from_pretrained`] class method. Args: save_directory (`str` or `os.PathLike`): Directory where the configuration JSON file will be saved (will be created if it does not exist). push_to_hub (`bool`, *optional*, defaults to `False`): Whether or not to push your model to the Hugging Face model hub after saving it. You can specify the repository you want to push to with `repo_id` (will default to the name of `save_directory` in your namespace). kwargs (`Dict[str, Any]`, *optional*): Additional key word arguments passed along to the [`~utils.PushToHubMixin.push_to_hub`] method.\n\n\nto_dict\nSerializes this instance to a Python dictionary. Returns: `Dict[str, Any]`: Dictionary of all the attributes that make up this configuration instance.\n\n\nto_diff_dict\nRemoves all attributes from config which correspond to the default config attributes for better readability and serializes to a Python dictionary. Returns: `Dict[str, Any]`: Dictionary of all the attributes that make up this configuration instance,\n\n\nto_json_file\nSave this instance to a JSON file. Args: json_file_path (`str` or `os.PathLike`): Path to the JSON file in which this configuration instance's parameters will be saved. use_diff (`bool`, *optional*, defaults to `True`): If set to `True`, only the difference between the config instance and the default `PretrainedConfig()` is serialized to JSON file.\n\n\nto_json_string\nSerializes this instance to a JSON string. Args: use_diff (`bool`, *optional*, defaults to `True`): If set to `True`, only the difference between the config instance and the default `PretrainedConfig()` is serialized to JSON string. Returns: `str`: String containing all the attributes that make up this configuration instance in JSON format.\n\n\nupdate\nUpdates attributes of this class with attributes from `config_dict`. Args: config_dict (`Dict[str, Any]`): Dictionary of attributes that should be updated for this class.\n\n\nupdate_from_string\nUpdates attributes of this class with attributes from `update_str`. The expected format is ints, floats and strings as is, and for booleans use `true` or `false`. For example: \"n_embd=10,resid_pdrop=0.2,scale_attn_weights=false,summary_type=cls_index\" The keys to change have to already exist in the config object. Args: update_str (`str`): String with attributes that should be updated for this class.\n\n\nstr\nactivation\nstr(object='') -&gt; str str(bytes_or_buffer[, encoding[, errors]]) -&gt; str Create a new string object from the given object. If encoding or errors is specified, then the object must expose a data buffer that will be decoded using the given encoding and error handler. Otherwise, returns the result of object.__str__() (if defined) or repr(object). encoding defaults to sys.getdefaultencoding(). errors defaults to 'strict'.\n\n\nmodel_type\nstr(object='') -&gt; str str(bytes_or_buffer[, encoding[, errors]]) -&gt; str Create a new string object from the given object. If encoding or errors is specified, then the object must expose a data buffer that will be decoded using the given encoding and error handler. Otherwise, returns the result of object.__str__() (if defined) or repr(object). encoding defaults to sys.getdefaultencoding(). errors defaults to 'strict'.\n\n\nname_or_path\nstr(object='') -&gt; str str(bytes_or_buffer[, encoding[, errors]]) -&gt; str Create a new string object from the given object. If encoding or errors is specified, then the object must expose a data buffer that will be decoded using the given encoding and error handler. Otherwise, returns the result of object.__str__() (if defined) or repr(object). encoding defaults to sys.getdefaultencoding(). errors defaults to 'strict'.\n\n\ntransformers_version\nstr(object='') -&gt; str str(bytes_or_buffer[, encoding[, errors]]) -&gt; str Create a new string object from the given object. If encoding or errors is specified, then the object must expose a data buffer that will be decoded using the given encoding and error handler. Otherwise, returns the result of object.__str__() (if defined) or repr(object). encoding defaults to sys.getdefaultencoding(). errors defaults to 'strict'.\n\n\n\n\n\n설정값변경\n\nconfig.max_position_embeddings = 4096\nconfig.num_labels = 2 # 이건 잘 설정되어있어서.. \n\n설정값으로 모델불러오기\n\nmodel1_large = transformers.AutoModelForSequenceClassification.from_config(config)\n\n모델사용\n\nmodel1_large(\n    tokenizer(d['posts'],padding=True,return_tensors=\"pt\")['input_ids']\n)\n\nSequenceClassifierOutput(loss=None, logits=tensor([[ 0.1689, -0.3778],\n        [ 0.0231, -0.3971],\n        [-0.2340, -0.2929]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)\n\n\n#\n# 예제4 – sms_spam\n\nsms_spam = datasets.load_dataset('sms_spam')['train'].train_test_split(test_size=0.2, seed=42)\nsms_spam\n\nDatasetDict({\n    train: Dataset({\n        features: ['sms', 'label'],\n        num_rows: 4459\n    })\n    test: Dataset({\n        features: ['sms', 'label'],\n        num_rows: 1115\n    })\n})\n\n\n\nd = sms_spam['train'].select(range(3))\nd\n\nDataset({\n    features: ['sms', 'label'],\n    num_rows: 3\n})\n\n\n(풀이)\n\nmodel1(\n    tokenizer(d['sms'],padding=True,return_tensors=\"pt\")['input_ids']\n)\n\nSequenceClassifierOutput(loss=None, logits=tensor([[-0.0414, -0.0771],\n        [-0.0181,  0.0315],\n        [ 0.0169,  0.0101]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)\n\n\n#"
  },
  {
    "objectID": "공부/HF/2024-11-08-(강의)-Model.html#b.-이미지",
    "href": "공부/HF/2024-11-08-(강의)-Model.html#b.-이미지",
    "title": "(강의) Model",
    "section": "B. 이미지",
    "text": "B. 이미지\n\nmodel2 = transformers.AutoModelForImageClassification.from_pretrained(\n    \"google/vit-base-patch16-224-in21k\",\n    num_labels=3 # 그냥 대충 3이라고 했음.. 별 이유는 없음\n)\n\nSome weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n\n# 예제1 – food101\n\nd = datasets.load_dataset(\"food101\", split=\"train[:3]\")\nd\n\nDataset({\n    features: ['image', 'label'],\n    num_rows: 3\n})\n\n\n(예비학습) – torchvision.transforms 에서 제공하는 기능들은 배치처리가 가능한가?\n\ntotensor = torchvision.transforms.ToTensor()\n\n\ntotensor(d['image'][0]) # 하나의 obs는 처리가능 \n\ntensor([[[0.1216, 0.1137, 0.1098,  ..., 0.0039, 0.0039, 0.0000],\n         [0.1255, 0.1216, 0.1176,  ..., 0.0039, 0.0039, 0.0000],\n         [0.1294, 0.1255, 0.1255,  ..., 0.0039, 0.0000, 0.0000],\n         ...,\n         [0.2588, 0.2745, 0.2863,  ..., 0.3765, 0.3882, 0.3922],\n         [0.2353, 0.2471, 0.2667,  ..., 0.3373, 0.3373, 0.3373],\n         [0.2235, 0.2275, 0.2471,  ..., 0.3333, 0.3176, 0.3059]],\n\n        [[0.1373, 0.1294, 0.1255,  ..., 0.1020, 0.1020, 0.0980],\n         [0.1412, 0.1373, 0.1333,  ..., 0.1020, 0.1020, 0.0980],\n         [0.1451, 0.1412, 0.1412,  ..., 0.1020, 0.0980, 0.0980],\n         ...,\n         [0.2471, 0.2627, 0.2745,  ..., 0.3647, 0.3765, 0.3882],\n         [0.2235, 0.2353, 0.2549,  ..., 0.3255, 0.3333, 0.3333],\n         [0.2118, 0.2157, 0.2353,  ..., 0.3216, 0.3137, 0.3020]],\n\n        [[0.1412, 0.1333, 0.1294,  ..., 0.0902, 0.0902, 0.0863],\n         [0.1451, 0.1412, 0.1451,  ..., 0.0902, 0.0902, 0.0863],\n         [0.1490, 0.1451, 0.1529,  ..., 0.0902, 0.0863, 0.0863],\n         ...,\n         [0.1725, 0.1882, 0.2000,  ..., 0.2431, 0.2549, 0.2667],\n         [0.1490, 0.1608, 0.1804,  ..., 0.2039, 0.2118, 0.2118],\n         [0.1373, 0.1412, 0.1608,  ..., 0.2000, 0.1922, 0.1804]]])\n\n\n\ntotensor(d['image']) # 배치는 처리불가능\n\nTypeError: pic should be PIL Image or ndarray. Got &lt;class 'list'&gt;\n\n\n(풀이)\n\ncompose = torchvision.transforms.Compose([\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Resize((224,224)) \n])\n\n\ncompose(d['image'][0])\n\ntensor([[[0.1223, 0.1166, 0.1159,  ..., 0.0054, 0.0041, 0.0014],\n         [0.1314, 0.1290, 0.1266,  ..., 0.0037, 0.0024, 0.0033],\n         [0.1425, 0.1380, 0.1339,  ..., 0.0040, 0.0026, 0.0009],\n         ...,\n         [0.2242, 0.2150, 0.2476,  ..., 0.3578, 0.3704, 0.3554],\n         [0.2610, 0.2583, 0.2324,  ..., 0.3488, 0.3618, 0.3625],\n         [0.2408, 0.2613, 0.2533,  ..., 0.3370, 0.3427, 0.3388]],\n\n        [[0.1380, 0.1323, 0.1316,  ..., 0.1040, 0.1022, 0.0995],\n         [0.1471, 0.1447, 0.1423,  ..., 0.1018, 0.0985, 0.0935],\n         [0.1582, 0.1537, 0.1495,  ..., 0.1001, 0.0921, 0.0865],\n         ...,\n         [0.2155, 0.2087, 0.2431,  ..., 0.3306, 0.3478, 0.3367],\n         [0.2492, 0.2468, 0.2231,  ..., 0.3224, 0.3469, 0.3519],\n         [0.2290, 0.2496, 0.2419,  ..., 0.3107, 0.3303, 0.3340]],\n\n        [[0.1421, 0.1409, 0.1434,  ..., 0.0922, 0.0904, 0.0877],\n         [0.1565, 0.1559, 0.1541,  ..., 0.0900, 0.0874, 0.0844],\n         [0.1700, 0.1654, 0.1614,  ..., 0.0890, 0.0832, 0.0786],\n         ...,\n         [0.1395, 0.1314, 0.1649,  ..., 0.2197, 0.2347, 0.2217],\n         [0.1747, 0.1722, 0.1474,  ..., 0.2076, 0.2271, 0.2307],\n         [0.1545, 0.1750, 0.1672,  ..., 0.1958, 0.2097, 0.2124]]])\n\n\n\nmodel2(\n    pixel_values = torch.stack(list(map(compose,d['image']))),\n    labels = torch.tensor([0,1,0]) # 그냥 확인없이 아무거나 넣음\n)\n\nImageClassifierOutput(loss=tensor(1.1654, grad_fn=&lt;NllLossBackward0&gt;), logits=tensor([[-0.0286, -0.1753, -0.0153],\n        [ 0.0542, -0.2082,  0.0403],\n        [-0.0875, -0.1001,  0.1060]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)\n\n\n#\n# 예제2\n\nbeans = datasets.load_dataset('beans')\nd = beans['train'].select(range(3))\nd\n\nDataset({\n    features: ['image_file_path', 'image', 'labels'],\n    num_rows: 3\n})\n\n\n(풀이)\n\nmodel2(\n    torch.stack(list(map(compose,d['image'])))\n)\n\nImageClassifierOutput(loss=None, logits=tensor([[-0.2100, -0.1126, -0.1297],\n        [-0.1711, -0.0252, -0.0553],\n        [-0.1465,  0.0183, -0.0034]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)\n\n\n#"
  },
  {
    "objectID": "공부/HF/2024-11-08-(강의)-Model.html#c.-동영상",
    "href": "공부/HF/2024-11-08-(강의)-Model.html#c.-동영상",
    "title": "(강의) Model",
    "section": "C. 동영상",
    "text": "C. 동영상\n\nmodel3 = transformers.VideoMAEForVideoClassification.from_pretrained(\n    \"MCG-NJU/videomae-base\",\n)\n\nSome weights of VideoMAEForVideoClassification were not initialized from the model checkpoint at MCG-NJU/videomae-base and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n\n# 예제1 – UCF101_subset\n\nfile_path = huggingface_hub.hf_hub_download(\n    repo_id=\"sayakpaul/ucf101-subset\",\n    filename=\"UCF101_subset.tar.gz\",\n    repo_type=\"dataset\"\n)\n# file_path는 다운로드한 압축파일이 존재하는 경로와 파일명이 string으로 저장되어있음.\nwith tarfile.open(file_path) as t:\n     t.extractall(\"./data\") # 여기에서 \".\"은 현재폴더라는 의미\n\n\nmp.tree(\"./data/UCF101_subset\")\n\n├── test\n│   ├── ApplyEyeMakeup\n│   │   ├── UCF101\n│   │   ├── v_ApplyEyeMakeup_g03_c01.avi\n│   │   └── ...\n│   │   └── v_ApplyEyeMakeup_g23_c06.avi\n│   ├── ApplyLipstick\n│   │   ├── UCF101\n│   │   ├── v_ApplyLipstick_g14_c01.avi\n│   │   └── ...\n│   │   └── v_ApplyLipstick_g16_c04.avi\n│   └── ...\n│   └── BenchPress\n│       ├── UCF101\n│       ├── v_BenchPress_g05_c02.avi\n│       └── ...\n│       └── v_BenchPress_g25_c06.avi\n├── train\n│   ├── ApplyEyeMakeup\n│   │   ├── UCF101\n│   │   ├── v_ApplyEyeMakeup_g02_c03.avi\n│   │   └── ...\n│   │   └── v_ApplyEyeMakeup_g25_c07.avi\n│   ├── ApplyLipstick\n│   │   ├── UCF101\n│   │   ├── v_ApplyLipstick_g01_c02.avi\n│   │   └── ...\n│   │   └── v_ApplyLipstick_g24_c05.avi\n│   └── ...\n│   └── BenchPress\n│       ├── UCF101\n│       ├── v_BenchPress_g01_c05.avi\n│       └── ...\n│       └── v_BenchPress_g24_c05.avi\n└── val\n    ├── ApplyEyeMakeup\n    │   ├── UCF101\n    │   ├── v_ApplyEyeMakeup_g01_c01.avi\n    │   ├── v_ApplyEyeMakeup_g14_c05.avi\n    │   └── v_ApplyEyeMakeup_g20_c04.avi\n    ├── ApplyLipstick\n    │   ├── UCF101\n    │   ├── v_ApplyLipstick_g10_c04.avi\n    │   ├── v_ApplyLipstick_g20_c04.avi\n    │   └── v_ApplyLipstick_g25_c02.avi\n    └── ...\n    └── BenchPress\n        ├── UCF101\n        ├── v_BenchPress_g11_c05.avi\n        ├── v_BenchPress_g17_c02.avi\n        └── v_BenchPress_g17_c06.avi\n\n\n\nvideo_path = \"./data/UCF101_subset/test/BenchPress/v_BenchPress_g05_c02.avi\"\nvideo = pytorchvideo.data.encoded_video.EncodedVideo.from_path(video_path).get_clip(0, float('inf'))['video']\nvideo.shape\n\ntorch.Size([3, 67, 240, 320])\n\n\n(풀이)\n\nvideo.permute(1,0,2,3)[:16,:,:224,:224].shape\n\ntorch.Size([16, 3, 224, 224])\n\n\n\nmodel3(\n    #video.permute(1,0,2,3)[:16,:,:224,:224].reshape(1,16,3,224,224)\n    #video.permute(1,0,2,3)[:16,:,:224,:224].unsqueeze(0)\n    torch.stack([video.permute(1,0,2,3)[:16,:,:224,:224]])\n)\n\nImageClassifierOutput(loss=None, logits=tensor([[-0.1593, -0.2056]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)"
  },
  {
    "objectID": "공부/HF/2024-11-03-(강의) with의사용.html#a.-기본사용",
    "href": "공부/HF/2024-11-03-(강의) with의사용.html#a.-기본사용",
    "title": "(강의) with의 사용",
    "section": "A. 기본사용",
    "text": "A. 기본사용\n- 아래와 같이 with를 사용한다. 여기에서 컨텍스트_관리_객체란 __enter__ 와 __exit__을 포함하는 어떠한 오브젝트이다.\nwith 컨텍스트_관리_객체:\n    블라블라~\n    야디야디~\n# 예제1 – 기본예제\n- context manager\n\nclass Dummy: \n    def __enter__(self):\n        print(\"enter\")\n    def __exit__(self,*args): # *args는 에러처리 관련된 기본변수들\n        print(\"exit\")\n\n- 아래의 2개는 같은코드임..\n\nd = Dummy()\nd.__enter__()\nprint('context')\nd.__exit__()\n\nenter\ncontext\nexit\n\n\n\nd = Dummy()\nwith d:\n    print(\"context\")\n\nenter\ncontext\nexit\n\n\n#\n- with 뒤에 올수 있는 오브젝트는 __enter__ 와 __exit__ 을 포함해야한다.\n\nlst = [1,2,3]\nwith lst:\n    pass\n\nTypeError: 'list' object does not support the context manager protocol\n\n\n\nclass Dummy: \n    def __enter__(self):\n        pass\n    def __exit__(self,*args): # *args는 에러처리 관련된 기본변수들\n        pass\nwith Dummy():\n    pass\n\n# 예제2 – 타이머\n\nclass Timer:\n    def __enter__(self):\n        self.start = time.time()\n    def __exit__(self,*args):\n        self.end = time.time()\n        print(f'{self.end- self.start:.4f} 초 걸림')\n\n\nwith Timer():\n    np.random.randn(10000,10000) + 30\n\n1.5234 초 걸림\n\n\n#\n# 예제3\n\nclass 미분꼬리표추적금지:\n    def __enter__(self):\n        torch.set_grad_enabled(False)\n    def __exit__(self,*args):\n        torch.set_grad_enabled(True)\n\n\na = torch.tensor([1.0,2,3],requires_grad=True)\nb = a*10\na,b\n\n(tensor([1., 2., 3.], requires_grad=True),\n tensor([10., 20., 30.], grad_fn=&lt;MulBackward0&gt;))\n\n\n\nwith 미분꼬리표추적금지():\n    a = torch.tensor([1.0,2,3],requires_grad=True)\n    b = a*10\na,b\n\n(tensor([1., 2., 3.], requires_grad=True), tensor([10., 20., 30.]))\n\n\n\na = torch.tensor([1.0,2,3],requires_grad=True)\nb = a*10\na,b\n\n(tensor([1., 2., 3.], requires_grad=True),\n tensor([10., 20., 30.], grad_fn=&lt;MulBackward0&gt;))\n\n\n#\n# 예제4\n아래의 코드를 모델을 활용하여 로짓을 계산하라.\n\nmodel = transformers.AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert/distilbert-base-uncased\", num_labels=2\n)\nmodel_input = {\n    'input_ids': torch.tensor([[101, 2023, 3185, 2003, 6659, 2021, 2009, 2038, 2070, 2204, 3896, 1012, 102]]),\n    'attention_mask': torch.tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n    'labels': torch.tensor([0])\n}\n\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n\n(풀이)\n\nmodel(**model_input)\n\nSequenceClassifierOutput(loss=tensor(0.6349, grad_fn=&lt;NllLossBackward0&gt;), logits=tensor([[ 0.0272, -0.0929]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)\n\n\n\nlogits = model(**model_input).logits\nlogits\n\ntensor([[ 0.0272, -0.0929]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n(풀이2)\n그런데 이런코드도 많이 보셨을거에요..\n\nwith torch.no_grad():\n    logits = model(**model_input).logits\nlogits\n\ntensor([[ 0.0272, -0.0929]])\n\n\nref: https://huggingface.co/docs/transformers/tasks/sequence_classification\n- 코드를 좀 뜯어봅시다..\n\ncontext_manager = torch.no_grad()\n\n\ncontext_manager.__enter__??\n\nSignature: context_manager.__enter__() -&gt; None\nDocstring: &lt;no docstring&gt;\nSource:   \n    def __enter__(self) -&gt; None:\n        self.prev = torch.is_grad_enabled()\n        torch.set_grad_enabled(False)\nFile:      ~/anaconda3/envs/hf/lib/python3.12/site-packages/torch/autograd/grad_mode.py\nType:      method\n\n\n\ncontext_manager.__exit__??\n\nSignature: context_manager.__exit__(exc_type: Any, exc_value: Any, traceback: Any) -&gt; None\nDocstring: &lt;no docstring&gt;\nSource:   \n    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -&gt; None:\n        torch.set_grad_enabled(self.prev)\nFile:      ~/anaconda3/envs/hf/lib/python3.12/site-packages/torch/autograd/grad_mode.py\nType:      method\n\n\n#"
  },
  {
    "objectID": "공부/HF/2024-11-03-(강의) with의사용.html#b.-약간고급사용",
    "href": "공부/HF/2024-11-03-(강의) with의사용.html#b.-약간고급사용",
    "title": "(강의) with의 사용",
    "section": "B. 약간고급사용",
    "text": "B. 약간고급사용\n# 예비학습\n- 기본플랏\n\nplt.plot([1,2,3,4],'--o')\n\n\n\n\n\n\n\n\n- 크기를 (10,3)으로 조정\n\nplt.rcParams['figure.figsize'] = (10, 3)\nplt.plot([1,2,3,4],'--o',)\n\n\n\n\n\n\n\n\n- 한번 뒤틀린 설정이 그대로 있음\n\nplt.plot([4,3,2,1],'--o') # 다른그림도 이렇게 보임\n\n\n\n\n\n\n\n\n- 설정을 원래대로\n\nplt.rcdefaults()\n\n\nplt.plot([4,3,2,1],'--o') # 다른그림도 이렇게 보임\n\n\n\n\n\n\n\n\n#\n# 예제4 – 크기조정\n\nclass FigureSizeContext:\n    def __enter__(self):\n        def resize(w,h):\n            plt.rcParams['figure.figsize'] = (w,h)\n        return resize\n    def __exit__(self,*args):\n        plt.rcdefaults()\n\n- 사용예시1\n\ncontext_manager = FigureSizeContext()\nresize = context_manager.__enter__()\nresize(3,3)\nplt.plot([1,2,3],'--o')\ncontext_manager.__exit__()\n\n\n\n\n\n\n\n\n\nplt.plot([1,2,2],'--o')\n\n\n\n\n\n\n\n\n- 사용예시2\n\ncontext_manager = FigureSizeContext()\nwith context_manager as resize:\n    resize(3,3)\n    plt.plot([1,2,3],'--o')\n\n\n\n\n\n\n\n\n\nplt.plot([1,2,2],'--o')\n\n\n\n\n\n\n\n\n- 정리하면 아래는 같은코드이다.\n\n### 코드1\ncontext_manager = FigureSizeContext()\nresize = context_manager.__enter__()\nresize(3,3)\nplt.plot([1,3,2],'--o')\ncontext_manager.__exit__()\n\n\n\n\n\n\n\n\n\n## 코드2\ncontext_manager = FigureSizeContext()\nwith context_manager as resize:\n    resize(3,3)\n    plt.plot([1,3,2],'--o')\n\n\n\n\n\n\n\n\n\n## 코드3\nwith FigureSizeContext() as resize:\n    resize(3,3)\n    plt.plot([1,3,2],'--o')    \n\n\n\n\n\n\n\n\n#\n# 예제5 – 샌드위치만들기\n\nclass 샌드위치생성기:\n    def __init__(self, 빵=\"기본빵\"):\n        self.빵 = 빵\n        self.재료들 = []\n    def __enter__(self):\n        print(f'---{self.빵}---')    \n        return self # 보통이런패턴..\n    def __exit__(self, *args):\n        print(f'---{self.빵}---')\n    def 재료추가하기(self,재료):\n        print(재료)\n        self.재료들.append(재료)\n\n- 사용예시1\n\nwith 샌드위치생성기() as 샌드위치1:\n    pass\n\n---기본빵---\n---기본빵---\n\n\n\n샌드위치1.빵, 샌드위치1.재료들\n\n('기본빵', [])\n\n\n- 사용예시2\n\nwith 샌드위치생성기(빵='허니오토') as 샌드위치2:\n    샌드위치2.재료추가하기('양상추')\n    샌드위치2.재료추가하기('토마토')\n    샌드위치2.재료추가하기('햄')\n\n---허니오토---\n양상추\n토마토\n햄\n---허니오토---\n\n\n\n샌드위치2.빵, 샌드위치2.재료들\n\n('허니오토', ['양상추', '토마토', '햄'])\n\n\n- 정리하면 __enter__() 의 리턴값이 self일 경우에 한정하여 아래의 문법이 같은효과.. (그런데 보통 이런 경우가 많음 )\n\nwith 샌드위치생성기(빵='허니오토') as 샌드위치2:\n    샌드위치2.재료추가하기('양상추')\n    샌드위치2.재료추가하기('토마토')\n    샌드위치2.재료추가하기('햄')\n\n---허니오토---\n양상추\n토마토\n햄\n---허니오토---\n\n\n\n샌드위치2 = 샌드위치생성기(빵='허니오토')\n샌드위치2 = 샌드위치2.__enter__()\n샌드위치2.재료추가하기('양상추')\n샌드위치2.재료추가하기('토마토')\n샌드위치2.재료추가하기('햄')\n샌드위치2.__exit__()\n\n---허니오토---\n양상추\n토마토\n햄\n---허니오토---\n\n\n\n샌드위치2 = 샌드위치생성기(빵='허니오토').__enter__()\n샌드위치2.재료추가하기('양상추')\n샌드위치2.재료추가하기('토마토')\n샌드위치2.재료추가하기('햄')\n샌드위치2.__exit__()\n\n---허니오토---\n양상추\n토마토\n햄\n---허니오토---\n\n\n\n샌드위치2 = 샌드위치생성기(빵='허니오토')\n샌드위치2.__enter__()\n샌드위치2.재료추가하기('양상추')\n샌드위치2.재료추가하기('토마토')\n샌드위치2.재료추가하기('햄')\n샌드위치2.__exit__()\n\n---허니오토---\n양상추\n토마토\n햄\n---허니오토---\n\n\n#\n# 예제6\n- example.txt 를 만들고 “asdf” 라는 글자를 넣는 파이썬코드\n\nwith open(\"example.txt\",\"w\") as file:\n    file.write(\"asdf\")\n\n\n!cat example.txt # example.txt 를 출력하는 리눅스 명령어..\n\nasdf\n\n\n- 분석하기..\n\ncontext_manager = open(\"example.txt\",\"w\")\ntype(context_manager), type(file)\n\n(_io.TextIOWrapper, _io.TextIOWrapper)\n\n\n- 분석하기2: __enter__ 가 self를 리턴하는지 보자\n\ncontext_manager.__enter__??\n# 코드를 볼수없음 -- 아쉽당..\n\nDocstring: &lt;no docstring&gt;\nType:      builtin_function_or_method\n\n\n#\n# 예제7\n- example.txt 파일을 example.tar.gz로 압축하는 코드\n\nwith tarfile.open(\"example.tar.gz\", \"w:gz\") as tar:\n    tar.add(\"example.txt\", arcname=\"example.txt\")\n\n- 분석하기\n\ncontext_manager = tarfile.open(\"example.tar.gz\", \"w:gz\")\ntype(context_manager), type(tar)\n\n(tarfile.TarFile, tarfile.TarFile)\n\n\n- 분석하기2: __enter__ 가 self를 리턴하는지 보자\n\ncontext_manager.__enter__??\n# 역시 셀프를 리턴하는 구조..\n\nSignature: context_manager.__enter__()\nDocstring: &lt;no docstring&gt;\nSource:   \n    def __enter__(self):\n        self._check()\n        return self\nFile:      ~/anaconda3/envs/hf/lib/python3.12/tarfile.py\nType:      method\n\n\n#"
  },
  {
    "objectID": "공부/HF/2024-10-30-(강의) 이미지분류 SIIM-ISIC.html",
    "href": "공부/HF/2024-10-30-(강의) 이미지분류 SIIM-ISIC.html",
    "title": "(강의) 이미지분류 SIIM-ISIC",
    "section": "",
    "text": "SIIM-ISIC\nhttps://www.kaggle.com/competitions/siim-isic-melanoma-classification/data"
  },
  {
    "objectID": "공부/HF/2024-08-29-image_classification-2.html",
    "href": "공부/HF/2024-08-29-image_classification-2.html",
    "title": "(공부) image_classification 2",
    "section": "",
    "text": "This notebook shows how to fine-tune any pretrained Vision model for Image Classification on a custom dataset. The idea is to add a randomly initialized classification head on top of a pre-trained encoder, and fine-tune the model altogether on a labeled dataset.\n\n\nThis notebook leverages the ImageFolder feature to easily run the notebook on a custom dataset (namely, EuroSAT in this tutorial). You can either load a Dataset from local folders or from local/remote files, like zip or tar.\n\n\n\nThis notebook is built to run on any image classification dataset with any vision model checkpoint from the Model Hub as long as that model has a version with a Image Classification head, such as: * ViT * Swin Transformer * ConvNeXT\n\nin short, any model supported by AutoModelForImageClassification.\n\n\n\n\nThis notebook leverages Torchvision’s transforms for applying data augmentation - note that we do provide alternative notebooks which leverage other libraries, including:\n\nAlbumentations\nKornia\nimgaug.\n\n\nDepending on the model and the GPU you are using, you might need to adjust the batch size to avoid out-of-memory errors. Set those two parameters, then the rest of the notebook should run smoothly.\nIn this notebook, we’ll fine-tune from the https://huggingface.co/microsoft/swin-tiny-patch4-window7-224 checkpoint, but note that there are many, many more available on the hub.\n\nmodel_checkpoint = \"microsoft/swin-tiny-patch4-window7-224\" # pre-trained model from which to fine-tune\nbatch_size = 32 # batch size for training and evaluation\n\nBefore we start, let’s install the datasets, transformers and accelerate libraries.\n\n!pip install -q datasets transformers accelerate\n\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n\n\nIf you’re opening this notebook locally, make sure your environment has an install from the last version of those libraries.\nTo be able to share your model with the community and generate results like the one shown in the picture below via the inference API, there are a few more steps to follow.\nFirst you have to store your authentication token from the Hugging Face website (sign up here if you haven’t already!) then execute the following cell and input your token:\nWe also quickly upload some telemetry - this tells us which examples and software versions are getting used so we know where to prioritize our maintenance efforts. We don’t collect (or care about) any personally identifiable information, but if you’d prefer not to be counted, feel free to skip this step or delete this cell entirely.\n\nfrom transformers.utils import send_example_telemetry\n\nsend_example_telemetry(\"image_classification_notebook\", framework=\"pytorch\")\n\n\n\n\nIn this notebook, we will see how to fine-tune one of the 🤗 Transformers vision models on an Image Classification dataset.\nGiven an image, the goal is to predict an appropriate class for it, like “tiger”. The screenshot below is taken from a ViT fine-tuned on ImageNet-1k - try out the inference widget!\n\n\n\nWe will use the 🤗 Datasets library’s ImageFolder feature to download our custom dataset into a DatasetDict.\nIn this case, the EuroSAT dataset is hosted remotely, so we provide the data_files argument. Alternatively, if you have local folders with images, you can load them using the data_dir argument.\n\nfrom datasets import load_dataset\n\n# load a custom dataset from local/remote files or folders using the ImageFolder feature\n\n# option 1: local/remote files (supporting the following formats: tar, gzip, zip, xz, rar, zstd)\ndataset = load_dataset(\"imagefolder\", data_files=\"https://madm.dfki.de/files/sentinel/EuroSAT.zip\")\n\n# note that you can also provide several splits:\n# dataset = load_dataset(\"imagefolder\", data_files={\"train\": [\"path/to/file1\", \"path/to/file2\"], \"test\": [\"path/to/file3\", \"path/to/file4\"]})\n\n# note that you can push your dataset to the hub very easily (and reload afterwards using load_dataset)!\n# dataset.push_to_hub(\"nielsr/eurosat\")\n# dataset.push_to_hub(\"nielsr/eurosat\", private=True)\n\n# option 2: local folder\n# dataset = load_dataset(\"imagefolder\", data_dir=\"path_to_folder\")\n\n# option 3: just load any existing dataset from the hub, like CIFAR-10, FashionMNIST ...\n# dataset = load_dataset(\"cifar10\")\n\nFileNotFoundError: Unable to find 'https://madm.dfki.de/files/sentinel/EuroSAT.zip'\n\n\nLet us also load the Accuracy metric, which we’ll use to evaluate our model both during and after training.\n\nfrom datasets import load_metric\n\nmetric = load_metric(\"accuracy\")\n\n/tmp/ipykernel_36201/1780215247.py:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n  metric = load_metric(\"accuracy\")\nDownloading builder script: 4.21kB [00:00, 10.7MB/s]                   \n\n\nValueError: Loading accuracy requires you to execute the dataset script in that repo on your local machine. Make sure you have read the code there to avoid malicious use, then set the option `trust_remote_code=True` to remove this error.\n\n\nThe dataset object itself is a DatasetDict, which contains one key per split (in this case, only “train” for a training split).\n\ndataset\n\nDatasetDict({\n    train: Dataset({\n        features: ['image', 'label'],\n        num_rows: 27000\n    })\n})\n\n\nTo access an actual element, you need to select a split first, then give an index:\n\nexample = dataset[\"train\"][10]\nexample\n\n{'image': &lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=64x64 at 0x7FF2F6277B10&gt;,\n 'label': 2}\n\n\nEach example consists of an image and a corresponding label. We can also verify this by checking the features of the dataset:\n\ndataset[\"train\"].features\n\n{'image': Image(decode=True, id=None),\n 'label': ClassLabel(num_classes=10, names=['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake'], id=None)}\n\n\nThe cool thing is that we can directly view the image (as the ‘image’ field is an Image feature), as follows:\n\nexample['image']\n\n\n\n\n\n\n\n\nLet’s make it a little bigger as the images in the EuroSAT dataset are of low resolution (64x64 pixels):\n\nexample['image'].resize((200, 200))\n\n\n\n\n\n\n\n\nLet’s print the corresponding label:\n\nexample['label']\n\n2\n\n\nAs you can see, the label field is not an actual string label. By default the ClassLabel fields are encoded into integers for convenience:\n\ndataset[\"train\"].features[\"label\"]\n\nClassLabel(num_classes=10, names=['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake'], id=None)\n\n\nLet’s create an id2label dictionary to decode them back to strings and see what they are. The inverse label2id will be useful too, when we load the model later.\n\nlabels = dataset[\"train\"].features[\"label\"].names\nlabel2id, id2label = dict(), dict()\nfor i, label in enumerate(labels):\n    label2id[label] = i\n    id2label[i] = label\n\nid2label[2]\n\n'HerbaceousVegetation'\n\n\n\n\n\nBefore we can feed these images to our model, we need to preprocess them.\nPreprocessing images typically comes down to (1) resizing them to a particular size (2) normalizing the color channels (R,G,B) using a mean and standard deviation. These are referred to as image transformations.\nIn addition, one typically performs what is called data augmentation during training (like random cropping and flipping) to make the model more robust and achieve higher accuracy. Data augmentation is also a great technique to increase the size of the training data.\nWe will use torchvision.transforms for the image transformations/data augmentation in this tutorial, but note that one can use any other package (like albumentations, imgaug, Kornia etc.).\nTo make sure we (1) resize to the appropriate size (2) use the appropriate image mean and standard deviation for the model architecture we are going to use, we instantiate what is called an image processor with the AutoImageProcessor.from_pretrained method.\nThis image processor is a minimal preprocessor that can be used to prepare images for inference.\n\nfrom transformers import AutoImageProcessor\n\nimage_processor  = AutoImageProcessor.from_pretrained(model_checkpoint)\nimage_processor\n\n\n\n\nViTFeatureExtractor {\n  \"do_normalize\": true,\n  \"do_resize\": true,\n  \"feature_extractor_type\": \"ViTFeatureExtractor\",\n  \"image_mean\": [\n    0.485,\n    0.456,\n    0.406\n  ],\n  \"image_std\": [\n    0.229,\n    0.224,\n    0.225\n  ],\n  \"resample\": 3,\n  \"size\": 224\n}\n\n\nThe Datasets library is made for processing data very easily. We can write custom functions, which can then be applied on an entire dataset (either using .map() or .set_transform()).\nHere we define 2 separate functions, one for training (which includes data augmentation) and one for validation (which only includes resizing, center cropping and normalizing).\n\nfrom torchvision.transforms import (\n    CenterCrop,\n    Compose,\n    Normalize,\n    RandomHorizontalFlip,\n    RandomResizedCrop,\n    Resize,\n    ToTensor,\n)\n\nnormalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\nif \"height\" in image_processor.size:\n    size = (image_processor.size[\"height\"], image_processor.size[\"width\"])\n    crop_size = size\n    max_size = None\nelif \"shortest_edge\" in image_processor.size:\n    size = image_processor.size[\"shortest_edge\"]\n    crop_size = (size, size)\n    max_size = image_processor.size.get(\"longest_edge\")\n\ntrain_transforms = Compose(\n        [\n            RandomResizedCrop(crop_size),\n            RandomHorizontalFlip(),\n            ToTensor(),\n            normalize,\n        ]\n    )\n\nval_transforms = Compose(\n        [\n            Resize(size),\n            CenterCrop(crop_size),\n            ToTensor(),\n            normalize,\n        ]\n    )\n\ndef preprocess_train(example_batch):\n    \"\"\"Apply train_transforms across a batch.\"\"\"\n    example_batch[\"pixel_values\"] = [\n        train_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]\n    ]\n    return example_batch\n\ndef preprocess_val(example_batch):\n    \"\"\"Apply val_transforms across a batch.\"\"\"\n    example_batch[\"pixel_values\"] = [val_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]]\n    return example_batch\n\nNext, we can preprocess our dataset by applying these functions. We will use the set_transform functionality, which allows to apply the functions above on-the-fly (meaning that they will only be applied when the images are loaded in RAM).\n\n# split up training into training + validation\nsplits = dataset[\"train\"].train_test_split(test_size=0.1)\ntrain_ds = splits['train']\nval_ds = splits['test']\n\n\ntrain_ds.set_transform(preprocess_train)\nval_ds.set_transform(preprocess_val)\n\nLet’s access an element to see that we’ve added a “pixel_values” feature:\n\ntrain_ds[0]\n\n{'image': &lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=64x64 at 0x7FF2EFFB0D90&gt;,\n 'label': 9,\n 'pixel_values': tensor([[[-0.3541, -0.3541, -0.3541,  ..., -0.3712, -0.3712, -0.3712],\n          [-0.3541, -0.3541, -0.3541,  ..., -0.3712, -0.3712, -0.3712],\n          [-0.3541, -0.3541, -0.3541,  ..., -0.3712, -0.3712, -0.3712],\n          ...,\n          [-0.4397, -0.4397, -0.4397,  ..., -0.4911, -0.4911, -0.4911],\n          [-0.4397, -0.4397, -0.4397,  ..., -0.4911, -0.4911, -0.4911],\n          [-0.4397, -0.4397, -0.4397,  ..., -0.4911, -0.4911, -0.4911]],\n \n         [[-0.2500, -0.2500, -0.2500,  ..., -0.2850, -0.2850, -0.2850],\n          [-0.2500, -0.2500, -0.2500,  ..., -0.2850, -0.2850, -0.2850],\n          [-0.2500, -0.2500, -0.2500,  ..., -0.2850, -0.2850, -0.2850],\n          ...,\n          [-0.3550, -0.3550, -0.3550,  ..., -0.4076, -0.4076, -0.4076],\n          [-0.3550, -0.3550, -0.3550,  ..., -0.4076, -0.4076, -0.4076],\n          [-0.3550, -0.3550, -0.3550,  ..., -0.4076, -0.4076, -0.4076]],\n \n         [[ 0.1128,  0.1128,  0.1128,  ...,  0.1651,  0.1651,  0.1651],\n          [ 0.1128,  0.1128,  0.1128,  ...,  0.1651,  0.1651,  0.1651],\n          [ 0.1128,  0.1128,  0.1128,  ...,  0.1651,  0.1651,  0.1651],\n          ...,\n          [ 0.0605,  0.0605,  0.0605,  ...,  0.0082,  0.0082,  0.0082],\n          [ 0.0605,  0.0605,  0.0605,  ...,  0.0082,  0.0082,  0.0082],\n          [ 0.0605,  0.0605,  0.0605,  ...,  0.0082,  0.0082,  0.0082]]])}\n\n\n\n\n\nNow that our data is ready, we can download the pretrained model and fine-tune it. For classification we use the AutoModelForImageClassification class. Calling the from_pretrained method on it will download and cache the weights for us. As the label ids and the number of labels are dataset dependent, we pass label2id, and id2label alongside the model_checkpoint here. This will make sure a custom classification head will be created (with a custom number of output neurons).\nNOTE: in case you’re planning to fine-tune an already fine-tuned checkpoint, like facebook/convnext-tiny-224 (which has already been fine-tuned on ImageNet-1k), then you need to provide the additional argument ignore_mismatched_sizes=True to the from_pretrained method. This will make sure the output head (with 1000 output neurons) is thrown away and replaced by a new, randomly initialized classification head that includes a custom number of output neurons. You don’t need to specify this argument in case the pre-trained model doesn’t include a head.\n\nfrom transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n\nmodel = AutoModelForImageClassification.from_pretrained(\n    model_checkpoint,\n    label2id=label2id,\n    id2label=id2label,\n    ignore_mismatched_sizes = True, # provide this in case you're planning to fine-tune an already fine-tuned checkpoint\n)\n\n\n\n\n\n\n\n/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\nSome weights of SwinForImageClassification were not initialized from the model checkpoint at microsoft/swin-tiny-patch4-window7-224 and are newly initialized because the shapes did not match:\n- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([10, 768]) in the model instantiated\n- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([10]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n\nThe warning is telling us we are throwing away some weights (the weights and bias of the classifier layer) and randomly initializing some other (the weights and bias of a new classifier layer). This is expected in this case, because we are adding a new head for which we don’t have pretrained weights, so the library warns us we should fine-tune this model before using it for inference, which is exactly what we are going to do.\nTo instantiate a Trainer, we will need to define the training configuration and the evaluation metric. The most important is the TrainingArguments, which is a class that contains all the attributes to customize the training. It requires one folder name, which will be used to save the checkpoints of the model.\nMost of the training arguments are pretty self-explanatory, but one that is quite important here is remove_unused_columns=False. This one will drop any features not used by the model’s call function. By default it’s True because usually it’s ideal to drop unused feature columns, making it easier to unpack inputs into the model’s call function. But, in our case, we need the unused features (‘image’ in particular) in order to create ‘pixel_values’.\n\nmodel_name = model_checkpoint.split(\"/\")[-1]\n\nargs = TrainingArguments(\n    f\"{model_name}-finetuned-eurosat\",\n    remove_unused_columns=False,\n    evaluation_strategy = \"epoch\",\n    save_strategy = \"epoch\",\n    learning_rate=5e-5,\n    per_device_train_batch_size=batch_size,\n    gradient_accumulation_steps=4,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=3,\n    warmup_ratio=0.1,\n    logging_steps=10,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"accuracy\",\n    push_to_hub=True,\n)\n\nHere we set the evaluation to be done at the end of each epoch, tweak the learning rate, use the batch_size defined at the top of the notebook and customize the number of epochs for training, as well as the weight decay. Since the best model might not be the one at the end of training, we ask the Trainer to load the best model it saved (according to metric_name) at the end of training.\nThe last argument push_to_hub allows the Trainer to push the model to the Hub regularly during training. Remove it if you didn’t follow the installation steps at the top of the notebook. If you want to save your model locally with a name that is different from the name of the repository, or if you want to push your model under an organization and not your name space, use the hub_model_id argument to set the repo name (it needs to be the full name, including your namespace: for instance \"nielsr/vit-finetuned-cifar10\" or \"huggingface/nielsr/vit-finetuned-cifar10\").\nNext, we need to define a function for how to compute the metrics from the predictions, which will just use the metric we loaded earlier. The only preprocessing we have to do is to take the argmax of our predicted logits:\n\nimport numpy as np\n\n# the compute_metrics function takes a Named Tuple as input:\n# predictions, which are the logits of the model as Numpy arrays,\n# and label_ids, which are the ground-truth labels as Numpy arrays.\ndef compute_metrics(eval_pred):\n    \"\"\"Computes accuracy on a batch of predictions\"\"\"\n    predictions = np.argmax(eval_pred.predictions, axis=1)\n    return metric.compute(predictions=predictions, references=eval_pred.label_ids)\n\nWe also define a collate_fn, which will be used to batch examples together. Each batch consists of 2 keys, namely pixel_values and labels.\n\nimport torch\n\ndef collate_fn(examples):\n    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n    labels = torch.tensor([example[\"label\"] for example in examples])\n    return {\"pixel_values\": pixel_values, \"labels\": labels}\n\nThen we just need to pass all of this along with our datasets to the Trainer:\n\ntrainer = Trainer(\n    model,\n    args,\n    train_dataset=train_ds,\n    eval_dataset=val_ds,\n    tokenizer=image_processor,\n    compute_metrics=compute_metrics,\n    data_collator=collate_fn,\n)\n\nCloning https://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat into local empty directory.\n\n\nYou might wonder why we pass along the image_processor as a tokenizer when we already preprocessed our data. This is only to make sure the image processor configuration file (stored as JSON) will also be uploaded to the repo on the hub.\nNow we can finetune our model by calling the train method:\n\ntrain_results = trainer.train()\n# rest is optional but nice to have\ntrainer.save_model()\ntrainer.log_metrics(\"train\", train_results.metrics)\ntrainer.save_metrics(\"train\", train_results.metrics)\ntrainer.save_state()\n\n/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 24300\n  Num Epochs = 3\n  Instantaneous batch size per device = 32\n  Total train batch size (w. parallel, distributed & accumulation) = 128\n  Gradient Accumulation steps = 4\n  Total optimization steps = 570\n***** Running Evaluation *****\n  Num examples = 2700\n  Batch size = 32\nSaving model checkpoint to swin-tiny-patch4-window7-224-finetuned-eurosat/checkpoint-190\nConfiguration saved in swin-tiny-patch4-window7-224-finetuned-eurosat/checkpoint-190/config.json\nModel weights saved in swin-tiny-patch4-window7-224-finetuned-eurosat/checkpoint-190/pytorch_model.bin\nFeature extractor saved in swin-tiny-patch4-window7-224-finetuned-eurosat/checkpoint-190/preprocessor_config.json\nFeature extractor saved in swin-tiny-patch4-window7-224-finetuned-eurosat/preprocessor_config.json\n***** Running Evaluation *****\n  Num examples = 2700\n  Batch size = 32\nSaving model checkpoint to swin-tiny-patch4-window7-224-finetuned-eurosat/checkpoint-380\nConfiguration saved in swin-tiny-patch4-window7-224-finetuned-eurosat/checkpoint-380/config.json\nModel weights saved in swin-tiny-patch4-window7-224-finetuned-eurosat/checkpoint-380/pytorch_model.bin\nFeature extractor saved in swin-tiny-patch4-window7-224-finetuned-eurosat/checkpoint-380/preprocessor_config.json\nFeature extractor saved in swin-tiny-patch4-window7-224-finetuned-eurosat/preprocessor_config.json\n***** Running Evaluation *****\n  Num examples = 2700\n  Batch size = 32\nSaving model checkpoint to swin-tiny-patch4-window7-224-finetuned-eurosat/checkpoint-570\nConfiguration saved in swin-tiny-patch4-window7-224-finetuned-eurosat/checkpoint-570/config.json\nModel weights saved in swin-tiny-patch4-window7-224-finetuned-eurosat/checkpoint-570/pytorch_model.bin\nFeature extractor saved in swin-tiny-patch4-window7-224-finetuned-eurosat/checkpoint-570/preprocessor_config.json\nFeature extractor saved in swin-tiny-patch4-window7-224-finetuned-eurosat/preprocessor_config.json\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\nLoading best model from swin-tiny-patch4-window7-224-finetuned-eurosat/checkpoint-570 (score: 0.9744444444444444).\nSaving model checkpoint to swin-tiny-patch4-window7-224-finetuned-eurosat\nConfiguration saved in swin-tiny-patch4-window7-224-finetuned-eurosat/config.json\nModel weights saved in swin-tiny-patch4-window7-224-finetuned-eurosat/pytorch_model.bin\nFeature extractor saved in swin-tiny-patch4-window7-224-finetuned-eurosat/preprocessor_config.json\nSaving model checkpoint to swin-tiny-patch4-window7-224-finetuned-eurosat\nConfiguration saved in swin-tiny-patch4-window7-224-finetuned-eurosat/config.json\nModel weights saved in swin-tiny-patch4-window7-224-finetuned-eurosat/pytorch_model.bin\nFeature extractor saved in swin-tiny-patch4-window7-224-finetuned-eurosat/preprocessor_config.json\nSeveral commits (2) will be pushed upstream.\nThe progress bars may be unreliable.\nTo https://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat\n   b46a767..6d6b8dc  main -&gt; main\n\nTo https://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat\n   6d6b8dc..25dd5d7  main -&gt; main\n\n\n\n\n    \n      \n      \n      [570/570 16:11, Epoch 3/3]\n    \n    \n\n\n\nEpoch\nTraining Loss\nValidation Loss\nAccuracy\n\n\n\n\n1\n0.262100\n0.108344\n0.962963\n\n\n2\n0.176900\n0.142533\n0.950000\n\n\n3\n0.134300\n0.066442\n0.974444\n\n\n\n\n\n\n\n\n\n\n\n\n***** train metrics *****\n  epoch                    =          3.0\n  total_flos               = 1687935228GF\n  train_loss               =       0.3276\n  train_runtime            =   0:16:13.91\n  train_samples_per_second =       74.852\n  train_steps_per_second   =        0.585\n\n\nWe can check with the evaluate method that our Trainer did reload the best model properly (if it was not the last one):\n\nmetrics = trainer.evaluate()\n# some nice to haves:\ntrainer.log_metrics(\"eval\", metrics)\ntrainer.save_metrics(\"eval\", metrics)\n\n***** Running Evaluation *****\n  Num examples = 2700\n  Batch size = 32\n\n\n\n    \n      \n      \n      [85/85 00:15]\n    \n    \n\n\n***** eval metrics *****\n  epoch                   =        3.0\n  eval_accuracy           =     0.9744\n  eval_loss               =     0.0664\n  eval_runtime            = 0:00:16.12\n  eval_samples_per_second =     167.48\n  eval_steps_per_second   =      5.273\n\n\nYou can now upload the result of the training to the Hub, just execute this instruction (note that the Trainer will automatically create a model card as well as Tensorboard logs - see the “Training metrics” tab - amazing isn’t it?):\n\ntrainer.push_to_hub()\n\nSaving model checkpoint to swin-tiny-patch4-window7-224-finetuned-eurosat\nConfiguration saved in swin-tiny-patch4-window7-224-finetuned-eurosat/config.json\nModel weights saved in swin-tiny-patch4-window7-224-finetuned-eurosat/pytorch_model.bin\nFeature extractor saved in swin-tiny-patch4-window7-224-finetuned-eurosat/preprocessor_config.json\nTo https://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat\n   25dd5d7..2164338  main -&gt; main\n\n\n\n\n\n\n'https://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat/commit/2164338db59d40004286bc65800bfa50561ecd3d'\n\n\nYou can now share this model with all your friends, family, favorite pets: they can all load it with the identifier \"your-username/the-name-you-picked\" so for instance:\nfrom transformers import AutoModelForImageClassification, AutoImageProcessor\n\nimage_processor = AutoImageProcessor.from_pretrained(\"nielsr/my-awesome-model\")\nmodel = AutoModelForImageClassification.from_pretrained(\"nielsr/my-awesome-model\")\n\n\n\n\nLet’s say you have a new image, on which you’d like to make a prediction. Let’s load a satellite image of a forest (that’s not part of the EuroSAT dataset), and see how the model does.\n\nfrom PIL import Image\nimport requests\n\nurl = 'https://huggingface.co/nielsr/convnext-tiny-finetuned-eurostat/resolve/main/forest.png'\nimage = Image.open(requests.get(url, stream=True).raw)\nimage\n\n\n\n\n\n\n\n\nWe’ll load the image processor and model from the hub (here, we use the Auto Classes, which will make sure the appropriate classes will be loaded automatically based on the config.json and preprocessor_config.json files of the repo on the hub):\n\nfrom transformers import AutoModelForImageClassification, AutoImageProcessor\n\nrepo_name = \"nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat\"\n\nimage_processor = AutoImageProcessor.from_pretrained(repo_name)\nmodel = AutoModelForImageClassification.from_pretrained(repo_name)\n\nhttps://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat/resolve/main/preprocessor_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpqggthctf\nstoring https://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat/resolve/main/preprocessor_config.json in cache at /root/.cache/huggingface/transformers/7b742d61fc51f2ef5f81a75f80b26419c9f5bd86cc3022ed5784d09823f219f2.e34548f8325ec440fcf4990d4a8dbbfd665397400e9a700766de032d2b45cf6b\ncreating metadata file for /root/.cache/huggingface/transformers/7b742d61fc51f2ef5f81a75f80b26419c9f5bd86cc3022ed5784d09823f219f2.e34548f8325ec440fcf4990d4a8dbbfd665397400e9a700766de032d2b45cf6b\nloading feature extractor configuration file https://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat/resolve/main/preprocessor_config.json from cache at /root/.cache/huggingface/transformers/7b742d61fc51f2ef5f81a75f80b26419c9f5bd86cc3022ed5784d09823f219f2.e34548f8325ec440fcf4990d4a8dbbfd665397400e9a700766de032d2b45cf6b\nFeature extractor ViTFeatureExtractor {\n  \"do_normalize\": true,\n  \"do_resize\": true,\n  \"feature_extractor_type\": \"ViTFeatureExtractor\",\n  \"image_mean\": [\n    0.485,\n    0.456,\n    0.406\n  ],\n  \"image_std\": [\n    0.229,\n    0.224,\n    0.225\n  ],\n  \"resample\": 3,\n  \"size\": 224\n}\n\nhttps://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpzdd89w3g\nstoring https://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/83e4a1dea85e8e284e4da8ae1e3cf950c2c7e74d65a5a188049b3371fcd151bd.f1ed4852dd8f4c3d0c565427607bc41fff51b58ac73a0970bec8456e5c64cea0\ncreating metadata file for /root/.cache/huggingface/transformers/83e4a1dea85e8e284e4da8ae1e3cf950c2c7e74d65a5a188049b3371fcd151bd.f1ed4852dd8f4c3d0c565427607bc41fff51b58ac73a0970bec8456e5c64cea0\nloading configuration file https://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/83e4a1dea85e8e284e4da8ae1e3cf950c2c7e74d65a5a188049b3371fcd151bd.f1ed4852dd8f4c3d0c565427607bc41fff51b58ac73a0970bec8456e5c64cea0\nModel config SwinConfig {\n  \"_name_or_path\": \"nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat\",\n  \"architectures\": [\n    \"SwinForImageClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.0,\n  \"depths\": [\n    2,\n    2,\n    6,\n    2\n  ],\n  \"drop_path_rate\": 0.1,\n  \"embed_dim\": 96,\n  \"encoder_stride\": 32,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.0,\n  \"hidden_size\": 768,\n  \"id2label\": {\n    \"0\": \"AnnualCrop\",\n    \"1\": \"Forest\",\n    \"2\": \"HerbaceousVegetation\",\n    \"3\": \"Highway\",\n    \"4\": \"Industrial\",\n    \"5\": \"Pasture\",\n    \"6\": \"PermanentCrop\",\n    \"7\": \"Residential\",\n    \"8\": \"River\",\n    \"9\": \"SeaLake\"\n  },\n  \"image_size\": 224,\n  \"initializer_range\": 0.02,\n  \"label2id\": {\n    \"AnnualCrop\": 0,\n    \"Forest\": 1,\n    \"HerbaceousVegetation\": 2,\n    \"Highway\": 3,\n    \"Industrial\": 4,\n    \"Pasture\": 5,\n    \"PermanentCrop\": 6,\n    \"Residential\": 7,\n    \"River\": 8,\n    \"SeaLake\": 9\n  },\n  \"layer_norm_eps\": 1e-05,\n  \"mlp_ratio\": 4.0,\n  \"model_type\": \"swin\",\n  \"num_channels\": 3,\n  \"num_heads\": [\n    3,\n    6,\n    12,\n    24\n  ],\n  \"num_layers\": 4,\n  \"patch_size\": 4,\n  \"path_norm\": true,\n  \"problem_type\": \"single_label_classification\",\n  \"qkv_bias\": true,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.18.0\",\n  \"use_absolute_embeddings\": false,\n  \"window_size\": 7\n}\n\nhttps://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpkh0vdu53\nstoring https://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/3daadbe0cabef18dc0e2232ae080d135a9d4ee6b1dc7675725ef38bedb990b81.818e63819e125637bd8a94f43b6899d1552f0b45884f1c28c458a5cb55dfa9e5\ncreating metadata file for /root/.cache/huggingface/transformers/3daadbe0cabef18dc0e2232ae080d135a9d4ee6b1dc7675725ef38bedb990b81.818e63819e125637bd8a94f43b6899d1552f0b45884f1c28c458a5cb55dfa9e5\nloading weights file https://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/3daadbe0cabef18dc0e2232ae080d135a9d4ee6b1dc7675725ef38bedb990b81.818e63819e125637bd8a94f43b6899d1552f0b45884f1c28c458a5cb55dfa9e5\nAll model checkpoint weights were used when initializing SwinForImageClassification.\n\nAll the weights of SwinForImageClassification were initialized from the model checkpoint at nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use SwinForImageClassification for predictions without further training.\n\n\n\n\n\n\n\n\n\n\n\n\n# prepare image for the model\nencoding = image_processor(image.convert(\"RGB\"), return_tensors=\"pt\")\nprint(encoding.pixel_values.shape)\n\ntorch.Size([1, 3, 224, 224])\n\n\n\nimport torch\n\n# forward pass\nwith torch.no_grad():\n    outputs = model(**encoding)\n    logits = outputs.logits\n\n\npredicted_class_idx = logits.argmax(-1).item()\nprint(\"Predicted class:\", model.config.id2label[predicted_class_idx])\n\nPredicted class: Forest\n\n\nLooks like our model got it correct!\n\n\n\nAn alternative way to quickly perform inference with any model on the hub is by leveraging the Pipeline API, which abstracts away all the steps we did manually above for us. It will perform the preprocessing, forward pass and postprocessing all in a single object.\nLet’s showcase this for our trained model:\n\nfrom transformers import pipeline\n\npipe = pipeline(\"image-classification\", \"nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat\")\n\nloading configuration file https://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/83e4a1dea85e8e284e4da8ae1e3cf950c2c7e74d65a5a188049b3371fcd151bd.f1ed4852dd8f4c3d0c565427607bc41fff51b58ac73a0970bec8456e5c64cea0\nModel config SwinConfig {\n  \"_name_or_path\": \"nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat\",\n  \"architectures\": [\n    \"SwinForImageClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.0,\n  \"depths\": [\n    2,\n    2,\n    6,\n    2\n  ],\n  \"drop_path_rate\": 0.1,\n  \"embed_dim\": 96,\n  \"encoder_stride\": 32,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.0,\n  \"hidden_size\": 768,\n  \"id2label\": {\n    \"0\": \"AnnualCrop\",\n    \"1\": \"Forest\",\n    \"2\": \"HerbaceousVegetation\",\n    \"3\": \"Highway\",\n    \"4\": \"Industrial\",\n    \"5\": \"Pasture\",\n    \"6\": \"PermanentCrop\",\n    \"7\": \"Residential\",\n    \"8\": \"River\",\n    \"9\": \"SeaLake\"\n  },\n  \"image_size\": 224,\n  \"initializer_range\": 0.02,\n  \"label2id\": {\n    \"AnnualCrop\": 0,\n    \"Forest\": 1,\n    \"HerbaceousVegetation\": 2,\n    \"Highway\": 3,\n    \"Industrial\": 4,\n    \"Pasture\": 5,\n    \"PermanentCrop\": 6,\n    \"Residential\": 7,\n    \"River\": 8,\n    \"SeaLake\": 9\n  },\n  \"layer_norm_eps\": 1e-05,\n  \"mlp_ratio\": 4.0,\n  \"model_type\": \"swin\",\n  \"num_channels\": 3,\n  \"num_heads\": [\n    3,\n    6,\n    12,\n    24\n  ],\n  \"num_layers\": 4,\n  \"patch_size\": 4,\n  \"path_norm\": true,\n  \"problem_type\": \"single_label_classification\",\n  \"qkv_bias\": true,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.18.0\",\n  \"use_absolute_embeddings\": false,\n  \"window_size\": 7\n}\n\nloading configuration file https://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/83e4a1dea85e8e284e4da8ae1e3cf950c2c7e74d65a5a188049b3371fcd151bd.f1ed4852dd8f4c3d0c565427607bc41fff51b58ac73a0970bec8456e5c64cea0\nModel config SwinConfig {\n  \"_name_or_path\": \"nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat\",\n  \"architectures\": [\n    \"SwinForImageClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.0,\n  \"depths\": [\n    2,\n    2,\n    6,\n    2\n  ],\n  \"drop_path_rate\": 0.1,\n  \"embed_dim\": 96,\n  \"encoder_stride\": 32,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.0,\n  \"hidden_size\": 768,\n  \"id2label\": {\n    \"0\": \"AnnualCrop\",\n    \"1\": \"Forest\",\n    \"2\": \"HerbaceousVegetation\",\n    \"3\": \"Highway\",\n    \"4\": \"Industrial\",\n    \"5\": \"Pasture\",\n    \"6\": \"PermanentCrop\",\n    \"7\": \"Residential\",\n    \"8\": \"River\",\n    \"9\": \"SeaLake\"\n  },\n  \"image_size\": 224,\n  \"initializer_range\": 0.02,\n  \"label2id\": {\n    \"AnnualCrop\": 0,\n    \"Forest\": 1,\n    \"HerbaceousVegetation\": 2,\n    \"Highway\": 3,\n    \"Industrial\": 4,\n    \"Pasture\": 5,\n    \"PermanentCrop\": 6,\n    \"Residential\": 7,\n    \"River\": 8,\n    \"SeaLake\": 9\n  },\n  \"layer_norm_eps\": 1e-05,\n  \"mlp_ratio\": 4.0,\n  \"model_type\": \"swin\",\n  \"num_channels\": 3,\n  \"num_heads\": [\n    3,\n    6,\n    12,\n    24\n  ],\n  \"num_layers\": 4,\n  \"patch_size\": 4,\n  \"path_norm\": true,\n  \"problem_type\": \"single_label_classification\",\n  \"qkv_bias\": true,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.18.0\",\n  \"use_absolute_embeddings\": false,\n  \"window_size\": 7\n}\n\nloading weights file https://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/3daadbe0cabef18dc0e2232ae080d135a9d4ee6b1dc7675725ef38bedb990b81.818e63819e125637bd8a94f43b6899d1552f0b45884f1c28c458a5cb55dfa9e5\nAll model checkpoint weights were used when initializing SwinForImageClassification.\n\nAll the weights of SwinForImageClassification were initialized from the model checkpoint at nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use SwinForImageClassification for predictions without further training.\nloading feature extractor configuration file https://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat/resolve/main/preprocessor_config.json from cache at /root/.cache/huggingface/transformers/7b742d61fc51f2ef5f81a75f80b26419c9f5bd86cc3022ed5784d09823f219f2.e34548f8325ec440fcf4990d4a8dbbfd665397400e9a700766de032d2b45cf6b\nFeature extractor ViTFeatureExtractor {\n  \"do_normalize\": true,\n  \"do_resize\": true,\n  \"feature_extractor_type\": \"ViTFeatureExtractor\",\n  \"image_mean\": [\n    0.485,\n    0.456,\n    0.406\n  ],\n  \"image_std\": [\n    0.229,\n    0.224,\n    0.225\n  ],\n  \"resample\": 3,\n  \"size\": 224\n}\n\n\n\n\npipe(image)\n\n[{'label': 'Forest', 'score': 0.7000269889831543},\n {'label': 'HerbaceousVegetation', 'score': 0.14589950442314148},\n {'label': 'Pasture', 'score': 0.10370415449142456},\n {'label': 'Highway', 'score': 0.014327816665172577},\n {'label': 'Residential', 'score': 0.0139168007299304}]\n\n\nAs we can see, it does not only show the class label with the highest probability, but does return the top 5 labels, with their corresponding scores. Note that the pipelines also work with local models and mage processors:\n\npipe = pipeline(\"image-classification\",\n                model=model,\n                feature_extractor=image_processor)\n\n\npipe(image)\n\n[{'label': 'Forest', 'score': 0.7000269889831543},\n {'label': 'HerbaceousVegetation', 'score': 0.14589950442314148},\n {'label': 'Pasture', 'score': 0.10370415449142456},\n {'label': 'Highway', 'score': 0.014327816665172577},\n {'label': 'Residential', 'score': 0.0139168007299304}]"
  },
  {
    "objectID": "공부/HF/2024-08-29-image_classification-2.html#imagefolder",
    "href": "공부/HF/2024-08-29-image_classification-2.html#imagefolder",
    "title": "(공부) image_classification 2",
    "section": "",
    "text": "This notebook leverages the ImageFolder feature to easily run the notebook on a custom dataset (namely, EuroSAT in this tutorial). You can either load a Dataset from local folders or from local/remote files, like zip or tar."
  },
  {
    "objectID": "공부/HF/2024-08-29-image_classification-2.html#any-model",
    "href": "공부/HF/2024-08-29-image_classification-2.html#any-model",
    "title": "(공부) image_classification 2",
    "section": "",
    "text": "This notebook is built to run on any image classification dataset with any vision model checkpoint from the Model Hub as long as that model has a version with a Image Classification head, such as: * ViT * Swin Transformer * ConvNeXT\n\nin short, any model supported by AutoModelForImageClassification."
  },
  {
    "objectID": "공부/HF/2024-08-29-image_classification-2.html#data-augmentation",
    "href": "공부/HF/2024-08-29-image_classification-2.html#data-augmentation",
    "title": "(공부) image_classification 2",
    "section": "",
    "text": "This notebook leverages Torchvision’s transforms for applying data augmentation - note that we do provide alternative notebooks which leverage other libraries, including:\n\nAlbumentations\nKornia\nimgaug.\n\n\nDepending on the model and the GPU you are using, you might need to adjust the batch size to avoid out-of-memory errors. Set those two parameters, then the rest of the notebook should run smoothly.\nIn this notebook, we’ll fine-tune from the https://huggingface.co/microsoft/swin-tiny-patch4-window7-224 checkpoint, but note that there are many, many more available on the hub.\n\nmodel_checkpoint = \"microsoft/swin-tiny-patch4-window7-224\" # pre-trained model from which to fine-tune\nbatch_size = 32 # batch size for training and evaluation\n\nBefore we start, let’s install the datasets, transformers and accelerate libraries.\n\n!pip install -q datasets transformers accelerate\n\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n\n\nIf you’re opening this notebook locally, make sure your environment has an install from the last version of those libraries.\nTo be able to share your model with the community and generate results like the one shown in the picture below via the inference API, there are a few more steps to follow.\nFirst you have to store your authentication token from the Hugging Face website (sign up here if you haven’t already!) then execute the following cell and input your token:\nWe also quickly upload some telemetry - this tells us which examples and software versions are getting used so we know where to prioritize our maintenance efforts. We don’t collect (or care about) any personally identifiable information, but if you’d prefer not to be counted, feel free to skip this step or delete this cell entirely.\n\nfrom transformers.utils import send_example_telemetry\n\nsend_example_telemetry(\"image_classification_notebook\", framework=\"pytorch\")"
  },
  {
    "objectID": "공부/HF/2024-08-29-image_classification-2.html#fine-tuning-a-model-on-an-image-classification-task",
    "href": "공부/HF/2024-08-29-image_classification-2.html#fine-tuning-a-model-on-an-image-classification-task",
    "title": "(공부) image_classification 2",
    "section": "",
    "text": "In this notebook, we will see how to fine-tune one of the 🤗 Transformers vision models on an Image Classification dataset.\nGiven an image, the goal is to predict an appropriate class for it, like “tiger”. The screenshot below is taken from a ViT fine-tuned on ImageNet-1k - try out the inference widget!\n\n\n\nWe will use the 🤗 Datasets library’s ImageFolder feature to download our custom dataset into a DatasetDict.\nIn this case, the EuroSAT dataset is hosted remotely, so we provide the data_files argument. Alternatively, if you have local folders with images, you can load them using the data_dir argument.\n\nfrom datasets import load_dataset\n\n# load a custom dataset from local/remote files or folders using the ImageFolder feature\n\n# option 1: local/remote files (supporting the following formats: tar, gzip, zip, xz, rar, zstd)\ndataset = load_dataset(\"imagefolder\", data_files=\"https://madm.dfki.de/files/sentinel/EuroSAT.zip\")\n\n# note that you can also provide several splits:\n# dataset = load_dataset(\"imagefolder\", data_files={\"train\": [\"path/to/file1\", \"path/to/file2\"], \"test\": [\"path/to/file3\", \"path/to/file4\"]})\n\n# note that you can push your dataset to the hub very easily (and reload afterwards using load_dataset)!\n# dataset.push_to_hub(\"nielsr/eurosat\")\n# dataset.push_to_hub(\"nielsr/eurosat\", private=True)\n\n# option 2: local folder\n# dataset = load_dataset(\"imagefolder\", data_dir=\"path_to_folder\")\n\n# option 3: just load any existing dataset from the hub, like CIFAR-10, FashionMNIST ...\n# dataset = load_dataset(\"cifar10\")\n\nFileNotFoundError: Unable to find 'https://madm.dfki.de/files/sentinel/EuroSAT.zip'\n\n\nLet us also load the Accuracy metric, which we’ll use to evaluate our model both during and after training.\n\nfrom datasets import load_metric\n\nmetric = load_metric(\"accuracy\")\n\n/tmp/ipykernel_36201/1780215247.py:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n  metric = load_metric(\"accuracy\")\nDownloading builder script: 4.21kB [00:00, 10.7MB/s]                   \n\n\nValueError: Loading accuracy requires you to execute the dataset script in that repo on your local machine. Make sure you have read the code there to avoid malicious use, then set the option `trust_remote_code=True` to remove this error.\n\n\nThe dataset object itself is a DatasetDict, which contains one key per split (in this case, only “train” for a training split).\n\ndataset\n\nDatasetDict({\n    train: Dataset({\n        features: ['image', 'label'],\n        num_rows: 27000\n    })\n})\n\n\nTo access an actual element, you need to select a split first, then give an index:\n\nexample = dataset[\"train\"][10]\nexample\n\n{'image': &lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=64x64 at 0x7FF2F6277B10&gt;,\n 'label': 2}\n\n\nEach example consists of an image and a corresponding label. We can also verify this by checking the features of the dataset:\n\ndataset[\"train\"].features\n\n{'image': Image(decode=True, id=None),\n 'label': ClassLabel(num_classes=10, names=['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake'], id=None)}\n\n\nThe cool thing is that we can directly view the image (as the ‘image’ field is an Image feature), as follows:\n\nexample['image']\n\n\n\n\n\n\n\n\nLet’s make it a little bigger as the images in the EuroSAT dataset are of low resolution (64x64 pixels):\n\nexample['image'].resize((200, 200))\n\n\n\n\n\n\n\n\nLet’s print the corresponding label:\n\nexample['label']\n\n2\n\n\nAs you can see, the label field is not an actual string label. By default the ClassLabel fields are encoded into integers for convenience:\n\ndataset[\"train\"].features[\"label\"]\n\nClassLabel(num_classes=10, names=['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake'], id=None)\n\n\nLet’s create an id2label dictionary to decode them back to strings and see what they are. The inverse label2id will be useful too, when we load the model later.\n\nlabels = dataset[\"train\"].features[\"label\"].names\nlabel2id, id2label = dict(), dict()\nfor i, label in enumerate(labels):\n    label2id[label] = i\n    id2label[i] = label\n\nid2label[2]\n\n'HerbaceousVegetation'\n\n\n\n\n\nBefore we can feed these images to our model, we need to preprocess them.\nPreprocessing images typically comes down to (1) resizing them to a particular size (2) normalizing the color channels (R,G,B) using a mean and standard deviation. These are referred to as image transformations.\nIn addition, one typically performs what is called data augmentation during training (like random cropping and flipping) to make the model more robust and achieve higher accuracy. Data augmentation is also a great technique to increase the size of the training data.\nWe will use torchvision.transforms for the image transformations/data augmentation in this tutorial, but note that one can use any other package (like albumentations, imgaug, Kornia etc.).\nTo make sure we (1) resize to the appropriate size (2) use the appropriate image mean and standard deviation for the model architecture we are going to use, we instantiate what is called an image processor with the AutoImageProcessor.from_pretrained method.\nThis image processor is a minimal preprocessor that can be used to prepare images for inference.\n\nfrom transformers import AutoImageProcessor\n\nimage_processor  = AutoImageProcessor.from_pretrained(model_checkpoint)\nimage_processor\n\n\n\n\nViTFeatureExtractor {\n  \"do_normalize\": true,\n  \"do_resize\": true,\n  \"feature_extractor_type\": \"ViTFeatureExtractor\",\n  \"image_mean\": [\n    0.485,\n    0.456,\n    0.406\n  ],\n  \"image_std\": [\n    0.229,\n    0.224,\n    0.225\n  ],\n  \"resample\": 3,\n  \"size\": 224\n}\n\n\nThe Datasets library is made for processing data very easily. We can write custom functions, which can then be applied on an entire dataset (either using .map() or .set_transform()).\nHere we define 2 separate functions, one for training (which includes data augmentation) and one for validation (which only includes resizing, center cropping and normalizing).\n\nfrom torchvision.transforms import (\n    CenterCrop,\n    Compose,\n    Normalize,\n    RandomHorizontalFlip,\n    RandomResizedCrop,\n    Resize,\n    ToTensor,\n)\n\nnormalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\nif \"height\" in image_processor.size:\n    size = (image_processor.size[\"height\"], image_processor.size[\"width\"])\n    crop_size = size\n    max_size = None\nelif \"shortest_edge\" in image_processor.size:\n    size = image_processor.size[\"shortest_edge\"]\n    crop_size = (size, size)\n    max_size = image_processor.size.get(\"longest_edge\")\n\ntrain_transforms = Compose(\n        [\n            RandomResizedCrop(crop_size),\n            RandomHorizontalFlip(),\n            ToTensor(),\n            normalize,\n        ]\n    )\n\nval_transforms = Compose(\n        [\n            Resize(size),\n            CenterCrop(crop_size),\n            ToTensor(),\n            normalize,\n        ]\n    )\n\ndef preprocess_train(example_batch):\n    \"\"\"Apply train_transforms across a batch.\"\"\"\n    example_batch[\"pixel_values\"] = [\n        train_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]\n    ]\n    return example_batch\n\ndef preprocess_val(example_batch):\n    \"\"\"Apply val_transforms across a batch.\"\"\"\n    example_batch[\"pixel_values\"] = [val_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]]\n    return example_batch\n\nNext, we can preprocess our dataset by applying these functions. We will use the set_transform functionality, which allows to apply the functions above on-the-fly (meaning that they will only be applied when the images are loaded in RAM).\n\n# split up training into training + validation\nsplits = dataset[\"train\"].train_test_split(test_size=0.1)\ntrain_ds = splits['train']\nval_ds = splits['test']\n\n\ntrain_ds.set_transform(preprocess_train)\nval_ds.set_transform(preprocess_val)\n\nLet’s access an element to see that we’ve added a “pixel_values” feature:\n\ntrain_ds[0]\n\n{'image': &lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=64x64 at 0x7FF2EFFB0D90&gt;,\n 'label': 9,\n 'pixel_values': tensor([[[-0.3541, -0.3541, -0.3541,  ..., -0.3712, -0.3712, -0.3712],\n          [-0.3541, -0.3541, -0.3541,  ..., -0.3712, -0.3712, -0.3712],\n          [-0.3541, -0.3541, -0.3541,  ..., -0.3712, -0.3712, -0.3712],\n          ...,\n          [-0.4397, -0.4397, -0.4397,  ..., -0.4911, -0.4911, -0.4911],\n          [-0.4397, -0.4397, -0.4397,  ..., -0.4911, -0.4911, -0.4911],\n          [-0.4397, -0.4397, -0.4397,  ..., -0.4911, -0.4911, -0.4911]],\n \n         [[-0.2500, -0.2500, -0.2500,  ..., -0.2850, -0.2850, -0.2850],\n          [-0.2500, -0.2500, -0.2500,  ..., -0.2850, -0.2850, -0.2850],\n          [-0.2500, -0.2500, -0.2500,  ..., -0.2850, -0.2850, -0.2850],\n          ...,\n          [-0.3550, -0.3550, -0.3550,  ..., -0.4076, -0.4076, -0.4076],\n          [-0.3550, -0.3550, -0.3550,  ..., -0.4076, -0.4076, -0.4076],\n          [-0.3550, -0.3550, -0.3550,  ..., -0.4076, -0.4076, -0.4076]],\n \n         [[ 0.1128,  0.1128,  0.1128,  ...,  0.1651,  0.1651,  0.1651],\n          [ 0.1128,  0.1128,  0.1128,  ...,  0.1651,  0.1651,  0.1651],\n          [ 0.1128,  0.1128,  0.1128,  ...,  0.1651,  0.1651,  0.1651],\n          ...,\n          [ 0.0605,  0.0605,  0.0605,  ...,  0.0082,  0.0082,  0.0082],\n          [ 0.0605,  0.0605,  0.0605,  ...,  0.0082,  0.0082,  0.0082],\n          [ 0.0605,  0.0605,  0.0605,  ...,  0.0082,  0.0082,  0.0082]]])}\n\n\n\n\n\nNow that our data is ready, we can download the pretrained model and fine-tune it. For classification we use the AutoModelForImageClassification class. Calling the from_pretrained method on it will download and cache the weights for us. As the label ids and the number of labels are dataset dependent, we pass label2id, and id2label alongside the model_checkpoint here. This will make sure a custom classification head will be created (with a custom number of output neurons).\nNOTE: in case you’re planning to fine-tune an already fine-tuned checkpoint, like facebook/convnext-tiny-224 (which has already been fine-tuned on ImageNet-1k), then you need to provide the additional argument ignore_mismatched_sizes=True to the from_pretrained method. This will make sure the output head (with 1000 output neurons) is thrown away and replaced by a new, randomly initialized classification head that includes a custom number of output neurons. You don’t need to specify this argument in case the pre-trained model doesn’t include a head.\n\nfrom transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n\nmodel = AutoModelForImageClassification.from_pretrained(\n    model_checkpoint,\n    label2id=label2id,\n    id2label=id2label,\n    ignore_mismatched_sizes = True, # provide this in case you're planning to fine-tune an already fine-tuned checkpoint\n)\n\n\n\n\n\n\n\n/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\nSome weights of SwinForImageClassification were not initialized from the model checkpoint at microsoft/swin-tiny-patch4-window7-224 and are newly initialized because the shapes did not match:\n- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([10, 768]) in the model instantiated\n- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([10]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n\nThe warning is telling us we are throwing away some weights (the weights and bias of the classifier layer) and randomly initializing some other (the weights and bias of a new classifier layer). This is expected in this case, because we are adding a new head for which we don’t have pretrained weights, so the library warns us we should fine-tune this model before using it for inference, which is exactly what we are going to do.\nTo instantiate a Trainer, we will need to define the training configuration and the evaluation metric. The most important is the TrainingArguments, which is a class that contains all the attributes to customize the training. It requires one folder name, which will be used to save the checkpoints of the model.\nMost of the training arguments are pretty self-explanatory, but one that is quite important here is remove_unused_columns=False. This one will drop any features not used by the model’s call function. By default it’s True because usually it’s ideal to drop unused feature columns, making it easier to unpack inputs into the model’s call function. But, in our case, we need the unused features (‘image’ in particular) in order to create ‘pixel_values’.\n\nmodel_name = model_checkpoint.split(\"/\")[-1]\n\nargs = TrainingArguments(\n    f\"{model_name}-finetuned-eurosat\",\n    remove_unused_columns=False,\n    evaluation_strategy = \"epoch\",\n    save_strategy = \"epoch\",\n    learning_rate=5e-5,\n    per_device_train_batch_size=batch_size,\n    gradient_accumulation_steps=4,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=3,\n    warmup_ratio=0.1,\n    logging_steps=10,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"accuracy\",\n    push_to_hub=True,\n)\n\nHere we set the evaluation to be done at the end of each epoch, tweak the learning rate, use the batch_size defined at the top of the notebook and customize the number of epochs for training, as well as the weight decay. Since the best model might not be the one at the end of training, we ask the Trainer to load the best model it saved (according to metric_name) at the end of training.\nThe last argument push_to_hub allows the Trainer to push the model to the Hub regularly during training. Remove it if you didn’t follow the installation steps at the top of the notebook. If you want to save your model locally with a name that is different from the name of the repository, or if you want to push your model under an organization and not your name space, use the hub_model_id argument to set the repo name (it needs to be the full name, including your namespace: for instance \"nielsr/vit-finetuned-cifar10\" or \"huggingface/nielsr/vit-finetuned-cifar10\").\nNext, we need to define a function for how to compute the metrics from the predictions, which will just use the metric we loaded earlier. The only preprocessing we have to do is to take the argmax of our predicted logits:\n\nimport numpy as np\n\n# the compute_metrics function takes a Named Tuple as input:\n# predictions, which are the logits of the model as Numpy arrays,\n# and label_ids, which are the ground-truth labels as Numpy arrays.\ndef compute_metrics(eval_pred):\n    \"\"\"Computes accuracy on a batch of predictions\"\"\"\n    predictions = np.argmax(eval_pred.predictions, axis=1)\n    return metric.compute(predictions=predictions, references=eval_pred.label_ids)\n\nWe also define a collate_fn, which will be used to batch examples together. Each batch consists of 2 keys, namely pixel_values and labels.\n\nimport torch\n\ndef collate_fn(examples):\n    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n    labels = torch.tensor([example[\"label\"] for example in examples])\n    return {\"pixel_values\": pixel_values, \"labels\": labels}\n\nThen we just need to pass all of this along with our datasets to the Trainer:\n\ntrainer = Trainer(\n    model,\n    args,\n    train_dataset=train_ds,\n    eval_dataset=val_ds,\n    tokenizer=image_processor,\n    compute_metrics=compute_metrics,\n    data_collator=collate_fn,\n)\n\nCloning https://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat into local empty directory.\n\n\nYou might wonder why we pass along the image_processor as a tokenizer when we already preprocessed our data. This is only to make sure the image processor configuration file (stored as JSON) will also be uploaded to the repo on the hub.\nNow we can finetune our model by calling the train method:\n\ntrain_results = trainer.train()\n# rest is optional but nice to have\ntrainer.save_model()\ntrainer.log_metrics(\"train\", train_results.metrics)\ntrainer.save_metrics(\"train\", train_results.metrics)\ntrainer.save_state()\n\n/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 24300\n  Num Epochs = 3\n  Instantaneous batch size per device = 32\n  Total train batch size (w. parallel, distributed & accumulation) = 128\n  Gradient Accumulation steps = 4\n  Total optimization steps = 570\n***** Running Evaluation *****\n  Num examples = 2700\n  Batch size = 32\nSaving model checkpoint to swin-tiny-patch4-window7-224-finetuned-eurosat/checkpoint-190\nConfiguration saved in swin-tiny-patch4-window7-224-finetuned-eurosat/checkpoint-190/config.json\nModel weights saved in swin-tiny-patch4-window7-224-finetuned-eurosat/checkpoint-190/pytorch_model.bin\nFeature extractor saved in swin-tiny-patch4-window7-224-finetuned-eurosat/checkpoint-190/preprocessor_config.json\nFeature extractor saved in swin-tiny-patch4-window7-224-finetuned-eurosat/preprocessor_config.json\n***** Running Evaluation *****\n  Num examples = 2700\n  Batch size = 32\nSaving model checkpoint to swin-tiny-patch4-window7-224-finetuned-eurosat/checkpoint-380\nConfiguration saved in swin-tiny-patch4-window7-224-finetuned-eurosat/checkpoint-380/config.json\nModel weights saved in swin-tiny-patch4-window7-224-finetuned-eurosat/checkpoint-380/pytorch_model.bin\nFeature extractor saved in swin-tiny-patch4-window7-224-finetuned-eurosat/checkpoint-380/preprocessor_config.json\nFeature extractor saved in swin-tiny-patch4-window7-224-finetuned-eurosat/preprocessor_config.json\n***** Running Evaluation *****\n  Num examples = 2700\n  Batch size = 32\nSaving model checkpoint to swin-tiny-patch4-window7-224-finetuned-eurosat/checkpoint-570\nConfiguration saved in swin-tiny-patch4-window7-224-finetuned-eurosat/checkpoint-570/config.json\nModel weights saved in swin-tiny-patch4-window7-224-finetuned-eurosat/checkpoint-570/pytorch_model.bin\nFeature extractor saved in swin-tiny-patch4-window7-224-finetuned-eurosat/checkpoint-570/preprocessor_config.json\nFeature extractor saved in swin-tiny-patch4-window7-224-finetuned-eurosat/preprocessor_config.json\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\nLoading best model from swin-tiny-patch4-window7-224-finetuned-eurosat/checkpoint-570 (score: 0.9744444444444444).\nSaving model checkpoint to swin-tiny-patch4-window7-224-finetuned-eurosat\nConfiguration saved in swin-tiny-patch4-window7-224-finetuned-eurosat/config.json\nModel weights saved in swin-tiny-patch4-window7-224-finetuned-eurosat/pytorch_model.bin\nFeature extractor saved in swin-tiny-patch4-window7-224-finetuned-eurosat/preprocessor_config.json\nSaving model checkpoint to swin-tiny-patch4-window7-224-finetuned-eurosat\nConfiguration saved in swin-tiny-patch4-window7-224-finetuned-eurosat/config.json\nModel weights saved in swin-tiny-patch4-window7-224-finetuned-eurosat/pytorch_model.bin\nFeature extractor saved in swin-tiny-patch4-window7-224-finetuned-eurosat/preprocessor_config.json\nSeveral commits (2) will be pushed upstream.\nThe progress bars may be unreliable.\nTo https://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat\n   b46a767..6d6b8dc  main -&gt; main\n\nTo https://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat\n   6d6b8dc..25dd5d7  main -&gt; main\n\n\n\n\n    \n      \n      \n      [570/570 16:11, Epoch 3/3]\n    \n    \n\n\n\nEpoch\nTraining Loss\nValidation Loss\nAccuracy\n\n\n\n\n1\n0.262100\n0.108344\n0.962963\n\n\n2\n0.176900\n0.142533\n0.950000\n\n\n3\n0.134300\n0.066442\n0.974444\n\n\n\n\n\n\n\n\n\n\n\n\n***** train metrics *****\n  epoch                    =          3.0\n  total_flos               = 1687935228GF\n  train_loss               =       0.3276\n  train_runtime            =   0:16:13.91\n  train_samples_per_second =       74.852\n  train_steps_per_second   =        0.585\n\n\nWe can check with the evaluate method that our Trainer did reload the best model properly (if it was not the last one):\n\nmetrics = trainer.evaluate()\n# some nice to haves:\ntrainer.log_metrics(\"eval\", metrics)\ntrainer.save_metrics(\"eval\", metrics)\n\n***** Running Evaluation *****\n  Num examples = 2700\n  Batch size = 32\n\n\n\n    \n      \n      \n      [85/85 00:15]\n    \n    \n\n\n***** eval metrics *****\n  epoch                   =        3.0\n  eval_accuracy           =     0.9744\n  eval_loss               =     0.0664\n  eval_runtime            = 0:00:16.12\n  eval_samples_per_second =     167.48\n  eval_steps_per_second   =      5.273\n\n\nYou can now upload the result of the training to the Hub, just execute this instruction (note that the Trainer will automatically create a model card as well as Tensorboard logs - see the “Training metrics” tab - amazing isn’t it?):\n\ntrainer.push_to_hub()\n\nSaving model checkpoint to swin-tiny-patch4-window7-224-finetuned-eurosat\nConfiguration saved in swin-tiny-patch4-window7-224-finetuned-eurosat/config.json\nModel weights saved in swin-tiny-patch4-window7-224-finetuned-eurosat/pytorch_model.bin\nFeature extractor saved in swin-tiny-patch4-window7-224-finetuned-eurosat/preprocessor_config.json\nTo https://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat\n   25dd5d7..2164338  main -&gt; main\n\n\n\n\n\n\n'https://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat/commit/2164338db59d40004286bc65800bfa50561ecd3d'\n\n\nYou can now share this model with all your friends, family, favorite pets: they can all load it with the identifier \"your-username/the-name-you-picked\" so for instance:\nfrom transformers import AutoModelForImageClassification, AutoImageProcessor\n\nimage_processor = AutoImageProcessor.from_pretrained(\"nielsr/my-awesome-model\")\nmodel = AutoModelForImageClassification.from_pretrained(\"nielsr/my-awesome-model\")"
  },
  {
    "objectID": "공부/HF/2024-08-29-image_classification-2.html#inference",
    "href": "공부/HF/2024-08-29-image_classification-2.html#inference",
    "title": "(공부) image_classification 2",
    "section": "",
    "text": "Let’s say you have a new image, on which you’d like to make a prediction. Let’s load a satellite image of a forest (that’s not part of the EuroSAT dataset), and see how the model does.\n\nfrom PIL import Image\nimport requests\n\nurl = 'https://huggingface.co/nielsr/convnext-tiny-finetuned-eurostat/resolve/main/forest.png'\nimage = Image.open(requests.get(url, stream=True).raw)\nimage\n\n\n\n\n\n\n\n\nWe’ll load the image processor and model from the hub (here, we use the Auto Classes, which will make sure the appropriate classes will be loaded automatically based on the config.json and preprocessor_config.json files of the repo on the hub):\n\nfrom transformers import AutoModelForImageClassification, AutoImageProcessor\n\nrepo_name = \"nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat\"\n\nimage_processor = AutoImageProcessor.from_pretrained(repo_name)\nmodel = AutoModelForImageClassification.from_pretrained(repo_name)\n\nhttps://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat/resolve/main/preprocessor_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpqggthctf\nstoring https://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat/resolve/main/preprocessor_config.json in cache at /root/.cache/huggingface/transformers/7b742d61fc51f2ef5f81a75f80b26419c9f5bd86cc3022ed5784d09823f219f2.e34548f8325ec440fcf4990d4a8dbbfd665397400e9a700766de032d2b45cf6b\ncreating metadata file for /root/.cache/huggingface/transformers/7b742d61fc51f2ef5f81a75f80b26419c9f5bd86cc3022ed5784d09823f219f2.e34548f8325ec440fcf4990d4a8dbbfd665397400e9a700766de032d2b45cf6b\nloading feature extractor configuration file https://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat/resolve/main/preprocessor_config.json from cache at /root/.cache/huggingface/transformers/7b742d61fc51f2ef5f81a75f80b26419c9f5bd86cc3022ed5784d09823f219f2.e34548f8325ec440fcf4990d4a8dbbfd665397400e9a700766de032d2b45cf6b\nFeature extractor ViTFeatureExtractor {\n  \"do_normalize\": true,\n  \"do_resize\": true,\n  \"feature_extractor_type\": \"ViTFeatureExtractor\",\n  \"image_mean\": [\n    0.485,\n    0.456,\n    0.406\n  ],\n  \"image_std\": [\n    0.229,\n    0.224,\n    0.225\n  ],\n  \"resample\": 3,\n  \"size\": 224\n}\n\nhttps://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpzdd89w3g\nstoring https://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/83e4a1dea85e8e284e4da8ae1e3cf950c2c7e74d65a5a188049b3371fcd151bd.f1ed4852dd8f4c3d0c565427607bc41fff51b58ac73a0970bec8456e5c64cea0\ncreating metadata file for /root/.cache/huggingface/transformers/83e4a1dea85e8e284e4da8ae1e3cf950c2c7e74d65a5a188049b3371fcd151bd.f1ed4852dd8f4c3d0c565427607bc41fff51b58ac73a0970bec8456e5c64cea0\nloading configuration file https://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/83e4a1dea85e8e284e4da8ae1e3cf950c2c7e74d65a5a188049b3371fcd151bd.f1ed4852dd8f4c3d0c565427607bc41fff51b58ac73a0970bec8456e5c64cea0\nModel config SwinConfig {\n  \"_name_or_path\": \"nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat\",\n  \"architectures\": [\n    \"SwinForImageClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.0,\n  \"depths\": [\n    2,\n    2,\n    6,\n    2\n  ],\n  \"drop_path_rate\": 0.1,\n  \"embed_dim\": 96,\n  \"encoder_stride\": 32,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.0,\n  \"hidden_size\": 768,\n  \"id2label\": {\n    \"0\": \"AnnualCrop\",\n    \"1\": \"Forest\",\n    \"2\": \"HerbaceousVegetation\",\n    \"3\": \"Highway\",\n    \"4\": \"Industrial\",\n    \"5\": \"Pasture\",\n    \"6\": \"PermanentCrop\",\n    \"7\": \"Residential\",\n    \"8\": \"River\",\n    \"9\": \"SeaLake\"\n  },\n  \"image_size\": 224,\n  \"initializer_range\": 0.02,\n  \"label2id\": {\n    \"AnnualCrop\": 0,\n    \"Forest\": 1,\n    \"HerbaceousVegetation\": 2,\n    \"Highway\": 3,\n    \"Industrial\": 4,\n    \"Pasture\": 5,\n    \"PermanentCrop\": 6,\n    \"Residential\": 7,\n    \"River\": 8,\n    \"SeaLake\": 9\n  },\n  \"layer_norm_eps\": 1e-05,\n  \"mlp_ratio\": 4.0,\n  \"model_type\": \"swin\",\n  \"num_channels\": 3,\n  \"num_heads\": [\n    3,\n    6,\n    12,\n    24\n  ],\n  \"num_layers\": 4,\n  \"patch_size\": 4,\n  \"path_norm\": true,\n  \"problem_type\": \"single_label_classification\",\n  \"qkv_bias\": true,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.18.0\",\n  \"use_absolute_embeddings\": false,\n  \"window_size\": 7\n}\n\nhttps://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpkh0vdu53\nstoring https://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/3daadbe0cabef18dc0e2232ae080d135a9d4ee6b1dc7675725ef38bedb990b81.818e63819e125637bd8a94f43b6899d1552f0b45884f1c28c458a5cb55dfa9e5\ncreating metadata file for /root/.cache/huggingface/transformers/3daadbe0cabef18dc0e2232ae080d135a9d4ee6b1dc7675725ef38bedb990b81.818e63819e125637bd8a94f43b6899d1552f0b45884f1c28c458a5cb55dfa9e5\nloading weights file https://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/3daadbe0cabef18dc0e2232ae080d135a9d4ee6b1dc7675725ef38bedb990b81.818e63819e125637bd8a94f43b6899d1552f0b45884f1c28c458a5cb55dfa9e5\nAll model checkpoint weights were used when initializing SwinForImageClassification.\n\nAll the weights of SwinForImageClassification were initialized from the model checkpoint at nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use SwinForImageClassification for predictions without further training.\n\n\n\n\n\n\n\n\n\n\n\n\n# prepare image for the model\nencoding = image_processor(image.convert(\"RGB\"), return_tensors=\"pt\")\nprint(encoding.pixel_values.shape)\n\ntorch.Size([1, 3, 224, 224])\n\n\n\nimport torch\n\n# forward pass\nwith torch.no_grad():\n    outputs = model(**encoding)\n    logits = outputs.logits\n\n\npredicted_class_idx = logits.argmax(-1).item()\nprint(\"Predicted class:\", model.config.id2label[predicted_class_idx])\n\nPredicted class: Forest\n\n\nLooks like our model got it correct!"
  },
  {
    "objectID": "공부/HF/2024-08-29-image_classification-2.html#pipeline-api",
    "href": "공부/HF/2024-08-29-image_classification-2.html#pipeline-api",
    "title": "(공부) image_classification 2",
    "section": "",
    "text": "An alternative way to quickly perform inference with any model on the hub is by leveraging the Pipeline API, which abstracts away all the steps we did manually above for us. It will perform the preprocessing, forward pass and postprocessing all in a single object.\nLet’s showcase this for our trained model:\n\nfrom transformers import pipeline\n\npipe = pipeline(\"image-classification\", \"nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat\")\n\nloading configuration file https://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/83e4a1dea85e8e284e4da8ae1e3cf950c2c7e74d65a5a188049b3371fcd151bd.f1ed4852dd8f4c3d0c565427607bc41fff51b58ac73a0970bec8456e5c64cea0\nModel config SwinConfig {\n  \"_name_or_path\": \"nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat\",\n  \"architectures\": [\n    \"SwinForImageClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.0,\n  \"depths\": [\n    2,\n    2,\n    6,\n    2\n  ],\n  \"drop_path_rate\": 0.1,\n  \"embed_dim\": 96,\n  \"encoder_stride\": 32,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.0,\n  \"hidden_size\": 768,\n  \"id2label\": {\n    \"0\": \"AnnualCrop\",\n    \"1\": \"Forest\",\n    \"2\": \"HerbaceousVegetation\",\n    \"3\": \"Highway\",\n    \"4\": \"Industrial\",\n    \"5\": \"Pasture\",\n    \"6\": \"PermanentCrop\",\n    \"7\": \"Residential\",\n    \"8\": \"River\",\n    \"9\": \"SeaLake\"\n  },\n  \"image_size\": 224,\n  \"initializer_range\": 0.02,\n  \"label2id\": {\n    \"AnnualCrop\": 0,\n    \"Forest\": 1,\n    \"HerbaceousVegetation\": 2,\n    \"Highway\": 3,\n    \"Industrial\": 4,\n    \"Pasture\": 5,\n    \"PermanentCrop\": 6,\n    \"Residential\": 7,\n    \"River\": 8,\n    \"SeaLake\": 9\n  },\n  \"layer_norm_eps\": 1e-05,\n  \"mlp_ratio\": 4.0,\n  \"model_type\": \"swin\",\n  \"num_channels\": 3,\n  \"num_heads\": [\n    3,\n    6,\n    12,\n    24\n  ],\n  \"num_layers\": 4,\n  \"patch_size\": 4,\n  \"path_norm\": true,\n  \"problem_type\": \"single_label_classification\",\n  \"qkv_bias\": true,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.18.0\",\n  \"use_absolute_embeddings\": false,\n  \"window_size\": 7\n}\n\nloading configuration file https://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/83e4a1dea85e8e284e4da8ae1e3cf950c2c7e74d65a5a188049b3371fcd151bd.f1ed4852dd8f4c3d0c565427607bc41fff51b58ac73a0970bec8456e5c64cea0\nModel config SwinConfig {\n  \"_name_or_path\": \"nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat\",\n  \"architectures\": [\n    \"SwinForImageClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.0,\n  \"depths\": [\n    2,\n    2,\n    6,\n    2\n  ],\n  \"drop_path_rate\": 0.1,\n  \"embed_dim\": 96,\n  \"encoder_stride\": 32,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.0,\n  \"hidden_size\": 768,\n  \"id2label\": {\n    \"0\": \"AnnualCrop\",\n    \"1\": \"Forest\",\n    \"2\": \"HerbaceousVegetation\",\n    \"3\": \"Highway\",\n    \"4\": \"Industrial\",\n    \"5\": \"Pasture\",\n    \"6\": \"PermanentCrop\",\n    \"7\": \"Residential\",\n    \"8\": \"River\",\n    \"9\": \"SeaLake\"\n  },\n  \"image_size\": 224,\n  \"initializer_range\": 0.02,\n  \"label2id\": {\n    \"AnnualCrop\": 0,\n    \"Forest\": 1,\n    \"HerbaceousVegetation\": 2,\n    \"Highway\": 3,\n    \"Industrial\": 4,\n    \"Pasture\": 5,\n    \"PermanentCrop\": 6,\n    \"Residential\": 7,\n    \"River\": 8,\n    \"SeaLake\": 9\n  },\n  \"layer_norm_eps\": 1e-05,\n  \"mlp_ratio\": 4.0,\n  \"model_type\": \"swin\",\n  \"num_channels\": 3,\n  \"num_heads\": [\n    3,\n    6,\n    12,\n    24\n  ],\n  \"num_layers\": 4,\n  \"patch_size\": 4,\n  \"path_norm\": true,\n  \"problem_type\": \"single_label_classification\",\n  \"qkv_bias\": true,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.18.0\",\n  \"use_absolute_embeddings\": false,\n  \"window_size\": 7\n}\n\nloading weights file https://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/3daadbe0cabef18dc0e2232ae080d135a9d4ee6b1dc7675725ef38bedb990b81.818e63819e125637bd8a94f43b6899d1552f0b45884f1c28c458a5cb55dfa9e5\nAll model checkpoint weights were used when initializing SwinForImageClassification.\n\nAll the weights of SwinForImageClassification were initialized from the model checkpoint at nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use SwinForImageClassification for predictions without further training.\nloading feature extractor configuration file https://huggingface.co/nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat/resolve/main/preprocessor_config.json from cache at /root/.cache/huggingface/transformers/7b742d61fc51f2ef5f81a75f80b26419c9f5bd86cc3022ed5784d09823f219f2.e34548f8325ec440fcf4990d4a8dbbfd665397400e9a700766de032d2b45cf6b\nFeature extractor ViTFeatureExtractor {\n  \"do_normalize\": true,\n  \"do_resize\": true,\n  \"feature_extractor_type\": \"ViTFeatureExtractor\",\n  \"image_mean\": [\n    0.485,\n    0.456,\n    0.406\n  ],\n  \"image_std\": [\n    0.229,\n    0.224,\n    0.225\n  ],\n  \"resample\": 3,\n  \"size\": 224\n}\n\n\n\n\npipe(image)\n\n[{'label': 'Forest', 'score': 0.7000269889831543},\n {'label': 'HerbaceousVegetation', 'score': 0.14589950442314148},\n {'label': 'Pasture', 'score': 0.10370415449142456},\n {'label': 'Highway', 'score': 0.014327816665172577},\n {'label': 'Residential', 'score': 0.0139168007299304}]\n\n\nAs we can see, it does not only show the class label with the highest probability, but does return the top 5 labels, with their corresponding scores. Note that the pipelines also work with local models and mage processors:\n\npipe = pipeline(\"image-classification\",\n                model=model,\n                feature_extractor=image_processor)\n\n\npipe(image)\n\n[{'label': 'Forest', 'score': 0.7000269889831543},\n {'label': 'HerbaceousVegetation', 'score': 0.14589950442314148},\n {'label': 'Pasture', 'score': 0.10370415449142456},\n {'label': 'Highway', 'score': 0.014327816665172577},\n {'label': 'Residential', 'score': 0.0139168007299304}]"
  },
  {
    "objectID": "공부/HF/2024-11-09-(강의)-Dataset.html",
    "href": "공부/HF/2024-11-09-(강의)-Dataset.html",
    "title": "(강의) Dataset",
    "section": "",
    "text": "# !pip uninstall mp2024pkg -y\n# !pip install git+https://github.com/guebin/mp2024pkg.git\n\n\nimport pandas as pd\nimport numpy as np\nimport datasets \nimport transformers\nimport torch\nfrom mp2024pkg import signature, show\nfrom rich import print as rprint\n\n/home/cgb3/anaconda3/envs/hf/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n\n\nmodel = transformers.AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert/distilbert-base-uncased\", num_labels=2\n)\ntokenizer = transformers.AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference."
  },
  {
    "objectID": "공부/HF/2024-11-09-(강의)-Dataset.html#a.-.select",
    "href": "공부/HF/2024-11-09-(강의)-Dataset.html#a.-.select",
    "title": "(강의) Dataset",
    "section": "A. .select()",
    "text": "A. .select()\n# 예시1\n\nd = emotion['train'].select(range(8))\nd\n\nDataset({\n    features: ['text', 'label'],\n    num_rows: 8\n})\n\n\n\nshow(d.select(range(2)))\n\nList Overview:\nTotal items: 2\n\n1. list[0]\n   - Type: dict\n   - Length: 2\n   - Values: {'text': 'i didnt feel humiliated', 'label': 0}\n\n2. list[1]\n   - Type: dict\n   - Length: 2\n   - Values: {'text': 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake', 'label': 0}\n\n\n\nshow(d.select(range(1,3)))\n\nList Overview:\nTotal items: 2\n\n1. list[0]\n   - Type: dict\n   - Length: 2\n   - Values: {'text': 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake', 'label': 0}\n\n2. list[1]\n   - Type: dict\n   - Length: 2\n   - Values: {'text': 'im grabbing a minute to post i feel greedy wrong', 'label': 3}\n\n\n#"
  },
  {
    "objectID": "공부/HF/2024-11-09-(강의)-Dataset.html#b.-.shuffle",
    "href": "공부/HF/2024-11-09-(강의)-Dataset.html#b.-.shuffle",
    "title": "(강의) Dataset",
    "section": "B. .shuffle()",
    "text": "B. .shuffle()\n# 예시1\n\nd = emotion['train'].select(range(4))\nd\n\nDataset({\n    features: ['text', 'label'],\n    num_rows: 4\n})\n\n\n\nshow(d.shuffle())\n\nList Overview:\nTotal items: 4\n\n1. list[0]\n   - Type: dict\n   - Length: 2\n   - Values: {'text': 'im grabbing a minute to post i feel greedy wrong', 'label': 3}\n\n2. list[1]\n   - Type: dict\n   - Length: 2\n   - Values: {'text': 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property', 'label': 2}\n\n3. list[2]\n   - Type: dict\n   - Length: 2\n   - Values: {'text': 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake', 'label': 0}\n\n4. list[3]\n   - Type: dict\n   - Length: 2\n   - Values: {'text': 'i didnt feel humiliated', 'label': 0}\n\n\n#"
  },
  {
    "objectID": "공부/HF/2024-11-09-(강의)-Dataset.html#c.-.select_columns",
    "href": "공부/HF/2024-11-09-(강의)-Dataset.html#c.-.select_columns",
    "title": "(강의) Dataset",
    "section": "C. .select_columns()",
    "text": "C. .select_columns()\n# 예시1\n\nd = emotion['train'].select(range(4))\nd\n\nDataset({\n    features: ['text', 'label'],\n    num_rows: 4\n})\n\n\n\nd.select_columns(['text'])\n\nDataset({\n    features: ['text'],\n    num_rows: 4\n})\n\n\n\nd.select_columns(['label'])\n\nDataset({\n    features: ['label'],\n    num_rows: 4\n})\n\n\n\nd.select_columns(['text','label'])\n\nDataset({\n    features: ['text', 'label'],\n    num_rows: 4\n})\n\n\n#"
  },
  {
    "objectID": "공부/HF/2024-11-09-(강의)-Dataset.html#d.-.set_format",
    "href": "공부/HF/2024-11-09-(강의)-Dataset.html#d.-.set_format",
    "title": "(강의) Dataset",
    "section": "D. .set_format()",
    "text": "D. .set_format()\n# 예시1\n\nd = emotion['train'].select(range(4))\nd\n\nDataset({\n    features: ['text', 'label'],\n    num_rows: 4\n})\n\n\n\nd.set_format(type='pandas',columns=['label'])\n\n\nd['text']\n\n['i didnt feel humiliated',\n 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n 'im grabbing a minute to post i feel greedy wrong',\n 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property']\n\n\n\nd['label']\n\n0    0\n1    0\n2    3\n3    2\nName: label, dtype: int64\n\n\n#\n# 예시2\n\nd = emotion['train'].select(range(4))\nd\n\nDataset({\n    features: ['text', 'label'],\n    num_rows: 4\n})\n\n\n\nd.set_format(type='pandas',columns=['label','text'])\n\n\nd['text']\n\n0                              i didnt feel humiliated\n1    i can go from feeling so hopeless to so damned...\n2     im grabbing a minute to post i feel greedy wrong\n3    i am ever feeling nostalgic about the fireplac...\nName: text, dtype: object\n\n\n\nd['label']\n\n0    0\n1    0\n2    3\n3    2\nName: label, dtype: int64\n\n\n#\n# 예시3\n\nd = emotion['train'].select(range(4))\nd\n\nDataset({\n    features: ['text', 'label'],\n    num_rows: 4\n})\n\n\n\nd.set_format(type='pt',columns=['label'])\n\n\nd['text']\n\n['i didnt feel humiliated',\n 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n 'im grabbing a minute to post i feel greedy wrong',\n 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property']\n\n\n\nd['label']\n\ntensor([0, 0, 3, 2])\n\n\n#"
  },
  {
    "objectID": "공부/HF/2024-11-09-(강의)-Dataset.html#e.-.reset_format",
    "href": "공부/HF/2024-11-09-(강의)-Dataset.html#e.-.reset_format",
    "title": "(강의) Dataset",
    "section": "E. .reset_format()",
    "text": "E. .reset_format()\n# 예시1\n\nd = emotion['train'].select(range(4))\nd\n\nDataset({\n    features: ['text', 'label'],\n    num_rows: 4\n})\n\n\n\nd.set_format(type='torch',columns=['label'])\n\n\nd['text']\n\n['i didnt feel humiliated',\n 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n 'im grabbing a minute to post i feel greedy wrong',\n 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property']\n\n\n\nd['label']\n\ntensor([0, 0, 3, 2])\n\n\n\nd.reset_format()\n\n\nd['label']\n\n[0, 0, 3, 2]\n\n\n#"
  },
  {
    "objectID": "공부/HF/2024-11-09-(강의)-Dataset.html#a.-d.map",
    "href": "공부/HF/2024-11-09-(강의)-Dataset.html#a.-d.map",
    "title": "(강의) Dataset",
    "section": "A. d.map()",
    "text": "A. d.map()\n# 예제1 – .map()에 대한 이해\n아래와 같은 Dataset이 있다고 하자.\n\nd = emotion['train'].select(range(4))\nd\n\nDataset({\n    features: ['text', 'label'],\n    num_rows: 4\n})\n\n\nd.map()을 이용하여 아래와 같이 변환하라.\n\n\n\n\n\n\n\n\n데이터\n변환전\n변환후\n\n\n\n\nd[0]\ntext: strlabel: int\ntext: strlabel: intinput_ids: [int,…,int]attention_mask: [int,…,int]\n\n\nd[:1]\ntext: [str]label: [int]\ntext: [str]label: [int]input_ids: [[int,…,int]]attention_mask: [[int,…,int]]\n\n\n\n(풀이1) – d.map()을 사용하지 않은 풀이..\nd는 아래와 같은 구조로 이해할 수 있음\n\nd = [example_1, example_2, example_3, example_4]\nexample_i = {‘text’: xxx, ‘label’ = yyy}\n\n리스트화\n\nlst = list(d)\nlst\n\n[{'text': 'i didnt feel humiliated', 'label': 0},\n {'text': 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n  'label': 0},\n {'text': 'im grabbing a minute to post i feel greedy wrong', 'label': 3},\n {'text': 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property',\n  'label': 2}]\n\n\n리스트의 첫 요소에 변환적용\n\nl = lst[0]\nl\n\n{'text': 'i didnt feel humiliated', 'label': 0}\n\n\n\nr = tokenizer(l['text'])\nr\n\n{'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}\n\n\nl와 tokenizer(l['text'])을 합침\n\n# 예비학습\n{'a':[1,2,3], 'b':[4,5,6]} | {'c':[2,3,4]}\n\n{'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [2, 3, 4]}\n\n\n\nshow(l | r)\n\nDictionary Overview:\nTotal keys: 4\nKeys: ['text', 'label', 'input_ids', 'attention_mask']\n\n1. dict['text']\n   - Type: str\n   - Length: 23\n   - Values: i didnt feel humiliated\n2. dict['label']\n   - Type: int\n   - Values: 0\n3. dict['input_ids']\n   - Type: list\n   - Length: 7\n   - Values: [101, 1045, 2134, 2102, 2514, 26608, 102]\n4. dict['attention_mask']\n   - Type: list\n   - Length: 7\n   - Values: [1, 1, 1, 1, 1, 1, 1]\n\n\n반복\n\ndef m_transform(example):\n    # example = l = {'text': xxx, 'label':yyy} \n    result = tokenizer(example['text'])\n    return result\n\n\nlst2 = [l | m_transform(l) for l in lst]\n\n\nd2 = datasets.Dataset.from_list(lst2)\nd2\n\nDataset({\n    features: ['text', 'label', 'input_ids', 'attention_mask'],\n    num_rows: 4\n})\n\n\n\nd2[0]\n\n{'text': 'i didnt feel humiliated',\n 'label': 0,\n 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}\n\n\n\nd2[:1]\n\n{'text': ['i didnt feel humiliated'],\n 'label': [0],\n 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]],\n 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]]}\n\n\n(풀이2)\n\ndef m_transform(example):\n    # example = l = {'text': xxx, 'label':yyy} \n    rsult = tokenizer(example['text'])\n    return rsult\n\n\nd2 = d.map(m_transform)\n\n\nd2[0]\n\n{'text': 'i didnt feel humiliated',\n 'label': 0,\n 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}\n\n\n\nd2[:1]\n\n{'text': ['i didnt feel humiliated'],\n 'label': [0],\n 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]],\n 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]]}\n\n\n#\n:::{.callout-note}\n.map()의 특징\n\n특징1: .map()은 입력으로 example = {'text':xxx, 'label':yyy} 꼴을 가정한다.\n특징2: .map()은 변환전 dict와 변환후 dict를 합친다."
  },
  {
    "objectID": "공부/HF/2024-11-09-(강의)-Dataset.html#b.-dd.map",
    "href": "공부/HF/2024-11-09-(강의)-Dataset.html#b.-dd.map",
    "title": "(강의) Dataset",
    "section": "B. dd.map()",
    "text": "B. dd.map()\n# 예제1 – dd에도 .map을 적용할 수 있음\n아래와 같은 DatasetDict가 있다고 하자.\n\ndd = datasets.DatasetDict({\n    'train':emotion['train'].select(range(4)),\n    'test':emotion['test'].select(range(4)),\n})\ndd\n\nDatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 4\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 4\n    })\n})\n\n\ndd.map()을 이용하여 아래와 같이 변환하라.\n\n\n\n\n\n\n\n\n\ntr/test\n데이터\n변환전\n변환후\n\n\n\n\ntrain\nd[0]\ntext: strlabel: int\ntext: strlabel: intinput_ids: [int,…,int]attention_mask: [int,…,int]\n\n\ntrain\nd[:1]\ntext: [str]label: [int]\ntext: [str]label: [int]input_ids: [[int,…,int]]attention_mask: [[int,…,int]]\n\n\ntest\nd[0]\ntext: strlabel: int\ntext: strlabel: intinput_ids: [int,…,int]attention_mask: [int,…,int]\n\n\ntest\nd[:1]\ntext: [str]label: [int]\ntext: [str]label: [int]input_ids: [[int,…,int]]attention_mask: [[int,…,int]]\n\n\n\n(풀이)\n\ndef m_transform(example):\n    # example = {'text': xxx, 'label': yyy} \n    result = tokenizer(example['text'])\n    return result\n\n\ndd.map(m_transform)\n\nDatasetDict({\n    train: Dataset({\n        features: ['text', 'label', 'input_ids', 'attention_mask'],\n        num_rows: 4\n    })\n    test: Dataset({\n        features: ['text', 'label', 'input_ids', 'attention_mask'],\n        num_rows: 4\n    })\n})\n\n\n#"
  },
  {
    "objectID": "공부/HF/2024-11-09-(강의)-Dataset.html#c.-d.mapbatchtrue",
    "href": "공부/HF/2024-11-09-(강의)-Dataset.html#c.-d.mapbatchtrue",
    "title": "(강의) Dataset",
    "section": "C. d.map(batch=True)",
    "text": "C. d.map(batch=True)\n# 예제1 – d.map(batch=True)의 이해\n아래와 같은 Dataset이 있다고 하자.\n\nd = emotion['train'].select(range(8))\nd\n\nDataset({\n    features: ['text', 'label'],\n    num_rows: 8\n})\n\n\nd.map(batch=True)을 이용하여 아래와 같이 변환하라.\n\n\n\n\n\n\n\n\n\n데이터\n변환전\n변환후\n특이사항\n\n\n\n\nd[0]\ntext: strlabel: int\ntext: strlabel: intinput_ids: [int,…,int]attention_mask: [int,…,int]\n변환시 2개의 observation씩 묶어서 패딩\n\n\nd[:1]\ntext: [str]label: [int]\ntext: [str]label: [int]input_ids: [[int,…,int]]attention_mask: [[int,…,int]]\n변환시 2개의 observation씩 묶어서 패딩\n\n\n\n(풀이1) – 실패\n\ndef m_transform(example):\n    # example = {'text': xxx, 'label': yyy}\n    result = tokenizer(example['text'],padding=True)\n    return result\n\n\nd2 = d.map(m_transform)\nd2\n\nMap: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00&lt;00:00, 1205.26 examples/s]\n\n\nDataset({\n    features: ['text', 'label', 'input_ids', 'attention_mask'],\n    num_rows: 8\n})\n\n\n\nrprint(\"d2[:4]['input_ids']\")\nshow(d2[:4]['input_ids'])\n\nd2[:4]['input_ids']\n\n\n\nList Overview:\nTotal items: 4\n\n1. list[0]\n   - Type: list\n   - Length: 7\n   - Values: [101, 1045, 2134, 2102, 2514, 26608, 102]\n\n2. list[1]\n   - Type: list\n   - Length: 23\n   - Values: [101, 1045, 2064, 2175, 2013, 3110, 2061, 20625, 2000, 2061, 9636, 17772, 2074, 2013, 2108, 2105, 2619, 2040, 14977, 1998, 2003, 8300, 102]\n\n3. list[2]\n   - Type: list\n   - Length: 12\n   - Values: [101, 10047, 9775, 1037, 3371, 2000, 2695, 1045, 2514, 20505, 3308, 102]\n\n4. list[3]\n   - Type: list\n   - Length: 22\n   - Values: [101, 1045, 2572, 2412, 3110, 16839, 9080, 12863, 2055, 1996, 13788, 1045, 2097, 2113, 2008, 2009, 2003, 2145, 2006, 1996, 3200, 102]\n\n\n(풀이2) – 성공\n\n# def m_transform(example):\n#     # example = {'text': xxx, 'label': yyy}\n#     result = tokenizer(example['text'], padding=True)\n#     return result\n\ndef m_transform_batch(example_batch):\n    #example_batch = {'text': [xxx,xxxx], 'label': [yyy,yyyy]}\n    result = tokenizer(example_batch['text'], padding=True)\n    return result\n\n\nd2 = d.map(m_transform_batch,batch_size=2,batched=True)\nd2\n\nMap: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00&lt;00:00, 1426.51 examples/s]\n\n\nDataset({\n    features: ['text', 'label', 'input_ids', 'attention_mask'],\n    num_rows: 8\n})\n\n\n\nrprint(\"d2[:4]['input_ids']\")\nshow(d2[:4]['input_ids'])\n\nd2[:4]['input_ids']\n\n\n\nList Overview:\nTotal items: 4\n\n1. list[0]\n   - Type: list\n   - Length: 23\n   - Values: [101, 1045, 2134, 2102, 2514, 26608, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n\n2. list[1]\n   - Type: list\n   - Length: 23\n   - Values: [101, 1045, 2064, 2175, 2013, 3110, 2061, 20625, 2000, 2061, 9636, 17772, 2074, 2013, 2108, 2105, 2619, 2040, 14977, 1998, 2003, 8300, 102]\n\n3. list[2]\n   - Type: list\n   - Length: 22\n   - Values: [101, 10047, 9775, 1037, 3371, 2000, 2695, 1045, 2514, 20505, 3308, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n\n4. list[3]\n   - Type: list\n   - Length: 22\n   - Values: [101, 1045, 2572, 2412, 3110, 16839, 9080, 12863, 2055, 1996, 13788, 1045, 2097, 2113, 2008, 2009, 2003, 2145, 2006, 1996, 3200, 102]\n\n\n#\n:::{.callout-note}\n.map(batch=True)의 특징\n\n특징1: .map(batch=True)은 입력으로 example_batch = {'text':[xxx,xxxx,...], 'label':[yyy,yyyy,...]} 꼴을 가정한다.\n특징2: example_batch는 batch_size 만큼 데이터가 있다고 생각한다. `"
  },
  {
    "objectID": "공부/HF/2024-11-09-(강의)-Dataset.html#d.-d.map-칼럼선택",
    "href": "공부/HF/2024-11-09-(강의)-Dataset.html#d.-d.map-칼럼선택",
    "title": "(강의) Dataset",
    "section": "D. d.map() + 칼럼선택",
    "text": "D. d.map() + 칼럼선택\n# 예제1 – attention_maks 제외\n아래와 같은 Dataset이 있다고 하자.\n\nd = emotion['train'].select(range(4))\nd\n\nDataset({\n    features: ['text', 'label'],\n    num_rows: 4\n})\n\n\nd.map()을 이용하여 아래와 같이 변환하라.\n\n\n\n\n\n\n\n\n데이터\n변환전\n변환후\n\n\n\n\nd[0]\ntext: strlabel: int\ntext: strlabel: intinput_ids: [int,…,int]\n\n\nd[:1]\ntext: [str]label: [int]\ntext: [str]label: [int]input_ids: [[int,…,int]]\n\n\n\n(풀이1)\n\ndef m_transform(example):\n    # example = {'text': xxx, 'label': yyy} \n    result = tokenizer(example['text'])\n    del result['attention_mask'] \n    return result\n\n\nd2 = d.map(m_transform)\nd2\n\nMap: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00&lt;00:00, 761.53 examples/s]\n\n\nDataset({\n    features: ['text', 'label', 'input_ids'],\n    num_rows: 4\n})\n\n\n\nd2[0]\n\n{'text': 'i didnt feel humiliated',\n 'label': 0,\n 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102]}\n\n\n\nd2[:1]\n\n{'text': ['i didnt feel humiliated'],\n 'label': [0],\n 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]]}\n\n\n(풀이2)\n\ndef m_transform(example):\n    # example = {'text': xxx, 'label': yyy} \n    result = tokenizer(example['text'])\n    return result\n\n\nd2 = d.map(m_transform)\nd2 = d2.select_columns(['text','label','input_ids'])\nd2\n\nDataset({\n    features: ['text', 'label', 'input_ids'],\n    num_rows: 4\n})\n\n\n\nd2[0]\n\n{'text': 'i didnt feel humiliated',\n 'label': 0,\n 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102]}\n\n\n\nd2[:1]\n\n{'text': ['i didnt feel humiliated'],\n 'label': [0],\n 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]]}\n\n\n#\n# 예제2 – text 제외\n아래와 같은 Dataset이 있다고 하자.\n\nd = emotion['train'].select(range(4))\nd\n\nDataset({\n    features: ['text', 'label'],\n    num_rows: 4\n})\n\n\nd.map()을 이용하여 아래와 같이 변환하라.\n\n\n\n\n\n\n\n\n데이터\n변환전\n변환후\n\n\n\n\nd[0]\ntext: strlabel: int\nlabel: intinput_ids: [int,…,int]attention_mask: [int,…,int]\n\n\nd[:1]\ntext: [str]label: [int]\nlabel: [int]input_ids: [[int,…,int]]attention_mask: [[int,…,int]]\n\n\n\n(풀이1)\n\ndef m_transform(example):\n    # example = {'text': xxx, 'label': yyy} \n    result = tokenizer(example['text'])\n    del example['text'] \n    return result\n\n\nd2 = d.map(m_transform)\nd2\n\nDataset({\n    features: ['label', 'input_ids', 'attention_mask'],\n    num_rows: 4\n})\n\n\n\nd2[0]\n\n{'label': 0,\n 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}\n\n\n\nd2[:1]\n\n{'label': [0],\n 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]],\n 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]]}\n\n\n(풀이2)\n\ndef m_transform(example):\n    # example = {'text': xxx, 'label': yyy} \n    result = tokenizer(example['text'],padding=True)\n    return result\n\n\nd2 = d.map(m_transform)\nd2.select_columns(['text','label','input_ids'])\nd2\n\nDataset({\n    features: ['text', 'label', 'input_ids', 'attention_mask'],\n    num_rows: 4\n})\n\n\n\nd2[0]\n\n{'text': 'i didnt feel humiliated',\n 'label': 0,\n 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}\n\n\n\nd2[:1]\n\n{'text': ['i didnt feel humiliated'],\n 'label': [0],\n 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]],\n 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]]}\n\n\n#\n:::{.callout-note}\n.map()에서 컬럼을 제외하려면?\n\ndel을 이용한 풀이: 제외하고자 하는 column이 example에 있을 경우, result에 있을 경우 미묘하게 다름.\nselect를 이용한 풀이: 제외하고자 하는 column이 example에 있든지 result에 있든지 상관없음."
  },
  {
    "objectID": "공부/HF/2024-11-09-(강의)-Dataset.html#e.-d.map-타입변환-star",
    "href": "공부/HF/2024-11-09-(강의)-Dataset.html#e.-d.map-타입변환-star",
    "title": "(강의) Dataset",
    "section": "E. d.map() + 타입변환 (\\(\\star\\))",
    "text": "E. d.map() + 타입변환 (\\(\\star\\))\n# 예제1 – .map()을 이용한 타입변환은 불가능\n아래와 같은 Dataset이 있다고 하자.\n\nd = emotion['train'].select(range(4))\nd\n\nDataset({\n    features: ['text', 'label'],\n    num_rows: 4\n})\n\n\nd.map()을 이용하여 아래와 같이 변환하라.\n\n\n\n\n\n\n\n\n데이터\n변환전\n변환후\n\n\n\n\nd[0]\ntext: strlabel: int\nlabel: intinput_ids: tensor([int,…,int])attention_mask: tensor([int,…,int])\n\n\nd[:1]\ntext: [str]label: [int]\nlabel:[int]input_ids: tensor([[int,…,int]])attention_mask: tensor([[int,…,int]])\n\n\n\n(풀이1) – 실패\n\ndef m_transform(example):\n    # example = {'text': xxx, 'label': yyy} \n    result = tokenizer(example['text'])\n    del example['text']\n    result['input_ids'] = torch.tensor(result['input_ids'])\n    result['attention_mask'] = torch.tensor(result['attention_mask'])\n    return result\n\n\nd2 = d.map(m_transform)\nd2\n\nDataset({\n    features: ['label', 'input_ids', 'attention_mask'],\n    num_rows: 4\n})\n\n\n\nd2[0]\n\n{'label': 0,\n 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}\n\n\n\nd2[:1]\n\n{'label': [0],\n 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]],\n 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]]}\n\n\n(풀이2) – 실패\n\ndef m_transform(example):\n    # example = {'text': xxx, 'label': yyy} \n    result = tokenizer(example['text'], return_tensors='pt')\n    del example['text']\n    return result\n\n\nd2 = d.map(m_transform)\nd2\n\nDataset({\n    features: ['label', 'input_ids', 'attention_mask'],\n    num_rows: 4\n})\n\n\n\nd2[0]\n\n{'label': 0,\n 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]],\n 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]]}\n\n\n\nd2[:1]\n\n{'label': [0],\n 'input_ids': [[[101, 1045, 2134, 2102, 2514, 26608, 102]]],\n 'attention_mask': [[[1, 1, 1, 1, 1, 1, 1]]]}\n\n\n\n더 이상해짐.. 차원까지 이상함.. 차원이 문제가 아니고 형태가 아예 안바뀜..\n\n(풀이3) – 성공??\n\ndef m_transform(example):\n    # example = {'text': xxx, 'label': yyy} \n    result = tokenizer(example['text'])\n    return result\n\n\nd2 = d.map(m_transform)\nd2\n\nDataset({\n    features: ['text', 'label', 'input_ids', 'attention_mask'],\n    num_rows: 4\n})\n\n\n\nd2.set_format(type='pt',columns=['input_ids','attention_mask'])\n\n\nd2[0]\n\n{'input_ids': tensor([  101,  1045,  2134,  2102,  2514, 26608,   102]),\n 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])}\n\n\n\nd2[:1]\n\n{'input_ids': tensor([[  101,  1045,  2134,  2102,  2514, 26608,   102]]),\n 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}\n\n\n\nd2[:2] # 희한하게 나오네..\n\n{'input_ids': [tensor([  101,  1045,  2134,  2102,  2514, 26608,   102]),\n  tensor([  101,  1045,  2064,  2175,  2013,  3110,  2061, 20625,  2000,  2061,\n           9636, 17772,  2074,  2013,  2108,  2105,  2619,  2040, 14977,  1998,\n           2003,  8300,   102])],\n 'attention_mask': [tensor([1, 1, 1, 1, 1, 1, 1]),\n  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])]}\n\n\n#"
  },
  {
    "objectID": "공부/HF/2024-11-09-(강의)-Dataset.html#a.-d.with_transform",
    "href": "공부/HF/2024-11-09-(강의)-Dataset.html#a.-d.with_transform",
    "title": "(강의) Dataset",
    "section": "A. d.with_transform()",
    "text": "A. d.with_transform()\n# 예제1\n아래와 같은 Dataset이 있다고 하자.\n\nd = emotion['train'].select(range(4))\nd\n\nDataset({\n    features: ['text', 'label'],\n    num_rows: 4\n})\n\n\nd.with_transform()을 이용하여 아래와 같이 변환하라.\n\n\n\n\n\n\n\n\n데이터\n변환전\n변환후\n\n\n\n\nd[0]\ntext: strlabel: int\ntext: strlabel: intinput_ids: [int,…,int]attention_mask: [int,…,int]\n\n\nd[:1]\ntext: [str]label: [int]\ntext: [str]label: [int]input_ids: [[int,…,int]]attention_mask: [[int,…,int]]\n\n\n\n(풀이)\n\ndef w_transform(examples):\n    result = tokenizer(examples['text'])\n    result = result | examples\n    return result\n\n\nd2 = d.with_transform(w_transform)\n\n\nd2[0]\n\n{'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n 'attention_mask': [1, 1, 1, 1, 1, 1, 1],\n 'text': 'i didnt feel humiliated',\n 'label': 0}\n\n\n\nd2[:1]\n\n{'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]], 'text': ['i didnt feel humiliated'], 'label': [0]}\n\n\n#\n:::{.callout-note}\n.with_transform()와 .map()의 차이점\n\n.map()은 입력으로 example꼴을, .with_transform()은 입력으로 examples를 기대한다.\n.map()은 변환전과 변환후 데이터가 자동으로 합쳐진다. .with_transform()은 변환후 데이터만 살아남는다.\n.map()은 변환이 실제로 이루어진다. .with_transform()은 변환이 실제로 이루어지지 않다가 d[0],d[:1] 등이 실행하는 순간 이루어진다.\n\n# 예제2\n아래와 같은 Dataset이 있다고 하자.\n\nd = emotion['train'].select(range(4))\nd\n\nDataset({\n    features: ['text', 'label'],\n    num_rows: 4\n})\n\n\nd.with_transform()을 이용하여 아래와 같이 변환하라.\n\n\n\n\n\n\n\n\n데이터\n변환전\n변환후\n\n\n\n\nd[0]\ntext: strlabel: int\ntext: strlabel: intinput_ids: [int,…,int]\n\n\nd[:1]\ntext: [str]label: [int]\ntext: [str]label: [int]input_ids: [[int,…,int]]\n\n\n\n(풀이)\n\ndef w_transform(examples):\n    # examples = {'text': [xxx,xxxx,xxxxx], 'label': [yyy,yyyy,yyyyy]} \n    result = tokenizer(examples['text'])\n    result = examples | result \n    del result['attention_mask']\n    return result\n\n\nd2 = d.with_transform(w_transform)\n\n\nd2[0]\n\n{'text': 'i didnt feel humiliated',\n 'label': 0,\n 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102]}\n\n\n\nd2[0:1]\n\n{'text': ['i didnt feel humiliated'], 'label': [0], 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]]}\n\n\n#\n# 예제3\n아래와 같은 Dataset이 있다고 하자.\n\nd = emotion['train'].select(range(4))\nd\n\nDataset({\n    features: ['text', 'label'],\n    num_rows: 4\n})\n\n\nd.with_transform()을 이용하여 아래와 같이 변환하라.\n\n\n\n\n\n\n\n\n데이터\n변환전\n변환후\n\n\n\n\nd[0]\ntext: strlabel: int\nlabel: intinput_ids: [int,…,int]attention_mask: [int,…,int]\n\n\nd[:1]\ntext: [str]label: [int]\nlabel: [int]input_ids: [[int,…,int]]attention_mask: [[int,…,int]]\n\n\n\n(풀이)\n\ndef w_transform(examples):\n    # examples = {'text': [xxx,xxxx,xxxxx], 'label': [yyy,yyyy,yyyyy]} \n    result = tokenizer(examples['text'])\n    result['label'] = examples['label']\n    return result\n\n\nd2 = d.with_transform(w_transform)\n\n\nd2[0]\n\n{'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n 'attention_mask': [1, 1, 1, 1, 1, 1, 1],\n 'label': 0}\n\n\n\nd2[:1]\n\n{'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]], 'label': [0]}\n\n\n#\n# 예제4\n아래와 같은 Dataset이 있다고 하자.\n\nd = emotion['train'].select(range(4))\nd\n\nDataset({\n    features: ['text', 'label'],\n    num_rows: 4\n})\n\n\nd.with_transform()을 이용하여 아래와 같이 변환하라.\n\n\n\n\n\n\n\n\n데이터\n변환전\n변환후\n\n\n\n\nd[0]\ntext: strlabel: int\nlabel: tensor(int)input_ids: tensor([int,…,int])attention_mask: tensor([int,…,int])\n\n\nd[:1]\ntext: [str]label: [int]\nlabel: tensor([int])input_ids: tensor([[int,…,int]])attention_mask: tensor([[int,…,int]])\n\n\n\n(풀이) – 실패\n\ndef w_transform(examples):\n    # examples = {'text': [xxx,xxxx,xxxxx], 'label': [yyy,yyyy,yyyyy]} \n    result = tokenizer(examples['text'])\n    result['label'] = torch.tensor(examples['label'])\n    result['input_ids'] = torch.tensor(result['input_ids'])\n    result['attention_mask'] = torch.tensor(result['attention_mask'])\n    return result\n\n\nd2 = d.with_transform(w_transform)\nd2\n\nDataset({\n    features: ['text', 'label'],\n    num_rows: 4\n})\n\n\n\nd2[0]\n\n{'input_ids': tensor([  101,  1045,  2134,  2102,  2514, 26608,   102]),\n 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1]),\n 'label': tensor(0)}\n\n\n\nd2[:1]\n\n{'input_ids': tensor([[  101,  1045,  2134,  2102,  2514, 26608,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]]), 'label': tensor([0])}\n\n\n\nd2[:2]\n\nValueError: expected sequence of length 7 at dim 1 (got 23)\n\n\n에러나는이유\n\nd[:2]['text']\n\n['i didnt feel humiliated',\n 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake']\n\n\n\nresult = tokenizer(d[:2]['text'])\nresult\n\n{'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102], [101, 1045, 2064, 2175, 2013, 3110, 2061, 20625, 2000, 2061, 9636, 17772, 2074, 2013, 2108, 2105, 2619, 2040, 14977, 1998, 2003, 8300, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n\n\n\ntorch.tensor(result['input_ids'])\n\nValueError: expected sequence of length 7 at dim 1 (got 23)\n\n\n\n패딩………\n\n(풀이2) – 성공\n\ndef w_transform(examples):\n    # examples = {'text': [xxx,xxxx,xxxxx], 'label': [yyy,yyyy,yyyyy]} \n    result = tokenizer(examples['text'],padding=True)\n    result['label'] = torch.tensor(examples['label'])\n    result['input_ids'] = torch.tensor(result['input_ids'])\n    result['attention_mask'] = torch.tensor(result['attention_mask'])\n    return result\n\n\nd2 = d.with_transform(w_transform)\nd2\n\nDataset({\n    features: ['text', 'label'],\n    num_rows: 4\n})\n\n\n\nd2[0]\n\n{'input_ids': tensor([  101,  1045,  2134,  2102,  2514, 26608,   102]),\n 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1]),\n 'label': tensor(0)}\n\n\n\nd2[:1]\n\n{'input_ids': tensor([[  101,  1045,  2134,  2102,  2514, 26608,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]]), 'label': tensor([0])}\n\n\n\nd2[:2]\n\n{'input_ids': tensor([[  101,  1045,  2134,  2102,  2514, 26608,   102,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0],\n        [  101,  1045,  2064,  2175,  2013,  3110,  2061, 20625,  2000,  2061,\n          9636, 17772,  2074,  2013,  2108,  2105,  2619,  2040, 14977,  1998,\n          2003,  8300,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'label': tensor([0, 0])}\n\n\n(풀이3) – 이것도 성공..\n\ndef w_transform(examples):\n    # examples = {'text': [xxx,xxxx,xxxxx], 'label': [yyy,yyyy,yyyyy]} \n    result = tokenizer(examples['text'],padding=True,return_tensors=\"pt\")\n    result['label'] = torch.tensor(examples['label'])\n    return result\n\n\nd2 = d.with_transform(w_transform)\nd2\n\nDataset({\n    features: ['text', 'label'],\n    num_rows: 4\n})\n\n\n\nd2[0]\n\n{'input_ids': tensor([  101,  1045,  2134,  2102,  2514, 26608,   102]),\n 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1]),\n 'label': tensor(0)}\n\n\n\nd2[:1]\n\n{'input_ids': tensor([[  101,  1045,  2134,  2102,  2514, 26608,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]]), 'label': tensor([0])}\n\n\n\nd2[:2]\n\n{'input_ids': tensor([[  101,  1045,  2134,  2102,  2514, 26608,   102,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0],\n        [  101,  1045,  2064,  2175,  2013,  3110,  2061, 20625,  2000,  2061,\n          9636, 17772,  2074,  2013,  2108,  2105,  2619,  2040, 14977,  1998,\n          2003,  8300,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'label': tensor([0, 0])}\n\n\n#"
  },
  {
    "objectID": "공부/HF/2024-11-09-(강의)-Dataset.html#b.-dd.with_transform",
    "href": "공부/HF/2024-11-09-(강의)-Dataset.html#b.-dd.with_transform",
    "title": "(강의) Dataset",
    "section": "B. dd.with_transform()",
    "text": "B. dd.with_transform()\n# 예제1\n아래와 같은 DatasetDict가 있다고 하자.\n\ndd = datasets.DatasetDict({\n    'train':emotion['train'].select(range(4)),\n    'test':emotion['test'].select(range(4)),\n})\ndd\n\nDatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 4\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 4\n    })\n})\n\n\ndd.map()을 이용하여 아래와 같이 변환하라.\n\n\n\n\n\n\n\n\n\ntr/test\n데이터\n변환전\n변환후\n\n\n\n\ntrain\nd[0]\ntext: strlabel: int\ntext: strlabel: intinput_ids: [int,…,int]attention_mask: [int,…,int]\n\n\ntrain\nd[:1]\ntext: [str]label: [int]\ntext: [str]label: [int]input_ids: [[int,…,int]]attention_mask: [[int,…,int]]\n\n\ntest\nd[0]\ntext: strlabel: int\ntext: strlabel: intinput_ids: [int,…,int]attention_mask: [int,…,int]\n\n\ntest\nd[:1]\ntext: [str]label: [int]\ntext: [str]label: [int]input_ids: [[int,…,int]]attention_mask: [[int,…,int]]\n\n\n\n(풀이)\n\ndef w_transform(examples):\n    result = tokenizer(examples['text'])\n    result = examples | result\n    return result\n\n\ndd2 = dd.with_transform(w_transform)\n\n\ndd2['train'][0]\n\n{'text': 'i didnt feel humiliated',\n 'label': 0,\n 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}\n\n\n\ndd2['train'][:1]\n\n{'text': ['i didnt feel humiliated'], 'label': [0], 'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]]}\n\n\n#"
  },
  {
    "objectID": "공부/HF/2024-11-09-(강의)-Dataset.html#c.-d.reset_format",
    "href": "공부/HF/2024-11-09-(강의)-Dataset.html#c.-d.reset_format",
    "title": "(강의) Dataset",
    "section": "C. d.reset_format()",
    "text": "C. d.reset_format()\n# 예시1\n\nd = emotion['train'].select(range(4))\nd\n\nDataset({\n    features: ['text', 'label'],\n    num_rows: 4\n})\n\n\n\ndef w_transform(examples):\n    result = tokenizer(examples['text'])\n    result = result | examples\n    return result\n\n\nd2 = d.with_transform(w_transform)\n\n\nd2[0]\n\n{'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n 'attention_mask': [1, 1, 1, 1, 1, 1, 1],\n 'text': 'i didnt feel humiliated',\n 'label': 0}\n\n\n\nd2[:1]\n\n{'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]], 'text': ['i didnt feel humiliated'], 'label': [0]}\n\n\n\nd2.reset_format()\n\n\nd2[0]\n\n{'text': 'i didnt feel humiliated', 'label': 0}\n\n\n\nd2[:1]\n\n{'text': ['i didnt feel humiliated'], 'label': [0]}\n\n\n#\n# 예시1\n\nd = emotion['train'].select(range(4))\nd\n\nDataset({\n    features: ['text', 'label'],\n    num_rows: 4\n})\n\n\n\ndef w_transform(examples):\n    result = tokenizer(examples['text'])\n    result = result | examples\n    return result\n\n\nd2 = d.with_transform(w_transform)\n\n\nd2[0]\n\n{'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102],\n 'attention_mask': [1, 1, 1, 1, 1, 1, 1],\n 'text': 'i didnt feel humiliated',\n 'label': 0}\n\n\n\nd2[:1]\n\n{'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]], 'text': ['i didnt feel humiliated'], 'label': [0]}\n\n\n\nd2.set_format(type=\"pt\")\n\n\nd2[0]\n\n{'text': 'i didnt feel humiliated', 'label': tensor(0)}\n\n\n\nd2[:1]\n\n{'text': ['i didnt feel humiliated'], 'label': tensor([0])}\n\n\n#"
  },
  {
    "objectID": "공부/HF/2024-09-30-(강의) 이미지분류.html#a.-데이터불러오기",
    "href": "공부/HF/2024-09-30-(강의) 이미지분류.html#a.-데이터불러오기",
    "title": "(강의) 이미지분류",
    "section": "A. 데이터불러오기",
    "text": "A. 데이터불러오기\n- 원래는 자료가 많음\n\nfood_full = datasets.load_dataset(\"food101\")\nfood_full\n\nDatasetDict({\n    train: Dataset({\n        features: ['image', 'label'],\n        num_rows: 75750\n    })\n    validation: Dataset({\n        features: ['image', 'label'],\n        num_rows: 25250\n    })\n})\n\n\n- train에서 5000장만 가져옴\n\nfood5000 = datasets.load_dataset(\"food101\", split=\"train[:5000]\")\nfood5000\n\nDataset({\n    features: ['image', 'label'],\n    num_rows: 5000\n})\n\n\n- 거기서 8:2로 데이터를 분리\n\nfood = food5000.train_test_split(test_size=0.2)\nfood\n\nDatasetDict({\n    train: Dataset({\n        features: ['image', 'label'],\n        num_rows: 4000\n    })\n    test: Dataset({\n        features: ['image', 'label'],\n        num_rows: 1000\n    })\n})"
  },
  {
    "objectID": "공부/HF/2024-09-30-(강의) 이미지분류.html#b.-데이터-살펴보기",
    "href": "공부/HF/2024-09-30-(강의) 이미지분류.html#b.-데이터-살펴보기",
    "title": "(강의) 이미지분류",
    "section": "B. 데이터 살펴보기",
    "text": "B. 데이터 살펴보기\n- 이미지를 보는 방법\n\nfood['train'][0]['image']\n\n\n\n\n\n\n\n\n- 이미지에 해당하는 라벨을 같이 확인하는 방법\n\nprint(food['train'][0]['label'])\nfood['train'][0]['image']\n\n81\n\n\n\n\n\n\n\n\n\n53번이 뭐지?\n\nfood['train'].features['label'].names[53]\n\n'hamburger'\n\n\n- 이미지의 크기를 확인하는 방법\n\nsizes = [dct['image'].__str__().split(\" \")[-3] for dct in food['train']]\nsizes[:5]\n\n['size=512x512',\n 'size=512x512',\n 'size=512x512',\n 'size=512x512',\n 'size=512x384']\n\n\n\nsizes = [dct['image'].size for dct in food['train']]\nsizes[:5]\n\n[(512, 512), (512, 512), (512, 512), (512, 512), (512, 384)]\n\n\n\n이미지의 크기가 서로 다르네? (텍스트의 길이가 다르듯이?)\n인공지능입장에선 싫어하겠는걸"
  },
  {
    "objectID": "공부/HF/2024-09-30-(강의) 이미지분류.html#c.-torchvision.transforms-소개",
    "href": "공부/HF/2024-09-30-(강의) 이미지분류.html#c.-torchvision.transforms-소개",
    "title": "(강의) 이미지분류",
    "section": "C. torchvision.transforms 소개",
    "text": "C. torchvision.transforms 소개\n- 이미지자료 하나 받아두기\n\nimg = datasets.load_dataset(\"food101\",split=\"train[:1]\")[0]['image']\nimg\n\n\n\n\n\n\n\n\n\n# torchvision.transforms.RandomResizedCrop\n# 예시1 – 사이즈를 224,112로 조정\n\n자르고크기조정하기 = torchvision.transforms.RandomResizedCrop((224,112))\n\n\n자르고크기조정하기(img) # 5번정도 실행해보기..\n\n\n\n\n\n\n\n\n#\n# 예시2 – 사이즈를 224,224로 조정\n\n자르고크기조정하기 = torchvision.transforms.RandomResizedCrop(224)\n\n\n자르고크기조정하기(img) # 5번정도 실행해보기..\n\n\n\n\n\n\n\n\n#\n\n\n# torchvision.transforms.ToTensor()\n# 예시1\n\n텐서화하기 = torchvision.transforms.ToTensor()\n\n\n텐서화하기(img)\n\ntensor([[[0.1216, 0.1137, 0.1098,  ..., 0.0039, 0.0039, 0.0000],\n         [0.1255, 0.1216, 0.1176,  ..., 0.0039, 0.0039, 0.0000],\n         [0.1294, 0.1255, 0.1255,  ..., 0.0039, 0.0000, 0.0000],\n         ...,\n         [0.2588, 0.2745, 0.2863,  ..., 0.3765, 0.3882, 0.3922],\n         [0.2353, 0.2471, 0.2667,  ..., 0.3373, 0.3373, 0.3373],\n         [0.2235, 0.2275, 0.2471,  ..., 0.3333, 0.3176, 0.3059]],\n\n        [[0.1373, 0.1294, 0.1255,  ..., 0.1020, 0.1020, 0.0980],\n         [0.1412, 0.1373, 0.1333,  ..., 0.1020, 0.1020, 0.0980],\n         [0.1451, 0.1412, 0.1412,  ..., 0.1020, 0.0980, 0.0980],\n         ...,\n         [0.2471, 0.2627, 0.2745,  ..., 0.3647, 0.3765, 0.3882],\n         [0.2235, 0.2353, 0.2549,  ..., 0.3255, 0.3333, 0.3333],\n         [0.2118, 0.2157, 0.2353,  ..., 0.3216, 0.3137, 0.3020]],\n\n        [[0.1412, 0.1333, 0.1294,  ..., 0.0902, 0.0902, 0.0863],\n         [0.1451, 0.1412, 0.1451,  ..., 0.0902, 0.0902, 0.0863],\n         [0.1490, 0.1451, 0.1529,  ..., 0.0902, 0.0863, 0.0863],\n         ...,\n         [0.1725, 0.1882, 0.2000,  ..., 0.2431, 0.2549, 0.2667],\n         [0.1490, 0.1608, 0.1804,  ..., 0.2039, 0.2118, 0.2118],\n         [0.1373, 0.1412, 0.1608,  ..., 0.2000, 0.1922, 0.1804]]])\n\n\n\n텐서화하기(img).shape\n\ntorch.Size([3, 512, 384])\n\n\n#\n# 예시2 – 자르고크기조정하기 와 텐서화하기를 동시에 사용하는 경우\n\n텐서화하기(자르고크기조정하기(img)).shape\n\ntorch.Size([3, 224, 224])\n\n\n\n자르고크기조정하기(텐서화하기(img)).shape\n\ntorch.Size([3, 224, 224])\n\n\n#\n\n\n# torchvision.transforms.Normalize\n# 예시1\n\n표준화하기 = torchvision.transforms.Normalize(mean=[10,20,30], std=[0.5,1.0,1.5])\n\n\n표준화하기(텐서화하기(img))[0], (텐서화하기(img)[0] - 10 ) / 0.5\n\n(tensor([[-19.7569, -19.7725, -19.7804,  ..., -19.9922, -19.9922, -20.0000],\n         [-19.7490, -19.7569, -19.7647,  ..., -19.9922, -19.9922, -20.0000],\n         [-19.7412, -19.7490, -19.7490,  ..., -19.9922, -20.0000, -20.0000],\n         ...,\n         [-19.4824, -19.4510, -19.4275,  ..., -19.2471, -19.2235, -19.2157],\n         [-19.5294, -19.5059, -19.4667,  ..., -19.3255, -19.3255, -19.3255],\n         [-19.5529, -19.5451, -19.5059,  ..., -19.3333, -19.3647, -19.3882]]),\n tensor([[-19.7569, -19.7725, -19.7804,  ..., -19.9922, -19.9922, -20.0000],\n         [-19.7490, -19.7569, -19.7647,  ..., -19.9922, -19.9922, -20.0000],\n         [-19.7412, -19.7490, -19.7490,  ..., -19.9922, -20.0000, -20.0000],\n         ...,\n         [-19.4824, -19.4510, -19.4275,  ..., -19.2471, -19.2235, -19.2157],\n         [-19.5294, -19.5059, -19.4667,  ..., -19.3255, -19.3255, -19.3255],\n         [-19.5529, -19.5451, -19.5059,  ..., -19.3333, -19.3647, -19.3882]]))\n\n\n\n표준화하기(텐서화하기(img))[1], (텐서화하기(img)[1] - 20 ) / 1.0\n\n(tensor([[-19.8627, -19.8706, -19.8745,  ..., -19.8980, -19.8980, -19.9020],\n         [-19.8588, -19.8627, -19.8667,  ..., -19.8980, -19.8980, -19.9020],\n         [-19.8549, -19.8588, -19.8588,  ..., -19.8980, -19.9020, -19.9020],\n         ...,\n         [-19.7529, -19.7373, -19.7255,  ..., -19.6353, -19.6235, -19.6118],\n         [-19.7765, -19.7647, -19.7451,  ..., -19.6745, -19.6667, -19.6667],\n         [-19.7882, -19.7843, -19.7647,  ..., -19.6784, -19.6863, -19.6980]]),\n tensor([[-19.8627, -19.8706, -19.8745,  ..., -19.8980, -19.8980, -19.9020],\n         [-19.8588, -19.8627, -19.8667,  ..., -19.8980, -19.8980, -19.9020],\n         [-19.8549, -19.8588, -19.8588,  ..., -19.8980, -19.9020, -19.9020],\n         ...,\n         [-19.7529, -19.7373, -19.7255,  ..., -19.6353, -19.6235, -19.6118],\n         [-19.7765, -19.7647, -19.7451,  ..., -19.6745, -19.6667, -19.6667],\n         [-19.7882, -19.7843, -19.7647,  ..., -19.6784, -19.6863, -19.6980]]))\n\n\n\n표준화하기(텐서화하기(img))[2], (텐서화하기(img)[2] - 30 ) / 1.5\n\n(tensor([[-19.9059, -19.9111, -19.9137,  ..., -19.9399, -19.9399, -19.9425],\n         [-19.9033, -19.9059, -19.9033,  ..., -19.9399, -19.9399, -19.9425],\n         [-19.9007, -19.9033, -19.8980,  ..., -19.9399, -19.9425, -19.9425],\n         ...,\n         [-19.8850, -19.8745, -19.8667,  ..., -19.8379, -19.8301, -19.8222],\n         [-19.9007, -19.8928, -19.8797,  ..., -19.8641, -19.8588, -19.8588],\n         [-19.9085, -19.9059, -19.8928,  ..., -19.8667, -19.8719, -19.8797]]),\n tensor([[-19.9059, -19.9111, -19.9137,  ..., -19.9399, -19.9399, -19.9425],\n         [-19.9033, -19.9059, -19.9033,  ..., -19.9399, -19.9399, -19.9425],\n         [-19.9007, -19.9033, -19.8980,  ..., -19.9399, -19.9425, -19.9425],\n         ...,\n         [-19.8850, -19.8745, -19.8667,  ..., -19.8379, -19.8301, -19.8222],\n         [-19.9007, -19.8928, -19.8797,  ..., -19.8641, -19.8588, -19.8588],\n         [-19.9085, -19.9059, -19.8928,  ..., -19.8667, -19.8719, -19.8797]]))\n\n\n#\n\n\n# torchvision.transforms.Compose\n# 예시1 – 여러함수를 묶어 하나의 함수를 만드는 방법\n\n이미지처리하기 = torchvision.transforms.Compose([자르고크기조정하기,텐서화하기,표준화하기])\n\n\n이미지처리하기(img)\n\ntensor([[[-19.2549, -19.2235, -19.1765,  ..., -19.9451, -19.9608, -19.9451],\n         [-19.2314, -19.2157, -19.2000,  ..., -19.9373, -19.9765, -19.9608],\n         [-19.2157, -19.2000, -19.2078,  ..., -19.9294, -19.9373, -19.8745],\n         ...,\n         [-19.1686, -19.0902, -19.0431,  ..., -19.2706, -19.2157, -19.1373],\n         [-19.2314, -19.1686, -19.1137,  ..., -19.2549, -19.1922, -19.1216],\n         [-19.2157, -19.2000, -19.1843,  ..., -19.1373, -19.1137, -19.0824]],\n\n        [[-19.5725, -19.5569, -19.5333,  ..., -19.7922, -19.8039, -19.8000],\n         [-19.5608, -19.5529, -19.5451,  ..., -19.8039, -19.8235, -19.8196],\n         [-19.5529, -19.5451, -19.5490,  ..., -19.8196, -19.8235, -19.7922],\n         ...,\n         [-19.5765, -19.5373, -19.5176,  ..., -19.6824, -19.6549, -19.6235],\n         [-19.6118, -19.5804, -19.5569,  ..., -19.6667, -19.6392, -19.6078],\n         [-19.6000, -19.6000, -19.5961,  ..., -19.6000, -19.5922, -19.5843]],\n\n        [[-19.6863, -19.6758, -19.6601,  ..., -19.8562, -19.8693, -19.8693],\n         [-19.6784, -19.6732, -19.6680,  ..., -19.8641, -19.8824, -19.8824],\n         [-19.6732, -19.6680, -19.6706,  ..., -19.8745, -19.8824, -19.8641],\n         ...,\n         [-19.7673, -19.7386, -19.7255,  ..., -19.8431, -19.8248, -19.8013],\n         [-19.7908, -19.7699, -19.7542,  ..., -19.8301, -19.8092, -19.7882],\n         [-19.7882, -19.7856, -19.7830,  ..., -19.7830, -19.7752, -19.7699]]])\n\n\n#"
  },
  {
    "objectID": "공부/HF/2024-09-30-(강의) 이미지분류.html#d.-이미지전처리",
    "href": "공부/HF/2024-09-30-(강의) 이미지분류.html#d.-이미지전처리",
    "title": "(강의) 이미지분류",
    "section": "D. 이미지전처리",
    "text": "D. 이미지전처리\n- 아래의 샘플코드를 살펴보자.\nimage_processor = transformers.AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\nnormalize = torchvision.transforms.Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\nsize = (\n    image_processor.size[\"shortest_edge\"]\n    if \"shortest_edge\" in image_processor.size\n    else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n)\n_transforms = torchvision.transforms.Compose([\n    torchvision.transforms.RandomResizedCrop(size), \n    torchvision.transforms.ToTensor(), \n    normalize\n])\ndef transforms(examples):\n    examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n    del examples[\"image\"]\n    return examples\nfood = food.with_transform(transforms)\n# 예비학습 1\n\na=-2\n(\n    (a,\"양수\") if a&gt;0 else (a,\"음수\")\n)\n\n(-2, '음수')\n\n\n\ndct = {'shortest_edge': 16, 'height': 224, 'width': 224} \n#dct = {'height': 224, 'width': 224} \n(\n    dct['shortest_edge'] if 'shortest_edge' in dct \n    else (dct['height'], dct['width'])\n)\n\n16\n\n\n#\n# 예비학습 2\n\nimg.convert(\"L\")\n\n\n\n\n\n\n\n\n#\n- image_processor 살펴보기\n\nimage_processor = transformers.AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n\nFast image processor class &lt;class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'&gt; is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n\n\n\nimage_processor\n\nViTImageProcessor {\n  \"do_normalize\": true,\n  \"do_rescale\": true,\n  \"do_resize\": true,\n  \"image_mean\": [\n    0.5,\n    0.5,\n    0.5\n  ],\n  \"image_processor_type\": \"ViTImageProcessor\",\n  \"image_std\": [\n    0.5,\n    0.5,\n    0.5\n  ],\n  \"resample\": 2,\n  \"rescale_factor\": 0.00392156862745098,\n  \"size\": {\n    \"height\": 224,\n    \"width\": 224\n  }\n}\n\n\n- 코드는 아래와 같이 단순화하여 이해할 수 있음.\n\n_transforms = torchvision.transforms.Compose([\n    torchvision.transforms.RandomResizedCrop((224,224)), \n    torchvision.transforms.ToTensor(), \n    torchvision.transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n])\ndef transforms(examples):\n    examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n    del examples[\"image\"]\n    return examples\nfood_transformed = food.with_transform(transforms)"
  },
  {
    "objectID": "공부/HF/2024-09-30-(강의) 이미지분류.html#e.-모델생성",
    "href": "공부/HF/2024-09-30-(강의) 이미지분류.html#e.-모델생성",
    "title": "(강의) 이미지분류",
    "section": "E. 모델생성",
    "text": "E. 모델생성\n- 아래의 코드를 관찰하자.\n\nlabels = food[\"train\"].features[\"label\"].names\nlabel2id, id2label = dict(), dict()\nfor i, label in enumerate(labels):\n    label2id[label] = str(i)\n    id2label[str(i)] = label\n\n\n그냥 별거아님..\n\n- 아래와같이 해도 별로 상관없음\n\nlabels = food[\"train\"].features[\"label\"].names\nlabel2id, id2label = dict(), dict()\nfor i, label in enumerate(labels):\n    label2id[label] = i\n    id2label[i] = label\n\n\nmodel = transformers.AutoModelForImageClassification.from_pretrained(\n    \"google/vit-base-patch16-224-in21k\",\n    num_labels=len(labels),\n    id2label=id2label,\n    label2id=label2id,\n)\n\nSome weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n\n\n#model(표준화하기(자르고크기조정하기(텐서화하기(img))).reshape(1,3,224,224))"
  },
  {
    "objectID": "공부/HF/2024-09-30-(강의) 이미지분류.html#f.-데이터콜렉터",
    "href": "공부/HF/2024-09-30-(강의) 이미지분류.html#f.-데이터콜렉터",
    "title": "(강의) 이미지분류",
    "section": "F. 데이터콜렉터",
    "text": "F. 데이터콜렉터\n- 데이터 콜렉터 생성\n\ndata_collator = transformers.DefaultDataCollator()\n\n- 데이터콜렉터에게 이번에 크게 기대하는건 없음.. 그냥 배치화정도만 해주면 됨\n\nfood_transformed['train'][:2]['pixel_values']\n# [ (3,224,224)-텐서, (3,224,224)-텐서 ] 의 형태\n\n[tensor([[[ 0.9216,  0.9059,  0.8902,  ..., -0.1373, -0.1451, -0.1216],\n          [ 0.9216,  0.9137,  0.8980,  ...,  0.3412,  0.3490,  0.3882],\n          [ 0.8980,  0.9059,  0.9373,  ...,  0.6863,  0.7098,  0.7412],\n          ...,\n          [ 0.9529,  0.9529,  0.9451,  ...,  0.8039,  0.7961,  0.7961],\n          [ 0.9608,  0.9529,  0.9608,  ...,  0.8039,  0.8039,  0.7961],\n          [ 0.9686,  0.9608,  0.9608,  ...,  0.8039,  0.7961,  0.7882]],\n \n         [[ 0.7725,  0.7490,  0.7333,  ..., -0.2392, -0.2549, -0.1922],\n          [ 0.7647,  0.7412,  0.7333,  ...,  0.2392,  0.2471,  0.3176],\n          [ 0.6314,  0.6471,  0.7176,  ...,  0.6078,  0.6392,  0.6784],\n          ...,\n          [ 0.9451,  0.9451,  0.9373,  ...,  0.6863,  0.6784,  0.6941],\n          [ 0.9529,  0.9451,  0.9373,  ...,  0.6863,  0.6863,  0.6941],\n          [ 0.9608,  0.9451,  0.9294,  ...,  0.6863,  0.6784,  0.6863]],\n \n         [[ 0.7804,  0.7961,  0.8118,  ..., -0.2549, -0.2549, -0.1922],\n          [ 0.6627,  0.7098,  0.7647,  ...,  0.2000,  0.2157,  0.2863],\n          [ 0.2941,  0.3961,  0.5843,  ...,  0.5843,  0.6078,  0.6314],\n          ...,\n          [ 0.9373,  0.9294,  0.9216,  ...,  0.6392,  0.6314,  0.6471],\n          [ 0.9373,  0.9294,  0.9137,  ...,  0.6314,  0.6314,  0.6471],\n          [ 0.9373,  0.9137,  0.9059,  ...,  0.6314,  0.6235,  0.6314]]]),\n tensor([[[ 0.3725,  0.3725,  0.3725,  ...,  0.1922,  0.1765,  0.1373],\n          [ 0.3961,  0.3725,  0.3490,  ...,  0.2157,  0.2157,  0.1765],\n          [ 0.3569,  0.3490,  0.4118,  ...,  0.2000,  0.1765,  0.1608],\n          ...,\n          [-0.0039,  0.0118,  0.0275,  ..., -0.2549, -0.2627, -0.2392],\n          [ 0.0275,  0.0588,  0.0745,  ..., -0.2314, -0.2392, -0.2314],\n          [ 0.0667,  0.0902,  0.0824,  ..., -0.2863, -0.2471, -0.2549]],\n \n         [[ 0.4510,  0.4431,  0.4353,  ...,  0.1843,  0.2078,  0.1765],\n          [ 0.4980,  0.4824,  0.4353,  ...,  0.2392,  0.2471,  0.2157],\n          [ 0.4588,  0.4588,  0.5137,  ...,  0.2314,  0.2078,  0.1922],\n          ...,\n          [ 0.0118,  0.0275,  0.0431,  ..., -0.5922, -0.6235, -0.6000],\n          [ 0.0431,  0.0745,  0.0902,  ..., -0.5765, -0.5686, -0.5529],\n          [ 0.0824,  0.1059,  0.0980,  ..., -0.6314, -0.5608, -0.5608]],\n \n         [[ 0.5216,  0.5294,  0.5294,  ...,  0.2784,  0.2627,  0.2235],\n          [ 0.6000,  0.5765,  0.5373,  ...,  0.2784,  0.2941,  0.2627],\n          [ 0.5686,  0.5686,  0.6157,  ...,  0.2627,  0.2549,  0.2392],\n          ...,\n          [-0.0118, -0.0039,  0.0039,  ..., -0.9216, -0.9451, -0.9216],\n          [ 0.0196,  0.0431,  0.0510,  ..., -0.8902, -0.8980, -0.8902],\n          [ 0.0588,  0.0824,  0.0588,  ..., -0.9373, -0.8980, -0.8980]]])]\n\n\n\ndata_collator([food_transformed['train'][0],food_transformed['train'][1]])['pixel_values'].shape\n# (2,3,224,224)-텐서\n\ntorch.Size([2, 3, 224, 224])"
  },
  {
    "objectID": "공부/HF/2024-09-30-(강의) 이미지분류.html#g.-추론",
    "href": "공부/HF/2024-09-30-(강의) 이미지분류.html#g.-추론",
    "title": "(강의) 이미지분류",
    "section": "G. 추론",
    "text": "G. 추론\n- 코드정리1에 의하여 이미 학습되어있는 Trainer\n\nclassifier = transformers.pipeline(\"image-classification\", model=\"my_awesome_food_model/checkpoint-186\")\n\nHardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n\n\n- image url 에서 PIL 오브젝트 만들기: GPT 답변\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\n\n# 이미지 URL\nurl = \"https://example.com/image.jpg\"\n\n# URL에서 이미지 불러오기\nresponse = requests.get(url)\nimage = Image.open(BytesIO(response.content))\n\n# 이미지 확인\nimage.show()\n\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\n# 이미지 URL\nurl = \"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Shoyu_ramen%2C_at_Kasukabe_Station_%282014.05.05%29_1.jpg/500px-Shoyu_ramen%2C_at_Kasukabe_Station_%282014.05.05%29_1.jpg\"\n\n# URL에서 이미지 불러오기\nresponse = requests.get(url)\nimage = Image.open(BytesIO(response.content))\n\n\nimage\n\n\n\n\n\n\n\n\n\nclassifier(image)\n\n[{'label': 'ramen', 'score': 0.9723917841911316},\n {'label': 'prime_rib', 'score': 0.6323286890983582},\n {'label': 'chicken_wings', 'score': 0.5933451652526855},\n {'label': 'pork_chop', 'score': 0.5822263956069946},\n {'label': 'beignets', 'score': 0.5541594624519348}]"
  },
  {
    "objectID": "공부/2023-10-21-(공부&지윤) Imputer와 Scaler의 적용.html",
    "href": "공부/2023-10-21-(공부&지윤) Imputer와 Scaler의 적용.html",
    "title": "(공부&지윤) Imputer와 Scaler의 적용",
    "section": "",
    "text": "import numpy as np \nimport pandas as pd\nimport sklearn.preprocessing\nimport sklearn.impute \n\n\nX = pd.DataFrame({'X':[7.424885,4.201394,np.nan,np.nan,5.190914,np.nan,6.433033]})\nX\n\n\n\n\n\n\n\n\nX\n\n\n\n\n0\n7.424885\n\n\n1\n4.201394\n\n\n2\nNaN\n\n\n3\nNaN\n\n\n4\n5.190914\n\n\n5\nNaN\n\n\n6\n6.433033\n\n\n\n\n\n\n\n\nsclr = sklearn.preprocessing.StandardScaler()\nimputr = sklearn.impute.SimpleImputer()\n\n\nsclr.fit(X.dropna())\n\nStandardScaler()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.StandardScalerStandardScaler()\n\n\n\nsclr.transform(imputr.fit_transform(X))\n\n/home/cgb2/anaconda3/envs/ag/lib/python3.10/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n\n\narray([[ 1.32010944],\n       [-1.31915477],\n       [ 0.        ],\n       [ 0.        ],\n       [-0.50897577],\n       [ 0.        ],\n       [ 0.50802109]])"
  },
  {
    "objectID": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.out.html",
    "href": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.out.html",
    "title": "(공부) 리뷰 – EbayesThresh: R Programs for Empirical Bayes",
    "section": "",
    "text": "Thresholding\n신록예찬\n2022-12-23\nref: https://www.jstatsoft.org/article/view/v012i08"
  },
  {
    "objectID": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.out.html#ebayesthresh로-무엇을-할-수-있는가",
    "href": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.out.html#ebayesthresh로-무엇을-할-수-있는가",
    "title": "(공부) 리뷰 – EbayesThresh: R Programs for Empirical Bayes",
    "section": "Ebayesthresh로 무엇을 할 수 있는가?",
    "text": "Ebayesthresh로 무엇을 할 수 있는가?\n아래와 같은 상황을 가정하자.\n\\[X_i = \\mu_i +\\epsilon_i.\\]\n여기에서 아래를 가정한다.\n\n\\(\\epsilon_i \\overset{iid}{\\sim} N(0,1)\\)\neach \\(\\mu_i\\) is zero with probability \\((1−w)\\), while, with probability \\(w\\), \\(\\mu_i\\) is drawn from a symmetric heavy-tailed density \\(\\gamma\\).\n\n일반적으로 \\(w\\), 즉 \\(\\mu_i\\)가 0이 아닐 확률은 매우 작은값으로 설정된다. 따라서 위와 같은 구조로 \\(\\epsilon_i\\)와 \\(\\mu_i\\)를 생성하면 아래와 같이 된다.\n\n\\(\\epsilon_i\\): 절대값이 작은 신호들이 dense하게 있음.\n\\(\\mu_i\\): 절대값이 큰 신호들이 sparse하게 있음. (sparse한 이유는 \\(w\\)가 작으므로)\n\n따라서 \\(X_i\\)의 모양은 아래의 그림의 왼쪽과 같다.\n\n이 논문의 목표는 왼쪽의 그림 \\(X_i= \\mu_i +\\epsilon_i\\)로부터 오른쪽의 그림 \\(\\hat{\\mu}_i\\)을 구하는 것이다. 즉 작은 절대값의 노이즈 \\(\\epsilon_i\\)에서 큰 절대값의 신호 \\(\\mu_i\\)를 골라내는 일을 목표로 한다. 저자들은 이러한 작업을 “건초더미에서 바늘찾기”라는 말로 비유하였다. 이러한 “건초더미에서 바늘찾기”는 여러 분야에 응용될 수 있다. 구체적으로는 천문학, 이미지프로세싱, 데이터마이닝, 모형선택등에 사용될 수 있다고 한다. 언급한 분야에 대한 자세한 discussion은 Johnstone and Silverman (2004)에서 찾을 수 있다. 또한 “건초더미에서 바늘찾기”는 위에서 언급한 분야 이외에 퓨리에, 웨이블릿 혹은 다른 dictionaries에 의한 함수추정문제를 해결할 수 있다. 이는 퓨리에나 웨이블릿변환과 같은 multiscale trasnform이 원래 신호를 sparese한 구조로 바꾸기 때문이다. 즉 퓨리에변환 웨이블릿변환으로 underlying function을 추정할 수 있다는 의미이다. 우리는 이러한 접근법에 좀 더 초점을 맞추도록 하겠다."
  },
  {
    "objectID": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.out.html#간단한-사용법",
    "href": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.out.html#간단한-사용법",
    "title": "(공부) 리뷰 – EbayesThresh: R Programs for Empirical Bayes",
    "section": "간단한 사용법",
    "text": "간단한 사용법\nR을 이용하여 Ebayesthresh를 사용하는 간단한 방법을 살펴보도록 하자. 논문에 표현된 그림1을 재현하여 보자.\n\nlibrary(EbayesThresh)\n\n\nset.seed(1)\nx &lt;- rnorm(1000) + sample(c( runif(25,-7,7), rep(0,975)))\nplot(x,type='l',lwd=0.2)\n\n\n\n\n\n\n\n\n위와 같은 자료 \\(X_i\\)를 관측하였다고 가정하자. 이 신호에는 “건초(\\(\\epsilon_i\\))”더미에 25개의 “바늘(\\(\\mu_i\\))”이 섞여있다. 여기에서 “바늘”만 골라내는 코드는 아래와 같이 작성할 수 있다.\n\nmuhat &lt;- ebayesthresh(x, sdev=1)\n\n결과를 시각화하면 아래와 같다.\n\nplot(x,type='l',lwd=0.2)\nlines(muhat,col=2,lwd=2)"
  },
  {
    "objectID": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.out.html#arguments",
    "href": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.out.html#arguments",
    "title": "(공부) 리뷰 – EbayesThresh: R Programs for Empirical Bayes",
    "section": "arguments",
    "text": "arguments\n일반적으로 ebayesthresh 함수를 사용하는 방법은 아래와 같다.\n\nmuhat &lt;- ebayesthresh(\n    x,\n    prior = \"laplace\", \n    a = 0.5, \n    bayesfac = FALSE, \n    sdev = NA, \n    verbose = FALSE, \n    threshrule = \"median\"\n)\n\nprior, a: \\(\\mu_i\\)의 density. 보통 \\(\\frac{1}{2}a \\exp(-a|u|)\\)라고 가정한다. parameter \\(a\\)는 Section 2.1에서 자시해 나옴.\nbayesfac, threshrule: Section 2.2, 2.3에 자세히 나온다.\nsdev: \\(\\epsilon_i\\)의 sd를 의미한다. 이 값을 알고 있다면 설정하면 되지만 보통은 이 값을 모른다고 가정한다. \\(\\epsilon_i\\)의 sd를 모르는 경우는 observed data로 부터 추정하는데 보통 \\({\\tt median}(|X_i|)\\)로 추정한다.\n\\(\\epsilon_i\\)의 sd를 \\({\\tt median}(|X_i|)\\)로 추정하는 motivation을 이해하는 것이 중요하다. 이는 sparse assumption of \\(\\mu_i\\)에서 시작한다. 신호 \\(\\mu_i\\)가 합리적인 수준에서 sparse하다면 median absolute value of \\(X_i\\)는 \\(\\mu_i\\)의 값들과 상관이 없을 것이다. 하지만 당연히 신호가 sparse하지 않다면 이러한 방식으로 sdev를 추정하는 것은 매우 조심스럽게 수행되어야 할 것이다.\n\nn &lt;- 1000\nx &lt;- rnorm(n) + sample(c(runif(25,-7,7), rep(0,n-25)))\nprint(sd(x))\nprint(median(abs(x)))\n\n[1] 1.117016\n[1] 0.6787613\n\n\n\n실제로는 잘 추론하지 못하는 것 같다?"
  },
  {
    "objectID": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.out.html#원리",
    "href": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.out.html#원리",
    "title": "(공부) 리뷰 – EbayesThresh: R Programs for Empirical Bayes",
    "section": "원리",
    "text": "원리\n어떻게 \\(\\hat{\\mu}_i\\)를 추정할 수 있을까? 가장 간단한 방법은 thresholding이다.\n많은 실제예제에서 \\(\\mu_i\\)는 어떤 의미에서 (in some sense) sparse하다고 여길 수 있다. EbayesThresh 패키지는 이처럼 \\(\\mu_i\\)가 sparse하다는 구조 (혹은 가정)을 이용하여 \\(\\mu_i\\)를 적절하게 추정한다.\nSparsity를 이용하는 자연스러운 방법은 threshoding이다: 여기에서 threshold의 값 \\(t\\)를 너무 크게 잡으면 신호를 잡음으로 잘못 판단할 것이고 \\(t\\)의 값이 너무 작다면 잡음을 신호로 잘못 판단할 수 있다. 따라서 \\(t\\)의 선택은 이 양쪽 기준사이의 tradeoff가 있는데 EbayesThresh는 이러한 tradeoff를 자동으로 조정하는 효과가 있다.\n\n\\(\\mu_i\\)는 \\(w\\)의 확률로 0 이며 \\((1-w)\\)의 확률로 0이 아니다. \\(\\mu_i\\)가 0이 아닐경우에는 symmetric heavy-tailed density \\(\\gamma\\)에서 추출된다고 가정한다. 여기에서 prior에 대한 key parameter인 \\(w\\)는 데이터로부터 자동으로 추정된다. (marginal maximum likelihood 를 이용한다) 그리고 추정된 \\(w\\)는 Bayesian model로 다시 대입된다.\n\\(w\\)가 추정되면 Bayesian model은 thresholding procedure를 수행할 수 있다. 왜냐하면 \\(w\\)를 추정하면 \\(t(w)\\)를 선택한다는 말과 같은말이기 때문이다.\n\nargument"
  },
  {
    "objectID": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.out.html#the-bayesian-model",
    "href": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.out.html#the-bayesian-model",
    "title": "(공부) 리뷰 – EbayesThresh: R Programs for Empirical Bayes",
    "section": "The Bayesian model",
    "text": "The Bayesian model\n\\[X_i \\sim N(\\mu_i,1)\\]\n\\(f_{\\text{prior}}(\\mu)=(1-w)\\delta_0(\\mu)+w \\gamma_a(\\mu), \\quad \\gamma_a(\\mu)=\\frac{1}{2}a\\exp(-a|\\mu|)\\)\n여기에서 \\(\\gamma_a(\\mu)\\)는 하나의 예시일 뿐이다. Ebayesthresh에 디폴트로 설정된 prior=\"laplace\"를 셋팅하면 \\(\\gamma_a(\\mu)\\)가 사용된다. \\(\\gamma\\)의 선택은 tail이 polynomial rates로 줄어드는 어떠한 분포를 사용해도 무방하다. 저자들은 quasi-Cauchy분포를 제안하였는데 이는 Johnstone and Sliverman이 만든 theoretical assumption을 만족하는 분포중 가장 꼬리가 두꺼운 분포이다."
  },
  {
    "objectID": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.out.html#thresholding-rules",
    "href": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.out.html#thresholding-rules",
    "title": "(공부) 리뷰 – EbayesThresh: R Programs for Empirical Bayes",
    "section": "Thresholding rules",
    "text": "Thresholding rules\n모수 \\(\\mu\\)는 사전분포(prior distribution)를 가진다고 가정하고 \\(X \\sim N(\\mu,1)\\)이라고 가정하자. 이 경우 \\(X=x\\)가 given되었을 경우 \\(\\mu\\)의 사후분포(posterior distribution)를 구할 수 있다. (자세한 내용은 Section 6을 참고해야함) 사후분포의 중앙값을 \\(\\hat{\\mu}(x;w)\\)라고 하자. (사후분포의 중앙값이 \\(w\\)에 영향받는 이유는 사전분포가 \\(w\\)에 depend하기 때문이다. 여기에서 \\(w\\)는 marginal MLE로 적절히 추론한다고 가정한다)\n\\(X_i\\)는 독립이라고 가정한다. 여기에서 \\(X_i\\)가 독립이 아니라면 약간의 정보손실이 있을 수 있다. 하지만 \\(X_i\\) 사이에 너무 많은 dependency가 존재하는 경우가 아니라면 Ebayesthresh는 어느정도 합리적인 결과를 제공한다.\n만약에 bayesfac=TRUE를 사용하면 \\(\\mu\\)의 사후분포의 중앙값 대신에 Bayes factor threshold 를 쓸 수도 있다."
  },
  {
    "objectID": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.out.html#choosing-the-threshold",
    "href": "공부/2022-12-23-(공부) 리뷰 -- Ebayesthresh.out.html#choosing-the-threshold",
    "title": "(공부) 리뷰 – EbayesThresh: R Programs for Empirical Bayes",
    "section": "Choosing the threshold",
    "text": "Choosing the threshold\n\\(X_i\\)의 marginal density는\n\\((1-w)\\phi(x) +w(\\gamma \\star \\phi)(x)\\)\n\\(l(w) = \\sum_{i=1}^{n}\\log \\big\\{(1-w)\\phi(X_i)+wg(X_i) \\big\\}\\)\n와 같이 정의가능하다. 단, 여기에서 \\(g:= \\gamma\\star \\phi\\) 이다.\n이제 우리는 아래의 식을 풀면된다.\n\\[\\underset{w}{\\operatorname{argmax}} l(w)\\quad\\quad \\text{subject to}\\quad t(w) \\leq \\sqrt{2\\log n}\\]\n여기에서 \\(\\sqrt{2\\log n}\\)은 흔히 말하는 universal threshold 이다.\n만약에 \\(w\\)이외에 \\(a\\)도 추정해야 한다면 아래와 같이 추정할 수 있다.\n\\[\\underset{w}{\\operatorname{argmax}} l(w)\\quad\\quad \\text{subject to}\\quad t(w) \\leq \\sqrt{2\\log n}\\]"
  },
  {
    "objectID": "공부/2023-10-25-(공부) Julia -- 문자와 문자열.html",
    "href": "공부/2023-10-25-(공부) Julia -- 문자와 문자열.html",
    "title": "(공부) Julia – 문자와 문자열",
    "section": "",
    "text": "- 선언 및 자료형\n\n'B' # 선언 \n\n'B': ASCII/Unicode U+0042 (category Lu: Letter, uppercase)\n\n\n\ntypeof('b') # 자료형\n\nChar\n\n\n\n\n\n- 선언 및 자료형\n\n\"A\" # 선언\n\n\"A\"\n\n\n\ntypeof(\"A\") # 자료형\n\nString\n\n\n\n\n\n- \"a\"와 'a'의 차이\n\n'a' # 단일문자\n\n'a': ASCII/Unicode U+0061 (category Ll: Letter, lowercase)\n\n\n\n\"a\" # 문자열\n\n\"a\"\n\n\n\n\"a\"[1] # 'a'와 같음\n\n'a': ASCII/Unicode U+0061 (category Ll: Letter, lowercase)"
  },
  {
    "objectID": "공부/2023-10-25-(공부) Julia -- 문자와 문자열.html#a.-문자-0차원-자료형",
    "href": "공부/2023-10-25-(공부) Julia -- 문자와 문자열.html#a.-문자-0차원-자료형",
    "title": "(공부) Julia – 문자와 문자열",
    "section": "",
    "text": "- 선언 및 자료형\n\n'B' # 선언 \n\n'B': ASCII/Unicode U+0042 (category Lu: Letter, uppercase)\n\n\n\ntypeof('b') # 자료형\n\nChar"
  },
  {
    "objectID": "공부/2023-10-25-(공부) Julia -- 문자와 문자열.html#b.-문자열-1차원-자료형",
    "href": "공부/2023-10-25-(공부) Julia -- 문자와 문자열.html#b.-문자열-1차원-자료형",
    "title": "(공부) Julia – 문자와 문자열",
    "section": "",
    "text": "- 선언 및 자료형\n\n\"A\" # 선언\n\n\"A\"\n\n\n\ntypeof(\"A\") # 자료형\n\nString"
  },
  {
    "objectID": "공부/2023-10-25-(공부) Julia -- 문자와 문자열.html#c.-차이점",
    "href": "공부/2023-10-25-(공부) Julia -- 문자와 문자열.html#c.-차이점",
    "title": "(공부) Julia – 문자와 문자열",
    "section": "",
    "text": "- \"a\"와 'a'의 차이\n\n'a' # 단일문자\n\n'a': ASCII/Unicode U+0061 (category Ll: Letter, lowercase)\n\n\n\n\"a\" # 문자열\n\n\"a\"\n\n\n\n\"a\"[1] # 'a'와 같음\n\n'a': ASCII/Unicode U+0061 (category Ll: Letter, lowercase)"
  },
  {
    "objectID": "공부/2023-10-25-(공부) Julia -- 문자와 문자열.html#a.-문자-관련-기능",
    "href": "공부/2023-10-25-(공부) Julia -- 문자와 문자열.html#a.-문자-관련-기능",
    "title": "(공부) Julia – 문자와 문자열",
    "section": "A. 문자 관련 기능",
    "text": "A. 문자 관련 기능\n- isuppercase: 대소문자 판단\n\nisuppercase('a'), islowercase('a')\n\n(false, true)\n\n\n\nisuppercase('A'), islowercase('A')\n\n(true, false)"
  },
  {
    "objectID": "공부/2023-10-25-(공부) Julia -- 문자와 문자열.html#b.-문자열-관련-기능",
    "href": "공부/2023-10-25-(공부) Julia -- 문자와 문자열.html#b.-문자열-관련-기능",
    "title": "(공부) Julia – 문자와 문자열",
    "section": "B. 문자열 관련 기능",
    "text": "B. 문자열 관련 기능\n- 문자열 슬라이싱\n\nstr = \"Jeonbuk National University\"\nstr[end-1:end]\n\n\"ty\"\n\n\n- 문자열의 결합\n\n\"a\"*\"b\"\n\n\"ab\"\n\n\n- 문자열의 반복\n\n\"a\"^5\n\n\"aaaaa\"\n\n\n\nrepeat(\"a\",5)\n\n\"aaaaa\"\n\n\n- 문자열 끼워넣기\n\nname = \"최규빈\"\n\"제 이름은 $name 입니다\"\n\n\"제 이름은 최규빈 입니다\"\n\n\n- 문자열 바꾸기\n\nstr = \"abcdefg\"\nreplace(str, \"g\" =&gt; \"u\")\n\n\"abcdefu\"\n\n\n- 문자열 나누기\n\nstr = \"2023-08\"\nsplit(str,\"-\")\n\n2-element Vector{SubString{String}}:\n \"2023\"\n \"08\"\n\n\n- 문자열 합치기\n\njoin([\"2023\",\"08\"],\"-\")\n\n\"2023-08\"\n\n\n\njoin([\"2023\",\"08\"])\n\n\"202308\"\n\n\n- lowercase: 대문자를 소문자로 바꾸는 방법\n\nstr = \"HELLO, JULIA!\"\nlowercase(str)\n\n\"hello, julia!\""
  },
  {
    "objectID": "공부/2023-06-23-(공부&지윤) 퓨리에변환4jy.html",
    "href": "공부/2023-06-23-(공부&지윤) 퓨리에변환4jy.html",
    "title": "(공부&지윤) 퓨리에변환4jy",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\n\n회귀모형 (1)\n\nx = np.linspace(-10,10,1000)\nx0 = x*0+1\nx1 = x \nbeta0 = 3 \nbeta1 = 2\ny = x0*beta0+x1*beta1+np.random.randn(1000)\n\n\nplt.plot(x,y,'o')\n\n\n\n\n\n\n\n\n\n\n회귀모형 (2)\n- 관측한자료\n\nN=1000\nx=np.linspace(0,1,N)\neps = np.random.randn(N)\nX0 = np.sin(x*0*np.pi)\nX1 = np.sin(x*2*np.pi)\nX2 = np.sin(x*4*np.pi)\nX3 = np.sin(x*6*np.pi)\n\ny=2*X1+1*X2+3*X3+eps\n\n\nplt.plot(x,y,'o',alpha=0.1)\n\n\n\n\n\n\n\n\n\nobserved signal\n\n- 위의 자료를 해석하는 방법\n\ndef spec(y):\n    N= len(y)\n    return abs(np.fft.fft(y)/N)*2 \n\n\ny=2*X1+1*X2+3*X3+eps\nyfft =spec(y) \ny1=2*X1\ny2=1*X2\ny3=3*X3\nyfft1=spec(y1)\nyfft2=spec(y2)\nyfft3=spec(y3)\nepsfft=spec(eps)\n\n\nplt.plot(yfft[:20],'o',alpha=0.5)\nplt.plot(yfft1[:20],'x',alpha=1,)\nplt.plot(yfft2[:20],'x',alpha=1)\nplt.plot(yfft3[:20],'x',alpha=1)\nplt.plot(epsfft[:20],'x',alpha=1)\n\n\n\n\n\n\n\n\n- 퓨리에변환 -&gt; threshold -&gt; 역퓨리에변환을 이용한 스킬\n\nyfft=np.fft.fft(y)\n\n\nplt.plot(abs(yfft[1:50]),'o')\n\n\n\n\n\n\n\n\n\nyfft[abs(yfft)&lt;100] = 0\n\n\nplt.plot(y,'o',alpha=0.1)\nyhat=np.fft.ifft(yfft)\nplt.plot(yhat,'--')\nplt.plot(y-eps,'-')\n\n\n\n\n\n\n\n\n\nplt.plot(spec2(y)[:50],'o')\nplt.plot(spec2(yhat)[:50],'x')\n\n\n\n\n\n\n\n\n\n\n삼성전자 주가자료를 스무딩해보기\n- 삼성전자 자료\n\nimport yfinance as yf\n\n\nstart_date = \"2023-01-01\"\nend_date = \"2023-05-02\"\ny = yf.download(\"005930.KS\", start=start_date, end=end_date)['Adj Close'].to_numpy()\n\n[*********************100%***********************]  1 of 1 completed\n\n\n\nplt.plot(y)\n\n\n\n\n\n\n\n\n- 스펙트럼\n\nyfft = np.fft.fft(y)\n\n\nplt.plot(abs(yfft))\n\n\n\n\n\n\n\n\n- 처음 50개정도만 관찰\n\nplt.plot(abs(yfft[:50]),'o')\n\n\n\n\n\n\n\n\n\n첫값이 너무커서 나머지는 잘안보임\n\n- 2번째부터 50번째까지만 관찰\n\nplt.plot(abs(yfft)[2:50],'o')\nplt.axhline(y=22500, color='r', linestyle='--')\n\n\n\n\n\n\n\n\n\n대충 이정도 짜르면 될것같음\n\n- thresholded value\n\ntresh_value = 22500\n\n\nyfft[abs(yfft)&lt;tresh_value] =0 \n\n- 퓨리에역변환\n\nyhat = np.fft.ifft(yfft)\nyhat[:5]\n\narray([59664.72193044+8.87311904e-14j, 58572.98839934+8.87311904e-14j,\n       58066.07369126+3.39894326e-14j, 58169.18671667-6.87747670e-14j,\n       58706.41986821-1.14383435e-13j])\n\n\n실수화\n\nyhat = np.real(yhat)\nyhat[:5]\n\narray([59664.72193044, 58572.98839934, 58066.07369126, 58169.18671667,\n       58706.41986821])\n\n\n- 적합결과 시각화\n\nplt.plot(y)\nplt.plot(yhat,'--')\n\n\n\n\n\n\n\n\n- 숙제: treshold value를 관찰하며 시각화해볼것\n\n\nminor topics\n- y의 FFT 결과는 항상 y와 같은길이임\n\nlen(y)\n\n82\n\n\n\nlen(np.fft.fft(y))\n\n82\n\n\n- 에일리어싱: number of observation은 얼마나 세밀한 주파수까지 측정가능하냐를 결정함\n예시1: 에일리어싱\n\nx = np.linspace(-3.14,3.14,10)\n\n\nx1 = np.sin(8*x)\nx2 = np.sin(10*x)\n\n\nnp.corrcoef([x1,x2])\n\narray([[ 1.        , -0.99975131],\n       [-0.99975131,  1.        ]])\n\n\n\nplt.plot(x1,label='x1')\nplt.plot(x2,label='x2')\nplt.legend()\n\n\n\n\n\n\n\n\n\n실제로는 x2가 더 고주파인데, 같은 주파수처럼 보임\n\n예시2: 에일리어싱이 없는 경우\n\nx = np.linspace(-3.14,3.14,100000)\n\n\nx1 = np.sin(8*x)\nx2 = np.sin(10*x)\n\n\nnp.corrcoef([x1,x2])\n\narray([[ 1.00000000e+00, -6.45767105e-08],\n       [-6.45767105e-08,  1.00000000e+00]])\n\n\n\nplt.plot(x1)\nplt.plot(x2)\n\n\n\n\n\n\n\n\n\n주파수 왜곡떄문에 실제로는 corr ceof = 0 일지라도 관측되는건 corr coef &gt;0 일 수 있음"
  },
  {
    "objectID": "공부/2023-03-01-(공부&서연) 지수분포 가설검정.html",
    "href": "공부/2023-03-01-(공부&서연) 지수분포 가설검정.html",
    "title": "(공부&서연) 지수분포 가설검정",
    "section": "",
    "text": "using Distributions, Plots\n\n(문제) \\(X_1,X_2\\)가 평균이 \\(\\theta\\)인 지수분포에서 추출한 랜덤표본이라고 하자. 가설 \\(H_0: \\theta=2\\) vs \\(H_1:\\theta=1\\) 에 대하여, \\(H_0\\)에 대한 기각영역을\n\\[\\frac{f(x_1;\\theta=2)f(x_2;\\theta=2)}{f(x_1;\\theta=1)f(x_2;\\theta=1)}&lt;\\frac{1}{2}\\]\n와 같이 설정하자. 이와 같은 검정법에 대한 \\(\\alpha\\)와 \\(\\beta\\)를 구하라.\n(풀이)\n문제요약\n\n\\(f(x) = \\frac{1}{\\theta} \\exp(-\\frac{x}{\\theta})\\) -&gt; 평균이 \\(\\theta\\) 인 지수분포\n검정통계량: \\(T=\\frac{f(x_1;2)f(x_2;2)}{f(x_1;1)f(x_2;1)}\\)\n\\(\\alpha = P(\\text{Reject $H_0$|$H_0$ is true}) = P(T&lt;\\frac{1}{2} | \\text{$H_0$ is true})\\)\n\\(\\beta = P(\\text{Accept $H_0$|$H_1$ is true}) = P(T&gt;\\frac{1}{2} | \\text{$H_1$ is true})\\)\n\n풀이시작\n\nT= x -&gt; 0.5*exp(-0.5*x[1]) * 0.5*exp(-0.5*x[2])  / (exp(-x[1])*exp(-x[2]))\n\n#1 (generic function with 1 method)\n\n\n\\(\\alpha\\)를 구해보자. (시뮬)\n\nθ=2 \nx = rand(Exponential(θ),2)\n\n2-element Vector{Float64}:\n 1.4932782791687658\n 3.904496314340747\n\n\n\nT(x)\n\n3.715796051759978\n\n\n\nTs = [rand(Exponential(θ),2) |&gt; T for i in 1:1400000]\nmean(Ts .&lt; 1/2)\n\n0.1535007142857143\n\n\n\\(\\beta\\)를 구해보자. (시뮬)\n\nθ=1\nx = rand(Exponential(θ),2)\n\n2-element Vector{Float64}:\n 1.0915718974295616\n 3.322182470278192\n\n\n\nTs = [rand(Exponential(θ),2) |&gt; T for i in 1:1400000]\nmean(Ts .&gt; 1/2)\n\n0.5967985714285714\n\n\n\\(\\alpha\\)를 구해보자. (이론)\n\\(T(X_1,X_2) = \\frac{0.25\\exp(-0.5X_1 -0.5X_2)}{\\exp(-X_1-X_2)}=0.25\\exp(0.5X_1+0.5X_2)\\)\n$T(X_1,X_2)&lt; (0.5X_1+0.5X_2) &lt; 2 X_1+X_2&lt; 2 $\n그런데 \\(X_1+X_2 \\sim \\chi^2(4)\\) under \\(H_0\\)\n\\(P(X_1+X_2 &lt; 2\\ln2) = \\int_0^{2\\ln2} \\frac{1}{4\\Gamma(2)}x e^{-x/2}dx=\\int_0^{\\ln2} t e^{-t}dt=\\big[t(-e^{-t})-e^{-t}\\big]_0^{\\ln2}\\)\n\nt = log(2) \nu = t*(-exp(-t)) - exp(-t)\nt = 0\nl = t*(-exp(-t)) - exp(-t)\n\n-1.0\n\n\n\nu-l\n\n0.1534264097200273\n\n\n\\(\\beta\\)를 구해보자. (이론)\n$T(X_1,X_2)&gt; (0.5X_1+0.5X_2) &gt; 2 (X_1+X_2)&gt; 4 $\n그런데 \\(2(X_1+X_2) \\sim \\chi^2(4)\\) under \\(H_1\\)\n\\(P(2(X_1+X_2) &gt; 4\\ln2) = \\int_{4\\ln2}^{\\infty}\\frac{1}{4\\Gamma(2)}x e^{-x/2}dx=\\int_{2\\ln2}^{\\infty} t e^{-t}dt=\\big[t(-e^{-t})-e^{-t}\\big]_{2\\ln2}^{\\infty}\\)\n\nu = 0\nt = 2*log(2)\nl = t*(-exp(-t)) - exp(-t)\nu-l\n\n0.5965735902799727"
  },
  {
    "objectID": "공부/2023-07-04-(공부) 토폴로지.html",
    "href": "공부/2023-07-04-(공부) 토폴로지.html",
    "title": "(공부) 토폴로지",
    "section": "",
    "text": "About this doc\n- 수학공부\n- 학부수준\n- 이 문서는 논문을 읽을때 등장하는 topology 용어들을 좀더 명확하게 이해하고 싶어서 작성하였다. 가볍게 정의만 훑어보는 것이라 깊게 들어가지는 않을 예정이다. 교재는 Schaum’s General Topology 를 참고하였다. - Lipschutz, S. (1965). Schaum’s outline of theory and problems of general topology. Schaum’s Outline Series.\n- 여기에서는 토폴로지의 정의와 메트릭스페이스의 정의 그리고 컴플리션의 정의에 대하여 다룬다.\n\n\nChap 5: 토폴로지\n- (Lipschutz (1965), p.66) \\({\\cal T}\\) 가 \\(X\\) 의 subset 으로 이루어진 collection 이라고 하자. \\({\\cal T}\\) 가 \\(X\\) 를 포함하며 uncountable union 에 닫혀있고 finite intersection 에 닫혀있다면 \\({\\cal T}\\) 를 \\(X\\) 의 topology 라고 한다. 그리고 \\((X,{\\cal T})\\) 를 topological space 라고 한다. \\({\\cal T}\\) 가 \\(X\\)의 토플로지일때 \\({\\cal T}\\) 의 원소를 \\({\\cal T}\\)-open set 이라고 한다. 따라서 원래 오픈셋은 마치 확률변수처럼 단독으로 정의할 수 없고 어떠한 토폴로지 \\({\\cal T}\\)와 같이 정의된다.\n- (Lipschutz (1965), p.66) 아래와 같은 collection 을 생각하자.\n\\[{\\cal O}:=\\{O: O=\\cup_i(a_i,b_i), a_i,b_i \\in \\mathbb{R} \\} \\]\n컬렉션 \\({\\cal O}\\) 는 \\(\\mathbb{R}\\) 의 토폴로지가 된다. (증명은 알아서..) 이러한 토폴로지(=오픈인터벌의 카운터블-유니온으로 표현가능한 집합들의 모임)을 특별히 usual topology 라고 한다. 그리고 이 토폴로지의 원소를 \\({\\cal O}\\)-오픈셋이라고 부른다. 따라서 어떤 집합 \\(O\\) 가 \\({\\cal O}\\)-오픈셋 이라는 말은 그 집합이 오픈인터벌의 카운터블-유니온으로 표현가능한 집합임을 의미한다.\n- 참고로 \\({\\cal O}\\) 가 우리가 일반적으로 생각하는 ‘오픈셋들의 모임’ 이고 \\({\\cal O}\\)-오픈셋이 보통 우리가 일반적으로 유클리드 공간에서 상상하는 오픈셋이다. 그래서 앞으로 특별한 언급없이 그냥 ‘오픈셋’ 이라고 부르면 토폴로지 \\((\\mathbb{R},{\\cal O})\\) 에서 정의가능한 ‘\\({\\cal O}\\)-오픈셋’ 을 의미하는 것이라고 생각하면 된다.\n- 즉 우리가 일반적으로 생각하는 오픈셋1은 오픈인터벌 \\((a,b)\\) 의 countable-many union 으로 표현가능한 집합이라고 이해해도 된다.\n1 정확하게는 \\(\\cal O\\)-오픈셋- 오픈셋 \\(O\\)의 원소를 interior point of \\(O\\) 라고 한다. \\({\\cal O}\\)의 정의에 의해서 인테리어포인트는 모두 아래의 성질을 만족한다.\n\\[\\forall o \\in O ~ \\exists a,b \\in \\mathbb{R}~ st.~  o \\in (a,b)\\]\n증명은 귀류법을 쓰면 쉽게 된다.\n- 저 정리가 생각보다 중요하다. 그리고 이 정리를 나이테정리 라고 기억하자. 이 정리는 \\({\\cal O}\\)-오픈셋이 아닌 일반적인 \\({\\cal T}\\)-오픈셋에 대하여서도 성립한다. 즉 \\((X,{\\cal T})\\)가 위상공간이고 \\(T\\)가 \\({\\cal T}\\)의 임의의 집합이라 하자. \\(T\\)의 임의의 원소 \\(p\\)에 대하여 (1) \\(p\\) 를 포함하지만 (2) \\(T\\) 보다 작은 다른 \\({\\cal T}\\)-오픈셋이 항상 존재한다.\n- 그리고 교재에 따라서는 위와 같은 성질을 만족하는 것을 오픈셋이라고 정의하기도 한다. 이와 같은 논리흐름으로는 오픈인터벌 \\((a,b)\\)를 정의하고 그로부터 인테리어포인트 \\(o\\)와 오픈셋 \\(O\\)를 정의하고 그로부터 토폴로지 \\({\\cal O}\\)를 정의할 수 있다. 하지만 이러한 방식의 contruction 으로는 \\((\\mathbb{R},{\\cal O})\\) 만 만들수있다. 일반적으로는 적당한 \\({\\cal T}\\)가 \\(X\\)의 토폴로지임을 밝히고 그로부터 오픈셋을 정의하고 그 다음 인테리어포인트를 정의하는 식으로 각 요소들을 contruction 한다.\n- 오픈셋의 여집합을 클로즈드셋이라고 한다. 여기서 사람들이 “모든 집합은 오픈셋이거나 클로즈드셋 이어야 한다” 라고 착각하기 쉬운데 사실 그런것은 아니다.\n- 어떠한 construction을 사용하든지 아래의 사실들이 성립한다. 따로 설명을 쓰지 않은 것은 아주 약간의 머리를 쓰면 쉽게 증명할 수 있는 것들이다. (하지만 그냥 받아들이거나 외우는 것이 편하다.) 참고로 아래의 모든 사실들은 보통위상공간 즉 \\((\\mathbb{R},{\\cal O})\\) 를 전제하고 서술한 것이다.\n(1) \\((a,b)\\) 는 오픈셋이다.\n(2) \\(\\mathbb{R}\\) 은 오픈셋이다. 동시에 클로즈드셋이다2.\n2 공집합이 오픈셋이므로3 \\(\\mathbb{R}\\)이 오픈셋이므로(3) \\(\\emptyset\\) 은 오픈셋이다. 동시에 클로즈드셋이다3.\n(4) 오픈셋은 uncountable union 에 닫혀있다. 즉 \\(O_t\\)가 각각 오픈셋일때 \\(\\cup_t O_t\\) 역시 오픈셋이다.\n(5) 오픈셋은 finite intersection 에 닫혀있다. 즉 \\(O_i\\)가 각각 오픈셋이면 \\(\\cap_{i=1}^{n} O_i\\) 역시 오픈셋이다\n(6) 한점 \\(p\\)로 이루어진 집합 \\(\\{p\\}\\)는 오픈셋이 아니다. 이것이 오픈셋이 되려면 \\(\\{p\\}\\)의 모든원소(라고 해봤자 \\(p\\) 밖에 없음)가 내점이어야 하고 \\(p\\)가 \\(\\{p\\}\\)의 내점이려면 \\(p\\)를 포함하는 오픈인터벌 \\((a,b)\\)가 \\(\\{p\\}\\)의 부분집합으로 존재해야하는데 이것이 불가능하기 때문이다. 4\n4 다만 이것은 위상공간을 \\((\\mathbb{R},{\\cal O})\\)로 생각하였을때 이야기이고 위상공간을 \\((\\mathbb{R},2^{\\mathbb{R}})\\)로 생각한다면 \\(\\{p\\}\\) 도 오픈셋이 된다.(7) 오픈셋의 countable-many intersection 은 오픈셋이 아니다. 왜냐하면 \\(\\cap_{n=1}^{\\infty}(-1/n,1/n)=\\{0\\}\\) 인데 \\(\\{0\\}\\)은 오픈셋이 아니기 때문이다.\n- (Lipschutz (1965), p. 69) 위상공간 \\((X,{\\cal T})\\) 를 상상하자. \\(X\\)의 부분집합 \\(A\\)를 상상하자. “집합 \\(A\\)가 \\(X\\)에서 dense 하다” 라는 의미는 \\(\\bar{A}=X\\)라는 의미이다. 가장 빈번하게 사용하는 표현은 “유리수집합 \\(\\mathbb{Q}\\)는 실수 \\(\\mathbb{R}\\)에서 dense 하다” 인데 이것은\\(\\bar{\\mathbb{Q}}=\\mathbb{R}\\)이 성립하기 때문이다 (예제 4.3).\n\n\nChap 6: 기저\n- 오픈인터벌 \\((a,b)\\)를 적당히 countable-many union 하면 \\(\\mathbb{R}\\) 에 존재하는 어떠한 오픈셋 \\(O\\)도 표현할 수 있다. 이럴때 \\((a,b)\\) 모아놓은 collection \\({\\cal B}:=\\{(a,b): a&lt;b \\in \\mathbb{R}\\}\\) 를 토폴로지 \\({\\cal O}\\)의 base 라고 한다. 이처럼 어떠한 위상공간 \\((X,{\\cal T})\\) 가 있을때 토폴로지 \\({\\cal T}\\) 의 임의의 집합을 \\({\\cal B}\\)의 원소들의 uncountable union 으로 표현가능때 \\({\\cal B}\\)를 \\({\\cal T}\\)의 base 라고 한다. 그리고 추가적으로 base의 모든 원소는 \\({\\cal T}\\)-오픈셋이어야 한다는 조건도 포함된다.\n- 토폴로지 \\({\\cal T}\\)의 base는 유일하지 않다.\n- 아래와 같은 collection을 상상하여 보자.\n\\[\\tilde{\\cal B}:=\\{all~ ray~ in~\\mathbb{R} \\} := \\{(-\\infty,b): b\\in \\mathbb{R} \\} \\cup \\{(a,\\infty): a \\in \\mathbb{R}\\}\\]\n보는 것처럼 \\(\\tilde{\\cal B}\\)는 위상의 정의를 만족한다. 그리고 \\(\\tilde{\\cal B}\\)는 \\({\\cal O}\\)의 base가 아니다. 하지만 \\(\\pi(\\tilde{\\cal B})\\) 는 \\((a,b)\\)를 포함하고 있기에 \\({\\cal O}\\) 의 base가 된다. 여기에서 \\(\\pi(\\tilde{\\cal B})\\) 는 \\(\\tilde{\\cal B}\\) 에 의해서 생성된 가장 작은 \\(\\pi\\)-system 이다.\n- 참고로 \\(\\pi\\)-시스템은 모든 원소가 finite intersection 에 닫혀있는 collection 을 의미한다. 전체집합은 empty intersection 으로 해석할 수 있으므로 모든 파이시스템은 전체집합을 포함한다. 따라서 파이시스템을 정의하면 전체집합을 같이 정의하는것과 마찬가지이다. 따라서 파이시스템 역시 시그마필드와 토폴로지처럼 전체집합과 동시에 정의된다. 그리고 정의에 따라서 임의의 집합에 대한 토폴로지와 시그마필드 모두 파이시스템이 된다.\n- 위에서 예를 든 \\(\\tilde{\\cal B}\\) 와 같이 그것 자체가 어떤 위상 \\({\\cal T}\\) 의 base는 아니지만 \\(\\pi(\\tilde{\\cal B})\\) 는 \\({\\cal T}\\) 의 base가 될때 \\(\\tilde{\\cal B}\\)를 \\({\\cal T}\\)의 subbase 라고 한다.\n- \\(\\tilde{\\cal B}\\) 가 토폴로지 \\({\\cal T}\\)의 subbase이면 \\(\\tilde{\\cal B}\\)로 \\({\\cal T}\\)를 generate 할 수 있다.\n\n\nChap 8: Metric and Normed Spaces\n- \\(d:X \\times X \\to \\mathbb{R}\\) 가 (1) 음이 아니고 (2) 대칭이며 (3) 삼각부등식을 만족하면 집합 \\(X\\) 에서의 metric 이라고 한다. 이때 음이 아닐 조건은\n\\[\\begin{cases}\nd(a,b) &gt; 0 & a \\neq b \\\\\nd(a,b) = 0 & a=b\n\\end{cases}\\]\n이다. 만약에 메트릭의 모든 조건을 만족하는데 \\(d(a,b)=0\\) 인 서로 다른 \\(a,b \\in X\\) 가 존재하는 경우 \\(d\\) 를 pseudometric 이라고 한다.\n- \\(d\\) 을 집합 \\(X\\) 에서의 메트릭이라고 하자. 메트릭이 존재한다는 것은 집합 \\(X\\)의 어떠한 두 원소라도 그 사이의 거리를 잴 수 있다는 말이고 그것은 집합 \\(X\\)의 임의의 점 \\(p\\)에서 아래와 같은 ball 을 정의할 수 있는 말이다.\n\\[S(p,\\delta) := \\{x:d(p,x)&lt;\\delta,x \\in X \\}\\]\n참고로 위와 같은 ball 들을 모은 collection 을 \\({\\cal B}\\)라고 하자. 그리고 \\({\\cal B}\\)의 임의의 원소를 언카운터블-유니온하여 얻을 수 있는 집합들의 모임을 \\({\\cal T}\\)라고 하자. 그러면 (1) \\({\\cal T}\\) 가 \\(X\\) 의 토폴로지임을 보이고 (2) \\({\\cal B}\\)의 모든 원소가 \\({\\cal T}\\)-오픈셋임을 보인다면 \\({\\cal B}\\)는 \\({\\cal T}\\)의 base가 된다고 주장할 수 있다(Thm 8.4). 그런데 (2)는 (1)이 성립하면 자동으로 성립하므로 (1)만 보이면 된다. 그러기 위해서는 아래의 (i)-(iii)을 보이면 된다.\n(i) 우선 \\({\\cal T}\\)가 언카운터블-유니온에 닫혀있음은 associative laws 에 의해서 쉽게 증명된다.\n(ii) 이제 \\({\\cal T}\\)가 파이나이트-인터섹션에 닫혀있음을 보이자. \\({\\cal T}\\)의 임의의 두 원소는 각각 \\({\\cal B}\\)의 언카운터블-유니온으로 표현가능하다. 가령 예를들어 임의의 \\(T,S \\in {\\cal T}\\) 가 아래와 같이 표현되었다고 치자.\n\\[T=\\bigcup_{t\\in [0,1]}B_{t}, \\quad S=\\bigcup_{s\\in [2,3]}B_{s}\\]\n따라서 \\(T\\cap S\\) 는 distributive laws 에 의해서 아래와 같이 표현가능하다.\n\\[T \\cap S = \\bigcup_{(t,s) \\in [0,1]\\times[2,3]} B_t \\cap B_s \\]\n(i)에 의해서 \\(B_t \\cap B_s\\)가 \\({\\cal T}\\)의 원소이기만 하면 \\(T \\cap S\\) 역시 \\({\\cal T}\\)의 원소가 되는 구조라 (ii)가 증명된다. 따라서 이제 우리가 할일은 \\(B_t\\cap B_s\\)가 \\({\\cal T}\\)의 원소임을 보이는 것이고 이것은 \\(B_t \\cap B_s\\)가 \\({\\cal B}\\)의 언카운터블-유니온으로 표현가능하다는 조건과 동치이다. 우선 \\(B_t \\cap B_s\\)에 속하는 임의의 원소를 $b^* $ 라고 하자. 이 점에 대하여 나이테정리를 만족시키는 ball이 존재한다. 즉\n\\[\\exists S(b^* ,\\delta)~ st. ~ S(b^* ,\\delta) \\subset B_t \\cap B_s\\]\n이다(Lemma 8.3). 그런데 \\(B_t \\cap B_s\\)의 모든점에서 이런식으로 나이테정리를 만족하는 ball을 잡을 수 있다. 이러한 ball들의 합집합을\n\\[\\bigcup_{b^* \\in (B_t \\cap B_s)} S(b^* , \\delta)\\]\n이라고 하자. 자명하게 이 집합은 \\(B_t\\cap B_s\\) 보다 작다(부분집합들의 합이므로). 하지만 \\(B_t\\cap B_s\\)의 모든 원소는 이 집합에 포함되므로 이 집합은 \\(B_t\\cap B_s\\)보다 크다. 따라서\n\\[\\bigcup_{b^* \\in (B_t \\cap B_s)} S(b^* , \\delta)=B_t \\cap B_s\\]\n이 성립한다.\n(iii) \\({\\cal T}\\)가 \\(X\\)를 포함한다는 것을 보이는것은 볼의 반지름을 크게 만들면 쉽게 증명할 수 있다.\n- 참고로 위의 (i)-(iii)을 요약하면 (1) \\(X\\)가 \\({\\cal B}\\)의 언카운터블 유니온으로 표현가능하고 (2) \\({\\cal B}\\)의 임의의 두 원소가 \\({\\cal B}\\)의 언카운터블 유니온으로 표현가능하기만 하면 볼들이 집합이 아니라 어떠한 \\({\\cal B}\\)라도 특정 토폴로지의 base라고 주장할 수 있다. 이것이 교재의 Thm 6.1 이다.\n- 아무튼 위의 과정을 거치면 \\(X\\)위에서 거리를 정의할 수 있을때 그 거리에 의해서 ball을 정의할 수 있고 ball들의 콜렉션을 base \\({\\cal B}\\)로 정의하고 \\({\\cal B}\\) 원소들의 언카운터블-유니온으로 표현가능한 집합모임을 토폴로지 \\({\\cal T}\\)로 정의해도 논리적모순점이 없다. 즉 \\(X\\)에서 메트릭이 정의되기만 하면 그것에 의해서 순차적으로 토폴로지 \\({\\cal T}\\)를 자연스럽게 유도할 수 있는데 이러한 토폴로지를 특별히 \\(X\\)와 \\(d\\)에 의해서 유도된 metric topology 라고 한다. 그리고 \\((X,d)\\)를 metric-space 라고 한다.\n- \\(\\mathbb{R}\\)에서 \\({\\cal O}\\)를 유도하는 메트릭은 우리가 보통 생각하는 유클리드거리이다. 이러한 메트릭을 usual metric 이라고 한다.\n- \\(\\mathbb{R}\\)에서 아래와 같은 거리를 정의할 수 있다.\n\\[d(a,b)=\\begin{cases}\n0 & a=b \\\\\n1 & a\\neq b\n\\end{cases}\\]\n이러한 거리를 trivial metric 이라고 한다. 그리고 이 거리가 유도하는 토폴로지는 \\(2^{\\mathbb{R}}\\) 이다. (아 몰라.. 따지기 싫어.. 그냥 외워..)\n- 만약에 집합 \\(X\\)에서 정의된 2개의 메트릭 \\(d_1\\), \\(d_2\\)가 같은 토폴로지를 유도한다면 두 메트릭 \\(d_1\\)과 \\(d_2\\)는 equivalent 하다고 말한다.\n- 토폴로지컬-스페이스 \\((X,{\\cal T})\\) 가 있다고 하자. 그런데 \\(X\\) 에서 어떠한 메트릭 \\(d\\)가 존재해 그것이 \\({\\cal T}\\)를 유도하였다고 하자. 그럼 \\({\\cal T}\\)는 메트릭-토폴로지가 된다. 이와 같이 (1) \\(X\\)에서 정의되고 (2) 메트릭-토폴로지 \\({\\cal T}\\)를 유도하는 적당한 메트릭 \\(d\\)가 명시된것은 아니지만 그런 메트릭의 존재를 하나 이상 우리가 알고 있을때 위상공간 \\((X,{\\cal T})\\)를 metrizable 하다고 한다.\n- 두 메트릭스페이스 \\((X,d_1)\\) 와 \\((Y,d_2)\\) 가 isometric 하다는 것은 아래가 만족하는 one-one, onto 인 \\(f:X \\to Y\\) 가 존재한다는 것이다.\n\\[d_1(p,q) = d_2(f(p),f(q))\\]\n- 이때 isometric 이라는 relation 은 보는것 처럼 모든 메트릭공간들의 집합 \\({\\cal M}\\)에서 equivalence relation 이다. 즉 아래가 성립한다.\n(i) \\((X,d_1) \\overset{ism}{\\sim} (X,d_1)\\),\n(ii) \\((X,d_1) \\overset{ism}{\\sim} (Y,d_2)\\) implies \\((Y,d_2) \\overset{ism}{\\sim} (X,d_1)\\),\n(iii) \\((X,d_1) \\overset{ism}{\\sim} (Y,d_2)\\) and \\((Y,d_2) \\overset{ism}{\\sim} (Z,d_3)\\) imply \\((X,d_1) \\overset{ism}{\\sim} (Z,d_3)\\).\n\n\nChap 9: Countability\n- (Lipschutz (1965), p. 132) 위상공간 \\((X,{\\cal T})\\)가 separable 하다는 의미는 \\((X,{\\cal T})\\) countable dense subset 을 가진다는 의미이다.\n- 위상공간 \\((\\mathbb{R}, {\\cal O})\\)를 상상하자.\n\n\\(A_n = [-n,n] \\cap \\mathbb{Q}\\)\n\n라고 한다면 (1) \\({\\cal A} = \\{A_n\\}\\) 은 countable 하고 (2) \\(A_n\\)은 모두 (\\([-n,n]\\)에서) dense 하다. 따라서 \\(\\mathbb{R}\\)은 countable한 dense subset을 가진다. 따라서 \\((\\mathbb{R},{\\cal O})\\)는 seperable 하다.\n\n\nChap 10: Separation Axioms\n- 예비학습1: 위상공간 \\((X,{\\cal T})\\)를 고려하자. \\(X\\)의 임의의 닫힌집합 \\(F\\)를 상상하자. 그리고 \\(F\\)에 소속되지 않은 한 점 \\(p \\in X\\)를 상상하자. 이제 닫힌집합 \\(F\\)를 포함하는 아주 작은 열린집합 \\(G\\)와 \\(p\\)를 포함하는 아주 작은 열린집합 \\(H\\)를 상상하자. 위상공간 \\((X,{\\cal T})\\)에서 임의의 \\(F\\)와 \\(p\\)에 대하여서도 두 열린집합 \\(G\\),\\(H\\)가 서로소가 되도록 선택할 수 있다면 그 위상공간은 regular 하다고 표현한다 (Lipschutz (1965), p. 140).\n이해를 위한 예시\n\n\\(F= [0,1]\\)\n\\(p = 1.01\\)\n\\(G= (-0.001, 1.001)\\)\n\\(H= (1.009,1.011)\\)\n\n- 예비학습2: 위상공간 \\((X,{\\cal T})\\)를 고려하자. \\(X\\)의 부분집합중 서로소인 닫힌집합 \\(F_1,F_2\\)를 상상하자.이제 닫힌집합 \\(F_1\\)를 포함하는 아주 작은 열린집합 \\(G\\)와 \\(F_2\\)를 포함하는 아주 작은 열린집합 \\(H\\)를 상상하자. 위상공간 \\((X,{\\cal T})\\)에서 임의의 \\(F_1\\)와 \\(F_2\\)에 대하여서도 두 열린집합 \\(G\\),\\(H\\)가 서로소가 되도록 선택할 수 있다면 그 위상공간은 normal 하다고 표현한다 (Lipschutz (1965), p. 141).\n5 \\({\\cal T}=\\{\\emptyset, X\\}\\)로 설정한다면 이 조건은 당연히 성립하지 않겠지?- 위상공간 \\((X,{\\cal T})\\) 에는 얼마나 많은 (혹은 다양한) 열린집합이 있을까? 위상공간 \\((X,{\\cal T}_1)\\)이 \\(T_1\\)-space라는 의미는 서로 다른 \\(a,b \\in X\\)에 대하여 \\(a\\)만 포함하는 열린집합 혹은 \\(b\\)만 포함하는 열린집합이 각각 존재한다는 의미이다.5 위상공간 \\((X,{\\cal T}_2)\\)이 \\(T_2\\)-space 혹은 Hausdorff space라는 의미는 \\(T_1\\)-space에서, \\(a\\)만 포함하는 열린집합과 \\(b\\)만 포함하는 열린집합이 서로 disjoint한 경우를 의미한다. 위상공간 \\((X,{\\cal T}_3)\\)이 \\(T_3\\)-space 라는 의미는 \\(T_1\\)이고 regular space 라는 의미이다. 위상공간 \\((X,{\\cal T}_4)\\)이 \\(T_4\\)-space 라는 의미는 \\(T_1\\)이고 normal space 라는 의미이다.\n- 포함관계: \\(T_1\\)-space는 \\(T_2\\)-space를 포함하고, \\(T_2\\)-space는 \\(T_3\\)-space를, \\(T_3\\)-space는 \\(T_4\\)-space를 포함한다 (Lipschutz (1965), p. 141 그림). 그리고 metric space는 \\(T_4\\) space에 포함된다.\n- \\(T_1\\) 위상공간에서는 “singleton = closed set” 이라고 주장할 수 있다. (Lipschutz (1965), Thm 10.1) \\(T_2\\) 위상공간에서는 “convergent sequence has a unique limit” 을 주장할 수 있다 (Lipschutz (1965), Thm 10.3). \\(T_3\\) 위상공간은 특별히 기억할만한 부분이 없어보인다. \\(T_4\\) 위상공간은 우리손레마 (urysohn lemma) 가 성립하는 공간이다 (Lipschutz (1965), Thm 10.7).\n- 우리손레마: \\(T_4\\) 위상공간 \\((X,{\\cal T}_4)\\)를 상상하자. 그리고 \\(X\\)의 부분집합 중 서로소인 닫힌 부분집합 \\(F_1,F_2\\)를 상상하자. 우리손레마에 의하면 어떠한 \\(F_1,F_2\\)에 대하여서도,\n\n\\(f(F_1)=\\{0\\}\\)\n\\(f(F_1)=\\{1\\}\\)\n\n를 만족하는 적당한 연속함수 \\(f:X \\to [0,1]\\)이 항상 존재함이 알려져 있다 (Lipschutz (1965), Thm 10.7). 이것은 \\(F_1,F_2\\)를 구분할 수 있는 어떠한 함수 \\(f\\)가 항상 존재함을 의미하는데 이는 \\((X,{\\cal T}_4)\\)를 거리공간화 하는데 이용할 수 있다. 구체적으로 위상공간 \\((X,{\\cal T}_4)\\)가 추가적으로 second coutable 조건을 만족한다면6 \\((X,{\\cal T}_4)\\) 는 거리공간으로 바꿀 수 있음이 알려져 있다 (Lipschutz (1965), Thm 10.8).\n\nLipschutz, Seymour. 1965. “Schaum’s Outline of Theory and Problems of General Topology.” (No Title).\n6 즉 \\((X,{\\cal T}_4)\\)가 countable한 base를 가진다면- 위상공간 \\((X,{\\cal T})\\)가 \\(T_4\\)-space이고 추가적으로 second coutable space 라면 \\((X,{\\cal T})\\)는 Hilbert cube 와 호모몰픽(homeomorphic) 하다는 것이 알려져 있다 (Lipschutz (1965), p. 142).\n\n\nChap 14: Complete Metric Spaces\n- Convergent sequence 은 단독으로 정의될 수 없으며 위상공간 \\((X,{\\cal T})\\) 와 묶어서 정의된다. 그리고 Cauchy sequence 역시 단독으로 정의될 수 없으며 메트릭스페이스 \\((X,d)\\) 와 묶어서 정의된다.\n- Convergent sequence 와 Cauchy sequence 는 비슷해보이지만 미묘하게 다른점이 있다.\n(1) 컨버전트-시컨트는 위상공간 \\((X,{\\cal T})\\) 만 있으면 정의할 수 있지만 코시수열은 그 위상공간이 메트릭스페이스 이어야 한다는 제약이 있다. 왜냐하면 컨버전트-시컨스의 정의에는 오픈셋만 필요하지만 코시수열은 볼이 필요하고 볼은 메트릭에 의해서만 정의되기 때문이다.\n(2) 컨버전트-시컨스와 코시수열 모두 열의 각 항이 \\(X\\)의 원소이어야 한다는 조건이 있다. 하지만 컨버전트-시컨스는 그 limit 까지 \\(X\\)의 원소이어야 하는데 코시수열은 그렇지 않다는 차이점이 있다.\n- \\(X=(0,1)\\) 위의 usual metric 에 의해서 유도되는 메트릭스페이스 \\((X,d)\\) 를 생각하자. 수열\n\\[\\left\\{\\frac{1}{2},\\frac{1}{3},\\frac{1}{4},\\dots,\\right\\}\\]\n\\(X\\)에서 정의된 코시수열이지만 \\(X\\)에서 정의되는 컨버전트-시컨스는 아니다.\n- 내가 이해한 바는 아래와 같다.\n(1) 토폴로지 \\((X,{\\cal T})\\) 는 항상 컨버전트-시컨스를 정의할 준비가 되어있는 공간이다.\n(2) 위에서 정의가능한 컨버전트-시컨스는 코시수열과 아무런 관련이 없다. 그리고 우리가 통상적으로 고등학교때부터 다루어왔던 수열의 수렴의 개념과도 거리가 멀다.\n(3) 토폴로지 \\((X,{\\cal T})\\) 가 메트릭스페이스라면 컨버전트-시컨스는 코시수열과 어떤관계가 있으며 고등학교때부터 내가 다루어 왔던 상식적인 수렴하는 수열의 개념과도 관련이 있다.\n(4) \\((X,{\\cal T})\\) 가 메트릭스페이스 라고 가정하자. 그럼 아래가 만족한다고 생각할 수 있다.\n\n\\(\\{a_n\\}\\) converges on \\(X\\) \\(\\Longleftrightarrow\\) \\(\\{a_b\\}\\) is Cauchy sequence on \\(X\\) and \\(\\lim_{n\\to\\infty} a_n \\in X\\)\n\n즉 러프하게 말해서 \\(X\\)에서의 컨버전트-시컨스는 (i) \\(X\\)에서의 코시수열이면서 (ii) limit 이 \\(X\\)에 포함되는 수열이라고 말할 수 있다. 이런 정의로 치면 우리가 고등학교때부터 생각해왔던 소박한 정의의 수렴하는 수열은 사실 코시수열에 가깝고 컨버전트-시컨스는 고등학교때부터 배운 소박한 수렴을 하며 동시에 수렴값이 \\(X\\)에서 잘 정의되는 수열을 의미한다고 볼 수 있다. 앞으로는 소박한 수렴과 컨버전트-시컨스를 엄밀하게 구분하여 말하도록 하자. 즉 \\(\\{a_n\\}\\)이 코시수열이라는 말은 \\(\\{a_n\\}\\)이 소박한 수렴을 한다는 의미이고 \\(\\{a_n\\}\\)이 컨버전트-시컨스라는 의미는 \\(\\{a_n\\}\\)이 소박한수렴을 하며 동시에 그 극한값이 well-define 된다는 의미(=\\(\\{a_n\\}\\)의 수렴값이 \\(X\\)의 원소라는 의미)이다.\n- (proposition 14.1) 메트릭스페이스 한정으로, 컨버전트-시컨스는 모두 코시수열이다. (당연한 소리를.. 이런걸 proposition 이라고..)\n- 당연히 위 정리의 역은 성립하지 않는다. 즉 메트릭스페이스 \\((X,{\\cal T})\\) 에서 정의된 코시수열이 반드시 컨버전트-시컨스라는 보장은 없다. (이것도 당연한 소리.. 왜냐하면 수렴값이 \\(X\\)에 포함된다는 보장이 없기 때문) 하지만 그 메트릭스페이스가 complete 하다면 위 정리의 역도 성립한다.\n- 컴플리트하지 않은 메트릭스페이스 \\((X,d)\\)를 컴플리트한 메트릭스페이스 \\((X^* , d)\\) 로 바꿀 수 없을까? 유주얼메트릭(usual metric) \\(d\\) 와 \\(X=(0,1)\\) 로 만들어지는 메트릭스페이스는 컴플리트하지 않지만 \\(d\\) 와 \\(X^* =[0,1]\\) 로 만들어지는 메트릭스페이스는 컴플리트하다. 이런 경우 $(X^* ,d) $ 는 \\((X,d)\\) 의 completion 이라고 한다.\n- 즉 아래의 조건들을 만족하면 공간 $(X^* ,d) $ 는 공간 \\((X,d)\\) 의 completion 이라고 부른다.\n(1) \\(X\\subset X^*\\)\n(2) \\((X^* ,d)\\) is complete metric space\n(3) \\((X,d) \\overset{ism}{\\sim} (X^* ,d)\\).\n\n- 메트릭스페이스 \\((X,d)\\)에서 아래의 식을 만족하는 두 코시수열 \\(\\{a_n\\}\\), \\(\\{\\tilde a_n\\}\\) 을 생각하여보자.\n\\[\\lim_{n\\to\\infty} d(a_n,\\tilde a_n)=0 \\]\n이러한 코시수열들을\n\\[\\{a_n\\} \\overset{slim}{\\sim} \\{\\tilde a_n\\}\\]\n이라고 표현하자. 이때 관계 \\(\\overset{slim}{\\sim}\\) 은 \\(X\\)에서 정의가능한 모든 코시수열들의 집합 \\({\\cal C}_ X\\) 에서 equivalence relation 이 된다고 한다. (증명은 알아서) 따라서 이걸 이용하면 거리공간에서 \\(slim\\) 의 관계를 가지는 임의의 두 수열은 같은 극한을 가진다는 결론이 나온다. (이것도 잘 따져보자.)\n- 잠시 (1) 바이너리-릴레이션(binary relation), (2) 이퀴배런스-릴레이션(equivalence relation), (3) 이퀴배런스-클래스(equivalence class) 그리고 (4) 코션트셋(quotient set)에 대하여 설명하고 넘어가겠다.\n(1) 집합 \\({\\cal C}_ X\\) 의 두 원소 \\(\\{a_n\\}\\), \\(\\{b_n\\}\\) 간 바이너리-릴레이션 \\(R\\)이 존재한다는 문장은 집합론적인 언어로 표현가능하다. 구체적으로는 \\(R\\)을 곱집합 \\({\\cal C}_ X \\times {\\cal C}_ X\\) 의 적당한 부분집합으로 설정하고 순서쌍 \\(\\big(\\{a_n\\},\\{b_n\\}\\big)\\) 이 \\(R\\) 의 원소라는 식으로 표현한다. 예를 들면 아래와 같은 식으로 말이다.\n$ {a_n} and {b_n} has arelation with~ R \\ ({a_n},{b_n}) R _ X _ X \\ {a_n} {b_n}$\n(2) 그리고 \\({\\cal C}_ X\\) 위에서의 바이너리-릴레이션 \\(R\\)이 (i) reflexivity (ii) symmetricity (iii) transitivity 를 만족하면 이 릴레이션을 특별히 이퀴배런스-릴레이션 이라고 말한다.\n(3) 그리고 아래와 같이 \\({\\cal C}_ X\\) 에서 \\(\\{a_n\\}\\) 과 이퀴배런스-릴레이션을 가지는 원소들을 모아놓은 집합을 생각할 수 있다. \\[\\big[\\{a_n\\}\\big]_ R:=\\big\\{ \\{x_n\\} : \\{x_n\\} \\overset{R}{\\sim} \\{a_n\\} ~and~ \\{x_n\\} \\in {\\cal C}_ X \\big\\}\\]\n이 집합을 \\(\\{a_n\\}\\)의 equivalence class on \\({\\cal C}_ X\\) by \\(R\\) 이라고 부른다. 보통은 \\(R\\)을 생략하여 \\(\\big[\\{a_n\\}\\big]\\)와 같이만 표현하지만 나는 기호의 명확성을 위해서 관계까지 명시하였다.\n(4) 이퀴배런스-클래스는 본질적으로 파티션과 밀접한 연관이 있다. 여기에서 클래스 \\({\\cal P}_ A\\) 가 집합 \\(A\\)의 파티션이란 의미는 클래스 \\({\\cal P}_ A\\) 에 속한 모든 원소의 합이 \\(A\\) 이며 클래스 \\({\\cal P}_ A\\) 의 각 원소는 서로 배타적이라는 의미이다. 이퀴배런스-클래스가 그럼 왜 파티션과 관련이 있을까? 그것은 어떠한 집합에서 이퀴배런스-릴레이션이 존재하면 그 집합을 배타적인 이퀴배런스-클래스의 합집합으로 표현가능하기 때문이다. 즉 이퀴배런스-릴레이션 혹은 이퀴배런-클래스의 존재는 파티션의 존재를 임플라이 한다. 그리고 이러한 파티션을 이퀴배런스-릴레이션 \\(R\\)에 의해 생성된 quotient set 혹은 quotient space 라고 한다. 관계 \\(R\\)에 의한 \\(A\\)의 코션트 셋은 기호로 \\(A ~\\overset{R}{\\sim}\\) 와 같이 쓴다. 예를들어 \\[\\begin{align}\n{\\cal C}_ X ~ /\\overset{slim}{\\sim}\n\\end{align}\\] 은 집합 \\(X\\) 상에서 존재하는 코시수열들의 집합 \\({\\cal C}_ X\\) 에서 이퀴배런스-릴레이션 \\(slim\\) 에 의해서 생성된 코션트셋을 의미한다."
  },
  {
    "objectID": "공부/2024-08-12-(공부) 시계열과 GSP.html",
    "href": "공부/2024-08-12-(공부) 시계열과 GSP.html",
    "title": "(공부) 시계열과 GSP",
    "section": "",
    "text": "아래와 같은 시계열을 고려하여 보자.\n\\[x_n = \\sum_{k=0}^{K-1}\\big(A_k \\cos(2\\pi \\omega_k t_n) + B_k\\sin(2\\pi \\omega_k t_n)\\big)\\]\n여기에서 \\(A_k\\) 와 \\(B_k\\)는 평균이 \\(0\\) 이고 분산이 \\(\\sigma_k\\) 인 분포에서 생성된 확률변수이다.\n이 \\(x_n\\)의 acf는 아래와 같다.\n\ncontinuous version: \\(\\gamma(h) = \\sum_{k=0}^{K-1}\\sigma^2_k\\cos(2\\pi \\omega_k h)\\), \\(h \\in \\mathbb{R}\\).\ndiscrete version: $h = {k=0}"
  },
  {
    "objectID": "공부/2019-04-26-(공부) 퓨리에변환.out.html",
    "href": "공부/2019-04-26-(공부) 퓨리에변환.out.html",
    "title": "(공부) 퓨리에변환",
    "section": "",
    "text": "신록예찬\n2019-04-26\n\nAbout this doc\n- 이번에는 퓨리에 표현들을 정리하도록 하겠다. 내생각엔 퓨리에 표현들도 벡터의 미분만큼 복잡한 것 같다. 정의가 너무 많고 그게 그거 같아서 그렇다. 이번기회에 깔끔하게 정리하도록 하자. 참고한 문헌은 아래와 같다.\n\nHaykin, S., & Van Veen, B. (2007). Signals and systems. John Wiley & Sons.\n\n\n\n들어가며\n- 우선 신호와 하나의 신호값을 구분하는 notation을 생각하자. 우리가 다루는 신호 즉 데이터는 값들의 집합이다. 우리가 시계열자료를 다룬다면 데이터는 아래와 같이 표현한다.\n\n\\(\\{x_i: i \\in \\mathbb{Z}\\}\\)\n\n이와 유시하게 우리가 다루는 자료가 \\(t \\in \\mathbb{R}\\)인 연속신호라면 아래와 같이 표현한다.\n\n\\(\\{x(t): t \\in \\mathbb{R}\\}\\)\n\n우리가 모든 \\(i \\in \\mathbb{Z}\\) 혹은 모든 \\(t \\in \\mathbb{R}\\)에서 신호를 다룰 생각이 없다면 아래와 같은 표현도 얼마든지 가능하다.\n\n\\(\\{x_i: i=0,1,\\dots, \\xi-1 \\}\\)\n\\(\\{x(t):t \\in (0,\\zeta) \\}\\)\n\n- 위와 같이 집합의 표현 없이 단독으로 \\(x_i\\), \\(x(t)\\)와 같이 쓰면 하나의 고정된 값 \\(i,t\\)에 대한 \\(x_i\\), \\(x(t)\\)로 이해하자. 솔직히 이렇게 꼭 신호를 엄밀하게 집합으로 정의하는게 유별나 보일수도 있다. 일반적으로 사람들은 \\(\\{x(t): ~t \\in \\mathbb{R} \\}\\) 대신에 보통 \\(x(t)\\)로 간단하게 줄여서 쓰곤한다.[1] 하지만 이 포스팅에 한정하여 위와 같이 집합의 형태로 엄밀하게 구분해 쓰도록 하자. 처음에는 익숙하지 않지만 나중에는 편리하다.\n\n\n퓨리에표현들\n- 지금부터 우리가 고려하는 모든 신호들은 기본적으로 (1) infinity range에서 정의된 신호라고 가정한다. 즉 연속신호이면 \\(\\mathbb{R}\\)에서 정의된다고 가정하고 이산신호면 \\(\\mathbb{Z}\\)에서 정의된다고 가정한다. 또한 우리가 분석하고자 하는 신호는 (2) integrable 하다고 가정한다. 이건 퓨리에표현들이 적분 혹은 무한합의 형태로 표현된다는 것을 상기하면 타당하여 보인다.\n- 즉 우리가 고려하는 신호는 인피니티-레인지에서 정의되며 인피니티-레인지에서 적분값이 유한한 연속신호 혹은 이산신호 임을 알 수 있다. 이러한 신호는 구체적으로는 아래와 같이 쓸 수 있다.\n\n\\(\\left\\{x(t): \\int_{-\\infty}^{\\infty} |x(t)| dt &lt;\\infty,~ t \\in \\mathbb{R} \\right\\}\\)\n\\(\\left\\{x_i: \\sum_{i=-\\infty}^{\\infty} |x_i| &lt;\\infty,~ i \\in \\mathbb{Z} \\right\\}\\)\n\n- 그런데 integrable 한 함수들만을 고려하다 보면 우리가 다룰 수 있는 신호의 범위가 확 줄어들게 된다. 가령 예를 들어서 아래와 같은 신호는 적분을 하면 무한대가 나오기 때문에 intergrable 하지 않다.\n\n\\(\\left\\{x(t): x(t)=\\sin(t)+1 ,~ t \\in \\mathbb{R} \\right\\}\\)\n\n이것은 좀 불합리해 보이는데 위의 신호는 주기신호라서 한 주기의 패턴만 분석하면 될것 같이 보이기 때문이다. 위의 신호는 intergrable 하지않지만 아래의 신호는 intergrable 하다.\n\n\\(\\left\\{x(t): x(t)=\\sin(t)+1 ,~ t \\in (0,2\\pi) \\right\\}\\)\n\n우리는 이런신호까지 분석하기로 한다. 이런신호를 분석할 수 있는 이유는 해석학 교재를 참고하면 된다.[2]\n- 아무튼 우리는 (1) 인피니티-레인지에서 정의되는 가지는 신호 (2) 인피니티-레인지에서 적분값이 잘 정의되는 신호, 혹은 한 주기만 적분해 보았을때 그 값이 잘 정의되는 주기신호 를 타겟팅해 분석한다. 즉 분석하는 신호는 구체적으로 아래의 4가지이다.\ncase 1: 연속/비주기\n\\(\\left\\{x(t): \\int_{-\\infty}^{\\infty} |x(t)| dt &lt;\\infty,~ t \\in \\mathbb{R} \\right\\}.\\)\ncase 2: 연속/주기\n\\(\\left\\{x(t): \\int_{0}^{\\zeta} |x(t)| dt &lt;\\infty, ~ , x(t)=x(t+\\zeta), ~ t \\in \\mathbb{R}, \\right\\}.\\)\ncase 3: 이산/비주기(=이산/무한)\n\\(\\left\\{x_i: \\sum_{i=-\\infty}^{\\infty} |x_i| &lt;\\infty,~ i \\in \\mathbb{Z} \\right\\}.\\)\ncase 4: 이산/주기(=이산/유한)\n\\(\\left\\{x_i: \\sum_{i=0}^{\\xi-1} |x_i| &lt;\\infty,~ i, x_i=x_{i+\\xi},~ i \\in \\mathbb{Z} \\right\\}.\\)\n- 표현들을 정리하기에 앞서서 몇 가지 알아두어야 할 사항이 있다. (1) 시간축에서 연속인 신호는 주파수측에서는 비주기신호가 나온다. (2) 시간축에서 디스크릿한 신호는 주파수측에서는 주기신호이다. (3) 시간축에서 주기인 신호는 주파수에서는 디스크릿하다. (4) 시간축에서 비주기신호는 주파수에서 연속이다. 이 사실들을 종합하면 각각의 경우에 해당하는 퓨리에 표현들은 아래와 같은 특징을 가지고 있음을 알 수 있다.\ncase 1: 연속/비주기 \\(\\star\\)\n\\(\\left\\{x(t): \\int_{-\\infty}^{\\infty} |x(t)| dt &lt;\\infty,~ t \\in \\mathbb{R} \\right\\}\\) – 시간\n\\(\\quad \\overset{FT}{\\Longleftrightarrow}\\)\n\\(\\left\\{\\hat x(\\omega): \\int_{-\\infty}^{\\infty} |\\hat x(\\omega)| d\\omega &lt;\\infty,~ \\omega \\in \\mathbb{R} \\right\\}\\) – 주파수\ncase 2: 연속/주기\n\\(\\left\\{x(t): \\int_{0}^{\\zeta} |x(t)| dt &lt;\\infty,~ x(t)=x(t+\\zeta),~ t \\in \\mathbb{R} \\right\\}\\) – 시간\n\\(\\quad \\overset{FS}{\\Longleftrightarrow}\\)\n\\(\\left\\{\\hat x_k: \\sum_{k=-\\infty}^{\\infty} |\\hat x_k| &lt;\\infty,~ k \\in \\mathbb{Z} \\right\\}\\) – 주파수\ncase 3: 이산/비주기(=이산/무한)\n\\(\\left\\{x_i: \\sum_{i=-\\infty}^{\\infty} |x_i| &lt;\\infty,~ i \\in \\mathbb{Z} \\right\\}\\)\n\\(\\quad \\overset{DTFT}{\\Longleftrightarrow}\\)\n\\(\\left\\{\\hat x(\\omega): \\int_{0}^{2\\pi} |\\hat x(\\omega)| d\\omega &lt;\\infty,~ \\hat x(\\omega)=\\hat x(\\omega+2\\pi),~ \\omega \\in \\mathbb{R} \\right\\}\\)\ncase 4: 이산/주기(=이산/유한) \\(\\star\\)\n\\(\\left\\{x_i: \\sum_{i=0}^{\\xi-1} |x_i| &lt;\\infty,~ x_i=x_{i+\\xi},~ i \\in \\mathbb{R} \\right\\}\\)\n\\(\\quad \\overset{DTFS}{\\Longleftrightarrow}\\)\n\\(\\left\\{\\hat x_k: \\sum_{k=0}^{\\xi-1} |\\hat x_k| &lt;\\infty,~\\hat x_k = \\hat x_{k+\\xi} ,~ k \\in \\mathbb{Z} \\right\\}\\)\n- 여기에서 \\(\\zeta\\)는 (시간축에서) 연속신호의 주기라고 정의하고 \\(\\xi\\)는 (시간축에서) 이산신호의 주기라고 약속하자. 주파수영역이 디스크릿하게 나오면 FS라고 부르고 주파수영역이 컨티뉴어스하게 나오면 FT라고 부른다. 특이한점은 비주기-이산신호에 대한 FS \\(\\hat x(\\omega)\\)는 주파수 영역에서 주기가 \\(2\\pi\\)임을 파악할 수 있다. 이유는 궁금해하지말자. (내생각에 그냥 \\(\\omega\\)를 적당히 스케일링하여 주기를 \\(2\\pi\\)로 맞췄을 거다.)\n- 이제 짜증나는 적분가능조건따위는 버리도록 하자. 대신에 각 경우에 퓨리에변환(혹은series)과 그 역이 어떻게 정의되는지 알아보자. 그리고 외우자. 각 신호가 어떠한 도메인에서 정의되는지만 잘 파악하면 의외로 외우기 쉽다.\ncase 1. 연속/비주기 \\(\\star\\star\\star\\)\n\\(\\left\\{x(t): x(t)=\\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty} \\hat x(\\omega)e^{j\\omega t} d\\omega,~ t \\in \\mathbb{R} \\right\\}\\)\n\\(\\quad \\overset{FT}{\\Longleftrightarrow}\\)\n\\(\\left\\{\\hat x(\\omega): \\hat x(\\omega)=\\int_{-\\infty}^{\\infty} x(t)e^{-j\\omega t} dt,~ \\omega \\in \\mathbb{R} \\right\\}\\)\ncase 2. 연속/주기\n\\(\\left\\{x(t): x(t)= \\sum_{k=-\\infty}^{\\infty} \\hat x_k e^{j \\frac{2\\pi}{\\zeta} t} ,~ t \\in \\mathbb{R} \\right\\}\\)\n\\(\\quad \\overset{FS}{\\Longleftrightarrow}\\)\n\\(\\left\\{\\hat x_k: \\hat x_k= \\frac{1}{\\zeta}\\int_{0}^{\\zeta}x(t)e^{-j \\frac{2\\pi k}{\\zeta}t}dt,~ k \\in \\mathbb{Z} \\right\\}\\)\ncase 3. 이산/비주기(=이산/무한)\n\\(\\left\\{x_i: x_i=\\frac{1}{2\\pi}\\int_{0}^{2\\pi}\\hat x(\\omega)e^{j \\omega i}d\\omega, ~ i \\in \\mathbb{Z} \\right\\}\\)\n\\(\\quad \\overset{DTFT}{\\Longleftrightarrow}\\)\n\\(\\left\\{\\hat x(\\omega): \\hat x(\\omega)=\\sum_{i=-\\infty}^{\\infty}x_ie^{-j\\omega i}, ~\\omega \\in \\mathbb{R} \\right\\}\\)\ncase 4. 이산/주기(=이산/유한) \\(\\star\\star\\star\\)\n\\(\\left\\{x_i: x_i=\\sum_{k=0}^{\\xi-1} \\hat x_k e^{-j\\frac{2\\pi k}{\\xi}i},~ i \\in \\mathbb{Z} \\right\\}\\)\n\\(\\quad \\overset{DTFS}{\\Longleftrightarrow}\\)\n\\(\\left\\{\\hat x_k: \\hat x_k= \\frac{1}{\\xi}\\sum_{i=0}^{\\xi-1} x_i e^{-j\\frac{2\\pi k}{\\xi}i},~ k \\in \\mathbb{Z} \\right\\}\\)\n- 주기함수는 (그것이 이산이든 연속이든) 주파수영역에서의 값이 디스크릿하다. 즉 위에서 case2와 case4인 경우는 주파수영역에서 값이 디스크릿하다. 이것을 연속함수인것처럼 바꿔보면 아래와 같이 쓸 수 있다.\ncase 2. 연속/주기\n\\(\\left\\{x(t): x(t)= \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty} \\hat x(\\omega)e^{j\\omega t} d\\omega,~ t \\in \\mathbb{R} \\right\\}\\)\n\\(\\quad \\overset{FT}{\\Longleftrightarrow}\\)\n\\(\\left\\{\\hat x(\\omega): 2\\pi\\sum_{k=-\\infty}^{\\infty}\\left[\\frac{1}{\\zeta}\\int_{0}^{\\zeta}x(t)e^{-j \\frac{2\\pi k}{\\zeta}t}dt\\right]\\delta\\left(\\omega-\\frac{2\\pi k}{\\zeta}\\right), ~ k \\in \\mathbb{Z} \\right\\}\\)\ncase 4. 이산/주기(=이산/유한)\n\\(\\left\\{x_i: x_i=\\frac{1}{2\\pi}\\int_{0}^{2\\pi}\\hat x(\\omega)e^{j \\omega i}d\\omega,,~ i \\in \\mathbb{Z} \\right\\}\\)\n\\(\\quad\\overset{DTFT}{\\Longleftrightarrow}\\)\n\\(\\left\\{\\hat x(\\omega): 2\\pi\\sum_{k=-\\infty}^{\\infty}\\left[\\frac{1}{\\xi}\\sum_{i=0}^{\\xi-1} x_i e^{-j\\frac{2\\pi k}{\\xi}i}\\right]\\delta\\left(\\omega-\\frac{2\\pi k}{\\xi}\\right),~ k \\in \\mathbb{Z} \\right\\}\\)\n- 주목할것은 주기가 \\(\\zeta\\) 혹은 \\(\\xi\\) 인 함수의 주파수 응답은 오로지\n\n\\(\\omega \\in \\left\\{\\frac{2 \\pi k}{\\zeta}, k \\in \\mathbb{Z}\\right\\}\\)\n\n혹은\n\n\\(\\omega \\in \\left\\{\\frac{2 \\pi k}{\\xi}, k \\in \\mathbb{Z}\\right\\}\\)\n\n에서만 존재한다는 점이다. 또한 이산신호의 경우 \\(x_i\\)의 주기가 \\(\\xi\\) 이면 \\(\\hat{x}(\\omega)\\)의 주기역시 \\(\\xi\\) 라는점 역시 주목할만한 부분이다.\n- 주파수영역에서 디스크릿한 함수를 연속인것처럼 표현했듯이 시간영역에서 디스크릿한 함수 역시 연속인것처럼 표현할 수 있다. 예를들면 \\(\\{x_i: x_i=x(iT),~i \\in \\mathbb{Z}\\}\\) 와 같은 관계가 있는 경우 아래와 같이 표현 가능하다.\n\\[x_{\\delta}(t)=\\sum_{i=-\\infty}^{\\infty}x_i\\delta(t-iT).\\]\n이거 엄청 중요하다.\n[1] 나도 그렇다.\n[2] 사실 나도 잘 모름 (뭐 quotient group이런거 알아야 하는데 공부하려면 꽤 걸릴듯)"
  },
  {
    "objectID": "공부/2022-11-29-(공부) 코드 -- 파이토치 라이트닝 선형회귀.html",
    "href": "공부/2022-11-29-(공부) 코드 -- 파이토치 라이트닝 선형회귀.html",
    "title": "(공부) 파이토치 라이트닝 선형회귀",
    "section": "",
    "text": "import torch\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport pytorch_lightning as pl \n\nModuleNotFoundError: No module named 'pytorch_lightning'\n\n\n\nref\nref: https://guebin.github.io/DL2022/posts/II.%20DNN/2022-09-20-3wk-2.html\n\n\nRegression 1: CPU\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2022/main/posts/II.%20DNN/2022-09-22-regression.csv\")\n\n\nx= torch.tensor(df.x).reshape(-1,1).float()\ny= torch.tensor(df.y).reshape(-1,1).float()\n\n\nds = torch.utils.data.TensorDataset(x,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=100)\n\n\nclass NetLO(pl.LightningModule):\n    def __init__(self):\n        super().__init__()\n        self.linr = torch.nn.Linear(1,1)\n        self.loss_fn = torch.nn.MSELoss()\n    def forward(self,x):\n        yhat = self.linr(x)\n        return yhat\n    def configure_optimizers(self):\n        optimizr = torch.optim.SGD(self.parameters(), lr=0.1)\n        return optimizr \n    def training_step(self,batch,batch_idx):\n        x,y = batch\n        yhat = self(x)\n        loss = self.loss_fn(yhat,y) \n        return loss \n\n\nnet = NetLO()\n\n\ntrnr = pl.Trainer(max_epochs=1)\n\nGPU available: True (cuda), used: False\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1767: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n  category=PossibleUserWarning,\n\n\n\nnet.linr.bias.data = torch.tensor([-5.0])\nnet.linr.weight.data = torch.tensor([[10.0]])\n\n\ntrnr.fit(net, train_dataloaders=dl) \n\n\n  | Name    | Type    | Params\n------------------------------------\n0 | linr    | Linear  | 2     \n1 | loss_fn | MSELoss | 0     \n------------------------------------\n2         Trainable params\n0         Non-trainable params\n2         Total params\n0.000     Total estimated model params size (MB)\n`Trainer.fit` stopped: `max_epochs=1` reached.\n\n\n\n\n\n\nnet.linr.weight, net.linr.bias\n\n(Parameter containing:\n tensor([[8.8111]], requires_grad=True),\n Parameter containing:\n tensor([-3.6577], requires_grad=True))\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n\n\n\n\nRegression 2: GPU\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2022/main/posts/II.%20DNN/2022-09-22-regression.csv\")\n\n\nx= torch.tensor(df.x).reshape(-1,1).float()\ny= torch.tensor(df.y).reshape(-1,1).float()\n\n\nds = torch.utils.data.TensorDataset(x,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=100)\n\n\nclass NetLO(pl.LightningModule):\n    def __init__(self):\n        super().__init__()\n        self.linr = torch.nn.Linear(1,1)\n        self.loss_fn = torch.nn.MSELoss()\n    def forward(self,x):\n        yhat = self.linr(x)\n        return yhat\n    def configure_optimizers(self):\n        optimizr = torch.optim.SGD(self.parameters(), lr=0.1)\n        return optimizr \n    def training_step(self,batch,batch_idx):\n        x,y = batch\n        yhat = self(x)\n        loss = self.loss_fn(yhat,y) \n        return loss \n\n\nnet = NetLO()\n\n\ntrnr = pl.Trainer(max_epochs=1, accelerator='gpu', devices=1)\n\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\n\n\n\nnet.linr.bias.data = torch.tensor([-5.0])\nnet.linr.weight.data = torch.tensor([[10.0]])\n\n\ntrnr.fit(net, train_dataloaders=dl) \n\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\n  | Name    | Type    | Params\n------------------------------------\n0 | linr    | Linear  | 2     \n1 | loss_fn | MSELoss | 0     \n------------------------------------\n2         Trainable params\n0         Non-trainable params\n2         Total params\n0.000     Total estimated model params size (MB)\n`Trainer.fit` stopped: `max_epochs=1` reached.\n\n\n\n\n\n\nnet.linr.weight, net.linr.bias\n\n(Parameter containing:\n tensor([[8.8111]], requires_grad=True),\n Parameter containing:\n tensor([-3.6577], requires_grad=True))\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')"
  },
  {
    "objectID": "공부/PyG/ls4.html",
    "href": "공부/PyG/ls4.html",
    "title": "(공부) PyG – lesson4: Data Transform???",
    "section": "",
    "text": "Download notebook\n!wget https://raw.githubusercontent.com/miruetoto/yechan3/main/posts/2_Studies/PyG/ls4.ipynb\n\n\nRef\n\nhttps://pytorch-geometric.readthedocs.io/en/latest/get_started/introduction.html\n\n\n\n데이터 변환\n\nfrom torch_geometric.datasets import ShapeNet\n\ndataset = ShapeNet(root='/tmp/ShapeNet', categories=['Airplane'])\n\ndataset[0]\n\nData(x=[2518, 3], y=[2518], pos=[2518, 3], category=[1])\n\n\n\nimport torch_geometric.transforms as T\nfrom torch_geometric.datasets import ShapeNet\n\ndataset = ShapeNet(root='/tmp/ShapeNet', categories=['Airplane'],\n                    pre_transform=T.KNNGraph(k=6))\n\ndataset[0]\n\n/home/cgb2/anaconda3/envs/pyg/lib/python3.10/site-packages/torch_geometric/data/dataset.py:209: UserWarning: The `pre_transform` argument differs from the one used in the pre-processed version of this dataset. If you want to make use of another pre-processing technique, make sure to delete '/tmp/ShapeNet/processed' first\n  warnings.warn(\n\n\nData(x=[2518, 3], y=[2518], pos=[2518, 3], category=[1])\n\n\n\nimport torch_geometric.transforms as T\nfrom torch_geometric.datasets import ShapeNet\n\ndataset = ShapeNet(root='/tmp/ShapeNet', categories=['Airplane'],\n                    pre_transform=T.KNNGraph(k=6),\n                    transform=T.RandomJitter(0.01))\n\ndataset[0]\n\nData(x=[2518, 3], y=[2518], pos=[2518, 3], category=[1])"
  },
  {
    "objectID": "공부/PyG/ls1.html",
    "href": "공부/PyG/ls1.html",
    "title": "(공부) PyG – lesson1: 자료형",
    "section": "",
    "text": "import torch\nimport torch_geometric"
  },
  {
    "objectID": "공부/PyG/ls1.html#예제1-아래와-같은-그래프자료를-고려하자.",
    "href": "공부/PyG/ls1.html#예제1-아래와-같은-그래프자료를-고려하자.",
    "title": "(공부) PyG – lesson1: 자료형",
    "section": "예제1: 아래와 같은 그래프자료를 고려하자.",
    "text": "예제1: 아래와 같은 그래프자료를 고려하자.\n\n- 이러한 자료형은 아래와 같은 형식으로 저장한다.\n\nedge_index = torch.tensor([[0, 1, 1, 2],\n                           [1, 0, 2, 1]], dtype=torch.long)\nx = torch.tensor([[-1], [0], [1]], dtype=torch.float)\ndata = torch_geometric.data.Data(x=x, edge_index=edge_index) # torch_geometric.data.Data는 그래프자료형을 만드는 클래스\n\n- data 의 자료형\n\ntype(data)\n\ntorch_geometric.data.data.Data\n\n\n- data의 __str__\n\ndata\n\nData(x=[3, 1], edge_index=[2, 4])\n\n\n\nx=[3, 1]: 이 자료는 3개의 노드가 있으며, 각 노드에는 1개의 feature가 있음\nedge_index=[2, 4]: \\({\\cal E}\\)는 총 4개의 원소가 있음.\n\n- 각 노드의 feature를 확인하는 방법 (즉 \\(f:{\\cal V} \\to \\mathbb{R}^k\\)를 확인하는 방법)\n\ndata.x\n\ntensor([[-1.],\n        [ 0.],\n        [ 1.]])\n\n\n- \\({\\cal E}\\)를 확인하는 방법\n\ndata.edge_index\n\ntensor([[0, 1, 1, 2],\n        [1, 0, 2, 1]])\n\n\n-\n\nlen(data)\n\n2"
  },
  {
    "objectID": "공부/PyG/ls1.html#예제2-잘못된-사용",
    "href": "공부/PyG/ls1.html#예제2-잘못된-사용",
    "title": "(공부) PyG – lesson1: 자료형",
    "section": "예제2: 잘못된 사용",
    "text": "예제2: 잘못된 사용\n- edge_index는 예제1과 같이 \\([2,|{\\cal E}|]\\) 의 shape으로 넣어야 한다. 그렇지 않으면 에러가 난다.\n\nedge_index = torch.tensor([[0, 1],\n                           [1, 0],\n                           [1, 2],\n                           [2, 1]], dtype=torch.long)\nx = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n\ndata = torch_geometric.data.Data(x=x, edge_index=edge_index)\n\n\n#data.validate(raise_on_error=True)\ndata.validate()\n\nValueError: 'edge_index' needs to be of shape [2, num_edges] in 'Data' (found torch.Size([4, 2]))"
  },
  {
    "objectID": "공부/PyG/ls1.html#예제3-예제2의-수정",
    "href": "공부/PyG/ls1.html#예제3-예제2의-수정",
    "title": "(공부) PyG – lesson1: 자료형",
    "section": "예제3: 예제2의 수정",
    "text": "예제3: 예제2의 수정\n- edge_index의 shape이 \\([|{\\cal E}|,2]\\) 꼴로 저장되어 있었을 경우 트랜스포즈이후 countiguous()함수를 사용하면 된다.1\n1 그런데 그냥 transpose만 해도되는것 같음\nedge_index = torch.tensor([[0, 1],\n                           [1, 0],\n                           [1, 2],\n                           [2, 1]], dtype=torch.long)\nx = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n\ndata = torch_geometric.data.Data(\n    x=x, \n    edge_index=edge_index.t().contiguous()\n)\n\n\n#data.validate(raise_on_error=True)\ndata.validate()\n\nTrue"
  },
  {
    "objectID": "공부/PyG/ls5.html",
    "href": "공부/PyG/ls5.html",
    "title": "(공부) PyG – lesson5: Learning Methods on Graphs",
    "section": "",
    "text": "Download notebook\n!wget https://raw.githubusercontent.com/miruetoto/yechan3/main/posts/2_Studies/PyG/ls5.ipynb\n\n\nRef\n\nhttps://pytorch-geometric.readthedocs.io/en/latest/get_started/introduction.html\n\n\n\ndata\n\nfrom torch_geometric.datasets import Planetoid\n\ndataset = Planetoid(root='/tmp/Cora', name='Cora')\n\n\ndataset[0]\n\nData(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n\n\n\ntype(dataset[0])\n\ntorch_geometric.data.data.Data\n\n\n\nimport torch_torch_geometric\n\n\ntorch_geometric.data.Data\n\nNameError: name 'torch_geometric' is not defined\n\n\n\ndataset[0].edge_index.shape\n\ntorch.Size([2, 10556])\n\n\n\ndataset[0].y.dtype\n\ntorch.int64\n\n\n\ndataset[0].train_mask\n\ntensor([ True,  True,  True,  ..., False, False, False])\n\n\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv\n\nclass GCN(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = GCNConv(dataset.num_node_features, 16)\n        self.conv2 = GCNConv(16, dataset.num_classes)\n\n    def forward(self, data):\n        x, edge_index = data.x, data.edge_index\n\n        x = self.conv1(x, edge_index)\n        x = F.relu(x)\n        x = F.dropout(x, training=self.training)\n        x = self.conv2(x, edge_index)\n\n        return F.log_softmax(x, dim=1)\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GCN().to(device)\ndata = dataset[0].to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n\nmodel.train()\nfor epoch in range(200):\n    optimizer.zero_grad()\n    out = model(data)\n    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask]) # train에 대한 loss만 따로 처리해야함\n    loss.backward()\n    optimizer.step()\n\n\nout.shape # 카테고리가 7개\n\ntorch.Size([2708, 7])\n\n\n\ndata.y.unique() # 카테고리가 7개\n\ntensor([0, 1, 2, 3, 4, 5, 6], device='cuda:0')\n\n\n\nmodel.eval()\npred = model(data).argmax(dim=1)\ncorrect = (pred[data.test_mask] == data.y[data.test_mask]).sum() # 애큐러시는 test\nacc = int(correct) / int(data.test_mask.sum())\nprint(f'Accuracy: {acc:.4f}')\n\nAccuracy: 0.8050\n\n\n\n\nFRAUD data에 활용?\n\n고객정보별로 그래프생성\n커다란 하나의 그래프 생성\n\n\n\nmodel 분석\n\nmodel\n\nGCN(\n  (conv1): GCNConv(1433, 16)\n  (conv2): GCNConv(16, 7)\n)\n\n\n\ndataset.data\n\nData(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n\n\n\n2708개의 노드가 있음 \\(\\to\\) 이걸 observation으로 해석해야함.\n각 노드에는 1433개의 특징(X)과 0-6까지의 label(y)이 연결되어 있음.\n2708개의 노드는 각각 tr,val,test로 나누어짐\n\n\nb,W = list(model.conv1.parameters())\n\n\nW,W.shape # 1433개의 특징을 16개로 줄임\n\n(Parameter containing:\n tensor([[ 0.0086, -0.0062, -0.1213,  ...,  0.1313, -0.0251,  0.0856],\n         [-0.0033, -0.0384, -0.1193,  ...,  0.0362, -0.1130,  0.0426],\n         [ 0.0118,  0.0722,  0.0481,  ..., -0.0677,  0.0497,  0.0095],\n         ...,\n         [ 0.0158,  0.1560, -0.0517,  ..., -0.0317,  0.1272,  0.0131],\n         [-0.0259,  0.0146, -0.0539,  ...,  0.0069, -0.0665,  0.0016],\n         [ 0.0191, -0.1023,  0.0411,  ..., -0.0415,  0.0125,  0.0015]],\n        device='cuda:0', requires_grad=True),\n torch.Size([16, 1433]))\n\n\n\nb,b.shape\n\n(Parameter containing:\n tensor([0.2343, 0.2136, 0.1581, 0.1914, 0.3095, 0.0851, 0.3675, 0.2414, 0.3099,\n         0.2571, 0.1340, 0.2693, 0.1588, 0.2984, 0.1877, 0.2014],\n        device='cuda:0', requires_grad=True),\n torch.Size([16]))\n\n\n\n\nGCNConv?? Kipf and Welling (2016)\n\nKipf, Thomas N, and Max Welling. 2016. “Semi-Supervised Classification with Graph Convolutional Networks.” arXiv Preprint arXiv:1609.02907.\n\nref: https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GCNConv.html\n\n아래의 논문에서 제안되었음.. (레퍼수가..)\nhttps://arxiv.org/abs/1609.02907\n대략적인 설명을 캡쳐하면 아래와 같음\n\n\n\nimage.png\n\n\n여기에서\n\n\\({\\bf A}\\)는 연결정보를 의미\n\\(\\hat{\\bf A}\\)는 연결정보에 자기자신의 노드를 추가\n\\({\\bf D}\\)는 \\({\\bf A}\\)를 표준화하기 위한 매트릭스\n결국 \\(\\hat{\\bf D}^{-1/2}\\hat{\\bf A}\\hat{\\bf D}^{-1/2}\\) 는 통째로 연결정보에 대한 matrix\n\\(\\hat{\\bf D}^{-1/2}\\hat{\\bf A}\\hat{\\bf D}^{-1/2}{\\bf X}\\) 는 통째로 \\({\\bf X}\\)를 평행이동한것을 의미 (혹은 그 비슷한 것을 의미)\n\\({\\bf \\Theta}\\)는 weight를 곱하는 과정임"
  },
  {
    "objectID": "공부/2024-08-20-(공부) xgboost 재현.html",
    "href": "공부/2024-08-20-(공부) xgboost 재현.html",
    "title": "(공부) xgboost 재현",
    "section": "",
    "text": "import xgboost as xgb\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport sklearn.tree\n#---#\nimport warnings\nwarnings.filterwarnings('ignore')\n#---#\nimport matplotlib.animation\nimport IPython"
  },
  {
    "objectID": "공부/2024-08-20-(공부) xgboost 재현.html#데이터",
    "href": "공부/2024-08-20-(공부) xgboost 재현.html#데이터",
    "title": "(공부) xgboost 재현",
    "section": "데이터",
    "text": "데이터\n\n# step1 \nX = df_train[['temp']]\nX = np.array(X).astype(np.float32)\ny = df_train['sales']\ny = np.array(y).astype(np.float32)"
  },
  {
    "objectID": "공부/2024-08-20-(공부) xgboost 재현.html#코드1",
    "href": "공부/2024-08-20-(공부) xgboost 재현.html#코드1",
    "title": "(공부) xgboost 재현",
    "section": "코드1",
    "text": "코드1\n\n## 코드1 \npredictr = xgb.XGBRegressor(\n    n_estimators=N,         # 부스팅 라운드 수\n    learning_rate=0.3,         # 학습률\n    max_depth=6,               # 최대 깊이\n    min_child_weight=1,        # 최소 자식 가중치\n    subsample=1.0,              # 데이터 샘플링 비율\n    tree_method='exact',\n    reg_lambda= 0.0\n)\npredictr.fit(X,y)\nyhat = predictr.predict(X)"
  },
  {
    "objectID": "공부/2024-08-20-(공부) xgboost 재현.html#코드2",
    "href": "공부/2024-08-20-(공부) xgboost 재현.html#코드2",
    "title": "(공부) xgboost 재현",
    "section": "코드2",
    "text": "코드2\n\n## 코드2 \nyhat2 = np.full(y.shape, np.mean(y), dtype=np.float32)\nnum_boosting_rounds = 100\nfor i in range(num_boosting_rounds):\n    residuals = y - yhat2\n    ## 코드1 \n    predictr = xgb.XGBRegressor(\n        n_estimators=1,         # 부스팅 라운드 수\n        learning_rate=0.3,         # 학습률\n        max_depth=6,               # 최대 깊이\n        min_child_weight=1,        # 최소 자식 가중치\n        subsample=1.0,              # 데이터 샘플링 비율\n        tree_method='exact',\n        reg_lambda= 0.0\n    )\n    predictr.fit(X,residuals)\n    new_pred = predictr.predict(X) \n    yhat2 += new_pred"
  },
  {
    "objectID": "공부/2024-08-20-(공부) xgboost 재현.html#비교",
    "href": "공부/2024-08-20-(공부) xgboost 재현.html#비교",
    "title": "(공부) xgboost 재현",
    "section": "비교",
    "text": "비교\n\n## 코드1,2 비교\ndiff = ((yhat - yhat2) ** 2).sum()\nprint(diff)\n\n6.274422e-08"
  }
]